{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IDEAT: Vix takas? Joku momentum indikaattori? Sentimentti?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mqpPtrCOkXAO"
      },
      "id": "mqpPtrCOkXAO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model settings"
      ],
      "metadata": {
        "id": "k1mEzhhWXup6"
      },
      "id": "k1mEzhhWXup6"
    },
    {
      "cell_type": "code",
      "source": [
        "use_regime_split = False\n",
        "\n",
        "#Default modelsD\n",
        "RF = True # perus random forest\n",
        "RF2 = False\n",
        "GB = True # perus gradient boost\n",
        "Hybrid = False\n",
        "\n",
        "#Looping models\n",
        "RF_feature_seek = False # random forest all combinations\n",
        "seek_all = False\n",
        "gb_loop = False\n",
        "\n",
        "#DATA\n",
        "FF5 = True\n",
        "FF5_long = False\n",
        "MSCI = False\n",
        "\n",
        "RSI = True\n",
        "\n",
        "local = False #ajetaanko colab vai oma kone\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AF3FdwvaLPp"
      },
      "id": "-AF3FdwvaLPp",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify active model flags\n",
        "active_modes = [name for name, flag in zip(\n",
        "    ['RF', 'GB', 'RF_feature_seek', 'Hybrid', 'seek_all', 'gb_loop'],\n",
        "    [RF, GB, RF_feature_seek, Hybrid, seek_all, gb_loop]\n",
        ") if flag]\n",
        "\n",
        "if active_modes:\n",
        "    print(\"âœ… Active model modes:\", \", \".join(active_modes))\n",
        "else:\n",
        "    print(\"âš ï¸ No active model mode selected.\")\n",
        "\n",
        "# Check dataset toggles: exactly one must be True\n",
        "datasets = {\n",
        "    'FF5': FF5,\n",
        "    'FF5_long': FF5_long,\n",
        "    'MSCI': MSCI\n",
        "}\n",
        "active_datasets = [name for name, flag in datasets.items() if flag]\n",
        "\n",
        "if len(active_datasets) != 1:\n",
        "    raise ValueError(\"Error: Exactly one of [FF5, FF5_long, MSCI] must be True.\")\n",
        "else:\n",
        "    print(f\"ğŸ“Š Using dataset: {active_datasets[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ktRzXgrQHYX",
        "outputId": "cd5a45eb-8df8-4ca5-a1ff-188e1639fa8d"
      },
      "id": "7ktRzXgrQHYX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Active model modes: RF, GB\n",
            "ğŸ“Š Using dataset: FF5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4085d55c-e568-465c-9bcc-6013281c105d",
      "metadata": {
        "tags": [],
        "id": "4085d55c-e568-465c-9bcc-6013281c105d"
      },
      "outputs": [],
      "source": [
        "# # Import Required Libraries\n",
        "#\n",
        "# Import all necessary libraries for data manipulation, visualization,\n",
        "# machine learning, and regression analysis.\n",
        "\n",
        "# %%\n",
        "import os\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not local:\n",
        "\n",
        "  %cd /content\n",
        "  !rm -rf Gradu\n",
        "  !git clone https://github.com/Elkkujou/Gradu.git\n",
        "  %cd /content/Gradu\n",
        "  !ls\n",
        "  xls_file = pd.ExcelFile(\"/content/Gradu/THE_2ND_latest.xlsx\")\n",
        "\n",
        "else:\n",
        "\n",
        "\n",
        "\n",
        "    repo_url = \"https://github.com/Elkkujou/Gradu.git\"\n",
        "    repo_name = \"Gradu\"  # Name of the cloned folder\n",
        "\n",
        "    # Check if the directory already exists\n",
        "    if os.path.exists(repo_name):\n",
        "        print(f\"Folder '{repo_name}' already exists. Pulling latest changes...\")\n",
        "        # Change to the existing repo folder and pull the latest updates\n",
        "        subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True)\n",
        "    else:\n",
        "        print(f\"Cloning repository into '{repo_name}'...\")\n",
        "        subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "\n",
        "    # List contents of the cloned repository\n",
        "    subprocess.run([\"ls\", repo_name], check=True)\n",
        "    xls_file = pd.ExcelFile(\"Gradu/THE_2ND_latest.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "j2fmaZCMluYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550dbb18-fe2c-42c3-8e8a-28c31954a4dd"
      },
      "id": "j2fmaZCMluYf",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 1032, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1032 (delta 188), reused 127 (delta 127), pack-reused 818 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1032/1032), 235.73 MiB | 16.21 MiB/s, done.\n",
            "Resolving deltas: 100% (519/519), done.\n",
            "/content/Gradu\n",
            " chatti_RF.ipynb\t\t      regime_prediction_msci.ipynb\n",
            " data+regimes.xlsx\t\t      regime_pred.txt\n",
            " Fama_french_XGBOOST.ipynb\t      RF_Gradu.ipynb\n",
            "'Financial turbulence.ipynb'\t      RF_REGIIMI_HYVAÌˆ_TRAINING.ipynb\n",
            " FT_source.xlsx\t\t\t     'RF_REGIIMI_HYVÃ„_TRAINING (MSCI).ipynb'\n",
            " Gradient_boost_malli.ipynb\t     'RF_regime (3).ipynb'\n",
            " MSCI_XGBOOST.ipynb\t\t      THE_2ND_latest.xlsx\n",
            " Regiimi_prediction.ipynb\t      THE_2ND.xlsx\n",
            " regime_prediction_famafrench.ipynb   THE_ONE.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if FF5:\n",
        "  SHEET_NAME = \"ajodata_FF5\"\n",
        "  FEATURES = ['CPI%','T10Y3', 'CFNAI', 'GARCH_1M']\n",
        "  FACTORS = [\n",
        "    'SMB',\n",
        "    'HML',\n",
        "    'CMA',\n",
        "    'RMW',\n",
        "    #'RF'\n",
        "]\n",
        "  BENCHMARK = ['Mkt']\n",
        "  show_benchmark = False"
      ],
      "metadata": {
        "id": "R_dU9PNF-Puv"
      },
      "id": "R_dU9PNF-Puv",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if FF5_long:\n",
        "  SHEET_NAME = \"ajodata_FF5_long\"\n",
        "  FEATURES = ['CPI%','T10Y3', 'CFNAI', 'GARCH_1M']\n",
        "  FACTORS = [\n",
        "    'SMB',\n",
        "    'HML',\n",
        "    'CMA',\n",
        "    'RMW',\n",
        "    #'RF'\n",
        "]\n",
        "  BENCHMARK = ['Mkt']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "wJo52ErY-v0Q"
      },
      "id": "wJo52ErY-v0Q",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MSCI:\n",
        "  SHEET_NAME = \"ajodata_MSCI\"\n",
        "  FEATURES = ['CPI%','T10Y3', 'CFNAI', 'GARCH_1M']\n",
        "  FACTORS = [\n",
        "    'Size',\n",
        "    'value',\n",
        "    'Quality',\n",
        "    'min_vola']\n",
        "  BENCHMARK = ['Us_standard']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "AT6Cf_ge_ApN"
      },
      "id": "AT6Cf_ge_ApN",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare data"
      ],
      "metadata": {
        "id": "ZwuAM8venlx5"
      },
      "id": "ZwuAM8venlx5"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc",
      "metadata": {
        "tags": [],
        "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc",
        "outputId": "a97875d2-c2e3-40be-ccaa-c11680cd3063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers in the 'ajodata_FF5' sheet:\n",
            "Index(['Date', 'SMB', 'HML', 'RMW', 'CMA', 'Mkt', 'RF', 'Mkt-RF', 'GARCH_1M',\n",
            "       'CPI%', 'T10YFF', 'Amihud', 'LEI%', 'Cape', 'Cape %', 'GDP', 'TED',\n",
            "       'T10Y3', 'LEI', 'CFNAI', 'HV', 'VIX', 'EWMA', 'AvgShock', 'AR_Shock',\n",
            "       'RealizedVol', 'RelVol_12m', 'VolBucket', 'GARCH_1M_REL', 'EWMA_1M_REL',\n",
            "       'EWMA_0.94', 'BAA10Y'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table class=\"dataframe table table-striped\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>First observation date</td>\n",
              "      <td>1963-07-30 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Last observation date</td>\n",
              "      <td>2024-11-30 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Total number of observations</td>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = xls_file.parse(SHEET_NAME)\n",
        "df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "# Print headers dynamically\n",
        "print(f\"Headers in the '{SHEET_NAME}' sheet:\")\n",
        "print(df.columns)\n",
        "\n",
        "REGIMES_COLUMN = 'Predicted_reg'\n",
        "\n",
        "# Convert the leftmost column (assumed to be the date column) to datetime\n",
        "date_column = df.columns[0]\n",
        "df[date_column] = pd.to_datetime(df[date_column])\n",
        "\n",
        "# Retrieve first and last observation dates and count observations\n",
        "first_date = df[date_column].iloc[0]\n",
        "last_date = df[date_column].iloc[-1]\n",
        "n_observations = len(df)\n",
        "\n",
        "# Create a DataFrame with the information\n",
        "info_df = pd.DataFrame({\n",
        "    \"Description\": [\"First observation date\", \"Last observation date\", \"Total number of observations\"],\n",
        "    \"Value\": [first_date, last_date, n_observations]\n",
        "})\n",
        "\n",
        "# Display the results as a neat HTML table\n",
        "display(HTML(info_df.to_html(index=False, classes=\"table table-striped\", border=0)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RSI:\n",
        "\n",
        "  # --- Add lagged 12â€‘month moving average for each factor return ---\n",
        "  for f in FACTORS:\n",
        "      # shift by 1 so that MA at time t uses returns t-12â€¦t-1\n",
        "      df[f + '_MA12'] = (\n",
        "          df[f]\n",
        "          .shift(1)                          # drop â€œtodayâ€\n",
        "          .rolling(window=12, min_periods=12)\n",
        "          .mean()\n",
        "      )\n",
        "\n",
        "  # update your FEATURES list\n",
        "  FEATURES += [f + '_MA12' for f in FACTORS]\n",
        "\n",
        "  print(\"âœ¨ Added lagged 12â€‘month MA columns:\", [f + '_MA12' for f in FACTORS])\n",
        "  print(\"ğŸ§© New FEATURES list:\", FEATURES)"
      ],
      "metadata": {
        "id": "3bGFK-QXeeDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab97c6a-ef4d-4d18-96d4-01e4d50f63f2"
      },
      "id": "3bGFK-QXeeDR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ Added lagged 12â€‘month MA columns: ['SMB_MA12', 'HML_MA12', 'CMA_MA12', 'RMW_MA12']\n",
            "ğŸ§© New FEATURES list: ['CPI%', 'T10Y3', 'CFNAI', 'GARCH_1M', 'SMB_MA12', 'HML_MA12', 'CMA_MA12', 'RMW_MA12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Define Helper Functions ---\n",
        "def annualized_return(returns):\n",
        "    \"\"\"Compute the compounded annualized return (assuming monthly returns).\"\"\"\n",
        "    return np.prod(1 + returns)**(12 / len(returns)) - 1\n",
        "\n",
        "def compute_metrics(returns):\n",
        "    \"\"\"\n",
        "    Compute key metrics for a returns series:\n",
        "      - Annualized Return\n",
        "      - Annualized Volatility (assuming monthly returns)\n",
        "      - Total Cumulative Return\n",
        "    \"\"\"\n",
        "    cumulative_returns = (1 + returns).cumprod()\n",
        "    total_cum_return = cumulative_returns.iloc[-1] - 1\n",
        "    ann_ret = annualized_return(returns)\n",
        "    ann_vol = np.std(returns) * np.sqrt(12)\n",
        "    return ann_ret, ann_vol, total_cum_return\n",
        "\n",
        "# --- Compute Metrics for Benchmark and Each Factor ---\n",
        "metrics = []\n",
        "\n",
        "# Compute metrics for the benchmark.\n",
        "benchmark_returns = df[BENCHMARK[0]]\n",
        "bench_ann_ret, bench_ann_vol, bench_cum_return = compute_metrics(benchmark_returns)\n",
        "metrics.append({\n",
        "    \"Strategy\": \"Benchmark\",\n",
        "    \"Annualized Return\": f\"{bench_ann_ret*100:.2f}%\",\n",
        "    \"Annualized Volatility\": f\"{bench_ann_vol*100:.2f}%\",\n",
        "    \"Total Cumulative Return\": f\"{bench_cum_return*100:.2f}%\"\n",
        "})\n",
        "\n",
        "# Compute metrics for each factor in FACTORS.\n",
        "for factor in FACTORS:\n",
        "    factor_returns = df[factor]\n",
        "    factor_ann_ret, factor_ann_vol, factor_cum_return = compute_metrics(factor_returns)\n",
        "    metrics.append({\n",
        "        \"Strategy\": factor,\n",
        "        \"Annualized Return\": f\"{factor_ann_ret*100:.2f}%\",\n",
        "        \"Annualized Volatility\": f\"{factor_ann_vol*100:.2f}%\",\n",
        "        \"Total Cumulative Return\": f\"{factor_cum_return*100:.2f}%\"\n",
        "    })\n",
        "\n",
        "# Create a DataFrame from the metrics.\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# --- Display the Results as an HTML Table ---\n",
        "display(HTML(metrics_df.to_html(index=False)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "phBSNpYXviHe",
        "outputId": "25398bc0-131d-4e3e-deb9-204da34d54e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "id": "phBSNpYXviHe",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Strategy</th>\n",
              "      <th>Annualized Return</th>\n",
              "      <th>Annualized Volatility</th>\n",
              "      <th>Total Cumulative Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Benchmark</td>\n",
              "      <td>10.71%</td>\n",
              "      <td>15.46%</td>\n",
              "      <td>51691.71%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SMB</td>\n",
              "      <td>1.89%</td>\n",
              "      <td>10.55%</td>\n",
              "      <td>216.75%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>HML</td>\n",
              "      <td>2.88%</td>\n",
              "      <td>10.37%</td>\n",
              "      <td>473.19%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>CMA</td>\n",
              "      <td>2.88%</td>\n",
              "      <td>7.18%</td>\n",
              "      <td>472.94%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RMW</td>\n",
              "      <td>3.14%</td>\n",
              "      <td>7.67%</td>\n",
              "      <td>568.93%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6",
      "metadata": {
        "tags": [],
        "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6",
        "outputId": "9e9971e2-32b0-4eaa-a1f3-ca9275e26df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows before cleaning: 737\n",
            "\n",
            "Missing values in FEATURES before cleaning:\n",
            "CPI%         0\n",
            "T10Y3        0\n",
            "CFNAI       45\n",
            "GARCH_1M     0\n",
            "SMB_MA12    12\n",
            "HML_MA12    12\n",
            "CMA_MA12    12\n",
            "RMW_MA12    12\n",
            "dtype: int64\n",
            "\n",
            "Dropped 45 rows due to missing FEATURES.\n",
            "\n",
            "Missing values in FEATURES after cleaning:\n",
            "CPI%        0\n",
            "T10Y3       0\n",
            "CFNAI       0\n",
            "GARCH_1M    0\n",
            "SMB_MA12    0\n",
            "HML_MA12    0\n",
            "CMA_MA12    0\n",
            "RMW_MA12    0\n",
            "dtype: int64\n",
            "\n",
            "Final dataset now has 692 rows.\n",
            "Target value counts:\n",
            "Winning Factor\n",
            "SMB    210\n",
            "RMW    209\n",
            "HML    164\n",
            "CMA    109\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Toggle for dropping rows with missing values in the FEATURES columns.\n",
        "drop_empty = True\n",
        "\n",
        "# 1) Print the initial number of rows.\n",
        "initial_rows = len(df)\n",
        "print(f\"Total number of rows before cleaning: {initial_rows}\")\n",
        "\n",
        "# 2) Show missingâ€value counts in FEATURES.\n",
        "missing_counts = df[FEATURES].isna().sum()\n",
        "print(\"\\nMissing values in FEATURES before cleaning:\")\n",
        "print(missing_counts)\n",
        "\n",
        "# 3) Drop any rows with NA in FEATURES, if requested.\n",
        "if drop_empty:\n",
        "    before = len(df)\n",
        "    df.dropna(subset=FEATURES, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    dropped = before - len(df)\n",
        "    print(f\"\\nDropped {dropped} rows due to missing FEATURES.\")\n",
        "else:\n",
        "    print(\"\\nKeeping all rows, including those with missing FEATURES.\")\n",
        "\n",
        "# 4) Reâ€check that FEATURES are now complete:\n",
        "print(\"\\nMissing values in FEATURES after cleaning:\")\n",
        "print(df[FEATURES].isna().sum())\n",
        "\n",
        "# 5) Compute your target column inâ€place.\n",
        "df['Winning Factor'] = df[FACTORS].idxmax(axis=1).astype('category')\n",
        "\n",
        "# 6) (Optionally) create a numeric code column\n",
        "df['Winning Factor Code'] = df['Winning Factor'].cat.codes\n",
        "\n",
        "# 7) Quick summary:\n",
        "print(f\"\\nFinal dataset now has {len(df)} rows.\")\n",
        "print(\"Target value counts:\")\n",
        "print(df['Winning Factor'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_regime_split:\n",
        "\n",
        "    # --- Regime Mapping & Conversion to Numeric Codes (Dynamic) ---\n",
        "\n",
        "    # Dynamically extract the unique values in the REGIMES_COLUMN.\n",
        "    unique_regimes = df[REGIMES_COLUMN].unique()\n",
        "\n",
        "    # Convert the Regimes column to a categorical type with the unique values, ordered alphabetically.\n",
        "    df[REGIMES_COLUMN] = pd.Categorical(df[REGIMES_COLUMN], categories=sorted(unique_regimes), ordered=True)\n",
        "\n",
        "    # Create a dictionary mapping numeric codes to the regime names based on the unique values.\n",
        "    regime_mapping = {i: cat for i, cat in enumerate(df[REGIMES_COLUMN].cat.categories)}\n",
        "\n",
        "    # Now encode the Regimes column as numeric codes.\n",
        "    df[REGIMES_COLUMN] = df[REGIMES_COLUMN].cat.codes\n",
        "\n",
        "    # Create a mapping from numeric codes to original regime names.\n",
        "    regime_short_mapping = {code: name for code, name in regime_mapping.items()}\n",
        "\n",
        "    # Calculate the number of observations for each regime using value_counts (without reindexing).\n",
        "    obs_counts = df[REGIMES_COLUMN].value_counts(sort=False)\n",
        "\n",
        "    # Create a DataFrame preview of the regime mapping, including observation counts.\n",
        "    mapping_table_data = []\n",
        "    for code in regime_mapping.keys():\n",
        "        mapping_table_data.append({\n",
        "            \"Numeric Code\": code,\n",
        "            \"Original Name\": regime_mapping.get(code, \"N/A\"),\n",
        "            \"Observations\": obs_counts.get(code, 0)\n",
        "        })\n",
        "\n",
        "    # Append a row with the total observations.\n",
        "    total_obs = obs_counts.sum()\n",
        "    mapping_table_data.append({\n",
        "        \"Numeric Code\": \"\",\n",
        "        \"Original Name\": \"Total\",\n",
        "        \"Observations\": total_obs\n",
        "    })\n",
        "\n",
        "    # Create the DataFrame for regime mapping preview and print.\n",
        "    regime_mapping_df = pd.DataFrame(mapping_table_data)\n",
        "\n",
        "    from tabulate import tabulate\n",
        "    print(\"Preview of Dynamic Regime Mapping:\")\n",
        "    print(tabulate(regime_mapping_df, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n"
      ],
      "metadata": {
        "id": "wYgvlvGRUUG4"
      },
      "id": "wYgvlvGRUUG4",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "0wYzowb5Xdau"
      },
      "id": "0wYzowb5Xdau"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature seek"
      ],
      "metadata": {
        "id": "KkFWbyO6XlRZ"
      },
      "id": "KkFWbyO6XlRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF_feature_seek:\n",
        "    import itertools\n",
        "    import os\n",
        "    import time\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    # --------------------------\n",
        "    # Parameters for Feature & Training Window Search\n",
        "    # --------------------------\n",
        "    min_features = 2                  # minimum number of features in a subset\n",
        "    max_features = len(FEATURES)      # maximum number of features (or set to a smaller number if desired)\n",
        "\n",
        "    # Define fixed rolling window sizes (in years) to test (assuming monthly data)\n",
        "    training_window_years = [5, 10, 15, 20]\n",
        "\n",
        "    # Also run an expanding window experiment\n",
        "    run_expanding_window = True\n",
        "\n",
        "    # Independent variable: minimum number of observations required for making a prediction.\n",
        "    # This is now decoupled from the training window calculation.\n",
        "    min_obs_for_prediction = 60  # adjust this value as desired\n",
        "\n",
        "    output_filename = \"feature_subset_results.csv\"\n",
        "    if os.path.exists(output_filename):\n",
        "        os.remove(output_filename)\n",
        "\n",
        "    # Ensure the data is sorted by date.\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # --------------------------\n",
        "    # Outer Loop: Fixed Rolling Window Modes\n",
        "    # --------------------------\n",
        "    for years in training_window_years:\n",
        "        # Convert years to number of observations (assume 12 obs per year)\n",
        "        rolling_window_size = years * 12\n",
        "        # Ensure predictions start only after both the rolling window and the independent minimum are met.\n",
        "        start_index = max(min_obs_for_prediction, rolling_window_size)\n",
        "        print(f\"\\n--- Testing fixed rolling window of {years} years \"\n",
        "              f\"({rolling_window_size} observations, starting predictions at index {start_index}) ---\")\n",
        "        outer_start_time = time.time()\n",
        "\n",
        "        # Inner loop over feature subset sizes\n",
        "        for r in range(min_features, max_features + 1):\n",
        "            # Loop over all combinations of size r\n",
        "            for comb in itertools.combinations(FEATURES, r):\n",
        "                current_features = list(comb)\n",
        "                inner_start_time = time.time()\n",
        "                print(f\"\\nTesting feature combination: {current_features}\")\n",
        "                results = []\n",
        "\n",
        "                # Loop over test rows, starting when we have enough training data\n",
        "                for i in range(start_index, len(df_sorted)):\n",
        "                    test_row = df_sorted.iloc[i]\n",
        "                    Predicted_month = test_row['Date']\n",
        "\n",
        "                    # Build fixed rolling training window (most recent rolling_window_size observations)\n",
        "                    train_window = df_sorted.iloc[i - rolling_window_size : i].copy()\n",
        "\n",
        "                    # Ensure the last training observation is strictly before test row date\n",
        "                    last_train_date = train_window['Date'].iloc[-1]\n",
        "                    if (last_train_date.year == Predicted_month.year) and \\\n",
        "                       (last_train_date.month >= Predicted_month.month):\n",
        "                        continue\n",
        "\n",
        "                    # (Optional) Regime check if use_regime_split is True:\n",
        "                    if use_regime_split:\n",
        "                        regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "                        insufficient_regimes = regime_counts[regime_counts < min_obs_regime].index.tolist()\n",
        "                        if insufficient_regimes:\n",
        "                            continue\n",
        "                        current_regime = test_row[REGIMES_COLUMN]\n",
        "                        train_window = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "                        if len(train_window) < min_obs_regime:\n",
        "                            continue\n",
        "\n",
        "                    # Prepare training data for the current feature subset.\n",
        "                    X_train = train_window[list(current_features)].dropna()\n",
        "                    y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "                    if len(X_train) < 1:\n",
        "                        continue\n",
        "\n",
        "                    # Train the RandomForest model.\n",
        "                    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                    rf_model.fit(X_train, y_train)\n",
        "\n",
        "                    # Use the last row of the training window as test data.\n",
        "                    X_test = train_window[list(current_features)].iloc[[-1]].dropna()\n",
        "                    if X_test.empty:\n",
        "                        continue\n",
        "\n",
        "                    predicted_probabilities = rf_model.predict_proba(X_test)[0]\n",
        "                    predicted_winner = rf_model.classes_[predicted_probabilities.argmax()]\n",
        "\n",
        "                    # Map the predicted probabilities to the full set of FACTORS.\n",
        "                    full_probs = np.zeros(len(FACTORS))\n",
        "                    for cls, prob in zip(rf_model.classes_, predicted_probabilities):\n",
        "                        try:\n",
        "                            idx = FACTORS.index(cls)\n",
        "                            full_probs[idx] = prob\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                    allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "\n",
        "                    # months_ahead: how many months ahead the prediction is (optional usage)\n",
        "                    months_ahead = (\n",
        "                        (Predicted_month.year - last_train_date.year) * 12 +\n",
        "                        (Predicted_month.month - last_train_date.month)\n",
        "                    )\n",
        "\n",
        "                    # Collect feature levels for logging\n",
        "                    feature_levels = {\n",
        "                        f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in current_features\n",
        "                    }\n",
        "\n",
        "                    # Create a result row\n",
        "                    result = {\n",
        "                        \"TrainingWindowYears\": years,   # <--- Record the training window\n",
        "                        \"Features_used\": str(current_features),\n",
        "                        \"Predicted_month\": Predicted_month,\n",
        "                        \"Allocated_Return\": allocated_return,\n",
        "                        \"Predicted_Winner\": predicted_winner,\n",
        "                        \"Actual_Winner\": test_row['Winning Factor'],\n",
        "                        \"Prediction_Horizon_Months\": months_ahead,\n",
        "                        **feature_levels\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "                # End of inner test row loop for this feature combination.\n",
        "                if results:\n",
        "                    df_results_comb = pd.DataFrame(results)\n",
        "                    if not os.path.exists(output_filename):\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=True, index=False)\n",
        "                    else:\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=False, index=False)\n",
        "                    elapsed_inner = time.time() - inner_start_time\n",
        "                    minutes = int(elapsed_inner // 60)\n",
        "                    seconds = int(elapsed_inner % 60)\n",
        "                    print(f\"Results for combination {current_features} appended to CSV. \"\n",
        "                          f\"Time taken: {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "        elapsed_outer = time.time() - outer_start_time\n",
        "        minutes = int(elapsed_outer // 60)\n",
        "        seconds = int(elapsed_outer % 60)\n",
        "        print(f\"Completed fixed rolling window of {years} years in {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "    # --------------------------\n",
        "    # Expanding Window Mode\n",
        "    # --------------------------\n",
        "    if run_expanding_window:\n",
        "        print(\"\\n--- Testing Expanding Window Mode ---\")\n",
        "        outer_start_time = time.time()\n",
        "        for r in range(min_features, max_features + 1):\n",
        "            for comb in itertools.combinations(FEATURES, r):\n",
        "                current_features = list(comb)\n",
        "                inner_start_time = time.time()\n",
        "                print(f\"\\nTesting feature combination (expanding): {current_features}\")\n",
        "                results = []\n",
        "\n",
        "                # In expanding mode, the training window goes from the start until the test row.\n",
        "                # Start predictions only after the minimum observation threshold is met.\n",
        "                for i in range(min_obs_for_prediction, len(df_sorted)):\n",
        "                    test_row = df_sorted.iloc[i]\n",
        "                    Predicted_month = test_row['Date']\n",
        "                    train_window = df_sorted.iloc[:i].copy()\n",
        "                    if train_window.empty:\n",
        "                        continue\n",
        "\n",
        "                    last_train_date = train_window['Date'].iloc[-1]\n",
        "                    if (last_train_date.year == Predicted_month.year) and \\\n",
        "                       (last_train_date.month >= Predicted_month.month):\n",
        "                        continue\n",
        "\n",
        "                    X_train = train_window[list(current_features)].dropna()\n",
        "                    y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "                    if len(X_train) < 1:\n",
        "                        continue\n",
        "\n",
        "                    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                    rf_model.fit(X_train, y_train)\n",
        "\n",
        "                    X_test = train_window[list(current_features)].iloc[[-1]].dropna()\n",
        "                    if X_test.empty:\n",
        "                        continue\n",
        "\n",
        "                    predicted_probabilities = rf_model.predict_proba(X_test)[0]\n",
        "                    predicted_winner = rf_model.classes_[predicted_probabilities.argmax()]\n",
        "\n",
        "                    full_probs = np.zeros(len(FACTORS))\n",
        "                    for cls, prob in zip(rf_model.classes_, predicted_probabilities):\n",
        "                        try:\n",
        "                            idx = FACTORS.index(cls)\n",
        "                            full_probs[idx] = prob\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                    allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "\n",
        "                    months_ahead = (\n",
        "                        (Predicted_month.year - last_train_date.year) * 12 +\n",
        "                        (Predicted_month.month - last_train_date.month)\n",
        "                    )\n",
        "\n",
        "                    feature_levels = {\n",
        "                        f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in current_features\n",
        "                    }\n",
        "\n",
        "                    result = {\n",
        "                        \"TrainingWindowYears\": \"expanding\",  # <--- Indicate expanding window\n",
        "                        \"Features_used\": str(current_features),\n",
        "                        \"Predicted_month\": Predicted_month,\n",
        "                        \"Allocated_Return\": allocated_return,\n",
        "                        \"Predicted_Winner\": predicted_winner,\n",
        "                        \"Actual_Winner\": test_row['Winning Factor'],\n",
        "                        \"Prediction_Horizon_Months\": months_ahead,\n",
        "                        **feature_levels\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "                if results:\n",
        "                    df_results_comb = pd.DataFrame(results)\n",
        "                    if not os.path.exists(output_filename):\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=True, index=False)\n",
        "                    else:\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=False, index=False)\n",
        "                    elapsed_inner = time.time() - inner_start_time\n",
        "                    minutes = int(elapsed_inner // 60)\n",
        "                    seconds = int(elapsed_inner % 60)\n",
        "                    print(f\"Expanding window: Results for combination {current_features} \"\n",
        "                          f\"appended to CSV. Time taken: {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "        elapsed_outer = time.time() - outer_start_time\n",
        "        minutes = int(elapsed_outer // 60)\n",
        "        seconds = int(elapsed_outer % 60)\n",
        "        print(f\"Completed Expanding Window Mode in {minutes:02d}:{seconds:02d}\")\n"
      ],
      "metadata": {
        "id": "kraj1YkNhEq4"
      },
      "id": "kraj1YkNhEq4",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Seek all"
      ],
      "metadata": {
        "id": "QkeGs9s9dExF"
      },
      "id": "QkeGs9s9dExF"
    },
    {
      "cell_type": "code",
      "source": [
        "if seek_all:\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import csv\n",
        "  import itertools\n",
        "  import time\n",
        "  import math\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # Assumes `df` (with 'Date' & 'Winning Factor'),\n",
        "  # `FACTORS` (list of all factor names) and\n",
        "  # `FEATURES` (base feature list) are defined above\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # Toggle featureâ€‘looping on/off\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  loop_features = False   # False â‡’ single run on FEATURES; True â‡’ sweep always+optional\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 1) Define alwaysâ€‘on & optional features\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  always_features = [\n",
        "      \"CMA_MA12\", \"SMB_MA12\", \"RMW_MA12\", \"HML_MA12\",\n",
        "      \"CPI%\"\n",
        "  ]\n",
        "  optional_features = [\n",
        "      \"LEI%\", \"Cape\", \"Cape %\", \"TED\",\n",
        "      \"T10Y3\", \"LEI\", \"AR_Shock\", \"HV\",\n",
        "      \"EWMA_0.94\", \"T10YFF\", \"CFNAI\", \"GARCH_1M\", \"VIX\",\"BAA10Y\"\n",
        "  ]\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 1a) Control how many optional features per combo\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  min_optional = 1   # minimum number of optional features in each combo\n",
        "  max_optional = 5   # maximum number of optional features in each combo\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 2) Build feature_combinations (with new constraints)\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  volatility_features = {\"GARCH_1M\", \"VIX\", \"AR_Shock\", \"HV\", \"EWMA_0.94\"}\n",
        "  lei_group          = {\"LEI\", \"LEI%\", \"CFNAI\"}\n",
        "  cape_group         = {\"Cape\", \"Cape %\"}\n",
        "\n",
        "  if loop_features:\n",
        "      def valid_combo(combo):\n",
        "          combo = set(combo)\n",
        "          # 1) at most 2 volatility measures\n",
        "          if len(combo & volatility_features) > 2:\n",
        "              return False\n",
        "          # 2) T10Y3 and T10YFF cannot coâ€‘exist\n",
        "          if {\"T10Y3\", \"T10YFF\"} <= combo:\n",
        "              return False\n",
        "          # 3) only one of LEI, LEI%, CFNAI\n",
        "          if len(combo & lei_group) > 1:\n",
        "              return False\n",
        "          # 4) only one of Cape, Cape %\n",
        "          if len(combo & cape_group) > 1:\n",
        "              return False\n",
        "          return True\n",
        "\n",
        "      feature_combinations = [\n",
        "          always_features + list(combo)\n",
        "          for r in range(min_optional, max_optional + 1)\n",
        "          for combo in itertools.combinations(optional_features, r)\n",
        "          if valid_combo(combo)\n",
        "      ]\n",
        "  else:\n",
        "      feature_combinations = [FEATURES]\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 3) RF hyperparameter template (excluding max_features)\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  param_grid_template = {\n",
        "      'n_estimators':      [100, 300, 500],\n",
        "      'max_depth':         [None, 7, 10, 15],\n",
        "      'min_samples_split': [2, 4, 6],\n",
        "      'min_samples_leaf':  [1, 3, 5, 7],\n",
        "      'bootstrap':         [False, True],\n",
        "      'n_jobs':            [-1]\n",
        "  }\n",
        "  base_param_list = list(ParameterGrid(param_grid_template))\n",
        "\n",
        "  # compute total iterations for progress display\n",
        "  total_iterations = sum(\n",
        "      len(base_param_list) * len(range(2, len(feat_set) + 1, 2))\n",
        "      for feat_set in feature_combinations\n",
        "  )\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 4) CSV logging setup\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  csv_file = 'rf_feature_search.csv'\n",
        "  fieldnames = [\n",
        "      'Iteration','Training_Window','Features','Hyperparameters',\n",
        "      'Num_Preds','First_Pred','Last_Pred',\n",
        "      'CumAlloc_Post2000','CumEqual_Post2000',\n",
        "      'CumAlloc_Total','CumEqual_Total',\n",
        "      'Sharpe_Post2000','Win_Count_Post2000'\n",
        "  ]\n",
        "  with open(csv_file, 'w', newline='') as f:\n",
        "      writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=';')\n",
        "      writer.writeheader()\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 5) Rollingâ€‘window & data settings\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  rolling_window_size = 60   # months in each fixed window\n",
        "  min_months_train    = 60   # minimum months of history required\n",
        "  min_obs_train       = 0    # minimum non-missing rows in X_train\n",
        "  use_fixed_window    = True # True: fixed-length rolling window; False: expanding window\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 6) Loop over feature sets & hyperparameters\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  iteration = 0\n",
        "  summary_records = []\n",
        "\n",
        "  for feat_set in feature_combinations:\n",
        "      n_feats = len(feat_set)\n",
        "      # for n_feats = 8, this gives [2, 4, 6, 8]\n",
        "      max_features_opts = list(range(2, n_feats + 1, 2))\n",
        "\n",
        "      # inject max_features into each base parameter combination\n",
        "      param_list = [\n",
        "          {**p, 'max_features': mf}\n",
        "          for p in base_param_list\n",
        "          for mf in max_features_opts\n",
        "      ]\n",
        "\n",
        "      for rf_params in param_list:\n",
        "          iteration += 1\n",
        "          start_time = time.perf_counter()\n",
        "\n",
        "          # --- print at start ---\n",
        "          print(f\"\\n=== Iteration {iteration}/{total_iterations} ===\")\n",
        "          if loop_features:\n",
        "              print(f\"Alwaysâ€‘on features ({len(always_features)}): {always_features}\")\n",
        "              print(f\"Optional count range: {min_optional}â€“{max_optional}\")\n",
        "          print(f\"Using features ({n_feats}): {feat_set}\")\n",
        "          print(f\"RF hyperparameters: {rf_params}\")\n",
        "\n",
        "          # drop rows with missing values in this feature set only\n",
        "          df_iter = df.dropna(subset=feat_set).copy()\n",
        "          df_sorted = df_iter.sort_values('Date').reset_index(drop=True)\n",
        "          results = []\n",
        "\n",
        "          # perâ€‘row prediction loop\n",
        "          for i in range(1, len(df_sorted)):\n",
        "              test_row = df_sorted.iloc[i]\n",
        "\n",
        "              # build training window from prior rows\n",
        "              if use_fixed_window:\n",
        "                  start_idx    = max(0, i - rolling_window_size)\n",
        "                  train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "              else:\n",
        "                  train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "              if len(train_window) < min_months_train:\n",
        "                  continue\n",
        "\n",
        "              # prepare training data\n",
        "              X_train = train_window[feat_set].dropna()\n",
        "              y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "              if len(X_train) < min_obs_train:\n",
        "                  continue\n",
        "\n",
        "              # fit RandomForest\n",
        "              rf = RandomForestClassifier(**rf_params, random_state=42)\n",
        "              rf.fit(X_train, y_train)\n",
        "\n",
        "              # predict on the last available row in train_window\n",
        "              X_test = train_window[feat_set].iloc[[-1]].dropna()\n",
        "              if X_test.empty:\n",
        "                  continue\n",
        "\n",
        "              probs      = rf.predict_proba(X_test)[0]\n",
        "              full_probs = np.zeros(len(FACTORS))\n",
        "              for cls, p in zip(rf.classes_, probs):\n",
        "                  full_probs[FACTORS.index(cls)] = p\n",
        "\n",
        "              alloc_ret = (full_probs * test_row[FACTORS].values).sum()\n",
        "              eq_ret    = test_row[FACTORS].mean()\n",
        "\n",
        "              results.append({\n",
        "                  'Date': test_row['Date'],\n",
        "                  'Allocated_Return': alloc_ret,\n",
        "                  'Equal_Weight_Return': eq_ret\n",
        "              })\n",
        "\n",
        "          # compute summary metrics\n",
        "          res_df = pd.DataFrame(results).sort_values('Date')\n",
        "          if res_df.empty:\n",
        "              summary = dict.fromkeys(fieldnames, np.nan)\n",
        "              summary.update({\n",
        "                  'Iteration': iteration,\n",
        "                  'Training_Window': rolling_window_size,\n",
        "                  'Features': \",\".join(feat_set),\n",
        "                  'Hyperparameters': \";\".join(f\"{k}={v}\" for k,v in rf_params.items()),\n",
        "                  'Num_Preds': 0\n",
        "              })\n",
        "          else:\n",
        "              post2k        = res_df[res_df['Date'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "              cum_alloc_2k  = (1 + post2k['Allocated_Return']).prod() - 1\n",
        "              cum_eq_2k     = (1 + post2k['Equal_Weight_Return']).prod()  - 1\n",
        "              cum_alloc_tot = (1 + res_df['Allocated_Return']).prod()     - 1\n",
        "              cum_eq_tot    = (1 + res_df['Equal_Weight_Return']).prod()  - 1\n",
        "\n",
        "              sharpe_2k = (post2k['Allocated_Return'].mean() /\n",
        "                          post2k['Allocated_Return'].std()) * np.sqrt(12)\n",
        "              win2k = (post2k['Allocated_Return'] > post2k['Equal_Weight_Return']).sum()\n",
        "\n",
        "              summary = {\n",
        "                  'Iteration': iteration,\n",
        "                  'Training_Window': rolling_window_size,\n",
        "                  'Features': \",\".join(feat_set),\n",
        "                  'Hyperparameters': \";\".join(f\"{k}={v}\" for k,v in rf_params.items()),\n",
        "                  'Num_Preds': len(res_df),\n",
        "                  'First_Pred': res_df['Date'].iloc[0].strftime(\"%Y-%m-%d\"),\n",
        "                  'Last_Pred':  res_df['Date'].iloc[-1].strftime(\"%Y-%m-%d\"),\n",
        "                  'CumAlloc_Post2000': cum_alloc_2k,\n",
        "                  'CumEqual_Post2000':  cum_eq_2k,\n",
        "                  'CumAlloc_Total':      cum_alloc_tot,\n",
        "                  'CumEqual_Total':       cum_eq_tot,\n",
        "                  'Sharpe_Post2000':     sharpe_2k,\n",
        "                  'Win_Count_Post2000':  win2k\n",
        "              }\n",
        "\n",
        "          # write one line to CSV\n",
        "          with open(csv_file, 'a', newline='') as f:\n",
        "              writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=';')\n",
        "              writer.writerow(summary)\n",
        "              f.flush()\n",
        "\n",
        "          # update running ranks & print end summary\n",
        "          summary_records.append(summary)\n",
        "          df_sum = pd.DataFrame(summary_records)\n",
        "          df_sum['Rank_CumAlloc_Post2000']   = df_sum['CumAlloc_Post2000'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_Sharpe_Post2000']     = df_sum['Sharpe_Post2000'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_CumAlloc_Total']      = df_sum['CumAlloc_Total'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_Win_Count_Post2000']  = df_sum['Win_Count_Post2000'].rank(ascending=False, method='min')\n",
        "\n",
        "          cur = df_sum.iloc[-1]\n",
        "          duration = time.perf_counter() - start_time\n",
        "\n",
        "          # print endâ€‘ofâ€‘iteration stats\n",
        "          print(f\"Completed iteration {iteration}/{total_iterations} in {duration:.1f}s\")\n",
        "          print(f\"  CumAlloc_Post2000: {cur['CumAlloc_Post2000']:.4f} (rank {int(cur['Rank_CumAlloc_Post2000'])}/{iteration})\")\n",
        "          print(f\"  Sharpe_Post2000:   {cur['Sharpe_Post2000']:.4f} (rank {int(cur['Rank_Sharpe_Post2000'])}/{iteration})\")\n",
        "          print(f\"  CumAlloc_Total:    {cur['CumAlloc_Total']:.4f} (rank {int(cur['Rank_CumAlloc_Total'])}/{iteration})\")\n",
        "          print(f\"  Win_Count_Post2000:{int(cur['Win_Count_Post2000'])} (rank {int(cur['Rank_Win_Count_Post2000'])}/{iteration})\")\n",
        "          print(f\"  EqualWeight_Post2000: {cur['CumEqual_Post2000']:.4f}\")\n",
        "          print(f\"  EqualWeight_Total:     {cur['CumEqual_Total']:.4f}\")\n"
      ],
      "metadata": {
        "id": "b_ac9qZ7ir9I"
      },
      "id": "b_ac9qZ7ir9I",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "MrSJ4xhmDuzE"
      },
      "id": "MrSJ4xhmDuzE"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -----------------------------------------------------------------------------\n",
        "    # Assumes these are already defined:\n",
        "    #   df, FEATURES, FACTORS, REGIMES_COLUMN, regime_short_mapping\n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    RF1_FEATURES = FEATURES\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train        = 60\n",
        "    min_obs_regime          = 50\n",
        "    min_obs_train           = 0\n",
        "    use_regime_split        = False\n",
        "    default_hyperparameters = False\n",
        "\n",
        "    use_fixed_window    = True\n",
        "    rolling_window_size = 60\n",
        "    n_jobs              = -1\n",
        "\n",
        "    # Toggle on/off heavy computations\n",
        "    compute_permutation_importance = False\n",
        "    compute_pdp                     = False\n",
        "    compute_shap                    = True  # â† collect SHAP data\n",
        "\n",
        "    if default_hyperparameters:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': 'sqrt',\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'bootstrap': True,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "    else:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': None,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 5,\n",
        "            'bootstrap': False,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "\n",
        "    # -------------------\n",
        "    # prepare PDP & SHAP storage if asked\n",
        "    # -------------------\n",
        "    if compute_pdp:\n",
        "        from sklearn.inspection import partial_dependence\n",
        "        pdp_data = {feat: [] for feat in RF1_FEATURES}\n",
        "\n",
        "    if compute_shap:\n",
        "        import shap\n",
        "        shap_data = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Sort data and init containers\n",
        "    # -------------------\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results   = []\n",
        "    rf_models = []\n",
        "\n",
        "    if compute_permutation_importance:\n",
        "        from sklearn.inspection import permutation_importance\n",
        "        perm_importances_list = []\n",
        "        months_list           = []\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Main Loop\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row        = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # build train window\n",
        "        if use_fixed_window:\n",
        "            start_idx    = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        if len(train_window) < min_months_train:\n",
        "            print(f\"{Predicted_month.date()}: only {len(train_window)} rows. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        train_start_date = train_window['Date'].iloc[0]\n",
        "        train_end_date   = train_window['Date'].iloc[-1]\n",
        "\n",
        "        # optional regimeâ€‘split\n",
        "        if use_regime_split:\n",
        "            counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "            bad    = counts[counts < min_obs_regime].index.tolist()\n",
        "            if bad:\n",
        "                print(f\"{Predicted_month.date()}: insufficient regimes {bad}. Skipping.\")\n",
        "                continue\n",
        "            current_regime = test_row[REGIMES_COLUMN]\n",
        "            train_window   = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "            if len(train_window) < min_obs_regime:\n",
        "                print(f\"{Predicted_month.date()}: regime {current_regime} has {len(train_window)} rows. Skipping.\")\n",
        "                continue\n",
        "            regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "        else:\n",
        "            regime_used = 'NoRegime'\n",
        "\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            print(f\"{Predicted_month.date()}: last train {last_train_date.date()} â‰¥ test. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        X_train = train_window[RF1_FEATURES].dropna()\n",
        "        y_train = train_window.loc[X_train.index, 'Winning Factor']\n",
        "        if len(X_train) < min_obs_train:\n",
        "            print(f\"{Predicted_month.date()}: {len(X_train)} < {min_obs_train} after NA drop. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # fit RF\n",
        "        rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        rf_models.append(rf_model)\n",
        "\n",
        "        # â”€â”€ collect PDP if toggled â”€â”€\n",
        "        if compute_pdp:\n",
        "            for feat in RF1_FEATURES:\n",
        "                pdp_res = partial_dependence(\n",
        "                    rf_model,\n",
        "                    X_train,\n",
        "                    features=[feat],\n",
        "                    grid_resolution=50,\n",
        "                    kind='average'\n",
        "                )\n",
        "                grid = pdp_res.get('values', pdp_res.get('grid_values'))[0]\n",
        "                avg  = pdp_res['average']  # shape = (n_factors, n_grid)\n",
        "                pdp_data[feat].append({\n",
        "                    'month':   Predicted_month,\n",
        "                    'values':  grid,\n",
        "                    'average': avg\n",
        "                })\n",
        "\n",
        "        # â”€â”€ collect SHAP if toggled â”€â”€\n",
        "        if compute_shap:\n",
        "            X_test = train_window[RF1_FEATURES].iloc[[-1]].dropna()\n",
        "            if not X_test.empty:\n",
        "                # try new shap.Explainer API\n",
        "                try:\n",
        "                    explainer = shap.Explainer(rf_model, X_train, feature_names=RF1_FEATURES)\n",
        "                    shap_exp  = explainer(X_test)\n",
        "                    vals      = shap_exp.values  # shape: (1, n_features, n_factors)\n",
        "                except Exception:\n",
        "                    # fallback to TreeExplainer\n",
        "                    explainer = shap.TreeExplainer(rf_model)\n",
        "                    sv_list   = explainer.shap_values(X_test)\n",
        "                    if isinstance(sv_list, list):\n",
        "                        vals = np.stack(sv_list, axis=-1)[0]  # (n_features, n_factors)\n",
        "                        vals = vals.T                          # â†’ (n_factors, n_features)\n",
        "                    else:\n",
        "                        vals = sv_list  # e.g. (1, n_features)\n",
        "                # normalize to (n_factors, n_features)\n",
        "                if vals.ndim == 3:\n",
        "                    shap_mat = vals[0].T\n",
        "                elif vals.ndim == 2 and vals.shape[0] == len(FEATURES):\n",
        "                    shap_mat = vals.T\n",
        "                elif vals.ndim == 2 and vals.shape[0] == 1:\n",
        "                    shap_mat = np.tile(vals, (len(FACTORS), 1))\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected SHAP shape {vals.shape}\")\n",
        "                shap_data.append({\n",
        "                    'month':        Predicted_month,\n",
        "                    'feature_vals': X_test.iloc[0].values,\n",
        "                    'shap_values':  shap_mat\n",
        "                })\n",
        "\n",
        "        # optional: compute permutation importance\n",
        "        if compute_permutation_importance:\n",
        "            pi = permutation_importance(\n",
        "                rf_model, X_train, y_train,\n",
        "                n_repeats=10, random_state=42, n_jobs=n_jobs\n",
        "            )\n",
        "            perm_importances_list.append(pi.importances_mean)\n",
        "            months_list.append(Predicted_month.strftime('%Y-%m-%d'))\n",
        "\n",
        "        # predict (unchanged)\n",
        "        X_test = train_window[RF1_FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            print(f\"{Predicted_month.date()}: empty test features. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        probs  = rf_model.predict_proba(X_test)[0]\n",
        "        winner = rf_model.classes_[probs.argmax()]\n",
        "\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for cls, p in zip(rf_model.classes_, probs):\n",
        "            try:\n",
        "                idx = FACTORS.index(cls)\n",
        "                full_probs[idx] = p\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "        allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = test_row[FACTORS].mean()\n",
        "\n",
        "        depths      = [e.tree_.max_depth for e in rf_model.estimators_]\n",
        "        avg_depth   = np.mean(depths)\n",
        "        max_depth   = np.max(depths)\n",
        "        months_ahead = ((Predicted_month.year - last_train_date.year)*12 +\n",
        "                        (Predicted_month.month - last_train_date.month))\n",
        "\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in RF1_FEATURES}\n",
        "\n",
        "        print(f\"{Predicted_month.date()}: trained {train_start_date.date()}â€“{train_end_date.date()} â†’ predicted\")\n",
        "\n",
        "        result = {\n",
        "            'Regime': regime_used,\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_start_date,\n",
        "            'Train_End_Date': train_end_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': rf_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': winner,\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': rf_model.n_estimators,\n",
        "            'Average_Tree_Depth': avg_depth,\n",
        "            'Max_Tree_Depth': max_depth,\n",
        "            'Prediction_Horizon_Months': months_ahead,\n",
        "            **feature_levels\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 4) Build results DataFrame\n",
        "    # -------------------\n",
        "    results_df_rf = pd.DataFrame(results)\n",
        "    print(\"Columns:\", results_df_rf.columns.tolist())\n",
        "    display(results_df_rf.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # 5) Cumulative Returns\n",
        "    # -------------------\n",
        "    filt = results_df_rf['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")\n",
        "    if filt.any():\n",
        "        cr_a = (1 + results_df_rf.loc[filt, 'Allocated_Return']).prod() - 1\n",
        "        cr_e = (1 + results_df_rf.loc[filt, 'Equal_Weight_Return']).prod() - 1\n",
        "        d0, d1 = results_df_rf.loc[filt, 'Predicted_month'].agg(['min','max'])\n",
        "        print(f\"\\nCumulative 2000-01-01â€“{d1.date()}: ML={cr_a:.4f}, EW={cr_e:.4f}\")\n",
        "    else:\n",
        "        print(\"No preds â‰¥ 2000-01-01\")\n",
        "\n",
        "    if not results_df_rf.empty:\n",
        "        cr_a = (1 + results_df_rf['Allocated_Return']).prod() - 1\n",
        "        cr_e = (1 + results_df_rf['Equal_Weight_Return']).prod() - 1\n",
        "        d0, d1 = results_df_rf['Predicted_month'].agg(['min','max'])\n",
        "        print(f\"\\nTotal {d0.date()}â€“{d1.date()}: ML={cr_a:.4f}, EW={cr_e:.4f}\")\n",
        "    else:\n",
        "        print(\"No predictions total.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aGwg80N9BmhI",
        "outputId": "f563c08f-0922-4021-d3c6-9ed5de1a9ea7"
      },
      "id": "aGwg80N9BmhI",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1967-05-30: only 1 rows. Skipping.\n",
            "1967-06-30: only 2 rows. Skipping.\n",
            "1967-07-30: only 3 rows. Skipping.\n",
            "1967-08-30: only 4 rows. Skipping.\n",
            "1967-09-30: only 5 rows. Skipping.\n",
            "1967-10-30: only 6 rows. Skipping.\n",
            "1967-11-30: only 7 rows. Skipping.\n",
            "1967-12-30: only 8 rows. Skipping.\n",
            "1968-01-30: only 9 rows. Skipping.\n",
            "1968-02-29: only 10 rows. Skipping.\n",
            "1968-03-30: only 11 rows. Skipping.\n",
            "1968-04-30: only 12 rows. Skipping.\n",
            "1968-05-30: only 13 rows. Skipping.\n",
            "1968-06-30: only 14 rows. Skipping.\n",
            "1968-07-30: only 15 rows. Skipping.\n",
            "1968-08-30: only 16 rows. Skipping.\n",
            "1968-09-30: only 17 rows. Skipping.\n",
            "1968-10-30: only 18 rows. Skipping.\n",
            "1968-11-30: only 19 rows. Skipping.\n",
            "1968-12-30: only 20 rows. Skipping.\n",
            "1969-01-30: only 21 rows. Skipping.\n",
            "1969-02-28: only 22 rows. Skipping.\n",
            "1969-03-30: only 23 rows. Skipping.\n",
            "1969-04-30: only 24 rows. Skipping.\n",
            "1969-05-30: only 25 rows. Skipping.\n",
            "1969-06-30: only 26 rows. Skipping.\n",
            "1969-07-30: only 27 rows. Skipping.\n",
            "1969-08-30: only 28 rows. Skipping.\n",
            "1969-09-30: only 29 rows. Skipping.\n",
            "1969-10-30: only 30 rows. Skipping.\n",
            "1969-11-30: only 31 rows. Skipping.\n",
            "1969-12-30: only 32 rows. Skipping.\n",
            "1970-01-30: only 33 rows. Skipping.\n",
            "1970-02-28: only 34 rows. Skipping.\n",
            "1970-03-30: only 35 rows. Skipping.\n",
            "1970-04-30: only 36 rows. Skipping.\n",
            "1970-05-30: only 37 rows. Skipping.\n",
            "1970-06-30: only 38 rows. Skipping.\n",
            "1970-07-30: only 39 rows. Skipping.\n",
            "1970-08-30: only 40 rows. Skipping.\n",
            "1970-09-30: only 41 rows. Skipping.\n",
            "1970-10-30: only 42 rows. Skipping.\n",
            "1970-11-30: only 43 rows. Skipping.\n",
            "1970-12-30: only 44 rows. Skipping.\n",
            "1971-01-30: only 45 rows. Skipping.\n",
            "1971-02-28: only 46 rows. Skipping.\n",
            "1971-03-30: only 47 rows. Skipping.\n",
            "1971-04-30: only 48 rows. Skipping.\n",
            "1971-05-30: only 49 rows. Skipping.\n",
            "1971-06-30: only 50 rows. Skipping.\n",
            "1971-07-30: only 51 rows. Skipping.\n",
            "1971-08-30: only 52 rows. Skipping.\n",
            "1971-09-30: only 53 rows. Skipping.\n",
            "1971-10-30: only 54 rows. Skipping.\n",
            "1971-11-30: only 55 rows. Skipping.\n",
            "1971-12-30: only 56 rows. Skipping.\n",
            "1972-01-30: only 57 rows. Skipping.\n",
            "1972-02-29: only 58 rows. Skipping.\n",
            "1972-03-30: only 59 rows. Skipping.\n",
            "1972-04-30: trained 1967-04-30â€“1972-03-30 â†’ predicted\n",
            "1972-05-30: trained 1967-05-30â€“1972-04-30 â†’ predicted\n",
            "1972-06-30: trained 1967-06-30â€“1972-05-30 â†’ predicted\n",
            "1972-07-30: trained 1967-07-30â€“1972-06-30 â†’ predicted\n",
            "1972-08-30: trained 1967-08-30â€“1972-07-30 â†’ predicted\n",
            "1972-09-30: trained 1967-09-30â€“1972-08-30 â†’ predicted\n",
            "1972-10-30: trained 1967-10-30â€“1972-09-30 â†’ predicted\n",
            "1972-11-30: trained 1967-11-30â€“1972-10-30 â†’ predicted\n",
            "1972-12-30: trained 1967-12-30â€“1972-11-30 â†’ predicted\n",
            "1973-01-30: trained 1968-01-30â€“1972-12-30 â†’ predicted\n",
            "1973-02-28: trained 1968-02-29â€“1973-01-30 â†’ predicted\n",
            "1973-03-30: trained 1968-03-30â€“1973-02-28 â†’ predicted\n",
            "1973-04-30: trained 1968-04-30â€“1973-03-30 â†’ predicted\n",
            "1973-05-30: trained 1968-05-30â€“1973-04-30 â†’ predicted\n",
            "1973-06-30: trained 1968-06-30â€“1973-05-30 â†’ predicted\n",
            "1973-07-30: trained 1968-07-30â€“1973-06-30 â†’ predicted\n",
            "1973-08-30: trained 1968-08-30â€“1973-07-30 â†’ predicted\n",
            "1973-09-30: trained 1968-09-30â€“1973-08-30 â†’ predicted\n",
            "1973-10-30: trained 1968-10-30â€“1973-09-30 â†’ predicted\n",
            "1973-11-30: trained 1968-11-30â€“1973-10-30 â†’ predicted\n",
            "1973-12-30: trained 1968-12-30â€“1973-11-30 â†’ predicted\n",
            "1974-01-30: trained 1969-01-30â€“1973-12-30 â†’ predicted\n",
            "1974-02-28: trained 1969-02-28â€“1974-01-30 â†’ predicted\n",
            "1974-03-30: trained 1969-03-30â€“1974-02-28 â†’ predicted\n",
            "1974-04-30: trained 1969-04-30â€“1974-03-30 â†’ predicted\n",
            "1974-05-30: trained 1969-05-30â€“1974-04-30 â†’ predicted\n",
            "1974-06-30: trained 1969-06-30â€“1974-05-30 â†’ predicted\n",
            "1974-07-30: trained 1969-07-30â€“1974-06-30 â†’ predicted\n",
            "1974-08-30: trained 1969-08-30â€“1974-07-30 â†’ predicted\n",
            "1974-09-30: trained 1969-09-30â€“1974-08-30 â†’ predicted\n",
            "1974-10-30: trained 1969-10-30â€“1974-09-30 â†’ predicted\n",
            "1974-11-30: trained 1969-11-30â€“1974-10-30 â†’ predicted\n",
            "1974-12-30: trained 1969-12-30â€“1974-11-30 â†’ predicted\n",
            "1975-01-30: trained 1970-01-30â€“1974-12-30 â†’ predicted\n",
            "1975-02-28: trained 1970-02-28â€“1975-01-30 â†’ predicted\n",
            "1975-03-30: trained 1970-03-30â€“1975-02-28 â†’ predicted\n",
            "1975-04-30: trained 1970-04-30â€“1975-03-30 â†’ predicted\n",
            "1975-05-30: trained 1970-05-30â€“1975-04-30 â†’ predicted\n",
            "1975-06-30: trained 1970-06-30â€“1975-05-30 â†’ predicted\n",
            "1975-07-30: trained 1970-07-30â€“1975-06-30 â†’ predicted\n",
            "1975-08-30: trained 1970-08-30â€“1975-07-30 â†’ predicted\n",
            "1975-09-30: trained 1970-09-30â€“1975-08-30 â†’ predicted\n",
            "1975-10-30: trained 1970-10-30â€“1975-09-30 â†’ predicted\n",
            "1975-11-30: trained 1970-11-30â€“1975-10-30 â†’ predicted\n",
            "1975-12-30: trained 1970-12-30â€“1975-11-30 â†’ predicted\n",
            "1976-01-30: trained 1971-01-30â€“1975-12-30 â†’ predicted\n",
            "1976-02-29: trained 1971-02-28â€“1976-01-30 â†’ predicted\n",
            "1976-03-30: trained 1971-03-30â€“1976-02-29 â†’ predicted\n",
            "1976-04-30: trained 1971-04-30â€“1976-03-30 â†’ predicted\n",
            "1976-05-30: trained 1971-05-30â€“1976-04-30 â†’ predicted\n",
            "1976-06-30: trained 1971-06-30â€“1976-05-30 â†’ predicted\n",
            "1976-07-30: trained 1971-07-30â€“1976-06-30 â†’ predicted\n",
            "1976-08-30: trained 1971-08-30â€“1976-07-30 â†’ predicted\n",
            "1976-09-30: trained 1971-09-30â€“1976-08-30 â†’ predicted\n",
            "1976-10-30: trained 1971-10-30â€“1976-09-30 â†’ predicted\n",
            "1976-11-30: trained 1971-11-30â€“1976-10-30 â†’ predicted\n",
            "1976-12-30: trained 1971-12-30â€“1976-11-30 â†’ predicted\n",
            "1977-01-30: trained 1972-01-30â€“1976-12-30 â†’ predicted\n",
            "1977-02-28: trained 1972-02-29â€“1977-01-30 â†’ predicted\n",
            "1977-03-30: trained 1972-03-30â€“1977-02-28 â†’ predicted\n",
            "1977-04-30: trained 1972-04-30â€“1977-03-30 â†’ predicted\n",
            "1977-05-30: trained 1972-05-30â€“1977-04-30 â†’ predicted\n",
            "1977-06-30: trained 1972-06-30â€“1977-05-30 â†’ predicted\n",
            "1977-07-30: trained 1972-07-30â€“1977-06-30 â†’ predicted\n",
            "1977-08-30: trained 1972-08-30â€“1977-07-30 â†’ predicted\n",
            "1977-09-30: trained 1972-09-30â€“1977-08-30 â†’ predicted\n",
            "1977-10-30: trained 1972-10-30â€“1977-09-30 â†’ predicted\n",
            "1977-11-30: trained 1972-11-30â€“1977-10-30 â†’ predicted\n",
            "1977-12-30: trained 1972-12-30â€“1977-11-30 â†’ predicted\n",
            "1978-01-30: trained 1973-01-30â€“1977-12-30 â†’ predicted\n",
            "1978-02-28: trained 1973-02-28â€“1978-01-30 â†’ predicted\n",
            "1978-03-30: trained 1973-03-30â€“1978-02-28 â†’ predicted\n",
            "1978-04-30: trained 1973-04-30â€“1978-03-30 â†’ predicted\n",
            "1978-05-30: trained 1973-05-30â€“1978-04-30 â†’ predicted\n",
            "1978-06-30: trained 1973-06-30â€“1978-05-30 â†’ predicted\n",
            "1978-07-30: trained 1973-07-30â€“1978-06-30 â†’ predicted\n",
            "1978-08-30: trained 1973-08-30â€“1978-07-30 â†’ predicted\n",
            "1978-09-30: trained 1973-09-30â€“1978-08-30 â†’ predicted\n",
            "1978-10-30: trained 1973-10-30â€“1978-09-30 â†’ predicted\n",
            "1978-11-30: trained 1973-11-30â€“1978-10-30 â†’ predicted\n",
            "1978-12-30: trained 1973-12-30â€“1978-11-30 â†’ predicted\n",
            "1979-01-30: trained 1974-01-30â€“1978-12-30 â†’ predicted\n",
            "1979-02-28: trained 1974-02-28â€“1979-01-30 â†’ predicted\n",
            "1979-03-30: trained 1974-03-30â€“1979-02-28 â†’ predicted\n",
            "1979-04-30: trained 1974-04-30â€“1979-03-30 â†’ predicted\n",
            "1979-05-30: trained 1974-05-30â€“1979-04-30 â†’ predicted\n",
            "1979-06-30: trained 1974-06-30â€“1979-05-30 â†’ predicted\n",
            "1979-07-30: trained 1974-07-30â€“1979-06-30 â†’ predicted\n",
            "1979-08-30: trained 1974-08-30â€“1979-07-30 â†’ predicted\n",
            "1979-09-30: trained 1974-09-30â€“1979-08-30 â†’ predicted\n",
            "1979-10-30: trained 1974-10-30â€“1979-09-30 â†’ predicted\n",
            "1979-11-30: trained 1974-11-30â€“1979-10-30 â†’ predicted\n",
            "1979-12-30: trained 1974-12-30â€“1979-11-30 â†’ predicted\n",
            "1980-01-30: trained 1975-01-30â€“1979-12-30 â†’ predicted\n",
            "1980-02-29: trained 1975-02-28â€“1980-01-30 â†’ predicted\n",
            "1980-03-30: trained 1975-03-30â€“1980-02-29 â†’ predicted\n",
            "1980-04-30: trained 1975-04-30â€“1980-03-30 â†’ predicted\n",
            "1980-05-30: trained 1975-05-30â€“1980-04-30 â†’ predicted\n",
            "1980-06-30: trained 1975-06-30â€“1980-05-30 â†’ predicted\n",
            "1980-07-30: trained 1975-07-30â€“1980-06-30 â†’ predicted\n",
            "1980-08-30: trained 1975-08-30â€“1980-07-30 â†’ predicted\n",
            "1980-09-30: trained 1975-09-30â€“1980-08-30 â†’ predicted\n",
            "1980-10-30: trained 1975-10-30â€“1980-09-30 â†’ predicted\n",
            "1980-11-30: trained 1975-11-30â€“1980-10-30 â†’ predicted\n",
            "1980-12-30: trained 1975-12-30â€“1980-11-30 â†’ predicted\n",
            "1981-01-30: trained 1976-01-30â€“1980-12-30 â†’ predicted\n",
            "1981-02-28: trained 1976-02-29â€“1981-01-30 â†’ predicted\n",
            "1981-03-30: trained 1976-03-30â€“1981-02-28 â†’ predicted\n",
            "1981-04-30: trained 1976-04-30â€“1981-03-30 â†’ predicted\n",
            "1981-05-30: trained 1976-05-30â€“1981-04-30 â†’ predicted\n",
            "1981-06-30: trained 1976-06-30â€“1981-05-30 â†’ predicted\n",
            "1981-07-30: trained 1976-07-30â€“1981-06-30 â†’ predicted\n",
            "1981-08-30: trained 1976-08-30â€“1981-07-30 â†’ predicted\n",
            "1981-09-30: trained 1976-09-30â€“1981-08-30 â†’ predicted\n",
            "1981-10-30: trained 1976-10-30â€“1981-09-30 â†’ predicted\n",
            "1981-11-30: trained 1976-11-30â€“1981-10-30 â†’ predicted\n",
            "1981-12-30: trained 1976-12-30â€“1981-11-30 â†’ predicted\n",
            "1982-01-30: trained 1977-01-30â€“1981-12-30 â†’ predicted\n",
            "1982-02-28: trained 1977-02-28â€“1982-01-30 â†’ predicted\n",
            "1982-03-30: trained 1977-03-30â€“1982-02-28 â†’ predicted\n",
            "1982-04-30: trained 1977-04-30â€“1982-03-30 â†’ predicted\n",
            "1982-05-30: trained 1977-05-30â€“1982-04-30 â†’ predicted\n",
            "1982-06-30: trained 1977-06-30â€“1982-05-30 â†’ predicted\n",
            "1982-07-30: trained 1977-07-30â€“1982-06-30 â†’ predicted\n",
            "1982-08-30: trained 1977-08-30â€“1982-07-30 â†’ predicted\n",
            "1982-09-30: trained 1977-09-30â€“1982-08-30 â†’ predicted\n",
            "1982-10-30: trained 1977-10-30â€“1982-09-30 â†’ predicted\n",
            "1982-11-30: trained 1977-11-30â€“1982-10-30 â†’ predicted\n",
            "1982-12-30: trained 1977-12-30â€“1982-11-30 â†’ predicted\n",
            "1983-01-30: trained 1978-01-30â€“1982-12-30 â†’ predicted\n",
            "1983-02-28: trained 1978-02-28â€“1983-01-30 â†’ predicted\n",
            "1983-03-30: trained 1978-03-30â€“1983-02-28 â†’ predicted\n",
            "1983-04-30: trained 1978-04-30â€“1983-03-30 â†’ predicted\n",
            "1983-05-30: trained 1978-05-30â€“1983-04-30 â†’ predicted\n",
            "1983-06-30: trained 1978-06-30â€“1983-05-30 â†’ predicted\n",
            "1983-07-30: trained 1978-07-30â€“1983-06-30 â†’ predicted\n",
            "1983-08-30: trained 1978-08-30â€“1983-07-30 â†’ predicted\n",
            "1983-09-30: trained 1978-09-30â€“1983-08-30 â†’ predicted\n",
            "1983-10-30: trained 1978-10-30â€“1983-09-30 â†’ predicted\n",
            "1983-11-30: trained 1978-11-30â€“1983-10-30 â†’ predicted\n",
            "1983-12-30: trained 1978-12-30â€“1983-11-30 â†’ predicted\n",
            "1984-01-30: trained 1979-01-30â€“1983-12-30 â†’ predicted\n",
            "1984-02-29: trained 1979-02-28â€“1984-01-30 â†’ predicted\n",
            "1984-03-30: trained 1979-03-30â€“1984-02-29 â†’ predicted\n",
            "1984-04-30: trained 1979-04-30â€“1984-03-30 â†’ predicted\n",
            "1984-05-30: trained 1979-05-30â€“1984-04-30 â†’ predicted\n",
            "1984-06-30: trained 1979-06-30â€“1984-05-30 â†’ predicted\n",
            "1984-07-30: trained 1979-07-30â€“1984-06-30 â†’ predicted\n",
            "1984-08-30: trained 1979-08-30â€“1984-07-30 â†’ predicted\n",
            "1984-09-30: trained 1979-09-30â€“1984-08-30 â†’ predicted\n",
            "1984-10-30: trained 1979-10-30â€“1984-09-30 â†’ predicted\n",
            "1984-11-30: trained 1979-11-30â€“1984-10-30 â†’ predicted\n",
            "1984-12-30: trained 1979-12-30â€“1984-11-30 â†’ predicted\n",
            "1985-01-30: trained 1980-01-30â€“1984-12-30 â†’ predicted\n",
            "1985-02-28: trained 1980-02-29â€“1985-01-30 â†’ predicted\n",
            "1985-03-30: trained 1980-03-30â€“1985-02-28 â†’ predicted\n",
            "1985-04-30: trained 1980-04-30â€“1985-03-30 â†’ predicted\n",
            "1985-05-30: trained 1980-05-30â€“1985-04-30 â†’ predicted\n",
            "1985-06-30: trained 1980-06-30â€“1985-05-30 â†’ predicted\n",
            "1985-07-30: trained 1980-07-30â€“1985-06-30 â†’ predicted\n",
            "1985-08-30: trained 1980-08-30â€“1985-07-30 â†’ predicted\n",
            "1985-09-30: trained 1980-09-30â€“1985-08-30 â†’ predicted\n",
            "1985-10-30: trained 1980-10-30â€“1985-09-30 â†’ predicted\n",
            "1985-11-30: trained 1980-11-30â€“1985-10-30 â†’ predicted\n",
            "1985-12-30: trained 1980-12-30â€“1985-11-30 â†’ predicted\n",
            "1986-01-30: trained 1981-01-30â€“1985-12-30 â†’ predicted\n",
            "1986-02-28: trained 1981-02-28â€“1986-01-30 â†’ predicted\n",
            "1986-03-30: trained 1981-03-30â€“1986-02-28 â†’ predicted\n",
            "1986-04-30: trained 1981-04-30â€“1986-03-30 â†’ predicted\n",
            "1986-05-30: trained 1981-05-30â€“1986-04-30 â†’ predicted\n",
            "1986-06-30: trained 1981-06-30â€“1986-05-30 â†’ predicted\n",
            "1986-07-30: trained 1981-07-30â€“1986-06-30 â†’ predicted\n",
            "1986-08-30: trained 1981-08-30â€“1986-07-30 â†’ predicted\n",
            "1986-09-30: trained 1981-09-30â€“1986-08-30 â†’ predicted\n",
            "1986-10-30: trained 1981-10-30â€“1986-09-30 â†’ predicted\n",
            "1986-11-30: trained 1981-11-30â€“1986-10-30 â†’ predicted\n",
            "1986-12-30: trained 1981-12-30â€“1986-11-30 â†’ predicted\n",
            "1987-01-30: trained 1982-01-30â€“1986-12-30 â†’ predicted\n",
            "1987-02-28: trained 1982-02-28â€“1987-01-30 â†’ predicted\n",
            "1987-03-30: trained 1982-03-30â€“1987-02-28 â†’ predicted\n",
            "1987-04-30: trained 1982-04-30â€“1987-03-30 â†’ predicted\n",
            "1987-05-30: trained 1982-05-30â€“1987-04-30 â†’ predicted\n",
            "1987-06-30: trained 1982-06-30â€“1987-05-30 â†’ predicted\n",
            "1987-07-30: trained 1982-07-30â€“1987-06-30 â†’ predicted\n",
            "1987-08-30: trained 1982-08-30â€“1987-07-30 â†’ predicted\n",
            "1987-09-30: trained 1982-09-30â€“1987-08-30 â†’ predicted\n",
            "1987-10-30: trained 1982-10-30â€“1987-09-30 â†’ predicted\n",
            "1987-11-30: trained 1982-11-30â€“1987-10-30 â†’ predicted\n",
            "1987-12-30: trained 1982-12-30â€“1987-11-30 â†’ predicted\n",
            "1988-01-30: trained 1983-01-30â€“1987-12-30 â†’ predicted\n",
            "1988-02-29: trained 1983-02-28â€“1988-01-30 â†’ predicted\n",
            "1988-03-30: trained 1983-03-30â€“1988-02-29 â†’ predicted\n",
            "1988-04-30: trained 1983-04-30â€“1988-03-30 â†’ predicted\n",
            "1988-05-30: trained 1983-05-30â€“1988-04-30 â†’ predicted\n",
            "1988-06-30: trained 1983-06-30â€“1988-05-30 â†’ predicted\n",
            "1988-07-30: trained 1983-07-30â€“1988-06-30 â†’ predicted\n",
            "1988-08-30: trained 1983-08-30â€“1988-07-30 â†’ predicted\n",
            "1988-09-30: trained 1983-09-30â€“1988-08-30 â†’ predicted\n",
            "1988-10-30: trained 1983-10-30â€“1988-09-30 â†’ predicted\n",
            "1988-11-30: trained 1983-11-30â€“1988-10-30 â†’ predicted\n",
            "1988-12-30: trained 1983-12-30â€“1988-11-30 â†’ predicted\n",
            "1989-01-30: trained 1984-01-30â€“1988-12-30 â†’ predicted\n",
            "1989-02-28: trained 1984-02-29â€“1989-01-30 â†’ predicted\n",
            "1989-03-30: trained 1984-03-30â€“1989-02-28 â†’ predicted\n",
            "1989-04-30: trained 1984-04-30â€“1989-03-30 â†’ predicted\n",
            "1989-05-30: trained 1984-05-30â€“1989-04-30 â†’ predicted\n",
            "1989-06-30: trained 1984-06-30â€“1989-05-30 â†’ predicted\n",
            "1989-07-30: trained 1984-07-30â€“1989-06-30 â†’ predicted\n",
            "1989-08-30: trained 1984-08-30â€“1989-07-30 â†’ predicted\n",
            "1989-09-30: trained 1984-09-30â€“1989-08-30 â†’ predicted\n",
            "1989-10-30: trained 1984-10-30â€“1989-09-30 â†’ predicted\n",
            "1989-11-30: trained 1984-11-30â€“1989-10-30 â†’ predicted\n",
            "1989-12-30: trained 1984-12-30â€“1989-11-30 â†’ predicted\n",
            "1990-01-30: trained 1985-01-30â€“1989-12-30 â†’ predicted\n",
            "1990-02-28: trained 1985-02-28â€“1990-01-30 â†’ predicted\n",
            "1990-03-30: trained 1985-03-30â€“1990-02-28 â†’ predicted\n",
            "1990-04-30: trained 1985-04-30â€“1990-03-30 â†’ predicted\n",
            "1990-05-30: trained 1985-05-30â€“1990-04-30 â†’ predicted\n",
            "1990-06-30: trained 1985-06-30â€“1990-05-30 â†’ predicted\n",
            "1990-07-30: trained 1985-07-30â€“1990-06-30 â†’ predicted\n",
            "1990-08-30: trained 1985-08-30â€“1990-07-30 â†’ predicted\n",
            "1990-09-30: trained 1985-09-30â€“1990-08-30 â†’ predicted\n",
            "1990-10-30: trained 1985-10-30â€“1990-09-30 â†’ predicted\n",
            "1990-11-30: trained 1985-11-30â€“1990-10-30 â†’ predicted\n",
            "1990-12-30: trained 1985-12-30â€“1990-11-30 â†’ predicted\n",
            "1991-01-30: trained 1986-01-30â€“1990-12-30 â†’ predicted\n",
            "1991-02-28: trained 1986-02-28â€“1991-01-30 â†’ predicted\n",
            "1991-03-30: trained 1986-03-30â€“1991-02-28 â†’ predicted\n",
            "1991-04-30: trained 1986-04-30â€“1991-03-30 â†’ predicted\n",
            "1991-05-30: trained 1986-05-30â€“1991-04-30 â†’ predicted\n",
            "1991-06-30: trained 1986-06-30â€“1991-05-30 â†’ predicted\n",
            "1991-07-30: trained 1986-07-30â€“1991-06-30 â†’ predicted\n",
            "1991-08-30: trained 1986-08-30â€“1991-07-30 â†’ predicted\n",
            "1991-09-30: trained 1986-09-30â€“1991-08-30 â†’ predicted\n",
            "1991-10-30: trained 1986-10-30â€“1991-09-30 â†’ predicted\n",
            "1991-11-30: trained 1986-11-30â€“1991-10-30 â†’ predicted\n",
            "1991-12-30: trained 1986-12-30â€“1991-11-30 â†’ predicted\n",
            "1992-01-30: trained 1987-01-30â€“1991-12-30 â†’ predicted\n",
            "1992-02-29: trained 1987-02-28â€“1992-01-30 â†’ predicted\n",
            "1992-03-30: trained 1987-03-30â€“1992-02-29 â†’ predicted\n",
            "1992-04-30: trained 1987-04-30â€“1992-03-30 â†’ predicted\n",
            "1992-05-30: trained 1987-05-30â€“1992-04-30 â†’ predicted\n",
            "1992-06-30: trained 1987-06-30â€“1992-05-30 â†’ predicted\n",
            "1992-07-30: trained 1987-07-30â€“1992-06-30 â†’ predicted\n",
            "1992-08-30: trained 1987-08-30â€“1992-07-30 â†’ predicted\n",
            "1992-09-30: trained 1987-09-30â€“1992-08-30 â†’ predicted\n",
            "1992-10-30: trained 1987-10-30â€“1992-09-30 â†’ predicted\n",
            "1992-11-30: trained 1987-11-30â€“1992-10-30 â†’ predicted\n",
            "1992-12-30: trained 1987-12-30â€“1992-11-30 â†’ predicted\n",
            "1993-01-30: trained 1988-01-30â€“1992-12-30 â†’ predicted\n",
            "1993-02-28: trained 1988-02-29â€“1993-01-30 â†’ predicted\n",
            "1993-03-30: trained 1988-03-30â€“1993-02-28 â†’ predicted\n",
            "1993-04-30: trained 1988-04-30â€“1993-03-30 â†’ predicted\n",
            "1993-05-30: trained 1988-05-30â€“1993-04-30 â†’ predicted\n",
            "1993-06-30: trained 1988-06-30â€“1993-05-30 â†’ predicted\n",
            "1993-07-30: trained 1988-07-30â€“1993-06-30 â†’ predicted\n",
            "1993-08-30: trained 1988-08-30â€“1993-07-30 â†’ predicted\n",
            "1993-09-30: trained 1988-09-30â€“1993-08-30 â†’ predicted\n",
            "1993-10-30: trained 1988-10-30â€“1993-09-30 â†’ predicted\n",
            "1993-11-30: trained 1988-11-30â€“1993-10-30 â†’ predicted\n",
            "1993-12-30: trained 1988-12-30â€“1993-11-30 â†’ predicted\n",
            "1994-01-30: trained 1989-01-30â€“1993-12-30 â†’ predicted\n",
            "1994-02-28: trained 1989-02-28â€“1994-01-30 â†’ predicted\n",
            "1994-03-30: trained 1989-03-30â€“1994-02-28 â†’ predicted\n",
            "1994-04-30: trained 1989-04-30â€“1994-03-30 â†’ predicted\n",
            "1994-05-30: trained 1989-05-30â€“1994-04-30 â†’ predicted\n",
            "1994-06-30: trained 1989-06-30â€“1994-05-30 â†’ predicted\n",
            "1994-07-30: trained 1989-07-30â€“1994-06-30 â†’ predicted\n",
            "1994-08-30: trained 1989-08-30â€“1994-07-30 â†’ predicted\n",
            "1994-09-30: trained 1989-09-30â€“1994-08-30 â†’ predicted\n",
            "1994-10-30: trained 1989-10-30â€“1994-09-30 â†’ predicted\n",
            "1994-11-30: trained 1989-11-30â€“1994-10-30 â†’ predicted\n",
            "1994-12-30: trained 1989-12-30â€“1994-11-30 â†’ predicted\n",
            "1995-01-30: trained 1990-01-30â€“1994-12-30 â†’ predicted\n",
            "1995-02-28: trained 1990-02-28â€“1995-01-30 â†’ predicted\n",
            "1995-03-30: trained 1990-03-30â€“1995-02-28 â†’ predicted\n",
            "1995-04-30: trained 1990-04-30â€“1995-03-30 â†’ predicted\n",
            "1995-05-30: trained 1990-05-30â€“1995-04-30 â†’ predicted\n",
            "1995-06-30: trained 1990-06-30â€“1995-05-30 â†’ predicted\n",
            "1995-07-30: trained 1990-07-30â€“1995-06-30 â†’ predicted\n",
            "1995-08-30: trained 1990-08-30â€“1995-07-30 â†’ predicted\n",
            "1995-09-30: trained 1990-09-30â€“1995-08-30 â†’ predicted\n",
            "1995-10-30: trained 1990-10-30â€“1995-09-30 â†’ predicted\n",
            "1995-11-30: trained 1990-11-30â€“1995-10-30 â†’ predicted\n",
            "1995-12-30: trained 1990-12-30â€“1995-11-30 â†’ predicted\n",
            "1996-01-30: trained 1991-01-30â€“1995-12-30 â†’ predicted\n",
            "1996-02-29: trained 1991-02-28â€“1996-01-30 â†’ predicted\n",
            "1996-03-30: trained 1991-03-30â€“1996-02-29 â†’ predicted\n",
            "1996-04-30: trained 1991-04-30â€“1996-03-30 â†’ predicted\n",
            "1996-05-30: trained 1991-05-30â€“1996-04-30 â†’ predicted\n",
            "1996-06-30: trained 1991-06-30â€“1996-05-30 â†’ predicted\n",
            "1996-07-30: trained 1991-07-30â€“1996-06-30 â†’ predicted\n",
            "1996-08-30: trained 1991-08-30â€“1996-07-30 â†’ predicted\n",
            "1996-09-30: trained 1991-09-30â€“1996-08-30 â†’ predicted\n",
            "1996-10-30: trained 1991-10-30â€“1996-09-30 â†’ predicted\n",
            "1996-11-30: trained 1991-11-30â€“1996-10-30 â†’ predicted\n",
            "1996-12-30: trained 1991-12-30â€“1996-11-30 â†’ predicted\n",
            "1997-01-30: trained 1992-01-30â€“1996-12-30 â†’ predicted\n",
            "1997-02-28: trained 1992-02-29â€“1997-01-30 â†’ predicted\n",
            "1997-03-30: trained 1992-03-30â€“1997-02-28 â†’ predicted\n",
            "1997-04-30: trained 1992-04-30â€“1997-03-30 â†’ predicted\n",
            "1997-05-30: trained 1992-05-30â€“1997-04-30 â†’ predicted\n",
            "1997-06-30: trained 1992-06-30â€“1997-05-30 â†’ predicted\n",
            "1997-07-30: trained 1992-07-30â€“1997-06-30 â†’ predicted\n",
            "1997-08-30: trained 1992-08-30â€“1997-07-30 â†’ predicted\n",
            "1997-09-30: trained 1992-09-30â€“1997-08-30 â†’ predicted\n",
            "1997-10-30: trained 1992-10-30â€“1997-09-30 â†’ predicted\n",
            "1997-11-30: trained 1992-11-30â€“1997-10-30 â†’ predicted\n",
            "1997-12-30: trained 1992-12-30â€“1997-11-30 â†’ predicted\n",
            "1998-01-30: trained 1993-01-30â€“1997-12-30 â†’ predicted\n",
            "1998-02-28: trained 1993-02-28â€“1998-01-30 â†’ predicted\n",
            "1998-03-30: trained 1993-03-30â€“1998-02-28 â†’ predicted\n",
            "1998-04-30: trained 1993-04-30â€“1998-03-30 â†’ predicted\n",
            "1998-05-30: trained 1993-05-30â€“1998-04-30 â†’ predicted\n",
            "1998-06-30: trained 1993-06-30â€“1998-05-30 â†’ predicted\n",
            "1998-07-30: trained 1993-07-30â€“1998-06-30 â†’ predicted\n",
            "1998-08-30: trained 1993-08-30â€“1998-07-30 â†’ predicted\n",
            "1998-09-30: trained 1993-09-30â€“1998-08-30 â†’ predicted\n",
            "1998-10-30: trained 1993-10-30â€“1998-09-30 â†’ predicted\n",
            "1998-11-30: trained 1993-11-30â€“1998-10-30 â†’ predicted\n",
            "1998-12-30: trained 1993-12-30â€“1998-11-30 â†’ predicted\n",
            "1999-01-30: trained 1994-01-30â€“1998-12-30 â†’ predicted\n",
            "1999-02-28: trained 1994-02-28â€“1999-01-30 â†’ predicted\n",
            "1999-03-30: trained 1994-03-30â€“1999-02-28 â†’ predicted\n",
            "1999-04-30: trained 1994-04-30â€“1999-03-30 â†’ predicted\n",
            "1999-05-30: trained 1994-05-30â€“1999-04-30 â†’ predicted\n",
            "1999-06-30: trained 1994-06-30â€“1999-05-30 â†’ predicted\n",
            "1999-07-30: trained 1994-07-30â€“1999-06-30 â†’ predicted\n",
            "1999-08-30: trained 1994-08-30â€“1999-07-30 â†’ predicted\n",
            "1999-09-30: trained 1994-09-30â€“1999-08-30 â†’ predicted\n",
            "1999-10-30: trained 1994-10-30â€“1999-09-30 â†’ predicted\n",
            "1999-11-30: trained 1994-11-30â€“1999-10-30 â†’ predicted\n",
            "1999-12-30: trained 1994-12-30â€“1999-11-30 â†’ predicted\n",
            "2000-01-30: trained 1995-01-30â€“1999-12-30 â†’ predicted\n",
            "2000-02-29: trained 1995-02-28â€“2000-01-30 â†’ predicted\n",
            "2000-03-30: trained 1995-03-30â€“2000-02-29 â†’ predicted\n",
            "2000-04-30: trained 1995-04-30â€“2000-03-30 â†’ predicted\n",
            "2000-05-30: trained 1995-05-30â€“2000-04-30 â†’ predicted\n",
            "2000-06-30: trained 1995-06-30â€“2000-05-30 â†’ predicted\n",
            "2000-07-30: trained 1995-07-30â€“2000-06-30 â†’ predicted\n",
            "2000-08-30: trained 1995-08-30â€“2000-07-30 â†’ predicted\n",
            "2000-09-30: trained 1995-09-30â€“2000-08-30 â†’ predicted\n",
            "2000-10-30: trained 1995-10-30â€“2000-09-30 â†’ predicted\n",
            "2000-11-30: trained 1995-11-30â€“2000-10-30 â†’ predicted\n",
            "2000-12-30: trained 1995-12-30â€“2000-11-30 â†’ predicted\n",
            "2001-01-30: trained 1996-01-30â€“2000-12-30 â†’ predicted\n",
            "2001-02-28: trained 1996-02-29â€“2001-01-30 â†’ predicted\n",
            "2001-03-30: trained 1996-03-30â€“2001-02-28 â†’ predicted\n",
            "2001-04-30: trained 1996-04-30â€“2001-03-30 â†’ predicted\n",
            "2001-05-30: trained 1996-05-30â€“2001-04-30 â†’ predicted\n",
            "2001-06-30: trained 1996-06-30â€“2001-05-30 â†’ predicted\n",
            "2001-07-30: trained 1996-07-30â€“2001-06-30 â†’ predicted\n",
            "2001-08-30: trained 1996-08-30â€“2001-07-30 â†’ predicted\n",
            "2001-09-30: trained 1996-09-30â€“2001-08-30 â†’ predicted\n",
            "2001-10-30: trained 1996-10-30â€“2001-09-30 â†’ predicted\n",
            "2001-11-30: trained 1996-11-30â€“2001-10-30 â†’ predicted\n",
            "2001-12-30: trained 1996-12-30â€“2001-11-30 â†’ predicted\n",
            "2002-01-30: trained 1997-01-30â€“2001-12-30 â†’ predicted\n",
            "2002-02-28: trained 1997-02-28â€“2002-01-30 â†’ predicted\n",
            "2002-03-30: trained 1997-03-30â€“2002-02-28 â†’ predicted\n",
            "2002-04-30: trained 1997-04-30â€“2002-03-30 â†’ predicted\n",
            "2002-05-30: trained 1997-05-30â€“2002-04-30 â†’ predicted\n",
            "2002-06-30: trained 1997-06-30â€“2002-05-30 â†’ predicted\n",
            "2002-07-30: trained 1997-07-30â€“2002-06-30 â†’ predicted\n",
            "2002-08-30: trained 1997-08-30â€“2002-07-30 â†’ predicted\n",
            "2002-09-30: trained 1997-09-30â€“2002-08-30 â†’ predicted\n",
            "2002-10-30: trained 1997-10-30â€“2002-09-30 â†’ predicted\n",
            "2002-11-30: trained 1997-11-30â€“2002-10-30 â†’ predicted\n",
            "2002-12-30: trained 1997-12-30â€“2002-11-30 â†’ predicted\n",
            "2003-01-30: trained 1998-01-30â€“2002-12-30 â†’ predicted\n",
            "2003-02-28: trained 1998-02-28â€“2003-01-30 â†’ predicted\n",
            "2003-03-30: trained 1998-03-30â€“2003-02-28 â†’ predicted\n",
            "2003-04-30: trained 1998-04-30â€“2003-03-30 â†’ predicted\n",
            "2003-05-30: trained 1998-05-30â€“2003-04-30 â†’ predicted\n",
            "2003-06-30: trained 1998-06-30â€“2003-05-30 â†’ predicted\n",
            "2003-07-30: trained 1998-07-30â€“2003-06-30 â†’ predicted\n",
            "2003-08-30: trained 1998-08-30â€“2003-07-30 â†’ predicted\n",
            "2003-09-30: trained 1998-09-30â€“2003-08-30 â†’ predicted\n",
            "2003-10-30: trained 1998-10-30â€“2003-09-30 â†’ predicted\n",
            "2003-11-30: trained 1998-11-30â€“2003-10-30 â†’ predicted\n",
            "2003-12-30: trained 1998-12-30â€“2003-11-30 â†’ predicted\n",
            "2004-01-30: trained 1999-01-30â€“2003-12-30 â†’ predicted\n",
            "2004-02-29: trained 1999-02-28â€“2004-01-30 â†’ predicted\n",
            "2004-03-30: trained 1999-03-30â€“2004-02-29 â†’ predicted\n",
            "2004-04-30: trained 1999-04-30â€“2004-03-30 â†’ predicted\n",
            "2004-05-30: trained 1999-05-30â€“2004-04-30 â†’ predicted\n",
            "2004-06-30: trained 1999-06-30â€“2004-05-30 â†’ predicted\n",
            "2004-07-30: trained 1999-07-30â€“2004-06-30 â†’ predicted\n",
            "2004-08-30: trained 1999-08-30â€“2004-07-30 â†’ predicted\n",
            "2004-09-30: trained 1999-09-30â€“2004-08-30 â†’ predicted\n",
            "2004-10-30: trained 1999-10-30â€“2004-09-30 â†’ predicted\n",
            "2004-11-30: trained 1999-11-30â€“2004-10-30 â†’ predicted\n",
            "2004-12-30: trained 1999-12-30â€“2004-11-30 â†’ predicted\n",
            "2005-01-30: trained 2000-01-30â€“2004-12-30 â†’ predicted\n",
            "2005-02-28: trained 2000-02-29â€“2005-01-30 â†’ predicted\n",
            "2005-03-30: trained 2000-03-30â€“2005-02-28 â†’ predicted\n",
            "2005-04-30: trained 2000-04-30â€“2005-03-30 â†’ predicted\n",
            "2005-05-30: trained 2000-05-30â€“2005-04-30 â†’ predicted\n",
            "2005-06-30: trained 2000-06-30â€“2005-05-30 â†’ predicted\n",
            "2005-07-30: trained 2000-07-30â€“2005-06-30 â†’ predicted\n",
            "2005-08-30: trained 2000-08-30â€“2005-07-30 â†’ predicted\n",
            "2005-09-30: trained 2000-09-30â€“2005-08-30 â†’ predicted\n",
            "2005-10-30: trained 2000-10-30â€“2005-09-30 â†’ predicted\n",
            "2005-11-30: trained 2000-11-30â€“2005-10-30 â†’ predicted\n",
            "2005-12-30: trained 2000-12-30â€“2005-11-30 â†’ predicted\n",
            "2006-01-30: trained 2001-01-30â€“2005-12-30 â†’ predicted\n",
            "2006-02-28: trained 2001-02-28â€“2006-01-30 â†’ predicted\n",
            "2006-03-30: trained 2001-03-30â€“2006-02-28 â†’ predicted\n",
            "2006-04-30: trained 2001-04-30â€“2006-03-30 â†’ predicted\n",
            "2006-05-30: trained 2001-05-30â€“2006-04-30 â†’ predicted\n",
            "2006-06-30: trained 2001-06-30â€“2006-05-30 â†’ predicted\n",
            "2006-07-30: trained 2001-07-30â€“2006-06-30 â†’ predicted\n",
            "2006-08-30: trained 2001-08-30â€“2006-07-30 â†’ predicted\n",
            "2006-09-30: trained 2001-09-30â€“2006-08-30 â†’ predicted\n",
            "2006-10-30: trained 2001-10-30â€“2006-09-30 â†’ predicted\n",
            "2006-11-30: trained 2001-11-30â€“2006-10-30 â†’ predicted\n",
            "2006-12-30: trained 2001-12-30â€“2006-11-30 â†’ predicted\n",
            "2007-01-30: trained 2002-01-30â€“2006-12-30 â†’ predicted\n",
            "2007-02-28: trained 2002-02-28â€“2007-01-30 â†’ predicted\n",
            "2007-03-30: trained 2002-03-30â€“2007-02-28 â†’ predicted\n",
            "2007-04-30: trained 2002-04-30â€“2007-03-30 â†’ predicted\n",
            "2007-05-30: trained 2002-05-30â€“2007-04-30 â†’ predicted\n",
            "2007-06-30: trained 2002-06-30â€“2007-05-30 â†’ predicted\n",
            "2007-07-30: trained 2002-07-30â€“2007-06-30 â†’ predicted\n",
            "2007-08-30: trained 2002-08-30â€“2007-07-30 â†’ predicted\n",
            "2007-09-30: trained 2002-09-30â€“2007-08-30 â†’ predicted\n",
            "2007-10-30: trained 2002-10-30â€“2007-09-30 â†’ predicted\n",
            "2007-11-30: trained 2002-11-30â€“2007-10-30 â†’ predicted\n",
            "2007-12-30: trained 2002-12-30â€“2007-11-30 â†’ predicted\n",
            "2008-01-30: trained 2003-01-30â€“2007-12-30 â†’ predicted\n",
            "2008-02-29: trained 2003-02-28â€“2008-01-30 â†’ predicted\n",
            "2008-03-30: trained 2003-03-30â€“2008-02-29 â†’ predicted\n",
            "2008-04-30: trained 2003-04-30â€“2008-03-30 â†’ predicted\n",
            "2008-05-30: trained 2003-05-30â€“2008-04-30 â†’ predicted\n",
            "2008-06-30: trained 2003-06-30â€“2008-05-30 â†’ predicted\n",
            "2008-07-30: trained 2003-07-30â€“2008-06-30 â†’ predicted\n",
            "2008-08-30: trained 2003-08-30â€“2008-07-30 â†’ predicted\n",
            "2008-09-30: trained 2003-09-30â€“2008-08-30 â†’ predicted\n",
            "2008-10-30: trained 2003-10-30â€“2008-09-30 â†’ predicted\n",
            "2008-11-30: trained 2003-11-30â€“2008-10-30 â†’ predicted\n",
            "2008-12-30: trained 2003-12-30â€“2008-11-30 â†’ predicted\n",
            "2009-01-30: trained 2004-01-30â€“2008-12-30 â†’ predicted\n",
            "2009-02-28: trained 2004-02-29â€“2009-01-30 â†’ predicted\n",
            "2009-03-30: trained 2004-03-30â€“2009-02-28 â†’ predicted\n",
            "2009-04-30: trained 2004-04-30â€“2009-03-30 â†’ predicted\n",
            "2009-05-30: trained 2004-05-30â€“2009-04-30 â†’ predicted\n",
            "2009-06-30: trained 2004-06-30â€“2009-05-30 â†’ predicted\n",
            "2009-07-30: trained 2004-07-30â€“2009-06-30 â†’ predicted\n",
            "2009-08-30: trained 2004-08-30â€“2009-07-30 â†’ predicted\n",
            "2009-09-30: trained 2004-09-30â€“2009-08-30 â†’ predicted\n",
            "2009-10-30: trained 2004-10-30â€“2009-09-30 â†’ predicted\n",
            "2009-11-30: trained 2004-11-30â€“2009-10-30 â†’ predicted\n",
            "2009-12-30: trained 2004-12-30â€“2009-11-30 â†’ predicted\n",
            "2010-01-30: trained 2005-01-30â€“2009-12-30 â†’ predicted\n",
            "2010-02-28: trained 2005-02-28â€“2010-01-30 â†’ predicted\n",
            "2010-03-30: trained 2005-03-30â€“2010-02-28 â†’ predicted\n",
            "2010-04-30: trained 2005-04-30â€“2010-03-30 â†’ predicted\n",
            "2010-05-30: trained 2005-05-30â€“2010-04-30 â†’ predicted\n",
            "2010-06-30: trained 2005-06-30â€“2010-05-30 â†’ predicted\n",
            "2010-07-30: trained 2005-07-30â€“2010-06-30 â†’ predicted\n",
            "2010-08-30: trained 2005-08-30â€“2010-07-30 â†’ predicted\n",
            "2010-09-30: trained 2005-09-30â€“2010-08-30 â†’ predicted\n",
            "2010-10-30: trained 2005-10-30â€“2010-09-30 â†’ predicted\n",
            "2010-11-30: trained 2005-11-30â€“2010-10-30 â†’ predicted\n",
            "2010-12-30: trained 2005-12-30â€“2010-11-30 â†’ predicted\n",
            "2011-01-30: trained 2006-01-30â€“2010-12-30 â†’ predicted\n",
            "2011-02-28: trained 2006-02-28â€“2011-01-30 â†’ predicted\n",
            "2011-03-30: trained 2006-03-30â€“2011-02-28 â†’ predicted\n",
            "2011-04-30: trained 2006-04-30â€“2011-03-30 â†’ predicted\n",
            "2011-05-30: trained 2006-05-30â€“2011-04-30 â†’ predicted\n",
            "2011-06-30: trained 2006-06-30â€“2011-05-30 â†’ predicted\n",
            "2011-07-30: trained 2006-07-30â€“2011-06-30 â†’ predicted\n",
            "2011-08-30: trained 2006-08-30â€“2011-07-30 â†’ predicted\n",
            "2011-09-30: trained 2006-09-30â€“2011-08-30 â†’ predicted\n",
            "2011-10-30: trained 2006-10-30â€“2011-09-30 â†’ predicted\n",
            "2011-11-30: trained 2006-11-30â€“2011-10-30 â†’ predicted\n",
            "2011-12-30: trained 2006-12-30â€“2011-11-30 â†’ predicted\n",
            "2012-01-30: trained 2007-01-30â€“2011-12-30 â†’ predicted\n",
            "2012-02-29: trained 2007-02-28â€“2012-01-30 â†’ predicted\n",
            "2012-03-30: trained 2007-03-30â€“2012-02-29 â†’ predicted\n",
            "2012-04-30: trained 2007-04-30â€“2012-03-30 â†’ predicted\n",
            "2012-05-30: trained 2007-05-30â€“2012-04-30 â†’ predicted\n",
            "2012-06-30: trained 2007-06-30â€“2012-05-30 â†’ predicted\n",
            "2012-07-30: trained 2007-07-30â€“2012-06-30 â†’ predicted\n",
            "2012-08-30: trained 2007-08-30â€“2012-07-30 â†’ predicted\n",
            "2012-09-30: trained 2007-09-30â€“2012-08-30 â†’ predicted\n",
            "2012-10-30: trained 2007-10-30â€“2012-09-30 â†’ predicted\n",
            "2012-11-30: trained 2007-11-30â€“2012-10-30 â†’ predicted\n",
            "2012-12-30: trained 2007-12-30â€“2012-11-30 â†’ predicted\n",
            "2013-01-30: trained 2008-01-30â€“2012-12-30 â†’ predicted\n",
            "2013-02-28: trained 2008-02-29â€“2013-01-30 â†’ predicted\n",
            "2013-03-30: trained 2008-03-30â€“2013-02-28 â†’ predicted\n",
            "2013-04-30: trained 2008-04-30â€“2013-03-30 â†’ predicted\n",
            "2013-05-30: trained 2008-05-30â€“2013-04-30 â†’ predicted\n",
            "2013-06-30: trained 2008-06-30â€“2013-05-30 â†’ predicted\n",
            "2013-07-30: trained 2008-07-30â€“2013-06-30 â†’ predicted\n",
            "2013-08-30: trained 2008-08-30â€“2013-07-30 â†’ predicted\n",
            "2013-09-30: trained 2008-09-30â€“2013-08-30 â†’ predicted\n",
            "2013-10-30: trained 2008-10-30â€“2013-09-30 â†’ predicted\n",
            "2013-11-30: trained 2008-11-30â€“2013-10-30 â†’ predicted\n",
            "2013-12-30: trained 2008-12-30â€“2013-11-30 â†’ predicted\n",
            "2014-01-30: trained 2009-01-30â€“2013-12-30 â†’ predicted\n",
            "2014-02-28: trained 2009-02-28â€“2014-01-30 â†’ predicted\n",
            "2014-03-30: trained 2009-03-30â€“2014-02-28 â†’ predicted\n",
            "2014-04-30: trained 2009-04-30â€“2014-03-30 â†’ predicted\n",
            "2014-05-30: trained 2009-05-30â€“2014-04-30 â†’ predicted\n",
            "2014-06-30: trained 2009-06-30â€“2014-05-30 â†’ predicted\n",
            "2014-07-30: trained 2009-07-30â€“2014-06-30 â†’ predicted\n",
            "2014-08-30: trained 2009-08-30â€“2014-07-30 â†’ predicted\n",
            "2014-09-30: trained 2009-09-30â€“2014-08-30 â†’ predicted\n",
            "2014-10-30: trained 2009-10-30â€“2014-09-30 â†’ predicted\n",
            "2014-11-30: trained 2009-11-30â€“2014-10-30 â†’ predicted\n",
            "2014-12-30: trained 2009-12-30â€“2014-11-30 â†’ predicted\n",
            "2015-01-30: trained 2010-01-30â€“2014-12-30 â†’ predicted\n",
            "2015-02-28: trained 2010-02-28â€“2015-01-30 â†’ predicted\n",
            "2015-03-30: trained 2010-03-30â€“2015-02-28 â†’ predicted\n",
            "2015-04-30: trained 2010-04-30â€“2015-03-30 â†’ predicted\n",
            "2015-05-30: trained 2010-05-30â€“2015-04-30 â†’ predicted\n",
            "2015-06-30: trained 2010-06-30â€“2015-05-30 â†’ predicted\n",
            "2015-07-30: trained 2010-07-30â€“2015-06-30 â†’ predicted\n",
            "2015-08-30: trained 2010-08-30â€“2015-07-30 â†’ predicted\n",
            "2015-09-30: trained 2010-09-30â€“2015-08-30 â†’ predicted\n",
            "2015-10-30: trained 2010-10-30â€“2015-09-30 â†’ predicted\n",
            "2015-11-30: trained 2010-11-30â€“2015-10-30 â†’ predicted\n",
            "2015-12-30: trained 2010-12-30â€“2015-11-30 â†’ predicted\n",
            "2016-01-30: trained 2011-01-30â€“2015-12-30 â†’ predicted\n",
            "2016-02-29: trained 2011-02-28â€“2016-01-30 â†’ predicted\n",
            "2016-03-30: trained 2011-03-30â€“2016-02-29 â†’ predicted\n",
            "2016-04-30: trained 2011-04-30â€“2016-03-30 â†’ predicted\n",
            "2016-05-30: trained 2011-05-30â€“2016-04-30 â†’ predicted\n",
            "2016-06-30: trained 2011-06-30â€“2016-05-30 â†’ predicted\n",
            "2016-07-30: trained 2011-07-30â€“2016-06-30 â†’ predicted\n",
            "2016-08-30: trained 2011-08-30â€“2016-07-30 â†’ predicted\n",
            "2016-09-30: trained 2011-09-30â€“2016-08-30 â†’ predicted\n",
            "2016-10-30: trained 2011-10-30â€“2016-09-30 â†’ predicted\n",
            "2016-11-30: trained 2011-11-30â€“2016-10-30 â†’ predicted\n",
            "2016-12-30: trained 2011-12-30â€“2016-11-30 â†’ predicted\n",
            "2017-01-30: trained 2012-01-30â€“2016-12-30 â†’ predicted\n",
            "2017-02-28: trained 2012-02-29â€“2017-01-30 â†’ predicted\n",
            "2017-03-30: trained 2012-03-30â€“2017-02-28 â†’ predicted\n",
            "2017-04-30: trained 2012-04-30â€“2017-03-30 â†’ predicted\n",
            "2017-05-30: trained 2012-05-30â€“2017-04-30 â†’ predicted\n",
            "2017-06-30: trained 2012-06-30â€“2017-05-30 â†’ predicted\n",
            "2017-07-30: trained 2012-07-30â€“2017-06-30 â†’ predicted\n",
            "2017-08-30: trained 2012-08-30â€“2017-07-30 â†’ predicted\n",
            "2017-09-30: trained 2012-09-30â€“2017-08-30 â†’ predicted\n",
            "2017-10-30: trained 2012-10-30â€“2017-09-30 â†’ predicted\n",
            "2017-11-30: trained 2012-11-30â€“2017-10-30 â†’ predicted\n",
            "2017-12-30: trained 2012-12-30â€“2017-11-30 â†’ predicted\n",
            "2018-01-30: trained 2013-01-30â€“2017-12-30 â†’ predicted\n",
            "2018-02-28: trained 2013-02-28â€“2018-01-30 â†’ predicted\n",
            "2018-03-30: trained 2013-03-30â€“2018-02-28 â†’ predicted\n",
            "2018-04-30: trained 2013-04-30â€“2018-03-30 â†’ predicted\n",
            "2018-05-30: trained 2013-05-30â€“2018-04-30 â†’ predicted\n",
            "2018-06-30: trained 2013-06-30â€“2018-05-30 â†’ predicted\n",
            "2018-07-30: trained 2013-07-30â€“2018-06-30 â†’ predicted\n",
            "2018-08-30: trained 2013-08-30â€“2018-07-30 â†’ predicted\n",
            "2018-09-30: trained 2013-09-30â€“2018-08-30 â†’ predicted\n",
            "2018-10-30: trained 2013-10-30â€“2018-09-30 â†’ predicted\n",
            "2018-11-30: trained 2013-11-30â€“2018-10-30 â†’ predicted\n",
            "2018-12-30: trained 2013-12-30â€“2018-11-30 â†’ predicted\n",
            "2019-01-30: trained 2014-01-30â€“2018-12-30 â†’ predicted\n",
            "2019-02-28: trained 2014-02-28â€“2019-01-30 â†’ predicted\n",
            "2019-03-30: trained 2014-03-30â€“2019-02-28 â†’ predicted\n",
            "2019-04-30: trained 2014-04-30â€“2019-03-30 â†’ predicted\n",
            "2019-05-30: trained 2014-05-30â€“2019-04-30 â†’ predicted\n",
            "2019-06-30: trained 2014-06-30â€“2019-05-30 â†’ predicted\n",
            "2019-07-30: trained 2014-07-30â€“2019-06-30 â†’ predicted\n",
            "2019-08-30: trained 2014-08-30â€“2019-07-30 â†’ predicted\n",
            "2019-09-30: trained 2014-09-30â€“2019-08-30 â†’ predicted\n",
            "2019-10-30: trained 2014-10-30â€“2019-09-30 â†’ predicted\n",
            "2019-11-30: trained 2014-11-30â€“2019-10-30 â†’ predicted\n",
            "2019-12-30: trained 2014-12-30â€“2019-11-30 â†’ predicted\n",
            "2020-01-30: trained 2015-01-30â€“2019-12-30 â†’ predicted\n",
            "2020-02-29: trained 2015-02-28â€“2020-01-30 â†’ predicted\n",
            "2020-03-30: trained 2015-03-30â€“2020-02-29 â†’ predicted\n",
            "2020-04-30: trained 2015-04-30â€“2020-03-30 â†’ predicted\n",
            "2020-05-30: trained 2015-05-30â€“2020-04-30 â†’ predicted\n",
            "2020-06-30: trained 2015-06-30â€“2020-05-30 â†’ predicted\n",
            "2020-07-30: trained 2015-07-30â€“2020-06-30 â†’ predicted\n",
            "2020-08-30: trained 2015-08-30â€“2020-07-30 â†’ predicted\n",
            "2020-09-30: trained 2015-09-30â€“2020-08-30 â†’ predicted\n",
            "2020-10-30: trained 2015-10-30â€“2020-09-30 â†’ predicted\n",
            "2020-11-30: trained 2015-11-30â€“2020-10-30 â†’ predicted\n",
            "2020-12-30: trained 2015-12-30â€“2020-11-30 â†’ predicted\n",
            "2021-01-30: trained 2016-01-30â€“2020-12-30 â†’ predicted\n",
            "2021-02-28: trained 2016-02-29â€“2021-01-30 â†’ predicted\n",
            "2021-03-30: trained 2016-03-30â€“2021-02-28 â†’ predicted\n",
            "2021-04-30: trained 2016-04-30â€“2021-03-30 â†’ predicted\n",
            "2021-05-30: trained 2016-05-30â€“2021-04-30 â†’ predicted\n",
            "2021-06-30: trained 2016-06-30â€“2021-05-30 â†’ predicted\n",
            "2021-07-30: trained 2016-07-30â€“2021-06-30 â†’ predicted\n",
            "2021-08-30: trained 2016-08-30â€“2021-07-30 â†’ predicted\n",
            "2021-09-30: trained 2016-09-30â€“2021-08-30 â†’ predicted\n",
            "2021-10-30: trained 2016-10-30â€“2021-09-30 â†’ predicted\n",
            "2021-11-30: trained 2016-11-30â€“2021-10-30 â†’ predicted\n",
            "2021-12-30: trained 2016-12-30â€“2021-11-30 â†’ predicted\n",
            "2022-01-30: trained 2017-01-30â€“2021-12-30 â†’ predicted\n",
            "2022-02-28: trained 2017-02-28â€“2022-01-30 â†’ predicted\n",
            "2022-03-30: trained 2017-03-30â€“2022-02-28 â†’ predicted\n",
            "2022-04-30: trained 2017-04-30â€“2022-03-30 â†’ predicted\n",
            "2022-05-30: trained 2017-05-30â€“2022-04-30 â†’ predicted\n",
            "2022-06-30: trained 2017-06-30â€“2022-05-30 â†’ predicted\n",
            "2022-07-30: trained 2017-07-30â€“2022-06-30 â†’ predicted\n",
            "2022-08-30: trained 2017-08-30â€“2022-07-30 â†’ predicted\n",
            "2022-09-30: trained 2017-09-30â€“2022-08-30 â†’ predicted\n",
            "2022-10-30: trained 2017-10-30â€“2022-09-30 â†’ predicted\n",
            "2022-11-30: trained 2017-11-30â€“2022-10-30 â†’ predicted\n",
            "2022-12-30: trained 2017-12-30â€“2022-11-30 â†’ predicted\n",
            "2023-01-30: trained 2018-01-30â€“2022-12-30 â†’ predicted\n",
            "2023-02-28: trained 2018-02-28â€“2023-01-30 â†’ predicted\n",
            "2023-03-30: trained 2018-03-30â€“2023-02-28 â†’ predicted\n",
            "2023-04-30: trained 2018-04-30â€“2023-03-30 â†’ predicted\n",
            "2023-05-30: trained 2018-05-30â€“2023-04-30 â†’ predicted\n",
            "2023-06-30: trained 2018-06-30â€“2023-05-30 â†’ predicted\n",
            "2023-07-30: trained 2018-07-30â€“2023-06-30 â†’ predicted\n",
            "2023-08-30: trained 2018-08-30â€“2023-07-30 â†’ predicted\n",
            "2023-09-30: trained 2018-09-30â€“2023-08-30 â†’ predicted\n",
            "2023-10-30: trained 2018-10-30â€“2023-09-30 â†’ predicted\n",
            "2023-11-30: trained 2018-11-30â€“2023-10-30 â†’ predicted\n",
            "2023-12-30: trained 2018-12-30â€“2023-11-30 â†’ predicted\n",
            "2024-01-30: trained 2019-01-30â€“2023-12-30 â†’ predicted\n",
            "2024-02-29: trained 2019-02-28â€“2024-01-30 â†’ predicted\n",
            "2024-03-30: trained 2019-03-30â€“2024-02-29 â†’ predicted\n",
            "2024-04-30: trained 2019-04-30â€“2024-03-30 â†’ predicted\n",
            "2024-05-30: trained 2019-05-30â€“2024-04-30 â†’ predicted\n",
            "2024-06-30: trained 2019-06-30â€“2024-05-30 â†’ predicted\n",
            "2024-07-30: trained 2019-07-30â€“2024-06-30 â†’ predicted\n",
            "2024-08-30: trained 2019-08-30â€“2024-07-30 â†’ predicted\n",
            "2024-09-30: trained 2019-09-30â€“2024-08-30 â†’ predicted\n",
            "2024-10-30: trained 2019-10-30â€“2024-09-30 â†’ predicted\n",
            "2024-11-30: trained 2019-11-30â€“2024-10-30 â†’ predicted\n",
            "Columns: ['Regime', 'Predicted_month', 'Train_Start_Date', 'Train_End_Date', 'Train_Count', 'Feature_Importances', 'Predicted_Probabilities', 'Predicted_Winner', 'Allocated_Return', 'Equal_Weight_Return', 'Actual_Winner', 'Num_Trees', 'Average_Tree_Depth', 'Max_Tree_Depth', 'Prediction_Horizon_Months', 'Feature_Level_CPI%', 'Feature_Level_T10Y3', 'Feature_Level_CFNAI', 'Feature_Level_GARCH_1M', 'Feature_Level_SMB_MA12', 'Feature_Level_HML_MA12', 'Feature_Level_CMA_MA12', 'Feature_Level_RMW_MA12']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "622  NoRegime      2024-02-29       2019-02-28     2024-01-30           60   \n",
              "623  NoRegime      2024-03-30       2019-03-30     2024-02-29           60   \n",
              "624  NoRegime      2024-04-30       2019-04-30     2024-03-30           60   \n",
              "625  NoRegime      2024-05-30       2019-05-30     2024-04-30           60   \n",
              "626  NoRegime      2024-06-30       2019-06-30     2024-05-30           60   \n",
              "627  NoRegime      2024-07-30       2019-07-30     2024-06-30           60   \n",
              "628  NoRegime      2024-08-30       2019-08-30     2024-07-30           60   \n",
              "629  NoRegime      2024-09-30       2019-09-30     2024-08-30           60   \n",
              "630  NoRegime      2024-10-30       2019-10-30     2024-09-30           60   \n",
              "631  NoRegime      2024-11-30       2019-11-30     2024-10-30           60   \n",
              "\n",
              "                                   Feature_Importances  \\\n",
              "622  [0.0013977369972425638, 0.07762256067207719, 0...   \n",
              "623  [0.0016301259096684801, 0.037638442878595385, ...   \n",
              "624  [0.0012938005390835628, 0.0377358490566038, 0....   \n",
              "625  [0.0, 0.030191507077435457, 0.4007972240327639...   \n",
              "626  [0.0, 0.029698996655518374, 0.4463940544995044...   \n",
              "627  [0.033400804348786825, 0.0, 0.5214319012013514...   \n",
              "628  [0.0, 0.0, 0.39146147166441136, 0.102862009504...   \n",
              "629  [0.09967845659163997, 0.3370695964671346, 0.14...   \n",
              "630  [0.1272924710424714, 0.31321027193621065, 0.11...   \n",
              "631  [0.13392007817204687, 0.2817468067595945, 0.14...   \n",
              "\n",
              "                               Predicted_Probabilities Predicted_Winner  \\\n",
              "622  [0.030000000000000006, 0.0, 0.0, 0.96999999999...              RMW   \n",
              "623  [0.518, 0.24600000000000016, 0.235999999999999...              SMB   \n",
              "624                           [0.0, 0.625, 0.375, 0.0]              HML   \n",
              "625                               [0.0, 0.0, 0.0, 1.0]              RMW   \n",
              "626                               [0.0, 0.0, 0.0, 1.0]              RMW   \n",
              "627  [0.39999999999999925, 0.19999999999999962, 0.0...              RMW   \n",
              "628                               [0.5, 0.0, 0.0, 0.5]              RMW   \n",
              "629  [0.3333333333333329, 0.0, 0.16666666666666646,...              RMW   \n",
              "630                               [0.0, 0.0, 0.0, 1.0]              RMW   \n",
              "631  [0.11111111111111088, 0.11111111111111088, 0.4...              CMA   \n",
              "\n",
              "     Allocated_Return  Equal_Weight_Return  ... Max_Tree_Depth  \\\n",
              "622         -0.019434            -0.021050  ...              5   \n",
              "623          0.007077             0.014250  ...              5   \n",
              "624         -0.004375            -0.004725  ...              5   \n",
              "625          0.029700            -0.002500  ...              4   \n",
              "626          0.005100            -0.022375  ...              4   \n",
              "627          0.045480             0.036675  ...              5   \n",
              "628         -0.014000            -0.007675  ...              5   \n",
              "629         -0.003633            -0.009575  ...              7   \n",
              "630         -0.013800            -0.000850  ...              6   \n",
              "631         -0.013122            -0.000150  ...              6   \n",
              "\n",
              "     Prediction_Horizon_Months  Feature_Level_CPI%  Feature_Level_T10Y3  \\\n",
              "622                          1             0.21033                -1.23   \n",
              "623                          1             0.34301                -0.99   \n",
              "624                          1             0.39639                -1.04   \n",
              "625                          1             0.34885                -0.55   \n",
              "626                          1             0.29125                -0.74   \n",
              "627                          1             0.03961                -0.88   \n",
              "628                          1            -0.00287                -1.11   \n",
              "629                          1             0.13892                -1.14   \n",
              "630                          1             0.18019                -0.91   \n",
              "631                          1             0.22920                -0.23   \n",
              "\n",
              "     Feature_Level_CFNAI  Feature_Level_GARCH_1M  Feature_Level_SMB_MA12  \\\n",
              "622                -0.14                0.726558               -0.002417   \n",
              "623                -0.83                0.780011               -0.010833   \n",
              "624                 0.39                0.496170               -0.012017   \n",
              "625                -0.20                0.944764               -0.007225   \n",
              "626                -0.39                0.569002               -0.007208   \n",
              "627                 0.15                0.327046               -0.006250   \n",
              "628                -0.17                1.087011               -0.011025   \n",
              "629                -0.30                0.641443               -0.006492   \n",
              "630                -0.05                0.396629               -0.006467   \n",
              "631                -0.21                0.684819               -0.005825   \n",
              "\n",
              "     Feature_Level_HML_MA12  Feature_Level_CMA_MA12  Feature_Level_RMW_MA12  \n",
              "622               -0.008700               -0.014225                0.003442  \n",
              "623               -0.007425               -0.011375                0.006008  \n",
              "624               -0.009667               -0.012075                0.003500  \n",
              "625                0.001242               -0.009092                0.002783  \n",
              "626                0.000850               -0.011717                0.002000  \n",
              "627                0.005908               -0.008275                0.005992  \n",
              "628                0.003317               -0.008408                0.004525  \n",
              "629                0.004675               -0.008567                0.005183  \n",
              "630                0.004633               -0.005875                0.003042  \n",
              "631                0.001267               -0.005392                0.001533  \n",
              "\n",
              "[10 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-193c542d-8d15-42bc-8d0f-3080bb01404b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>2024-01-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0013977369972425638, 0.07762256067207719, 0...</td>\n",
              "      <td>[0.030000000000000006, 0.0, 0.0, 0.96999999999...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019434</td>\n",
              "      <td>-0.021050</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.21033</td>\n",
              "      <td>-1.23</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.726558</td>\n",
              "      <td>-0.002417</td>\n",
              "      <td>-0.008700</td>\n",
              "      <td>-0.014225</td>\n",
              "      <td>0.003442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-03-30</td>\n",
              "      <td>2019-03-30</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0016301259096684801, 0.037638442878595385, ...</td>\n",
              "      <td>[0.518, 0.24600000000000016, 0.235999999999999...</td>\n",
              "      <td>SMB</td>\n",
              "      <td>0.007077</td>\n",
              "      <td>0.014250</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.34301</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>0.780011</td>\n",
              "      <td>-0.010833</td>\n",
              "      <td>-0.007425</td>\n",
              "      <td>-0.011375</td>\n",
              "      <td>0.006008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-04-30</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>2024-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0012938005390835628, 0.0377358490566038, 0....</td>\n",
              "      <td>[0.0, 0.625, 0.375, 0.0]</td>\n",
              "      <td>HML</td>\n",
              "      <td>-0.004375</td>\n",
              "      <td>-0.004725</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.39639</td>\n",
              "      <td>-1.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>-0.012017</td>\n",
              "      <td>-0.009667</td>\n",
              "      <td>-0.012075</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-05-30</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>2024-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.030191507077435457, 0.4007972240327639...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.34885</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>0.944764</td>\n",
              "      <td>-0.007225</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>-0.009092</td>\n",
              "      <td>0.002783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>2019-06-30</td>\n",
              "      <td>2024-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.029698996655518374, 0.4463940544995044...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>-0.022375</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29125</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>0.569002</td>\n",
              "      <td>-0.007208</td>\n",
              "      <td>0.000850</td>\n",
              "      <td>-0.011717</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>2019-07-30</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.033400804348786825, 0.0, 0.5214319012013514...</td>\n",
              "      <td>[0.39999999999999925, 0.19999999999999962, 0.0...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.045480</td>\n",
              "      <td>0.036675</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03961</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.327046</td>\n",
              "      <td>-0.006250</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>-0.008275</td>\n",
              "      <td>0.005992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>2019-08-30</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.0, 0.39146147166441136, 0.102862009504...</td>\n",
              "      <td>[0.5, 0.0, 0.0, 0.5]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.014000</td>\n",
              "      <td>-0.007675</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.00287</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.087011</td>\n",
              "      <td>-0.011025</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>-0.008408</td>\n",
              "      <td>0.004525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.09967845659163997, 0.3370695964671346, 0.14...</td>\n",
              "      <td>[0.3333333333333329, 0.0, 0.16666666666666646,...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.003633</td>\n",
              "      <td>-0.009575</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13892</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.641443</td>\n",
              "      <td>-0.006492</td>\n",
              "      <td>0.004675</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.005183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>2019-10-30</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1272924710424714, 0.31321027193621065, 0.11...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.013800</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.18019</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.396629</td>\n",
              "      <td>-0.006467</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>-0.005875</td>\n",
              "      <td>0.003042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-11-30</td>\n",
              "      <td>2019-11-30</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13392007817204687, 0.2817468067595945, 0.14...</td>\n",
              "      <td>[0.11111111111111088, 0.11111111111111088, 0.4...</td>\n",
              "      <td>CMA</td>\n",
              "      <td>-0.013122</td>\n",
              "      <td>-0.000150</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22920</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.684819</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>-0.005392</td>\n",
              "      <td>0.001533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-193c542d-8d15-42bc-8d0f-3080bb01404b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-193c542d-8d15-42bc-8d0f-3080bb01404b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-193c542d-8d15-42bc-8d0f-3080bb01404b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78fe4f4a-3683-4d04-afc9-83d7c6bd07ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78fe4f4a-3683-4d04-afc9-83d7c6bd07ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78fe4f4a-3683-4d04-afc9-83d7c6bd07ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cumulative 2000-01-01â€“2024-11-30: ML=2.4346, EW=1.1529\n",
            "\n",
            "Total 1972-04-30â€“2024-11-30: ML=11.1029, EW=3.5990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RF tree visualization"
      ],
      "metadata": {
        "id": "bDYVybt7Bcnd"
      },
      "id": "bDYVybt7Bcnd"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF:\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # CELL: Interactive selector for prediction date & tree number\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  import ipywidgets as widgets\n",
        "  from IPython.display import display\n",
        "  from sklearn import tree\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # build a list of the dates you predicted on\n",
        "  prediction_dates = [\n",
        "      res['Predicted_month'].date()\n",
        "      for res in results  # or results_df_rf['Predicted_month']\n",
        "  ]\n",
        "\n",
        "  # map date â†’ model\n",
        "  model_by_date = dict(zip(prediction_dates, rf_models))\n",
        "\n",
        "  # widget for selecting date\n",
        "  date_widget = widgets.Dropdown(\n",
        "      options=prediction_dates,\n",
        "      description='Date:',\n",
        "  )\n",
        "\n",
        "  # widget for selecting tree index\n",
        "  tree_widget = widgets.IntSlider(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=rf_params['n_estimators'] - 1,\n",
        "      step=1,\n",
        "      description='Tree #:',\n",
        "  )\n",
        "\n",
        "  def plot_tree_for_selection(chosen_date, tree_idx):\n",
        "      model = model_by_date[chosen_date]\n",
        "      estimator = model.estimators_[tree_idx]\n",
        "      plt.figure(figsize=(20, 10))\n",
        "      tree.plot_tree(\n",
        "          estimator,\n",
        "          feature_names=RF1_FEATURES,\n",
        "          class_names=[str(c) for c in model.classes_],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=8,\n",
        "      )\n",
        "      plt.title(f'Tree {tree_idx} from prediction on {chosen_date}')\n",
        "      plt.show()\n",
        "\n",
        "  # wire up interactive display\n",
        "  interactive_ui = widgets.interactive(\n",
        "      plot_tree_for_selection,\n",
        "      chosen_date=date_widget,\n",
        "      tree_idx=tree_widget\n",
        "  )\n",
        "  display(interactive_ui)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543,
          "referenced_widgets": [
            "e48b8849ed8d4c6f8bf5e37d00360566",
            "efd11c641b61473db4347b0d90c95e9b",
            "6ca13ab2bbd74e6ba8ce6a3c35f9124b",
            "4bd7ecbf6ea84721ba80762657f1727d",
            "846a31c1bcb64bfaa434e1912df3c121",
            "dc4e8cb0949646bcb877d6980c46066c",
            "85dbe666241343c2820fd4410d53b580",
            "e1f0ae204c624361bd11f6860b23e65b",
            "21508da16fc3437f999fdc7b5557ec08",
            "28028ef84fae4c7b9fbaf48524d74dab"
          ]
        },
        "id": "oL71XtZjsJp1",
        "outputId": "be4d5279-bf32-4829-bbb1-370bca2fe9dc"
      },
      "id": "oL71XtZjsJp1",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Dropdown(description='Date:', options=(datetime.date(1972, 4, 30), datetime.date(1972, 5â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e48b8849ed8d4c6f8bf5e37d00360566"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RF2"
      ],
      "metadata": {
        "id": "JuCQA8Oco0kP"
      },
      "id": "JuCQA8Oco0kP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 â€” second RF run under RF2\n",
        "if RF2:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -------------------\n",
        "    # RF2: Drop _MA12 and GARCH_1M\n",
        "    # -------------------\n",
        "    RF2_FEATURES = [f for f in FEATURES if not f.endswith('_MA12') and f != 'GARCH_1M']\n",
        "    #RF2_FEATURES = [f for f in FEATURES if f not in ['Cape']]\n",
        "\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train    = 60\n",
        "    min_obs_regime      = 50\n",
        "    min_obs_train       = 0\n",
        "    use_regime_split    = False\n",
        "    default_hyperparams = False\n",
        "\n",
        "    use_fixed_window    = True\n",
        "    rolling_window_size = 60\n",
        "\n",
        "    n_jobs = -1\n",
        "\n",
        "    # -------------------\n",
        "    # Hyperparameter Settings\n",
        "    # -------------------\n",
        "    if default_hyperparams:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': 'sqrt',\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'bootstrap': True,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "    else:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': None,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 5,\n",
        "            'bootstrap': False,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results_rf2 = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Main Loop\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # Build window\n",
        "        if use_fixed_window:\n",
        "            start_idx = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        # Skip if insufficient data or overlapping dates\n",
        "        if len(train_window) < min_months_train:\n",
        "            continue\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            continue\n",
        "\n",
        "        # Prepare X_train / y_train using RF2_FEATURES\n",
        "        X_train = train_window[RF2_FEATURES].dropna()\n",
        "        y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "        if len(X_train) < min_obs_train:\n",
        "            continue\n",
        "\n",
        "        # Train RF\n",
        "        rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Prepare X_test\n",
        "        X_test = train_window[RF2_FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            continue\n",
        "\n",
        "        # Predict and map probabilities\n",
        "        probs = rf_model.predict_proba(X_test)[0]\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for cls, p in zip(rf_model.classes_, probs):\n",
        "            if cls in FACTORS:\n",
        "                full_probs[FACTORS.index(cls)] = p\n",
        "\n",
        "        # Calculate returns\n",
        "        allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "        # Feature levels from RF2_FEATURES\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in RF2_FEATURES}\n",
        "\n",
        "        result = {\n",
        "            'Regime': 'NoRegime',\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_window['Date'].iloc[0],\n",
        "            'Train_End_Date': last_train_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': rf_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': rf_model.classes_[probs.argmax()],\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': rf_model.n_estimators,\n",
        "            'Average_Tree_Depth': np.mean([t.tree_.max_depth for t in rf_model.estimators_]),\n",
        "            'Max_Tree_Depth': np.max([t.tree_.max_depth for t in rf_model.estimators_]),\n",
        "            'Prediction_Horizon_Months': ((Predicted_month.year - last_train_date.year) * 12 +\n",
        "                                         (Predicted_month.month - last_train_date.month)),\n",
        "            **feature_levels\n",
        "        }\n",
        "        results_rf2.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Build RF2 results DataFrame\n",
        "    # -------------------\n",
        "    results_df_rf2 = pd.DataFrame(results_rf2)\n",
        "    print(\"Final results_df_rf2 columns:\", results_df_rf2.columns.tolist())\n",
        "    display(results_df_rf2.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # Cumulative returns (2000 onward & total)\n",
        "    # -------------------\n",
        "    filtered2 = results_df_rf2[results_df_rf2['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "    if not filtered2.empty:\n",
        "        cum_alloc2 = (1 + filtered2['Allocated_Return']).prod() - 1\n",
        "        cum_eq2    = (1 + filtered2['Equal_Weight_Return']).prod() - 1\n",
        "        print(f\"Cumulative 2000â€“present â€” RF2: {cum_alloc2:.4f}  /  Equal: {cum_eq2:.4f}\")\n",
        "\n",
        "    if not results_df_rf2.empty:\n",
        "        cum_alloc_all2 = (1 + results_df_rf2['Allocated_Return']).prod() - 1\n",
        "        cum_eq_all2    = (1 + results_df_rf2['Equal_Weight_Return']).prod() - 1\n",
        "        print(f\"Total cumulative â€” RF2: {cum_alloc_all2:.4f}  /  Equal: {cum_eq_all2:.4f}\")\n"
      ],
      "metadata": {
        "id": "CMbhV42UouKY"
      },
      "id": "CMbhV42UouKY",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient boosting\n"
      ],
      "metadata": {
        "id": "MSWv9xFlDbMz"
      },
      "id": "MSWv9xFlDbMz"
    },
    {
      "cell_type": "code",
      "source": [
        "if GB:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from xgboost import XGBClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train = 60     # Minimum months of data needed (5 years for monthly data)\n",
        "    min_obs_regime = 50       # Minimum observations per regime if splitting\n",
        "    min_obs_train = 0         # Minimum total observations after dropping NAs\n",
        "    use_regime_split = False  # Toggle regime-based training or not\n",
        "    default_hyperparameters = False  # If True, override manually set hyperparameters\n",
        "\n",
        "    # Toggle for training window type:\n",
        "    use_fixed_window = True   # True for fixed (rolling) window, False for expanding window\n",
        "    rolling_window_size = 60  # When using a fixed window, use this many most recent rows\n",
        "\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Main Loop: Predict for each row in df_sorted\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # Build training window: either fixed-size (rolling) or expanding window\n",
        "        if use_fixed_window:\n",
        "            start_idx = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        # Check that we have enough training rows (i.e., months)\n",
        "        if len(train_window) < min_months_train:\n",
        "            print(f\"Test row date: {Predicted_month.date()} - Insufficient training rows ({len(train_window)} rows). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Get first and last training dates\n",
        "        train_start_date = train_window['Date'].iloc[0]\n",
        "        train_end_date = train_window['Date'].iloc[-1]\n",
        "\n",
        "        # Regime-based checks (if enabled)\n",
        "        if use_regime_split:\n",
        "            regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "            insufficient_regimes = regime_counts[regime_counts < min_obs_regime].index.tolist()\n",
        "            if insufficient_regimes:\n",
        "                regime_str_list = [regime_short_mapping.get(r, str(r)) for r in insufficient_regimes]\n",
        "                regime_str = \", \".join(regime_str_list)\n",
        "                print(f\"Test row date: {Predicted_month.date()}\")\n",
        "                print(f\"  Regime split active. Insufficient data in: {regime_str}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Use only training data for the current regime\n",
        "            current_regime = test_row[REGIMES_COLUMN]\n",
        "            train_window = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "            if len(train_window) < min_obs_regime:\n",
        "                regime_str = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "                print(f\"Test row date: {Predicted_month.date()}\")\n",
        "                print(f\"  Regime split active ({regime_str}). Only {len(train_window)} obs. Skipping.\")\n",
        "                continue\n",
        "            regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "        else:\n",
        "            regime_used = 'NoRegime'\n",
        "\n",
        "        # Ensure the last training date is strictly before the test date\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            print(f\"Test row {Predicted_month.date()}: last training date not strictly before test month. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Prepare training data\n",
        "        X_train = train_window[FEATURES].dropna()\n",
        "        y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "        if len(X_train) < min_obs_train:\n",
        "            print(f\"   -> After dropping NAs: {len(X_train)} < {min_obs_train}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Convert y_train from strings to numeric codes and save mapping\n",
        "        y_train_cat = y_train.astype('category')\n",
        "        mapping = dict(enumerate(y_train_cat.cat.categories))\n",
        "        y_train_numeric = y_train_cat.cat.codes\n",
        "\n",
        "        # -------------------\n",
        "        # Set hyperparameters based on default_hyperparameters flag\n",
        "        # -------------------\n",
        "        if default_hyperparameters:\n",
        "            xgb_params = {\n",
        "                'n_estimators': 100,\n",
        "                'max_depth': 3,\n",
        "                'learning_rate': 0.1,\n",
        "                'subsample': 1.0,\n",
        "                'colsample_bytree': 1.0,\n",
        "                'random_state': 42,\n",
        "                'eval_metric': 'mlogloss'\n",
        "            }\n",
        "        else:\n",
        "            # Use manually defined hyperparameters (from Optuna or otherwise)\n",
        "          xgb_params = {\n",
        "              'n_estimators':      200,\n",
        "              'max_depth':         15,\n",
        "              'learning_rate':     0.17,\n",
        "              'subsample':         0.75,\n",
        "              'colsample_bytree':  0.5,\n",
        "              'min_child_weight':  7,\n",
        "              'random_state':      42,\n",
        "              'n_jobs':            -1,\n",
        "              'eval_metric':       'mlogloss'\n",
        "          }\n",
        "\n",
        "\n",
        "        # Fit XGBoost gradient boosting classifier on numeric labels (full training, no early stopping)\n",
        "        xgb_model = XGBClassifier(**xgb_params)\n",
        "        xgb_model.fit(X_train, y_train_numeric)\n",
        "\n",
        "        # Prepare test data (using the last row in the training window)\n",
        "        X_test = train_window[FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            print(\"   -> Test features empty, skipping iteration.\")\n",
        "            continue\n",
        "\n",
        "        predicted_probabilities = xgb_model.predict_proba(X_test)[0]\n",
        "        # Get predicted numeric class and convert back to original factor name\n",
        "        predicted_numeric = xgb_model.classes_[predicted_probabilities.argmax()]\n",
        "        predicted_winner = mapping[predicted_numeric]\n",
        "\n",
        "        # Map predicted probabilities onto the full set of FACTORS\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for code, prob in zip(xgb_model.classes_, predicted_probabilities):\n",
        "            factor_name = mapping[code]\n",
        "            try:\n",
        "                idx = FACTORS.index(factor_name)\n",
        "                full_probs[idx] = prob\n",
        "            except ValueError:\n",
        "                pass  # Skip if factor not found in FACTORS\n",
        "\n",
        "        # Compute allocated return and equal weight return using the test row's factor returns\n",
        "        allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "        # Tree depth statistics are not required for XGB; set to None\n",
        "        avg_depth = None\n",
        "        max_depth = None\n",
        "\n",
        "        # Calculate prediction horizon (months ahead)\n",
        "        months_ahead = (Predicted_month.year - last_train_date.year) * 12 + (Predicted_month.month - last_train_date.month)\n",
        "\n",
        "        # Store the actual feature levels used in X_test\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in FEATURES}\n",
        "\n",
        "        print(f\"Test row date: {Predicted_month.date()} -> Model trained, prediction made (using: {train_start_date.date()} - {train_end_date.date()})\")\n",
        "\n",
        "        # Build the result dictionary for this iteration\n",
        "        result = {\n",
        "            'Regime': regime_used,\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_start_date,\n",
        "            'Train_End_Date': train_end_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': xgb_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': predicted_winner,\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': xgb_model.n_estimators,\n",
        "            'Average_Tree_Depth': avg_depth,\n",
        "            'Max_Tree_Depth': max_depth,\n",
        "            'Prediction_Horizon_Months': months_ahead,\n",
        "            **feature_levels\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Build the final results DataFrame for GB\n",
        "    # -------------------\n",
        "    results_df_gb = pd.DataFrame(results)\n",
        "    print(\"Final results_df_gb columns:\", results_df_gb.columns.tolist())\n",
        "    display(results_df_gb.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # 4) Calculate and Print Cumulative Returns (Filtered: from 1 Jan 2000 onwards)\n",
        "    # -------------------\n",
        "    filtered_results = results_df_gb[results_df_gb['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "    if not filtered_results.empty:\n",
        "        cum_return_allocated = (1 + filtered_results['Allocated_Return']).prod() - 1\n",
        "        cum_return_equal = (1 + filtered_results['Equal_Weight_Return']).prod() - 1\n",
        "\n",
        "        first_pred_month = filtered_results.iloc[0]['Predicted_month']\n",
        "        last_pred_month = filtered_results.iloc[-1]['Predicted_month']\n",
        "\n",
        "        print(\"\\nCumulative returns {} - {} - ML strategy: {:.4f} / Equal weight: {:.4f}\".format(\n",
        "            first_pred_month.date(), last_pred_month.date(),\n",
        "            cum_return_allocated, cum_return_equal))\n",
        "    else:\n",
        "        print(\"No predictions from 1 Jan 2000 onwards.\")\n",
        "\n",
        "    # -------------------\n",
        "    # 5) Calculate and Print Cumulative Returns for Total Time\n",
        "    # -------------------\n",
        "    if not results_df_gb.empty:\n",
        "        cum_return_allocated_total = (1 + results_df_gb['Allocated_Return']).prod() - 1\n",
        "        cum_return_equal_total = (1 + results_df_gb['Equal_Weight_Return']).prod() - 1\n",
        "\n",
        "        first_total_month = results_df_gb.iloc[0]['Predicted_month']\n",
        "        last_total_month = results_df_gb.iloc[-1]['Predicted_month']\n",
        "\n",
        "        print(\"\\nCumulative returns {} - {} - ML strategy: {:.4f} / Equal weight: {:.4f}\".format(\n",
        "            first_total_month.date(), last_total_month.date(),\n",
        "            cum_return_allocated_total, cum_return_equal_total))\n",
        "    else:\n",
        "        print(\"No predictions available for total time.\")\n"
      ],
      "metadata": {
        "id": "9sWAd_BnDVlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35102242-e1d5-4f10-e929-540da1d8c9df"
      },
      "id": "9sWAd_BnDVlB",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test row date: 1967-05-30 - Insufficient training rows (1 rows). Skipping.\n",
            "Test row date: 1967-06-30 - Insufficient training rows (2 rows). Skipping.\n",
            "Test row date: 1967-07-30 - Insufficient training rows (3 rows). Skipping.\n",
            "Test row date: 1967-08-30 - Insufficient training rows (4 rows). Skipping.\n",
            "Test row date: 1967-09-30 - Insufficient training rows (5 rows). Skipping.\n",
            "Test row date: 1967-10-30 - Insufficient training rows (6 rows). Skipping.\n",
            "Test row date: 1967-11-30 - Insufficient training rows (7 rows). Skipping.\n",
            "Test row date: 1967-12-30 - Insufficient training rows (8 rows). Skipping.\n",
            "Test row date: 1968-01-30 - Insufficient training rows (9 rows). Skipping.\n",
            "Test row date: 1968-02-29 - Insufficient training rows (10 rows). Skipping.\n",
            "Test row date: 1968-03-30 - Insufficient training rows (11 rows). Skipping.\n",
            "Test row date: 1968-04-30 - Insufficient training rows (12 rows). Skipping.\n",
            "Test row date: 1968-05-30 - Insufficient training rows (13 rows). Skipping.\n",
            "Test row date: 1968-06-30 - Insufficient training rows (14 rows). Skipping.\n",
            "Test row date: 1968-07-30 - Insufficient training rows (15 rows). Skipping.\n",
            "Test row date: 1968-08-30 - Insufficient training rows (16 rows). Skipping.\n",
            "Test row date: 1968-09-30 - Insufficient training rows (17 rows). Skipping.\n",
            "Test row date: 1968-10-30 - Insufficient training rows (18 rows). Skipping.\n",
            "Test row date: 1968-11-30 - Insufficient training rows (19 rows). Skipping.\n",
            "Test row date: 1968-12-30 - Insufficient training rows (20 rows). Skipping.\n",
            "Test row date: 1969-01-30 - Insufficient training rows (21 rows). Skipping.\n",
            "Test row date: 1969-02-28 - Insufficient training rows (22 rows). Skipping.\n",
            "Test row date: 1969-03-30 - Insufficient training rows (23 rows). Skipping.\n",
            "Test row date: 1969-04-30 - Insufficient training rows (24 rows). Skipping.\n",
            "Test row date: 1969-05-30 - Insufficient training rows (25 rows). Skipping.\n",
            "Test row date: 1969-06-30 - Insufficient training rows (26 rows). Skipping.\n",
            "Test row date: 1969-07-30 - Insufficient training rows (27 rows). Skipping.\n",
            "Test row date: 1969-08-30 - Insufficient training rows (28 rows). Skipping.\n",
            "Test row date: 1969-09-30 - Insufficient training rows (29 rows). Skipping.\n",
            "Test row date: 1969-10-30 - Insufficient training rows (30 rows). Skipping.\n",
            "Test row date: 1969-11-30 - Insufficient training rows (31 rows). Skipping.\n",
            "Test row date: 1969-12-30 - Insufficient training rows (32 rows). Skipping.\n",
            "Test row date: 1970-01-30 - Insufficient training rows (33 rows). Skipping.\n",
            "Test row date: 1970-02-28 - Insufficient training rows (34 rows). Skipping.\n",
            "Test row date: 1970-03-30 - Insufficient training rows (35 rows). Skipping.\n",
            "Test row date: 1970-04-30 - Insufficient training rows (36 rows). Skipping.\n",
            "Test row date: 1970-05-30 - Insufficient training rows (37 rows). Skipping.\n",
            "Test row date: 1970-06-30 - Insufficient training rows (38 rows). Skipping.\n",
            "Test row date: 1970-07-30 - Insufficient training rows (39 rows). Skipping.\n",
            "Test row date: 1970-08-30 - Insufficient training rows (40 rows). Skipping.\n",
            "Test row date: 1970-09-30 - Insufficient training rows (41 rows). Skipping.\n",
            "Test row date: 1970-10-30 - Insufficient training rows (42 rows). Skipping.\n",
            "Test row date: 1970-11-30 - Insufficient training rows (43 rows). Skipping.\n",
            "Test row date: 1970-12-30 - Insufficient training rows (44 rows). Skipping.\n",
            "Test row date: 1971-01-30 - Insufficient training rows (45 rows). Skipping.\n",
            "Test row date: 1971-02-28 - Insufficient training rows (46 rows). Skipping.\n",
            "Test row date: 1971-03-30 - Insufficient training rows (47 rows). Skipping.\n",
            "Test row date: 1971-04-30 - Insufficient training rows (48 rows). Skipping.\n",
            "Test row date: 1971-05-30 - Insufficient training rows (49 rows). Skipping.\n",
            "Test row date: 1971-06-30 - Insufficient training rows (50 rows). Skipping.\n",
            "Test row date: 1971-07-30 - Insufficient training rows (51 rows). Skipping.\n",
            "Test row date: 1971-08-30 - Insufficient training rows (52 rows). Skipping.\n",
            "Test row date: 1971-09-30 - Insufficient training rows (53 rows). Skipping.\n",
            "Test row date: 1971-10-30 - Insufficient training rows (54 rows). Skipping.\n",
            "Test row date: 1971-11-30 - Insufficient training rows (55 rows). Skipping.\n",
            "Test row date: 1971-12-30 - Insufficient training rows (56 rows). Skipping.\n",
            "Test row date: 1972-01-30 - Insufficient training rows (57 rows). Skipping.\n",
            "Test row date: 1972-02-29 - Insufficient training rows (58 rows). Skipping.\n",
            "Test row date: 1972-03-30 - Insufficient training rows (59 rows). Skipping.\n",
            "Test row date: 1972-04-30 -> Model trained, prediction made (using: 1967-04-30 - 1972-03-30)\n",
            "Test row date: 1972-05-30 -> Model trained, prediction made (using: 1967-05-30 - 1972-04-30)\n",
            "Test row date: 1972-06-30 -> Model trained, prediction made (using: 1967-06-30 - 1972-05-30)\n",
            "Test row date: 1972-07-30 -> Model trained, prediction made (using: 1967-07-30 - 1972-06-30)\n",
            "Test row date: 1972-08-30 -> Model trained, prediction made (using: 1967-08-30 - 1972-07-30)\n",
            "Test row date: 1972-09-30 -> Model trained, prediction made (using: 1967-09-30 - 1972-08-30)\n",
            "Test row date: 1972-10-30 -> Model trained, prediction made (using: 1967-10-30 - 1972-09-30)\n",
            "Test row date: 1972-11-30 -> Model trained, prediction made (using: 1967-11-30 - 1972-10-30)\n",
            "Test row date: 1972-12-30 -> Model trained, prediction made (using: 1967-12-30 - 1972-11-30)\n",
            "Test row date: 1973-01-30 -> Model trained, prediction made (using: 1968-01-30 - 1972-12-30)\n",
            "Test row date: 1973-02-28 -> Model trained, prediction made (using: 1968-02-29 - 1973-01-30)\n",
            "Test row date: 1973-03-30 -> Model trained, prediction made (using: 1968-03-30 - 1973-02-28)\n",
            "Test row date: 1973-04-30 -> Model trained, prediction made (using: 1968-04-30 - 1973-03-30)\n",
            "Test row date: 1973-05-30 -> Model trained, prediction made (using: 1968-05-30 - 1973-04-30)\n",
            "Test row date: 1973-06-30 -> Model trained, prediction made (using: 1968-06-30 - 1973-05-30)\n",
            "Test row date: 1973-07-30 -> Model trained, prediction made (using: 1968-07-30 - 1973-06-30)\n",
            "Test row date: 1973-08-30 -> Model trained, prediction made (using: 1968-08-30 - 1973-07-30)\n",
            "Test row date: 1973-09-30 -> Model trained, prediction made (using: 1968-09-30 - 1973-08-30)\n",
            "Test row date: 1973-10-30 -> Model trained, prediction made (using: 1968-10-30 - 1973-09-30)\n",
            "Test row date: 1973-11-30 -> Model trained, prediction made (using: 1968-11-30 - 1973-10-30)\n",
            "Test row date: 1973-12-30 -> Model trained, prediction made (using: 1968-12-30 - 1973-11-30)\n",
            "Test row date: 1974-01-30 -> Model trained, prediction made (using: 1969-01-30 - 1973-12-30)\n",
            "Test row date: 1974-02-28 -> Model trained, prediction made (using: 1969-02-28 - 1974-01-30)\n",
            "Test row date: 1974-03-30 -> Model trained, prediction made (using: 1969-03-30 - 1974-02-28)\n",
            "Test row date: 1974-04-30 -> Model trained, prediction made (using: 1969-04-30 - 1974-03-30)\n",
            "Test row date: 1974-05-30 -> Model trained, prediction made (using: 1969-05-30 - 1974-04-30)\n",
            "Test row date: 1974-06-30 -> Model trained, prediction made (using: 1969-06-30 - 1974-05-30)\n",
            "Test row date: 1974-07-30 -> Model trained, prediction made (using: 1969-07-30 - 1974-06-30)\n",
            "Test row date: 1974-08-30 -> Model trained, prediction made (using: 1969-08-30 - 1974-07-30)\n",
            "Test row date: 1974-09-30 -> Model trained, prediction made (using: 1969-09-30 - 1974-08-30)\n",
            "Test row date: 1974-10-30 -> Model trained, prediction made (using: 1969-10-30 - 1974-09-30)\n",
            "Test row date: 1974-11-30 -> Model trained, prediction made (using: 1969-11-30 - 1974-10-30)\n",
            "Test row date: 1974-12-30 -> Model trained, prediction made (using: 1969-12-30 - 1974-11-30)\n",
            "Test row date: 1975-01-30 -> Model trained, prediction made (using: 1970-01-30 - 1974-12-30)\n",
            "Test row date: 1975-02-28 -> Model trained, prediction made (using: 1970-02-28 - 1975-01-30)\n",
            "Test row date: 1975-03-30 -> Model trained, prediction made (using: 1970-03-30 - 1975-02-28)\n",
            "Test row date: 1975-04-30 -> Model trained, prediction made (using: 1970-04-30 - 1975-03-30)\n",
            "Test row date: 1975-05-30 -> Model trained, prediction made (using: 1970-05-30 - 1975-04-30)\n",
            "Test row date: 1975-06-30 -> Model trained, prediction made (using: 1970-06-30 - 1975-05-30)\n",
            "Test row date: 1975-07-30 -> Model trained, prediction made (using: 1970-07-30 - 1975-06-30)\n",
            "Test row date: 1975-08-30 -> Model trained, prediction made (using: 1970-08-30 - 1975-07-30)\n",
            "Test row date: 1975-09-30 -> Model trained, prediction made (using: 1970-09-30 - 1975-08-30)\n",
            "Test row date: 1975-10-30 -> Model trained, prediction made (using: 1970-10-30 - 1975-09-30)\n",
            "Test row date: 1975-11-30 -> Model trained, prediction made (using: 1970-11-30 - 1975-10-30)\n",
            "Test row date: 1975-12-30 -> Model trained, prediction made (using: 1970-12-30 - 1975-11-30)\n",
            "Test row date: 1976-01-30 -> Model trained, prediction made (using: 1971-01-30 - 1975-12-30)\n",
            "Test row date: 1976-02-29 -> Model trained, prediction made (using: 1971-02-28 - 1976-01-30)\n",
            "Test row date: 1976-03-30 -> Model trained, prediction made (using: 1971-03-30 - 1976-02-29)\n",
            "Test row date: 1976-04-30 -> Model trained, prediction made (using: 1971-04-30 - 1976-03-30)\n",
            "Test row date: 1976-05-30 -> Model trained, prediction made (using: 1971-05-30 - 1976-04-30)\n",
            "Test row date: 1976-06-30 -> Model trained, prediction made (using: 1971-06-30 - 1976-05-30)\n",
            "Test row date: 1976-07-30 -> Model trained, prediction made (using: 1971-07-30 - 1976-06-30)\n",
            "Test row date: 1976-08-30 -> Model trained, prediction made (using: 1971-08-30 - 1976-07-30)\n",
            "Test row date: 1976-09-30 -> Model trained, prediction made (using: 1971-09-30 - 1976-08-30)\n",
            "Test row date: 1976-10-30 -> Model trained, prediction made (using: 1971-10-30 - 1976-09-30)\n",
            "Test row date: 1976-11-30 -> Model trained, prediction made (using: 1971-11-30 - 1976-10-30)\n",
            "Test row date: 1976-12-30 -> Model trained, prediction made (using: 1971-12-30 - 1976-11-30)\n",
            "Test row date: 1977-01-30 -> Model trained, prediction made (using: 1972-01-30 - 1976-12-30)\n",
            "Test row date: 1977-02-28 -> Model trained, prediction made (using: 1972-02-29 - 1977-01-30)\n",
            "Test row date: 1977-03-30 -> Model trained, prediction made (using: 1972-03-30 - 1977-02-28)\n",
            "Test row date: 1977-04-30 -> Model trained, prediction made (using: 1972-04-30 - 1977-03-30)\n",
            "Test row date: 1977-05-30 -> Model trained, prediction made (using: 1972-05-30 - 1977-04-30)\n",
            "Test row date: 1977-06-30 -> Model trained, prediction made (using: 1972-06-30 - 1977-05-30)\n",
            "Test row date: 1977-07-30 -> Model trained, prediction made (using: 1972-07-30 - 1977-06-30)\n",
            "Test row date: 1977-08-30 -> Model trained, prediction made (using: 1972-08-30 - 1977-07-30)\n",
            "Test row date: 1977-09-30 -> Model trained, prediction made (using: 1972-09-30 - 1977-08-30)\n",
            "Test row date: 1977-10-30 -> Model trained, prediction made (using: 1972-10-30 - 1977-09-30)\n",
            "Test row date: 1977-11-30 -> Model trained, prediction made (using: 1972-11-30 - 1977-10-30)\n",
            "Test row date: 1977-12-30 -> Model trained, prediction made (using: 1972-12-30 - 1977-11-30)\n",
            "Test row date: 1978-01-30 -> Model trained, prediction made (using: 1973-01-30 - 1977-12-30)\n",
            "Test row date: 1978-02-28 -> Model trained, prediction made (using: 1973-02-28 - 1978-01-30)\n",
            "Test row date: 1978-03-30 -> Model trained, prediction made (using: 1973-03-30 - 1978-02-28)\n",
            "Test row date: 1978-04-30 -> Model trained, prediction made (using: 1973-04-30 - 1978-03-30)\n",
            "Test row date: 1978-05-30 -> Model trained, prediction made (using: 1973-05-30 - 1978-04-30)\n",
            "Test row date: 1978-06-30 -> Model trained, prediction made (using: 1973-06-30 - 1978-05-30)\n",
            "Test row date: 1978-07-30 -> Model trained, prediction made (using: 1973-07-30 - 1978-06-30)\n",
            "Test row date: 1978-08-30 -> Model trained, prediction made (using: 1973-08-30 - 1978-07-30)\n",
            "Test row date: 1978-09-30 -> Model trained, prediction made (using: 1973-09-30 - 1978-08-30)\n",
            "Test row date: 1978-10-30 -> Model trained, prediction made (using: 1973-10-30 - 1978-09-30)\n",
            "Test row date: 1978-11-30 -> Model trained, prediction made (using: 1973-11-30 - 1978-10-30)\n",
            "Test row date: 1978-12-30 -> Model trained, prediction made (using: 1973-12-30 - 1978-11-30)\n",
            "Test row date: 1979-01-30 -> Model trained, prediction made (using: 1974-01-30 - 1978-12-30)\n",
            "Test row date: 1979-02-28 -> Model trained, prediction made (using: 1974-02-28 - 1979-01-30)\n",
            "Test row date: 1979-03-30 -> Model trained, prediction made (using: 1974-03-30 - 1979-02-28)\n",
            "Test row date: 1979-04-30 -> Model trained, prediction made (using: 1974-04-30 - 1979-03-30)\n",
            "Test row date: 1979-05-30 -> Model trained, prediction made (using: 1974-05-30 - 1979-04-30)\n",
            "Test row date: 1979-06-30 -> Model trained, prediction made (using: 1974-06-30 - 1979-05-30)\n",
            "Test row date: 1979-07-30 -> Model trained, prediction made (using: 1974-07-30 - 1979-06-30)\n",
            "Test row date: 1979-08-30 -> Model trained, prediction made (using: 1974-08-30 - 1979-07-30)\n",
            "Test row date: 1979-09-30 -> Model trained, prediction made (using: 1974-09-30 - 1979-08-30)\n",
            "Test row date: 1979-10-30 -> Model trained, prediction made (using: 1974-10-30 - 1979-09-30)\n",
            "Test row date: 1979-11-30 -> Model trained, prediction made (using: 1974-11-30 - 1979-10-30)\n",
            "Test row date: 1979-12-30 -> Model trained, prediction made (using: 1974-12-30 - 1979-11-30)\n",
            "Test row date: 1980-01-30 -> Model trained, prediction made (using: 1975-01-30 - 1979-12-30)\n",
            "Test row date: 1980-02-29 -> Model trained, prediction made (using: 1975-02-28 - 1980-01-30)\n",
            "Test row date: 1980-03-30 -> Model trained, prediction made (using: 1975-03-30 - 1980-02-29)\n",
            "Test row date: 1980-04-30 -> Model trained, prediction made (using: 1975-04-30 - 1980-03-30)\n",
            "Test row date: 1980-05-30 -> Model trained, prediction made (using: 1975-05-30 - 1980-04-30)\n",
            "Test row date: 1980-06-30 -> Model trained, prediction made (using: 1975-06-30 - 1980-05-30)\n",
            "Test row date: 1980-07-30 -> Model trained, prediction made (using: 1975-07-30 - 1980-06-30)\n",
            "Test row date: 1980-08-30 -> Model trained, prediction made (using: 1975-08-30 - 1980-07-30)\n",
            "Test row date: 1980-09-30 -> Model trained, prediction made (using: 1975-09-30 - 1980-08-30)\n",
            "Test row date: 1980-10-30 -> Model trained, prediction made (using: 1975-10-30 - 1980-09-30)\n",
            "Test row date: 1980-11-30 -> Model trained, prediction made (using: 1975-11-30 - 1980-10-30)\n",
            "Test row date: 1980-12-30 -> Model trained, prediction made (using: 1975-12-30 - 1980-11-30)\n",
            "Test row date: 1981-01-30 -> Model trained, prediction made (using: 1976-01-30 - 1980-12-30)\n",
            "Test row date: 1981-02-28 -> Model trained, prediction made (using: 1976-02-29 - 1981-01-30)\n",
            "Test row date: 1981-03-30 -> Model trained, prediction made (using: 1976-03-30 - 1981-02-28)\n",
            "Test row date: 1981-04-30 -> Model trained, prediction made (using: 1976-04-30 - 1981-03-30)\n",
            "Test row date: 1981-05-30 -> Model trained, prediction made (using: 1976-05-30 - 1981-04-30)\n",
            "Test row date: 1981-06-30 -> Model trained, prediction made (using: 1976-06-30 - 1981-05-30)\n",
            "Test row date: 1981-07-30 -> Model trained, prediction made (using: 1976-07-30 - 1981-06-30)\n",
            "Test row date: 1981-08-30 -> Model trained, prediction made (using: 1976-08-30 - 1981-07-30)\n",
            "Test row date: 1981-09-30 -> Model trained, prediction made (using: 1976-09-30 - 1981-08-30)\n",
            "Test row date: 1981-10-30 -> Model trained, prediction made (using: 1976-10-30 - 1981-09-30)\n",
            "Test row date: 1981-11-30 -> Model trained, prediction made (using: 1976-11-30 - 1981-10-30)\n",
            "Test row date: 1981-12-30 -> Model trained, prediction made (using: 1976-12-30 - 1981-11-30)\n",
            "Test row date: 1982-01-30 -> Model trained, prediction made (using: 1977-01-30 - 1981-12-30)\n",
            "Test row date: 1982-02-28 -> Model trained, prediction made (using: 1977-02-28 - 1982-01-30)\n",
            "Test row date: 1982-03-30 -> Model trained, prediction made (using: 1977-03-30 - 1982-02-28)\n",
            "Test row date: 1982-04-30 -> Model trained, prediction made (using: 1977-04-30 - 1982-03-30)\n",
            "Test row date: 1982-05-30 -> Model trained, prediction made (using: 1977-05-30 - 1982-04-30)\n",
            "Test row date: 1982-06-30 -> Model trained, prediction made (using: 1977-06-30 - 1982-05-30)\n",
            "Test row date: 1982-07-30 -> Model trained, prediction made (using: 1977-07-30 - 1982-06-30)\n",
            "Test row date: 1982-08-30 -> Model trained, prediction made (using: 1977-08-30 - 1982-07-30)\n",
            "Test row date: 1982-09-30 -> Model trained, prediction made (using: 1977-09-30 - 1982-08-30)\n",
            "Test row date: 1982-10-30 -> Model trained, prediction made (using: 1977-10-30 - 1982-09-30)\n",
            "Test row date: 1982-11-30 -> Model trained, prediction made (using: 1977-11-30 - 1982-10-30)\n",
            "Test row date: 1982-12-30 -> Model trained, prediction made (using: 1977-12-30 - 1982-11-30)\n",
            "Test row date: 1983-01-30 -> Model trained, prediction made (using: 1978-01-30 - 1982-12-30)\n",
            "Test row date: 1983-02-28 -> Model trained, prediction made (using: 1978-02-28 - 1983-01-30)\n",
            "Test row date: 1983-03-30 -> Model trained, prediction made (using: 1978-03-30 - 1983-02-28)\n",
            "Test row date: 1983-04-30 -> Model trained, prediction made (using: 1978-04-30 - 1983-03-30)\n",
            "Test row date: 1983-05-30 -> Model trained, prediction made (using: 1978-05-30 - 1983-04-30)\n",
            "Test row date: 1983-06-30 -> Model trained, prediction made (using: 1978-06-30 - 1983-05-30)\n",
            "Test row date: 1983-07-30 -> Model trained, prediction made (using: 1978-07-30 - 1983-06-30)\n",
            "Test row date: 1983-08-30 -> Model trained, prediction made (using: 1978-08-30 - 1983-07-30)\n",
            "Test row date: 1983-09-30 -> Model trained, prediction made (using: 1978-09-30 - 1983-08-30)\n",
            "Test row date: 1983-10-30 -> Model trained, prediction made (using: 1978-10-30 - 1983-09-30)\n",
            "Test row date: 1983-11-30 -> Model trained, prediction made (using: 1978-11-30 - 1983-10-30)\n",
            "Test row date: 1983-12-30 -> Model trained, prediction made (using: 1978-12-30 - 1983-11-30)\n",
            "Test row date: 1984-01-30 -> Model trained, prediction made (using: 1979-01-30 - 1983-12-30)\n",
            "Test row date: 1984-02-29 -> Model trained, prediction made (using: 1979-02-28 - 1984-01-30)\n",
            "Test row date: 1984-03-30 -> Model trained, prediction made (using: 1979-03-30 - 1984-02-29)\n",
            "Test row date: 1984-04-30 -> Model trained, prediction made (using: 1979-04-30 - 1984-03-30)\n",
            "Test row date: 1984-05-30 -> Model trained, prediction made (using: 1979-05-30 - 1984-04-30)\n",
            "Test row date: 1984-06-30 -> Model trained, prediction made (using: 1979-06-30 - 1984-05-30)\n",
            "Test row date: 1984-07-30 -> Model trained, prediction made (using: 1979-07-30 - 1984-06-30)\n",
            "Test row date: 1984-08-30 -> Model trained, prediction made (using: 1979-08-30 - 1984-07-30)\n",
            "Test row date: 1984-09-30 -> Model trained, prediction made (using: 1979-09-30 - 1984-08-30)\n",
            "Test row date: 1984-10-30 -> Model trained, prediction made (using: 1979-10-30 - 1984-09-30)\n",
            "Test row date: 1984-11-30 -> Model trained, prediction made (using: 1979-11-30 - 1984-10-30)\n",
            "Test row date: 1984-12-30 -> Model trained, prediction made (using: 1979-12-30 - 1984-11-30)\n",
            "Test row date: 1985-01-30 -> Model trained, prediction made (using: 1980-01-30 - 1984-12-30)\n",
            "Test row date: 1985-02-28 -> Model trained, prediction made (using: 1980-02-29 - 1985-01-30)\n",
            "Test row date: 1985-03-30 -> Model trained, prediction made (using: 1980-03-30 - 1985-02-28)\n",
            "Test row date: 1985-04-30 -> Model trained, prediction made (using: 1980-04-30 - 1985-03-30)\n",
            "Test row date: 1985-05-30 -> Model trained, prediction made (using: 1980-05-30 - 1985-04-30)\n",
            "Test row date: 1985-06-30 -> Model trained, prediction made (using: 1980-06-30 - 1985-05-30)\n",
            "Test row date: 1985-07-30 -> Model trained, prediction made (using: 1980-07-30 - 1985-06-30)\n",
            "Test row date: 1985-08-30 -> Model trained, prediction made (using: 1980-08-30 - 1985-07-30)\n",
            "Test row date: 1985-09-30 -> Model trained, prediction made (using: 1980-09-30 - 1985-08-30)\n",
            "Test row date: 1985-10-30 -> Model trained, prediction made (using: 1980-10-30 - 1985-09-30)\n",
            "Test row date: 1985-11-30 -> Model trained, prediction made (using: 1980-11-30 - 1985-10-30)\n",
            "Test row date: 1985-12-30 -> Model trained, prediction made (using: 1980-12-30 - 1985-11-30)\n",
            "Test row date: 1986-01-30 -> Model trained, prediction made (using: 1981-01-30 - 1985-12-30)\n",
            "Test row date: 1986-02-28 -> Model trained, prediction made (using: 1981-02-28 - 1986-01-30)\n",
            "Test row date: 1986-03-30 -> Model trained, prediction made (using: 1981-03-30 - 1986-02-28)\n",
            "Test row date: 1986-04-30 -> Model trained, prediction made (using: 1981-04-30 - 1986-03-30)\n",
            "Test row date: 1986-05-30 -> Model trained, prediction made (using: 1981-05-30 - 1986-04-30)\n",
            "Test row date: 1986-06-30 -> Model trained, prediction made (using: 1981-06-30 - 1986-05-30)\n",
            "Test row date: 1986-07-30 -> Model trained, prediction made (using: 1981-07-30 - 1986-06-30)\n",
            "Test row date: 1986-08-30 -> Model trained, prediction made (using: 1981-08-30 - 1986-07-30)\n",
            "Test row date: 1986-09-30 -> Model trained, prediction made (using: 1981-09-30 - 1986-08-30)\n",
            "Test row date: 1986-10-30 -> Model trained, prediction made (using: 1981-10-30 - 1986-09-30)\n",
            "Test row date: 1986-11-30 -> Model trained, prediction made (using: 1981-11-30 - 1986-10-30)\n",
            "Test row date: 1986-12-30 -> Model trained, prediction made (using: 1981-12-30 - 1986-11-30)\n",
            "Test row date: 1987-01-30 -> Model trained, prediction made (using: 1982-01-30 - 1986-12-30)\n",
            "Test row date: 1987-02-28 -> Model trained, prediction made (using: 1982-02-28 - 1987-01-30)\n",
            "Test row date: 1987-03-30 -> Model trained, prediction made (using: 1982-03-30 - 1987-02-28)\n",
            "Test row date: 1987-04-30 -> Model trained, prediction made (using: 1982-04-30 - 1987-03-30)\n",
            "Test row date: 1987-05-30 -> Model trained, prediction made (using: 1982-05-30 - 1987-04-30)\n",
            "Test row date: 1987-06-30 -> Model trained, prediction made (using: 1982-06-30 - 1987-05-30)\n",
            "Test row date: 1987-07-30 -> Model trained, prediction made (using: 1982-07-30 - 1987-06-30)\n",
            "Test row date: 1987-08-30 -> Model trained, prediction made (using: 1982-08-30 - 1987-07-30)\n",
            "Test row date: 1987-09-30 -> Model trained, prediction made (using: 1982-09-30 - 1987-08-30)\n",
            "Test row date: 1987-10-30 -> Model trained, prediction made (using: 1982-10-30 - 1987-09-30)\n",
            "Test row date: 1987-11-30 -> Model trained, prediction made (using: 1982-11-30 - 1987-10-30)\n",
            "Test row date: 1987-12-30 -> Model trained, prediction made (using: 1982-12-30 - 1987-11-30)\n",
            "Test row date: 1988-01-30 -> Model trained, prediction made (using: 1983-01-30 - 1987-12-30)\n",
            "Test row date: 1988-02-29 -> Model trained, prediction made (using: 1983-02-28 - 1988-01-30)\n",
            "Test row date: 1988-03-30 -> Model trained, prediction made (using: 1983-03-30 - 1988-02-29)\n",
            "Test row date: 1988-04-30 -> Model trained, prediction made (using: 1983-04-30 - 1988-03-30)\n",
            "Test row date: 1988-05-30 -> Model trained, prediction made (using: 1983-05-30 - 1988-04-30)\n",
            "Test row date: 1988-06-30 -> Model trained, prediction made (using: 1983-06-30 - 1988-05-30)\n",
            "Test row date: 1988-07-30 -> Model trained, prediction made (using: 1983-07-30 - 1988-06-30)\n",
            "Test row date: 1988-08-30 -> Model trained, prediction made (using: 1983-08-30 - 1988-07-30)\n",
            "Test row date: 1988-09-30 -> Model trained, prediction made (using: 1983-09-30 - 1988-08-30)\n",
            "Test row date: 1988-10-30 -> Model trained, prediction made (using: 1983-10-30 - 1988-09-30)\n",
            "Test row date: 1988-11-30 -> Model trained, prediction made (using: 1983-11-30 - 1988-10-30)\n",
            "Test row date: 1988-12-30 -> Model trained, prediction made (using: 1983-12-30 - 1988-11-30)\n",
            "Test row date: 1989-01-30 -> Model trained, prediction made (using: 1984-01-30 - 1988-12-30)\n",
            "Test row date: 1989-02-28 -> Model trained, prediction made (using: 1984-02-29 - 1989-01-30)\n",
            "Test row date: 1989-03-30 -> Model trained, prediction made (using: 1984-03-30 - 1989-02-28)\n",
            "Test row date: 1989-04-30 -> Model trained, prediction made (using: 1984-04-30 - 1989-03-30)\n",
            "Test row date: 1989-05-30 -> Model trained, prediction made (using: 1984-05-30 - 1989-04-30)\n",
            "Test row date: 1989-06-30 -> Model trained, prediction made (using: 1984-06-30 - 1989-05-30)\n",
            "Test row date: 1989-07-30 -> Model trained, prediction made (using: 1984-07-30 - 1989-06-30)\n",
            "Test row date: 1989-08-30 -> Model trained, prediction made (using: 1984-08-30 - 1989-07-30)\n",
            "Test row date: 1989-09-30 -> Model trained, prediction made (using: 1984-09-30 - 1989-08-30)\n",
            "Test row date: 1989-10-30 -> Model trained, prediction made (using: 1984-10-30 - 1989-09-30)\n",
            "Test row date: 1989-11-30 -> Model trained, prediction made (using: 1984-11-30 - 1989-10-30)\n",
            "Test row date: 1989-12-30 -> Model trained, prediction made (using: 1984-12-30 - 1989-11-30)\n",
            "Test row date: 1990-01-30 -> Model trained, prediction made (using: 1985-01-30 - 1989-12-30)\n",
            "Test row date: 1990-02-28 -> Model trained, prediction made (using: 1985-02-28 - 1990-01-30)\n",
            "Test row date: 1990-03-30 -> Model trained, prediction made (using: 1985-03-30 - 1990-02-28)\n",
            "Test row date: 1990-04-30 -> Model trained, prediction made (using: 1985-04-30 - 1990-03-30)\n",
            "Test row date: 1990-05-30 -> Model trained, prediction made (using: 1985-05-30 - 1990-04-30)\n",
            "Test row date: 1990-06-30 -> Model trained, prediction made (using: 1985-06-30 - 1990-05-30)\n",
            "Test row date: 1990-07-30 -> Model trained, prediction made (using: 1985-07-30 - 1990-06-30)\n",
            "Test row date: 1990-08-30 -> Model trained, prediction made (using: 1985-08-30 - 1990-07-30)\n",
            "Test row date: 1990-09-30 -> Model trained, prediction made (using: 1985-09-30 - 1990-08-30)\n",
            "Test row date: 1990-10-30 -> Model trained, prediction made (using: 1985-10-30 - 1990-09-30)\n",
            "Test row date: 1990-11-30 -> Model trained, prediction made (using: 1985-11-30 - 1990-10-30)\n",
            "Test row date: 1990-12-30 -> Model trained, prediction made (using: 1985-12-30 - 1990-11-30)\n",
            "Test row date: 1991-01-30 -> Model trained, prediction made (using: 1986-01-30 - 1990-12-30)\n",
            "Test row date: 1991-02-28 -> Model trained, prediction made (using: 1986-02-28 - 1991-01-30)\n",
            "Test row date: 1991-03-30 -> Model trained, prediction made (using: 1986-03-30 - 1991-02-28)\n",
            "Test row date: 1991-04-30 -> Model trained, prediction made (using: 1986-04-30 - 1991-03-30)\n",
            "Test row date: 1991-05-30 -> Model trained, prediction made (using: 1986-05-30 - 1991-04-30)\n",
            "Test row date: 1991-06-30 -> Model trained, prediction made (using: 1986-06-30 - 1991-05-30)\n",
            "Test row date: 1991-07-30 -> Model trained, prediction made (using: 1986-07-30 - 1991-06-30)\n",
            "Test row date: 1991-08-30 -> Model trained, prediction made (using: 1986-08-30 - 1991-07-30)\n",
            "Test row date: 1991-09-30 -> Model trained, prediction made (using: 1986-09-30 - 1991-08-30)\n",
            "Test row date: 1991-10-30 -> Model trained, prediction made (using: 1986-10-30 - 1991-09-30)\n",
            "Test row date: 1991-11-30 -> Model trained, prediction made (using: 1986-11-30 - 1991-10-30)\n",
            "Test row date: 1991-12-30 -> Model trained, prediction made (using: 1986-12-30 - 1991-11-30)\n",
            "Test row date: 1992-01-30 -> Model trained, prediction made (using: 1987-01-30 - 1991-12-30)\n",
            "Test row date: 1992-02-29 -> Model trained, prediction made (using: 1987-02-28 - 1992-01-30)\n",
            "Test row date: 1992-03-30 -> Model trained, prediction made (using: 1987-03-30 - 1992-02-29)\n",
            "Test row date: 1992-04-30 -> Model trained, prediction made (using: 1987-04-30 - 1992-03-30)\n",
            "Test row date: 1992-05-30 -> Model trained, prediction made (using: 1987-05-30 - 1992-04-30)\n",
            "Test row date: 1992-06-30 -> Model trained, prediction made (using: 1987-06-30 - 1992-05-30)\n",
            "Test row date: 1992-07-30 -> Model trained, prediction made (using: 1987-07-30 - 1992-06-30)\n",
            "Test row date: 1992-08-30 -> Model trained, prediction made (using: 1987-08-30 - 1992-07-30)\n",
            "Test row date: 1992-09-30 -> Model trained, prediction made (using: 1987-09-30 - 1992-08-30)\n",
            "Test row date: 1992-10-30 -> Model trained, prediction made (using: 1987-10-30 - 1992-09-30)\n",
            "Test row date: 1992-11-30 -> Model trained, prediction made (using: 1987-11-30 - 1992-10-30)\n",
            "Test row date: 1992-12-30 -> Model trained, prediction made (using: 1987-12-30 - 1992-11-30)\n",
            "Test row date: 1993-01-30 -> Model trained, prediction made (using: 1988-01-30 - 1992-12-30)\n",
            "Test row date: 1993-02-28 -> Model trained, prediction made (using: 1988-02-29 - 1993-01-30)\n",
            "Test row date: 1993-03-30 -> Model trained, prediction made (using: 1988-03-30 - 1993-02-28)\n",
            "Test row date: 1993-04-30 -> Model trained, prediction made (using: 1988-04-30 - 1993-03-30)\n",
            "Test row date: 1993-05-30 -> Model trained, prediction made (using: 1988-05-30 - 1993-04-30)\n",
            "Test row date: 1993-06-30 -> Model trained, prediction made (using: 1988-06-30 - 1993-05-30)\n",
            "Test row date: 1993-07-30 -> Model trained, prediction made (using: 1988-07-30 - 1993-06-30)\n",
            "Test row date: 1993-08-30 -> Model trained, prediction made (using: 1988-08-30 - 1993-07-30)\n",
            "Test row date: 1993-09-30 -> Model trained, prediction made (using: 1988-09-30 - 1993-08-30)\n",
            "Test row date: 1993-10-30 -> Model trained, prediction made (using: 1988-10-30 - 1993-09-30)\n",
            "Test row date: 1993-11-30 -> Model trained, prediction made (using: 1988-11-30 - 1993-10-30)\n",
            "Test row date: 1993-12-30 -> Model trained, prediction made (using: 1988-12-30 - 1993-11-30)\n",
            "Test row date: 1994-01-30 -> Model trained, prediction made (using: 1989-01-30 - 1993-12-30)\n",
            "Test row date: 1994-02-28 -> Model trained, prediction made (using: 1989-02-28 - 1994-01-30)\n",
            "Test row date: 1994-03-30 -> Model trained, prediction made (using: 1989-03-30 - 1994-02-28)\n",
            "Test row date: 1994-04-30 -> Model trained, prediction made (using: 1989-04-30 - 1994-03-30)\n",
            "Test row date: 1994-05-30 -> Model trained, prediction made (using: 1989-05-30 - 1994-04-30)\n",
            "Test row date: 1994-06-30 -> Model trained, prediction made (using: 1989-06-30 - 1994-05-30)\n",
            "Test row date: 1994-07-30 -> Model trained, prediction made (using: 1989-07-30 - 1994-06-30)\n",
            "Test row date: 1994-08-30 -> Model trained, prediction made (using: 1989-08-30 - 1994-07-30)\n",
            "Test row date: 1994-09-30 -> Model trained, prediction made (using: 1989-09-30 - 1994-08-30)\n",
            "Test row date: 1994-10-30 -> Model trained, prediction made (using: 1989-10-30 - 1994-09-30)\n",
            "Test row date: 1994-11-30 -> Model trained, prediction made (using: 1989-11-30 - 1994-10-30)\n",
            "Test row date: 1994-12-30 -> Model trained, prediction made (using: 1989-12-30 - 1994-11-30)\n",
            "Test row date: 1995-01-30 -> Model trained, prediction made (using: 1990-01-30 - 1994-12-30)\n",
            "Test row date: 1995-02-28 -> Model trained, prediction made (using: 1990-02-28 - 1995-01-30)\n",
            "Test row date: 1995-03-30 -> Model trained, prediction made (using: 1990-03-30 - 1995-02-28)\n",
            "Test row date: 1995-04-30 -> Model trained, prediction made (using: 1990-04-30 - 1995-03-30)\n",
            "Test row date: 1995-05-30 -> Model trained, prediction made (using: 1990-05-30 - 1995-04-30)\n",
            "Test row date: 1995-06-30 -> Model trained, prediction made (using: 1990-06-30 - 1995-05-30)\n",
            "Test row date: 1995-07-30 -> Model trained, prediction made (using: 1990-07-30 - 1995-06-30)\n",
            "Test row date: 1995-08-30 -> Model trained, prediction made (using: 1990-08-30 - 1995-07-30)\n",
            "Test row date: 1995-09-30 -> Model trained, prediction made (using: 1990-09-30 - 1995-08-30)\n",
            "Test row date: 1995-10-30 -> Model trained, prediction made (using: 1990-10-30 - 1995-09-30)\n",
            "Test row date: 1995-11-30 -> Model trained, prediction made (using: 1990-11-30 - 1995-10-30)\n",
            "Test row date: 1995-12-30 -> Model trained, prediction made (using: 1990-12-30 - 1995-11-30)\n",
            "Test row date: 1996-01-30 -> Model trained, prediction made (using: 1991-01-30 - 1995-12-30)\n",
            "Test row date: 1996-02-29 -> Model trained, prediction made (using: 1991-02-28 - 1996-01-30)\n",
            "Test row date: 1996-03-30 -> Model trained, prediction made (using: 1991-03-30 - 1996-02-29)\n",
            "Test row date: 1996-04-30 -> Model trained, prediction made (using: 1991-04-30 - 1996-03-30)\n",
            "Test row date: 1996-05-30 -> Model trained, prediction made (using: 1991-05-30 - 1996-04-30)\n",
            "Test row date: 1996-06-30 -> Model trained, prediction made (using: 1991-06-30 - 1996-05-30)\n",
            "Test row date: 1996-07-30 -> Model trained, prediction made (using: 1991-07-30 - 1996-06-30)\n",
            "Test row date: 1996-08-30 -> Model trained, prediction made (using: 1991-08-30 - 1996-07-30)\n",
            "Test row date: 1996-09-30 -> Model trained, prediction made (using: 1991-09-30 - 1996-08-30)\n",
            "Test row date: 1996-10-30 -> Model trained, prediction made (using: 1991-10-30 - 1996-09-30)\n",
            "Test row date: 1996-11-30 -> Model trained, prediction made (using: 1991-11-30 - 1996-10-30)\n",
            "Test row date: 1996-12-30 -> Model trained, prediction made (using: 1991-12-30 - 1996-11-30)\n",
            "Test row date: 1997-01-30 -> Model trained, prediction made (using: 1992-01-30 - 1996-12-30)\n",
            "Test row date: 1997-02-28 -> Model trained, prediction made (using: 1992-02-29 - 1997-01-30)\n",
            "Test row date: 1997-03-30 -> Model trained, prediction made (using: 1992-03-30 - 1997-02-28)\n",
            "Test row date: 1997-04-30 -> Model trained, prediction made (using: 1992-04-30 - 1997-03-30)\n",
            "Test row date: 1997-05-30 -> Model trained, prediction made (using: 1992-05-30 - 1997-04-30)\n",
            "Test row date: 1997-06-30 -> Model trained, prediction made (using: 1992-06-30 - 1997-05-30)\n",
            "Test row date: 1997-07-30 -> Model trained, prediction made (using: 1992-07-30 - 1997-06-30)\n",
            "Test row date: 1997-08-30 -> Model trained, prediction made (using: 1992-08-30 - 1997-07-30)\n",
            "Test row date: 1997-09-30 -> Model trained, prediction made (using: 1992-09-30 - 1997-08-30)\n",
            "Test row date: 1997-10-30 -> Model trained, prediction made (using: 1992-10-30 - 1997-09-30)\n",
            "Test row date: 1997-11-30 -> Model trained, prediction made (using: 1992-11-30 - 1997-10-30)\n",
            "Test row date: 1997-12-30 -> Model trained, prediction made (using: 1992-12-30 - 1997-11-30)\n",
            "Test row date: 1998-01-30 -> Model trained, prediction made (using: 1993-01-30 - 1997-12-30)\n",
            "Test row date: 1998-02-28 -> Model trained, prediction made (using: 1993-02-28 - 1998-01-30)\n",
            "Test row date: 1998-03-30 -> Model trained, prediction made (using: 1993-03-30 - 1998-02-28)\n",
            "Test row date: 1998-04-30 -> Model trained, prediction made (using: 1993-04-30 - 1998-03-30)\n",
            "Test row date: 1998-05-30 -> Model trained, prediction made (using: 1993-05-30 - 1998-04-30)\n",
            "Test row date: 1998-06-30 -> Model trained, prediction made (using: 1993-06-30 - 1998-05-30)\n",
            "Test row date: 1998-07-30 -> Model trained, prediction made (using: 1993-07-30 - 1998-06-30)\n",
            "Test row date: 1998-08-30 -> Model trained, prediction made (using: 1993-08-30 - 1998-07-30)\n",
            "Test row date: 1998-09-30 -> Model trained, prediction made (using: 1993-09-30 - 1998-08-30)\n",
            "Test row date: 1998-10-30 -> Model trained, prediction made (using: 1993-10-30 - 1998-09-30)\n",
            "Test row date: 1998-11-30 -> Model trained, prediction made (using: 1993-11-30 - 1998-10-30)\n",
            "Test row date: 1998-12-30 -> Model trained, prediction made (using: 1993-12-30 - 1998-11-30)\n",
            "Test row date: 1999-01-30 -> Model trained, prediction made (using: 1994-01-30 - 1998-12-30)\n",
            "Test row date: 1999-02-28 -> Model trained, prediction made (using: 1994-02-28 - 1999-01-30)\n",
            "Test row date: 1999-03-30 -> Model trained, prediction made (using: 1994-03-30 - 1999-02-28)\n",
            "Test row date: 1999-04-30 -> Model trained, prediction made (using: 1994-04-30 - 1999-03-30)\n",
            "Test row date: 1999-05-30 -> Model trained, prediction made (using: 1994-05-30 - 1999-04-30)\n",
            "Test row date: 1999-06-30 -> Model trained, prediction made (using: 1994-06-30 - 1999-05-30)\n",
            "Test row date: 1999-07-30 -> Model trained, prediction made (using: 1994-07-30 - 1999-06-30)\n",
            "Test row date: 1999-08-30 -> Model trained, prediction made (using: 1994-08-30 - 1999-07-30)\n",
            "Test row date: 1999-09-30 -> Model trained, prediction made (using: 1994-09-30 - 1999-08-30)\n",
            "Test row date: 1999-10-30 -> Model trained, prediction made (using: 1994-10-30 - 1999-09-30)\n",
            "Test row date: 1999-11-30 -> Model trained, prediction made (using: 1994-11-30 - 1999-10-30)\n",
            "Test row date: 1999-12-30 -> Model trained, prediction made (using: 1994-12-30 - 1999-11-30)\n",
            "Test row date: 2000-01-30 -> Model trained, prediction made (using: 1995-01-30 - 1999-12-30)\n",
            "Test row date: 2000-02-29 -> Model trained, prediction made (using: 1995-02-28 - 2000-01-30)\n",
            "Test row date: 2000-03-30 -> Model trained, prediction made (using: 1995-03-30 - 2000-02-29)\n",
            "Test row date: 2000-04-30 -> Model trained, prediction made (using: 1995-04-30 - 2000-03-30)\n",
            "Test row date: 2000-05-30 -> Model trained, prediction made (using: 1995-05-30 - 2000-04-30)\n",
            "Test row date: 2000-06-30 -> Model trained, prediction made (using: 1995-06-30 - 2000-05-30)\n",
            "Test row date: 2000-07-30 -> Model trained, prediction made (using: 1995-07-30 - 2000-06-30)\n",
            "Test row date: 2000-08-30 -> Model trained, prediction made (using: 1995-08-30 - 2000-07-30)\n",
            "Test row date: 2000-09-30 -> Model trained, prediction made (using: 1995-09-30 - 2000-08-30)\n",
            "Test row date: 2000-10-30 -> Model trained, prediction made (using: 1995-10-30 - 2000-09-30)\n",
            "Test row date: 2000-11-30 -> Model trained, prediction made (using: 1995-11-30 - 2000-10-30)\n",
            "Test row date: 2000-12-30 -> Model trained, prediction made (using: 1995-12-30 - 2000-11-30)\n",
            "Test row date: 2001-01-30 -> Model trained, prediction made (using: 1996-01-30 - 2000-12-30)\n",
            "Test row date: 2001-02-28 -> Model trained, prediction made (using: 1996-02-29 - 2001-01-30)\n",
            "Test row date: 2001-03-30 -> Model trained, prediction made (using: 1996-03-30 - 2001-02-28)\n",
            "Test row date: 2001-04-30 -> Model trained, prediction made (using: 1996-04-30 - 2001-03-30)\n",
            "Test row date: 2001-05-30 -> Model trained, prediction made (using: 1996-05-30 - 2001-04-30)\n",
            "Test row date: 2001-06-30 -> Model trained, prediction made (using: 1996-06-30 - 2001-05-30)\n",
            "Test row date: 2001-07-30 -> Model trained, prediction made (using: 1996-07-30 - 2001-06-30)\n",
            "Test row date: 2001-08-30 -> Model trained, prediction made (using: 1996-08-30 - 2001-07-30)\n",
            "Test row date: 2001-09-30 -> Model trained, prediction made (using: 1996-09-30 - 2001-08-30)\n",
            "Test row date: 2001-10-30 -> Model trained, prediction made (using: 1996-10-30 - 2001-09-30)\n",
            "Test row date: 2001-11-30 -> Model trained, prediction made (using: 1996-11-30 - 2001-10-30)\n",
            "Test row date: 2001-12-30 -> Model trained, prediction made (using: 1996-12-30 - 2001-11-30)\n",
            "Test row date: 2002-01-30 -> Model trained, prediction made (using: 1997-01-30 - 2001-12-30)\n",
            "Test row date: 2002-02-28 -> Model trained, prediction made (using: 1997-02-28 - 2002-01-30)\n",
            "Test row date: 2002-03-30 -> Model trained, prediction made (using: 1997-03-30 - 2002-02-28)\n",
            "Test row date: 2002-04-30 -> Model trained, prediction made (using: 1997-04-30 - 2002-03-30)\n",
            "Test row date: 2002-05-30 -> Model trained, prediction made (using: 1997-05-30 - 2002-04-30)\n",
            "Test row date: 2002-06-30 -> Model trained, prediction made (using: 1997-06-30 - 2002-05-30)\n",
            "Test row date: 2002-07-30 -> Model trained, prediction made (using: 1997-07-30 - 2002-06-30)\n",
            "Test row date: 2002-08-30 -> Model trained, prediction made (using: 1997-08-30 - 2002-07-30)\n",
            "Test row date: 2002-09-30 -> Model trained, prediction made (using: 1997-09-30 - 2002-08-30)\n",
            "Test row date: 2002-10-30 -> Model trained, prediction made (using: 1997-10-30 - 2002-09-30)\n",
            "Test row date: 2002-11-30 -> Model trained, prediction made (using: 1997-11-30 - 2002-10-30)\n",
            "Test row date: 2002-12-30 -> Model trained, prediction made (using: 1997-12-30 - 2002-11-30)\n",
            "Test row date: 2003-01-30 -> Model trained, prediction made (using: 1998-01-30 - 2002-12-30)\n",
            "Test row date: 2003-02-28 -> Model trained, prediction made (using: 1998-02-28 - 2003-01-30)\n",
            "Test row date: 2003-03-30 -> Model trained, prediction made (using: 1998-03-30 - 2003-02-28)\n",
            "Test row date: 2003-04-30 -> Model trained, prediction made (using: 1998-04-30 - 2003-03-30)\n",
            "Test row date: 2003-05-30 -> Model trained, prediction made (using: 1998-05-30 - 2003-04-30)\n",
            "Test row date: 2003-06-30 -> Model trained, prediction made (using: 1998-06-30 - 2003-05-30)\n",
            "Test row date: 2003-07-30 -> Model trained, prediction made (using: 1998-07-30 - 2003-06-30)\n",
            "Test row date: 2003-08-30 -> Model trained, prediction made (using: 1998-08-30 - 2003-07-30)\n",
            "Test row date: 2003-09-30 -> Model trained, prediction made (using: 1998-09-30 - 2003-08-30)\n",
            "Test row date: 2003-10-30 -> Model trained, prediction made (using: 1998-10-30 - 2003-09-30)\n",
            "Test row date: 2003-11-30 -> Model trained, prediction made (using: 1998-11-30 - 2003-10-30)\n",
            "Test row date: 2003-12-30 -> Model trained, prediction made (using: 1998-12-30 - 2003-11-30)\n",
            "Test row date: 2004-01-30 -> Model trained, prediction made (using: 1999-01-30 - 2003-12-30)\n",
            "Test row date: 2004-02-29 -> Model trained, prediction made (using: 1999-02-28 - 2004-01-30)\n",
            "Test row date: 2004-03-30 -> Model trained, prediction made (using: 1999-03-30 - 2004-02-29)\n",
            "Test row date: 2004-04-30 -> Model trained, prediction made (using: 1999-04-30 - 2004-03-30)\n",
            "Test row date: 2004-05-30 -> Model trained, prediction made (using: 1999-05-30 - 2004-04-30)\n",
            "Test row date: 2004-06-30 -> Model trained, prediction made (using: 1999-06-30 - 2004-05-30)\n",
            "Test row date: 2004-07-30 -> Model trained, prediction made (using: 1999-07-30 - 2004-06-30)\n",
            "Test row date: 2004-08-30 -> Model trained, prediction made (using: 1999-08-30 - 2004-07-30)\n",
            "Test row date: 2004-09-30 -> Model trained, prediction made (using: 1999-09-30 - 2004-08-30)\n",
            "Test row date: 2004-10-30 -> Model trained, prediction made (using: 1999-10-30 - 2004-09-30)\n",
            "Test row date: 2004-11-30 -> Model trained, prediction made (using: 1999-11-30 - 2004-10-30)\n",
            "Test row date: 2004-12-30 -> Model trained, prediction made (using: 1999-12-30 - 2004-11-30)\n",
            "Test row date: 2005-01-30 -> Model trained, prediction made (using: 2000-01-30 - 2004-12-30)\n",
            "Test row date: 2005-02-28 -> Model trained, prediction made (using: 2000-02-29 - 2005-01-30)\n",
            "Test row date: 2005-03-30 -> Model trained, prediction made (using: 2000-03-30 - 2005-02-28)\n",
            "Test row date: 2005-04-30 -> Model trained, prediction made (using: 2000-04-30 - 2005-03-30)\n",
            "Test row date: 2005-05-30 -> Model trained, prediction made (using: 2000-05-30 - 2005-04-30)\n",
            "Test row date: 2005-06-30 -> Model trained, prediction made (using: 2000-06-30 - 2005-05-30)\n",
            "Test row date: 2005-07-30 -> Model trained, prediction made (using: 2000-07-30 - 2005-06-30)\n",
            "Test row date: 2005-08-30 -> Model trained, prediction made (using: 2000-08-30 - 2005-07-30)\n",
            "Test row date: 2005-09-30 -> Model trained, prediction made (using: 2000-09-30 - 2005-08-30)\n",
            "Test row date: 2005-10-30 -> Model trained, prediction made (using: 2000-10-30 - 2005-09-30)\n",
            "Test row date: 2005-11-30 -> Model trained, prediction made (using: 2000-11-30 - 2005-10-30)\n",
            "Test row date: 2005-12-30 -> Model trained, prediction made (using: 2000-12-30 - 2005-11-30)\n",
            "Test row date: 2006-01-30 -> Model trained, prediction made (using: 2001-01-30 - 2005-12-30)\n",
            "Test row date: 2006-02-28 -> Model trained, prediction made (using: 2001-02-28 - 2006-01-30)\n",
            "Test row date: 2006-03-30 -> Model trained, prediction made (using: 2001-03-30 - 2006-02-28)\n",
            "Test row date: 2006-04-30 -> Model trained, prediction made (using: 2001-04-30 - 2006-03-30)\n",
            "Test row date: 2006-05-30 -> Model trained, prediction made (using: 2001-05-30 - 2006-04-30)\n",
            "Test row date: 2006-06-30 -> Model trained, prediction made (using: 2001-06-30 - 2006-05-30)\n",
            "Test row date: 2006-07-30 -> Model trained, prediction made (using: 2001-07-30 - 2006-06-30)\n",
            "Test row date: 2006-08-30 -> Model trained, prediction made (using: 2001-08-30 - 2006-07-30)\n",
            "Test row date: 2006-09-30 -> Model trained, prediction made (using: 2001-09-30 - 2006-08-30)\n",
            "Test row date: 2006-10-30 -> Model trained, prediction made (using: 2001-10-30 - 2006-09-30)\n",
            "Test row date: 2006-11-30 -> Model trained, prediction made (using: 2001-11-30 - 2006-10-30)\n",
            "Test row date: 2006-12-30 -> Model trained, prediction made (using: 2001-12-30 - 2006-11-30)\n",
            "Test row date: 2007-01-30 -> Model trained, prediction made (using: 2002-01-30 - 2006-12-30)\n",
            "Test row date: 2007-02-28 -> Model trained, prediction made (using: 2002-02-28 - 2007-01-30)\n",
            "Test row date: 2007-03-30 -> Model trained, prediction made (using: 2002-03-30 - 2007-02-28)\n",
            "Test row date: 2007-04-30 -> Model trained, prediction made (using: 2002-04-30 - 2007-03-30)\n",
            "Test row date: 2007-05-30 -> Model trained, prediction made (using: 2002-05-30 - 2007-04-30)\n",
            "Test row date: 2007-06-30 -> Model trained, prediction made (using: 2002-06-30 - 2007-05-30)\n",
            "Test row date: 2007-07-30 -> Model trained, prediction made (using: 2002-07-30 - 2007-06-30)\n",
            "Test row date: 2007-08-30 -> Model trained, prediction made (using: 2002-08-30 - 2007-07-30)\n",
            "Test row date: 2007-09-30 -> Model trained, prediction made (using: 2002-09-30 - 2007-08-30)\n",
            "Test row date: 2007-10-30 -> Model trained, prediction made (using: 2002-10-30 - 2007-09-30)\n",
            "Test row date: 2007-11-30 -> Model trained, prediction made (using: 2002-11-30 - 2007-10-30)\n",
            "Test row date: 2007-12-30 -> Model trained, prediction made (using: 2002-12-30 - 2007-11-30)\n",
            "Test row date: 2008-01-30 -> Model trained, prediction made (using: 2003-01-30 - 2007-12-30)\n",
            "Test row date: 2008-02-29 -> Model trained, prediction made (using: 2003-02-28 - 2008-01-30)\n",
            "Test row date: 2008-03-30 -> Model trained, prediction made (using: 2003-03-30 - 2008-02-29)\n",
            "Test row date: 2008-04-30 -> Model trained, prediction made (using: 2003-04-30 - 2008-03-30)\n",
            "Test row date: 2008-05-30 -> Model trained, prediction made (using: 2003-05-30 - 2008-04-30)\n",
            "Test row date: 2008-06-30 -> Model trained, prediction made (using: 2003-06-30 - 2008-05-30)\n",
            "Test row date: 2008-07-30 -> Model trained, prediction made (using: 2003-07-30 - 2008-06-30)\n",
            "Test row date: 2008-08-30 -> Model trained, prediction made (using: 2003-08-30 - 2008-07-30)\n",
            "Test row date: 2008-09-30 -> Model trained, prediction made (using: 2003-09-30 - 2008-08-30)\n",
            "Test row date: 2008-10-30 -> Model trained, prediction made (using: 2003-10-30 - 2008-09-30)\n",
            "Test row date: 2008-11-30 -> Model trained, prediction made (using: 2003-11-30 - 2008-10-30)\n",
            "Test row date: 2008-12-30 -> Model trained, prediction made (using: 2003-12-30 - 2008-11-30)\n",
            "Test row date: 2009-01-30 -> Model trained, prediction made (using: 2004-01-30 - 2008-12-30)\n",
            "Test row date: 2009-02-28 -> Model trained, prediction made (using: 2004-02-29 - 2009-01-30)\n",
            "Test row date: 2009-03-30 -> Model trained, prediction made (using: 2004-03-30 - 2009-02-28)\n",
            "Test row date: 2009-04-30 -> Model trained, prediction made (using: 2004-04-30 - 2009-03-30)\n",
            "Test row date: 2009-05-30 -> Model trained, prediction made (using: 2004-05-30 - 2009-04-30)\n",
            "Test row date: 2009-06-30 -> Model trained, prediction made (using: 2004-06-30 - 2009-05-30)\n",
            "Test row date: 2009-07-30 -> Model trained, prediction made (using: 2004-07-30 - 2009-06-30)\n",
            "Test row date: 2009-08-30 -> Model trained, prediction made (using: 2004-08-30 - 2009-07-30)\n",
            "Test row date: 2009-09-30 -> Model trained, prediction made (using: 2004-09-30 - 2009-08-30)\n",
            "Test row date: 2009-10-30 -> Model trained, prediction made (using: 2004-10-30 - 2009-09-30)\n",
            "Test row date: 2009-11-30 -> Model trained, prediction made (using: 2004-11-30 - 2009-10-30)\n",
            "Test row date: 2009-12-30 -> Model trained, prediction made (using: 2004-12-30 - 2009-11-30)\n",
            "Test row date: 2010-01-30 -> Model trained, prediction made (using: 2005-01-30 - 2009-12-30)\n",
            "Test row date: 2010-02-28 -> Model trained, prediction made (using: 2005-02-28 - 2010-01-30)\n",
            "Test row date: 2010-03-30 -> Model trained, prediction made (using: 2005-03-30 - 2010-02-28)\n",
            "Test row date: 2010-04-30 -> Model trained, prediction made (using: 2005-04-30 - 2010-03-30)\n",
            "Test row date: 2010-05-30 -> Model trained, prediction made (using: 2005-05-30 - 2010-04-30)\n",
            "Test row date: 2010-06-30 -> Model trained, prediction made (using: 2005-06-30 - 2010-05-30)\n",
            "Test row date: 2010-07-30 -> Model trained, prediction made (using: 2005-07-30 - 2010-06-30)\n",
            "Test row date: 2010-08-30 -> Model trained, prediction made (using: 2005-08-30 - 2010-07-30)\n",
            "Test row date: 2010-09-30 -> Model trained, prediction made (using: 2005-09-30 - 2010-08-30)\n",
            "Test row date: 2010-10-30 -> Model trained, prediction made (using: 2005-10-30 - 2010-09-30)\n",
            "Test row date: 2010-11-30 -> Model trained, prediction made (using: 2005-11-30 - 2010-10-30)\n",
            "Test row date: 2010-12-30 -> Model trained, prediction made (using: 2005-12-30 - 2010-11-30)\n",
            "Test row date: 2011-01-30 -> Model trained, prediction made (using: 2006-01-30 - 2010-12-30)\n",
            "Test row date: 2011-02-28 -> Model trained, prediction made (using: 2006-02-28 - 2011-01-30)\n",
            "Test row date: 2011-03-30 -> Model trained, prediction made (using: 2006-03-30 - 2011-02-28)\n",
            "Test row date: 2011-04-30 -> Model trained, prediction made (using: 2006-04-30 - 2011-03-30)\n",
            "Test row date: 2011-05-30 -> Model trained, prediction made (using: 2006-05-30 - 2011-04-30)\n",
            "Test row date: 2011-06-30 -> Model trained, prediction made (using: 2006-06-30 - 2011-05-30)\n",
            "Test row date: 2011-07-30 -> Model trained, prediction made (using: 2006-07-30 - 2011-06-30)\n",
            "Test row date: 2011-08-30 -> Model trained, prediction made (using: 2006-08-30 - 2011-07-30)\n",
            "Test row date: 2011-09-30 -> Model trained, prediction made (using: 2006-09-30 - 2011-08-30)\n",
            "Test row date: 2011-10-30 -> Model trained, prediction made (using: 2006-10-30 - 2011-09-30)\n",
            "Test row date: 2011-11-30 -> Model trained, prediction made (using: 2006-11-30 - 2011-10-30)\n",
            "Test row date: 2011-12-30 -> Model trained, prediction made (using: 2006-12-30 - 2011-11-30)\n",
            "Test row date: 2012-01-30 -> Model trained, prediction made (using: 2007-01-30 - 2011-12-30)\n",
            "Test row date: 2012-02-29 -> Model trained, prediction made (using: 2007-02-28 - 2012-01-30)\n",
            "Test row date: 2012-03-30 -> Model trained, prediction made (using: 2007-03-30 - 2012-02-29)\n",
            "Test row date: 2012-04-30 -> Model trained, prediction made (using: 2007-04-30 - 2012-03-30)\n",
            "Test row date: 2012-05-30 -> Model trained, prediction made (using: 2007-05-30 - 2012-04-30)\n",
            "Test row date: 2012-06-30 -> Model trained, prediction made (using: 2007-06-30 - 2012-05-30)\n",
            "Test row date: 2012-07-30 -> Model trained, prediction made (using: 2007-07-30 - 2012-06-30)\n",
            "Test row date: 2012-08-30 -> Model trained, prediction made (using: 2007-08-30 - 2012-07-30)\n",
            "Test row date: 2012-09-30 -> Model trained, prediction made (using: 2007-09-30 - 2012-08-30)\n",
            "Test row date: 2012-10-30 -> Model trained, prediction made (using: 2007-10-30 - 2012-09-30)\n",
            "Test row date: 2012-11-30 -> Model trained, prediction made (using: 2007-11-30 - 2012-10-30)\n",
            "Test row date: 2012-12-30 -> Model trained, prediction made (using: 2007-12-30 - 2012-11-30)\n",
            "Test row date: 2013-01-30 -> Model trained, prediction made (using: 2008-01-30 - 2012-12-30)\n",
            "Test row date: 2013-02-28 -> Model trained, prediction made (using: 2008-02-29 - 2013-01-30)\n",
            "Test row date: 2013-03-30 -> Model trained, prediction made (using: 2008-03-30 - 2013-02-28)\n",
            "Test row date: 2013-04-30 -> Model trained, prediction made (using: 2008-04-30 - 2013-03-30)\n",
            "Test row date: 2013-05-30 -> Model trained, prediction made (using: 2008-05-30 - 2013-04-30)\n",
            "Test row date: 2013-06-30 -> Model trained, prediction made (using: 2008-06-30 - 2013-05-30)\n",
            "Test row date: 2013-07-30 -> Model trained, prediction made (using: 2008-07-30 - 2013-06-30)\n",
            "Test row date: 2013-08-30 -> Model trained, prediction made (using: 2008-08-30 - 2013-07-30)\n",
            "Test row date: 2013-09-30 -> Model trained, prediction made (using: 2008-09-30 - 2013-08-30)\n",
            "Test row date: 2013-10-30 -> Model trained, prediction made (using: 2008-10-30 - 2013-09-30)\n",
            "Test row date: 2013-11-30 -> Model trained, prediction made (using: 2008-11-30 - 2013-10-30)\n",
            "Test row date: 2013-12-30 -> Model trained, prediction made (using: 2008-12-30 - 2013-11-30)\n",
            "Test row date: 2014-01-30 -> Model trained, prediction made (using: 2009-01-30 - 2013-12-30)\n",
            "Test row date: 2014-02-28 -> Model trained, prediction made (using: 2009-02-28 - 2014-01-30)\n",
            "Test row date: 2014-03-30 -> Model trained, prediction made (using: 2009-03-30 - 2014-02-28)\n",
            "Test row date: 2014-04-30 -> Model trained, prediction made (using: 2009-04-30 - 2014-03-30)\n",
            "Test row date: 2014-05-30 -> Model trained, prediction made (using: 2009-05-30 - 2014-04-30)\n",
            "Test row date: 2014-06-30 -> Model trained, prediction made (using: 2009-06-30 - 2014-05-30)\n",
            "Test row date: 2014-07-30 -> Model trained, prediction made (using: 2009-07-30 - 2014-06-30)\n",
            "Test row date: 2014-08-30 -> Model trained, prediction made (using: 2009-08-30 - 2014-07-30)\n",
            "Test row date: 2014-09-30 -> Model trained, prediction made (using: 2009-09-30 - 2014-08-30)\n",
            "Test row date: 2014-10-30 -> Model trained, prediction made (using: 2009-10-30 - 2014-09-30)\n",
            "Test row date: 2014-11-30 -> Model trained, prediction made (using: 2009-11-30 - 2014-10-30)\n",
            "Test row date: 2014-12-30 -> Model trained, prediction made (using: 2009-12-30 - 2014-11-30)\n",
            "Test row date: 2015-01-30 -> Model trained, prediction made (using: 2010-01-30 - 2014-12-30)\n",
            "Test row date: 2015-02-28 -> Model trained, prediction made (using: 2010-02-28 - 2015-01-30)\n",
            "Test row date: 2015-03-30 -> Model trained, prediction made (using: 2010-03-30 - 2015-02-28)\n",
            "Test row date: 2015-04-30 -> Model trained, prediction made (using: 2010-04-30 - 2015-03-30)\n",
            "Test row date: 2015-05-30 -> Model trained, prediction made (using: 2010-05-30 - 2015-04-30)\n",
            "Test row date: 2015-06-30 -> Model trained, prediction made (using: 2010-06-30 - 2015-05-30)\n",
            "Test row date: 2015-07-30 -> Model trained, prediction made (using: 2010-07-30 - 2015-06-30)\n",
            "Test row date: 2015-08-30 -> Model trained, prediction made (using: 2010-08-30 - 2015-07-30)\n",
            "Test row date: 2015-09-30 -> Model trained, prediction made (using: 2010-09-30 - 2015-08-30)\n",
            "Test row date: 2015-10-30 -> Model trained, prediction made (using: 2010-10-30 - 2015-09-30)\n",
            "Test row date: 2015-11-30 -> Model trained, prediction made (using: 2010-11-30 - 2015-10-30)\n",
            "Test row date: 2015-12-30 -> Model trained, prediction made (using: 2010-12-30 - 2015-11-30)\n",
            "Test row date: 2016-01-30 -> Model trained, prediction made (using: 2011-01-30 - 2015-12-30)\n",
            "Test row date: 2016-02-29 -> Model trained, prediction made (using: 2011-02-28 - 2016-01-30)\n",
            "Test row date: 2016-03-30 -> Model trained, prediction made (using: 2011-03-30 - 2016-02-29)\n",
            "Test row date: 2016-04-30 -> Model trained, prediction made (using: 2011-04-30 - 2016-03-30)\n",
            "Test row date: 2016-05-30 -> Model trained, prediction made (using: 2011-05-30 - 2016-04-30)\n",
            "Test row date: 2016-06-30 -> Model trained, prediction made (using: 2011-06-30 - 2016-05-30)\n",
            "Test row date: 2016-07-30 -> Model trained, prediction made (using: 2011-07-30 - 2016-06-30)\n",
            "Test row date: 2016-08-30 -> Model trained, prediction made (using: 2011-08-30 - 2016-07-30)\n",
            "Test row date: 2016-09-30 -> Model trained, prediction made (using: 2011-09-30 - 2016-08-30)\n",
            "Test row date: 2016-10-30 -> Model trained, prediction made (using: 2011-10-30 - 2016-09-30)\n",
            "Test row date: 2016-11-30 -> Model trained, prediction made (using: 2011-11-30 - 2016-10-30)\n",
            "Test row date: 2016-12-30 -> Model trained, prediction made (using: 2011-12-30 - 2016-11-30)\n",
            "Test row date: 2017-01-30 -> Model trained, prediction made (using: 2012-01-30 - 2016-12-30)\n",
            "Test row date: 2017-02-28 -> Model trained, prediction made (using: 2012-02-29 - 2017-01-30)\n",
            "Test row date: 2017-03-30 -> Model trained, prediction made (using: 2012-03-30 - 2017-02-28)\n",
            "Test row date: 2017-04-30 -> Model trained, prediction made (using: 2012-04-30 - 2017-03-30)\n",
            "Test row date: 2017-05-30 -> Model trained, prediction made (using: 2012-05-30 - 2017-04-30)\n",
            "Test row date: 2017-06-30 -> Model trained, prediction made (using: 2012-06-30 - 2017-05-30)\n",
            "Test row date: 2017-07-30 -> Model trained, prediction made (using: 2012-07-30 - 2017-06-30)\n",
            "Test row date: 2017-08-30 -> Model trained, prediction made (using: 2012-08-30 - 2017-07-30)\n",
            "Test row date: 2017-09-30 -> Model trained, prediction made (using: 2012-09-30 - 2017-08-30)\n",
            "Test row date: 2017-10-30 -> Model trained, prediction made (using: 2012-10-30 - 2017-09-30)\n",
            "Test row date: 2017-11-30 -> Model trained, prediction made (using: 2012-11-30 - 2017-10-30)\n",
            "Test row date: 2017-12-30 -> Model trained, prediction made (using: 2012-12-30 - 2017-11-30)\n",
            "Test row date: 2018-01-30 -> Model trained, prediction made (using: 2013-01-30 - 2017-12-30)\n",
            "Test row date: 2018-02-28 -> Model trained, prediction made (using: 2013-02-28 - 2018-01-30)\n",
            "Test row date: 2018-03-30 -> Model trained, prediction made (using: 2013-03-30 - 2018-02-28)\n",
            "Test row date: 2018-04-30 -> Model trained, prediction made (using: 2013-04-30 - 2018-03-30)\n",
            "Test row date: 2018-05-30 -> Model trained, prediction made (using: 2013-05-30 - 2018-04-30)\n",
            "Test row date: 2018-06-30 -> Model trained, prediction made (using: 2013-06-30 - 2018-05-30)\n",
            "Test row date: 2018-07-30 -> Model trained, prediction made (using: 2013-07-30 - 2018-06-30)\n",
            "Test row date: 2018-08-30 -> Model trained, prediction made (using: 2013-08-30 - 2018-07-30)\n",
            "Test row date: 2018-09-30 -> Model trained, prediction made (using: 2013-09-30 - 2018-08-30)\n",
            "Test row date: 2018-10-30 -> Model trained, prediction made (using: 2013-10-30 - 2018-09-30)\n",
            "Test row date: 2018-11-30 -> Model trained, prediction made (using: 2013-11-30 - 2018-10-30)\n",
            "Test row date: 2018-12-30 -> Model trained, prediction made (using: 2013-12-30 - 2018-11-30)\n",
            "Test row date: 2019-01-30 -> Model trained, prediction made (using: 2014-01-30 - 2018-12-30)\n",
            "Test row date: 2019-02-28 -> Model trained, prediction made (using: 2014-02-28 - 2019-01-30)\n",
            "Test row date: 2019-03-30 -> Model trained, prediction made (using: 2014-03-30 - 2019-02-28)\n",
            "Test row date: 2019-04-30 -> Model trained, prediction made (using: 2014-04-30 - 2019-03-30)\n",
            "Test row date: 2019-05-30 -> Model trained, prediction made (using: 2014-05-30 - 2019-04-30)\n",
            "Test row date: 2019-06-30 -> Model trained, prediction made (using: 2014-06-30 - 2019-05-30)\n",
            "Test row date: 2019-07-30 -> Model trained, prediction made (using: 2014-07-30 - 2019-06-30)\n",
            "Test row date: 2019-08-30 -> Model trained, prediction made (using: 2014-08-30 - 2019-07-30)\n",
            "Test row date: 2019-09-30 -> Model trained, prediction made (using: 2014-09-30 - 2019-08-30)\n",
            "Test row date: 2019-10-30 -> Model trained, prediction made (using: 2014-10-30 - 2019-09-30)\n",
            "Test row date: 2019-11-30 -> Model trained, prediction made (using: 2014-11-30 - 2019-10-30)\n",
            "Test row date: 2019-12-30 -> Model trained, prediction made (using: 2014-12-30 - 2019-11-30)\n",
            "Test row date: 2020-01-30 -> Model trained, prediction made (using: 2015-01-30 - 2019-12-30)\n",
            "Test row date: 2020-02-29 -> Model trained, prediction made (using: 2015-02-28 - 2020-01-30)\n",
            "Test row date: 2020-03-30 -> Model trained, prediction made (using: 2015-03-30 - 2020-02-29)\n",
            "Test row date: 2020-04-30 -> Model trained, prediction made (using: 2015-04-30 - 2020-03-30)\n",
            "Test row date: 2020-05-30 -> Model trained, prediction made (using: 2015-05-30 - 2020-04-30)\n",
            "Test row date: 2020-06-30 -> Model trained, prediction made (using: 2015-06-30 - 2020-05-30)\n",
            "Test row date: 2020-07-30 -> Model trained, prediction made (using: 2015-07-30 - 2020-06-30)\n",
            "Test row date: 2020-08-30 -> Model trained, prediction made (using: 2015-08-30 - 2020-07-30)\n",
            "Test row date: 2020-09-30 -> Model trained, prediction made (using: 2015-09-30 - 2020-08-30)\n",
            "Test row date: 2020-10-30 -> Model trained, prediction made (using: 2015-10-30 - 2020-09-30)\n",
            "Test row date: 2020-11-30 -> Model trained, prediction made (using: 2015-11-30 - 2020-10-30)\n",
            "Test row date: 2020-12-30 -> Model trained, prediction made (using: 2015-12-30 - 2020-11-30)\n",
            "Test row date: 2021-01-30 -> Model trained, prediction made (using: 2016-01-30 - 2020-12-30)\n",
            "Test row date: 2021-02-28 -> Model trained, prediction made (using: 2016-02-29 - 2021-01-30)\n",
            "Test row date: 2021-03-30 -> Model trained, prediction made (using: 2016-03-30 - 2021-02-28)\n",
            "Test row date: 2021-04-30 -> Model trained, prediction made (using: 2016-04-30 - 2021-03-30)\n",
            "Test row date: 2021-05-30 -> Model trained, prediction made (using: 2016-05-30 - 2021-04-30)\n",
            "Test row date: 2021-06-30 -> Model trained, prediction made (using: 2016-06-30 - 2021-05-30)\n",
            "Test row date: 2021-07-30 -> Model trained, prediction made (using: 2016-07-30 - 2021-06-30)\n",
            "Test row date: 2021-08-30 -> Model trained, prediction made (using: 2016-08-30 - 2021-07-30)\n",
            "Test row date: 2021-09-30 -> Model trained, prediction made (using: 2016-09-30 - 2021-08-30)\n",
            "Test row date: 2021-10-30 -> Model trained, prediction made (using: 2016-10-30 - 2021-09-30)\n",
            "Test row date: 2021-11-30 -> Model trained, prediction made (using: 2016-11-30 - 2021-10-30)\n",
            "Test row date: 2021-12-30 -> Model trained, prediction made (using: 2016-12-30 - 2021-11-30)\n",
            "Test row date: 2022-01-30 -> Model trained, prediction made (using: 2017-01-30 - 2021-12-30)\n",
            "Test row date: 2022-02-28 -> Model trained, prediction made (using: 2017-02-28 - 2022-01-30)\n",
            "Test row date: 2022-03-30 -> Model trained, prediction made (using: 2017-03-30 - 2022-02-28)\n",
            "Test row date: 2022-04-30 -> Model trained, prediction made (using: 2017-04-30 - 2022-03-30)\n",
            "Test row date: 2022-05-30 -> Model trained, prediction made (using: 2017-05-30 - 2022-04-30)\n",
            "Test row date: 2022-06-30 -> Model trained, prediction made (using: 2017-06-30 - 2022-05-30)\n",
            "Test row date: 2022-07-30 -> Model trained, prediction made (using: 2017-07-30 - 2022-06-30)\n",
            "Test row date: 2022-08-30 -> Model trained, prediction made (using: 2017-08-30 - 2022-07-30)\n",
            "Test row date: 2022-09-30 -> Model trained, prediction made (using: 2017-09-30 - 2022-08-30)\n",
            "Test row date: 2022-10-30 -> Model trained, prediction made (using: 2017-10-30 - 2022-09-30)\n",
            "Test row date: 2022-11-30 -> Model trained, prediction made (using: 2017-11-30 - 2022-10-30)\n",
            "Test row date: 2022-12-30 -> Model trained, prediction made (using: 2017-12-30 - 2022-11-30)\n",
            "Test row date: 2023-01-30 -> Model trained, prediction made (using: 2018-01-30 - 2022-12-30)\n",
            "Test row date: 2023-02-28 -> Model trained, prediction made (using: 2018-02-28 - 2023-01-30)\n",
            "Test row date: 2023-03-30 -> Model trained, prediction made (using: 2018-03-30 - 2023-02-28)\n",
            "Test row date: 2023-04-30 -> Model trained, prediction made (using: 2018-04-30 - 2023-03-30)\n",
            "Test row date: 2023-05-30 -> Model trained, prediction made (using: 2018-05-30 - 2023-04-30)\n",
            "Test row date: 2023-06-30 -> Model trained, prediction made (using: 2018-06-30 - 2023-05-30)\n",
            "Test row date: 2023-07-30 -> Model trained, prediction made (using: 2018-07-30 - 2023-06-30)\n",
            "Test row date: 2023-08-30 -> Model trained, prediction made (using: 2018-08-30 - 2023-07-30)\n",
            "Test row date: 2023-09-30 -> Model trained, prediction made (using: 2018-09-30 - 2023-08-30)\n",
            "Test row date: 2023-10-30 -> Model trained, prediction made (using: 2018-10-30 - 2023-09-30)\n",
            "Test row date: 2023-11-30 -> Model trained, prediction made (using: 2018-11-30 - 2023-10-30)\n",
            "Test row date: 2023-12-30 -> Model trained, prediction made (using: 2018-12-30 - 2023-11-30)\n",
            "Test row date: 2024-01-30 -> Model trained, prediction made (using: 2019-01-30 - 2023-12-30)\n",
            "Test row date: 2024-02-29 -> Model trained, prediction made (using: 2019-02-28 - 2024-01-30)\n",
            "Test row date: 2024-03-30 -> Model trained, prediction made (using: 2019-03-30 - 2024-02-29)\n",
            "Test row date: 2024-04-30 -> Model trained, prediction made (using: 2019-04-30 - 2024-03-30)\n",
            "Test row date: 2024-05-30 -> Model trained, prediction made (using: 2019-05-30 - 2024-04-30)\n",
            "Test row date: 2024-06-30 -> Model trained, prediction made (using: 2019-06-30 - 2024-05-30)\n",
            "Test row date: 2024-07-30 -> Model trained, prediction made (using: 2019-07-30 - 2024-06-30)\n",
            "Test row date: 2024-08-30 -> Model trained, prediction made (using: 2019-08-30 - 2024-07-30)\n",
            "Test row date: 2024-09-30 -> Model trained, prediction made (using: 2019-09-30 - 2024-08-30)\n",
            "Test row date: 2024-10-30 -> Model trained, prediction made (using: 2019-10-30 - 2024-09-30)\n",
            "Test row date: 2024-11-30 -> Model trained, prediction made (using: 2019-11-30 - 2024-10-30)\n",
            "Final results_df_gb columns: ['Regime', 'Predicted_month', 'Train_Start_Date', 'Train_End_Date', 'Train_Count', 'Feature_Importances', 'Predicted_Probabilities', 'Predicted_Winner', 'Allocated_Return', 'Equal_Weight_Return', 'Actual_Winner', 'Num_Trees', 'Average_Tree_Depth', 'Max_Tree_Depth', 'Prediction_Horizon_Months', 'Feature_Level_CPI%', 'Feature_Level_T10Y3', 'Feature_Level_CFNAI', 'Feature_Level_GARCH_1M', 'Feature_Level_SMB_MA12', 'Feature_Level_HML_MA12', 'Feature_Level_CMA_MA12', 'Feature_Level_RMW_MA12']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "622  NoRegime      2024-02-29       2019-02-28     2024-01-30           60   \n",
              "623  NoRegime      2024-03-30       2019-03-30     2024-02-29           60   \n",
              "624  NoRegime      2024-04-30       2019-04-30     2024-03-30           60   \n",
              "625  NoRegime      2024-05-30       2019-05-30     2024-04-30           60   \n",
              "626  NoRegime      2024-06-30       2019-06-30     2024-05-30           60   \n",
              "627  NoRegime      2024-07-30       2019-07-30     2024-06-30           60   \n",
              "628  NoRegime      2024-08-30       2019-08-30     2024-07-30           60   \n",
              "629  NoRegime      2024-09-30       2019-09-30     2024-08-30           60   \n",
              "630  NoRegime      2024-10-30       2019-10-30     2024-09-30           60   \n",
              "631  NoRegime      2024-11-30       2019-11-30     2024-10-30           60   \n",
              "\n",
              "                                   Feature_Importances  \\\n",
              "622  [0.1439386, 0.13067745, 0.14304677, 0.1254781,...   \n",
              "623  [0.13323456, 0.14853302, 0.13322045, 0.1117841...   \n",
              "624  [0.12471897, 0.11442606, 0.16472061, 0.1301394...   \n",
              "625  [0.13316356, 0.12650332, 0.1441639, 0.12407308...   \n",
              "626  [0.11506013, 0.119746216, 0.17752361, 0.123442...   \n",
              "627  [0.1383057, 0.14141065, 0.13999258, 0.11885134...   \n",
              "628  [0.1258053, 0.14109226, 0.13648534, 0.12625147...   \n",
              "629  [0.13950507, 0.12203448, 0.12051911, 0.1360373...   \n",
              "630  [0.13405606, 0.1448167, 0.117900446, 0.1077575...   \n",
              "631  [0.15408151, 0.1483383, 0.10167967, 0.12251943...   \n",
              "\n",
              "                               Predicted_Probabilities Predicted_Winner  \\\n",
              "622  [0.15366147458553314, 0.07175527513027191, 0.0...              RMW   \n",
              "623  [0.5167845487594604, 0.07368388772010803, 0.11...              SMB   \n",
              "624  [0.2634696662425995, 0.41809695959091187, 0.12...              HML   \n",
              "625  [0.10407736897468567, 0.029400305822491646, 0....              RMW   \n",
              "626  [0.06824425607919693, 0.05612335726618767, 0.0...              RMW   \n",
              "627  [0.21670712530612946, 0.1424505114555359, 0.06...              RMW   \n",
              "628  [0.5750421285629272, 0.02234901487827301, 0.04...              SMB   \n",
              "629  [0.30214813351631165, 0.0692986324429512, 0.11...              RMW   \n",
              "630  [0.09118417650461197, 0.07643740624189377, 0.0...              RMW   \n",
              "631  [0.17551875114440918, 0.16604794561862946, 0.2...              RMW   \n",
              "\n",
              "     Allocated_Return  Equal_Weight_Return  ... Max_Tree_Depth  \\\n",
              "622         -0.019124            -0.021050  ...           None   \n",
              "623          0.002721             0.014250  ...           None   \n",
              "624         -0.006333            -0.004725  ...           None   \n",
              "625          0.018928            -0.002500  ...           None   \n",
              "626         -0.000879            -0.022375  ...           None   \n",
              "627          0.027664             0.036675  ...           None   \n",
              "628         -0.017815            -0.007675  ...           None   \n",
              "629         -0.004958            -0.009575  ...           None   \n",
              "630         -0.009737            -0.000850  ...           None   \n",
              "631         -0.007928            -0.000150  ...           None   \n",
              "\n",
              "     Prediction_Horizon_Months Feature_Level_CPI% Feature_Level_T10Y3  \\\n",
              "622                          1            0.21033               -1.23   \n",
              "623                          1            0.34301               -0.99   \n",
              "624                          1            0.39639               -1.04   \n",
              "625                          1            0.34885               -0.55   \n",
              "626                          1            0.29125               -0.74   \n",
              "627                          1            0.03961               -0.88   \n",
              "628                          1           -0.00287               -1.11   \n",
              "629                          1            0.13892               -1.14   \n",
              "630                          1            0.18019               -0.91   \n",
              "631                          1            0.22920               -0.23   \n",
              "\n",
              "     Feature_Level_CFNAI  Feature_Level_GARCH_1M  Feature_Level_SMB_MA12  \\\n",
              "622                -0.14                0.726558               -0.002417   \n",
              "623                -0.83                0.780011               -0.010833   \n",
              "624                 0.39                0.496170               -0.012017   \n",
              "625                -0.20                0.944764               -0.007225   \n",
              "626                -0.39                0.569002               -0.007208   \n",
              "627                 0.15                0.327046               -0.006250   \n",
              "628                -0.17                1.087011               -0.011025   \n",
              "629                -0.30                0.641443               -0.006492   \n",
              "630                -0.05                0.396629               -0.006467   \n",
              "631                -0.21                0.684819               -0.005825   \n",
              "\n",
              "     Feature_Level_HML_MA12  Feature_Level_CMA_MA12  Feature_Level_RMW_MA12  \n",
              "622               -0.008700               -0.014225                0.003442  \n",
              "623               -0.007425               -0.011375                0.006008  \n",
              "624               -0.009667               -0.012075                0.003500  \n",
              "625                0.001242               -0.009092                0.002783  \n",
              "626                0.000850               -0.011717                0.002000  \n",
              "627                0.005908               -0.008275                0.005992  \n",
              "628                0.003317               -0.008408                0.004525  \n",
              "629                0.004675               -0.008567                0.005183  \n",
              "630                0.004633               -0.005875                0.003042  \n",
              "631                0.001267               -0.005392                0.001533  \n",
              "\n",
              "[10 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a85f1e-c9b4-47f7-89d4-a8c6f042cc3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>2024-01-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1439386, 0.13067745, 0.14304677, 0.1254781,...</td>\n",
              "      <td>[0.15366147458553314, 0.07175527513027191, 0.0...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019124</td>\n",
              "      <td>-0.021050</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.21033</td>\n",
              "      <td>-1.23</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.726558</td>\n",
              "      <td>-0.002417</td>\n",
              "      <td>-0.008700</td>\n",
              "      <td>-0.014225</td>\n",
              "      <td>0.003442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-03-30</td>\n",
              "      <td>2019-03-30</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13323456, 0.14853302, 0.13322045, 0.1117841...</td>\n",
              "      <td>[0.5167845487594604, 0.07368388772010803, 0.11...</td>\n",
              "      <td>SMB</td>\n",
              "      <td>0.002721</td>\n",
              "      <td>0.014250</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.34301</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>0.780011</td>\n",
              "      <td>-0.010833</td>\n",
              "      <td>-0.007425</td>\n",
              "      <td>-0.011375</td>\n",
              "      <td>0.006008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-04-30</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>2024-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.12471897, 0.11442606, 0.16472061, 0.1301394...</td>\n",
              "      <td>[0.2634696662425995, 0.41809695959091187, 0.12...</td>\n",
              "      <td>HML</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.004725</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.39639</td>\n",
              "      <td>-1.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.496170</td>\n",
              "      <td>-0.012017</td>\n",
              "      <td>-0.009667</td>\n",
              "      <td>-0.012075</td>\n",
              "      <td>0.003500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-05-30</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>2024-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13316356, 0.12650332, 0.1441639, 0.12407308...</td>\n",
              "      <td>[0.10407736897468567, 0.029400305822491646, 0....</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.018928</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.34885</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>0.944764</td>\n",
              "      <td>-0.007225</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>-0.009092</td>\n",
              "      <td>0.002783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>2019-06-30</td>\n",
              "      <td>2024-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11506013, 0.119746216, 0.17752361, 0.123442...</td>\n",
              "      <td>[0.06824425607919693, 0.05612335726618767, 0.0...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.000879</td>\n",
              "      <td>-0.022375</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29125</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>0.569002</td>\n",
              "      <td>-0.007208</td>\n",
              "      <td>0.000850</td>\n",
              "      <td>-0.011717</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>2019-07-30</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1383057, 0.14141065, 0.13999258, 0.11885134...</td>\n",
              "      <td>[0.21670712530612946, 0.1424505114555359, 0.06...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.036675</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03961</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.327046</td>\n",
              "      <td>-0.006250</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>-0.008275</td>\n",
              "      <td>0.005992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>2019-08-30</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1258053, 0.14109226, 0.13648534, 0.12625147...</td>\n",
              "      <td>[0.5750421285629272, 0.02234901487827301, 0.04...</td>\n",
              "      <td>SMB</td>\n",
              "      <td>-0.017815</td>\n",
              "      <td>-0.007675</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.00287</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.087011</td>\n",
              "      <td>-0.011025</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>-0.008408</td>\n",
              "      <td>0.004525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13950507, 0.12203448, 0.12051911, 0.1360373...</td>\n",
              "      <td>[0.30214813351631165, 0.0692986324429512, 0.11...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.004958</td>\n",
              "      <td>-0.009575</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13892</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.641443</td>\n",
              "      <td>-0.006492</td>\n",
              "      <td>0.004675</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.005183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>2019-10-30</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13405606, 0.1448167, 0.117900446, 0.1077575...</td>\n",
              "      <td>[0.09118417650461197, 0.07643740624189377, 0.0...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.009737</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.18019</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.396629</td>\n",
              "      <td>-0.006467</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>-0.005875</td>\n",
              "      <td>0.003042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-11-30</td>\n",
              "      <td>2019-11-30</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.15408151, 0.1483383, 0.10167967, 0.12251943...</td>\n",
              "      <td>[0.17551875114440918, 0.16604794561862946, 0.2...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.007928</td>\n",
              "      <td>-0.000150</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22920</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.684819</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>-0.005392</td>\n",
              "      <td>0.001533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a85f1e-c9b4-47f7-89d4-a8c6f042cc3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a85f1e-c9b4-47f7-89d4-a8c6f042cc3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a85f1e-c9b4-47f7-89d4-a8c6f042cc3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed56ebd6-83a4-486c-a032-90eeabfcba09\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed56ebd6-83a4-486c-a032-90eeabfcba09')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed56ebd6-83a4-486c-a032-90eeabfcba09 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cumulative returns 2000-01-30 - 2024-11-30 - ML strategy: 1.7092 / Equal weight: 1.1529\n",
            "\n",
            "Cumulative returns 1972-04-30 - 2024-11-30 - ML strategy: 7.8104 / Equal weight: 3.5990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradint boosting loop"
      ],
      "metadata": {
        "id": "cqpzfBYhagcZ"
      },
      "id": "cqpzfBYhagcZ"
    },
    {
      "cell_type": "code",
      "source": [
        "if gb_loop:\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import random\n",
        "  from datetime import datetime\n",
        "  from xgboost import XGBClassifier\n",
        "  from IPython.display import display, HTML\n",
        "  import optuna\n",
        "  import optuna.visualization as vis\n",
        "  import time\n",
        "\n",
        "  # -------------------\n",
        "  # User-specified globals\n",
        "  # -------------------\n",
        "  seed = 39\n",
        "  n_trials = 350\n",
        "\n",
        "  # reproducibility\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "  min_months_train    = 60    # Minimum months of data needed (5 years for monthly data)\n",
        "  min_obs_regime      = 50    # Minimum observations per regime if splitting\n",
        "  min_obs_train       = 0     # Minimum total observations after dropping NAs\n",
        "  use_regime_split    = False # Toggle regime-based training\n",
        "  use_fixed_window    = True  # True for rolling window, False for expanding window\n",
        "  rolling_window_size = 60    # When using a fixed window, use this many most recent rows\n",
        "\n",
        "  # Ensure the data is sorted by Date\n",
        "  df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "  # Global list to store logging entries for Optuna iterations\n",
        "  gb_optuna_log = []\n",
        "\n",
        "  # Prepare results filename\n",
        "  now = datetime.now()\n",
        "  results_filename = f\"gp_loop_results_{now.strftime('%Y%m%d')}_{now.strftime('%H%M%S')}.csv\"\n",
        "\n",
        "  # -------------------\n",
        "  # Objective Function for Optuna\n",
        "  # -------------------\n",
        "  def objective(trial):\n",
        "      start_time = time.time()\n",
        "\n",
        "      # 1) choose number of trees (either 100 or 200)\n",
        "      n_trees = trial.suggest_categorical('n_estimators', [100, 200])\n",
        "\n",
        "      # 2) single unconditional learning-rate range\n",
        "      lr = trial.suggest_float('learning_rate', 0.005, 0.2, log=True)\n",
        "\n",
        "      # 3) other hyperparameters, including subsample now being tuned\n",
        "      xgb_params = {\n",
        "          'n_estimators':     n_trees,\n",
        "          'learning_rate':    lr,\n",
        "          'max_depth':        20,\n",
        "          'subsample':        trial.suggest_float('subsample', 0.5, 1.0),\n",
        "          'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "          'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
        "          'gamma':            trial.suggest_float('gamma', 0.0, 0.7),\n",
        "          'n_jobs':           -1,\n",
        "          'random_state':     seed,\n",
        "          'eval_metric':      'mlogloss'\n",
        "      }\n",
        "\n",
        "      results = []\n",
        "\n",
        "      # Loop through each test point\n",
        "      for i in range(1, len(df_sorted)):\n",
        "          test_row      = df_sorted.iloc[i]\n",
        "          Predicted_month = test_row['Date']\n",
        "\n",
        "          # Build training window\n",
        "          if use_fixed_window:\n",
        "              start_idx    = max(0, i - rolling_window_size)\n",
        "              train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "          else:\n",
        "              train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "          # Skip if not enough data\n",
        "          if len(train_window) < min_months_train:\n",
        "              continue\n",
        "\n",
        "          train_start_date = train_window['Date'].iloc[0]\n",
        "          train_end_date   = train_window['Date'].iloc[-1]\n",
        "\n",
        "          # Regime-based filtering (if enabled)\n",
        "          if use_regime_split:\n",
        "              regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "              if (regime_counts < min_obs_regime).any():\n",
        "                  continue\n",
        "              current_regime = test_row[REGIMES_COLUMN]\n",
        "              train_window   = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "              if len(train_window) < min_obs_regime:\n",
        "                  continue\n",
        "              regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "          else:\n",
        "              regime_used = 'NoRegime'\n",
        "\n",
        "          # Ensure last training date is before test date\n",
        "          last_train = train_window['Date'].iloc[-1]\n",
        "          if (last_train.year == Predicted_month.year and\n",
        "              last_train.month >= Predicted_month.month):\n",
        "              continue\n",
        "\n",
        "          # Prepare training data\n",
        "          X_train = train_window[FEATURES].dropna()\n",
        "          y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "          if len(X_train) < min_obs_train:\n",
        "              continue\n",
        "\n",
        "          # Encode labels\n",
        "          y_cat = y_train.astype('category')\n",
        "          mapping = dict(enumerate(y_cat.cat.categories))\n",
        "          y_num = y_cat.cat.codes\n",
        "\n",
        "          # Fit model\n",
        "          model = XGBClassifier(**xgb_params)\n",
        "          model.fit(X_train, y_num)\n",
        "\n",
        "          # Prepare test\n",
        "          X_test = train_window[FEATURES].iloc[[-1]].dropna()\n",
        "          if X_test.empty:\n",
        "              continue\n",
        "\n",
        "          probs        = model.predict_proba(X_test)[0]\n",
        "          pred_code    = model.classes_[probs.argmax()]\n",
        "          predicted_winner = mapping[pred_code]\n",
        "\n",
        "          # Map back to full FACTORS\n",
        "          full_probs = np.zeros(len(FACTORS))\n",
        "          for code, p in zip(model.classes_, probs):\n",
        "              factor = mapping[code]\n",
        "              if factor in FACTORS:\n",
        "                  full_probs[FACTORS.index(factor)] = p\n",
        "\n",
        "          allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "          equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "          # Record feature levels if desired\n",
        "          feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in FEATURES}\n",
        "\n",
        "          results.append({\n",
        "              'Predicted_month':     Predicted_month,\n",
        "              'Allocated_Return':    allocated_return,\n",
        "              'Equal_Weight_Return': equal_weight_return,\n",
        "              'Train_Start_Date':    train_start_date,\n",
        "              'Train_End_Date':      train_end_date,\n",
        "              **feature_levels\n",
        "          })\n",
        "\n",
        "      # If no valid predictions:\n",
        "      if not results:\n",
        "          for attr in [\"duration\", \"total_cum_return\", \"filtered_cum_return\", \"total_sharpe\", \"filtered_sharpe\"]:\n",
        "              trial.set_user_attr(attr, 0)\n",
        "          return 0\n",
        "\n",
        "      # Build DataFrame of results\n",
        "      res_df = pd.DataFrame(results)\n",
        "\n",
        "      # Compute cumulative returns\n",
        "      total_cum    = (1 + res_df['Allocated_Return']).prod() - 1\n",
        "      filt_df      = res_df[res_df['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "      filtered_cum = (1 + filt_df['Allocated_Return']).prod() - 1 if not filt_df.empty else 0\n",
        "\n",
        "      # Sharpe ratio function\n",
        "      def sharpe(returns):\n",
        "          sd = np.std(returns)\n",
        "          return (np.mean(returns) / sd) * np.sqrt(12) if sd else 0\n",
        "\n",
        "      total_sharpe    = sharpe(res_df['Allocated_Return'])\n",
        "      filtered_sharpe = sharpe(filt_df['Allocated_Return']) if not filt_df.empty else 0\n",
        "\n",
        "      # Log attributes\n",
        "      duration = time.time() - start_time\n",
        "      trial.set_user_attr(\"duration\", duration)\n",
        "      trial.set_user_attr(\"total_cum_return\", total_cum)\n",
        "      trial.set_user_attr(\"filtered_cum_return\", filtered_cum)\n",
        "      trial.set_user_attr(\"total_sharpe\", total_sharpe)\n",
        "      trial.set_user_attr(\"filtered_sharpe\", filtered_sharpe)\n",
        "\n",
        "      return filtered_cum  # objective: maximize post-2000 cumulative return\n",
        "\n",
        "\n",
        "  # -------------------\n",
        "  # Callback for logging after each trial\n",
        "  # -------------------\n",
        "  def logging_callback(study, trial):\n",
        "      ua   = trial.user_attrs\n",
        "      mins, secs = divmod(int(ua.get(\"duration\", 0)), 60)\n",
        "      msg = (\n",
        "          f\"Trial {trial.number} in {mins:02d}:{secs:02d} | \"\n",
        "          f\"Best: {study.best_trial.value:.4f} | \"\n",
        "          f\"TotRet: {ua.get('total_cum_return',0):.4f} | \"\n",
        "          f\"Ret2000+: {ua.get('filtered_cum_return',0):.4f} | \"\n",
        "          f\"TotSharpe: {ua.get('total_sharpe',0):.4f} | \"\n",
        "          f\"Sharpe2000+: {ua.get('filtered_sharpe',0):.4f}\"\n",
        "      )\n",
        "      print(msg)\n",
        "\n",
        "      log_entry = {\n",
        "          'Trial': trial.number,\n",
        "          'Duration': f\"{mins:02d}:{secs:02d}\",\n",
        "          'Best_Run_So_Far': study.best_trial.value,\n",
        "          'Total_Cum_Return': ua.get('total_cum_return',0),\n",
        "          'Cum_Return_after_2000': ua.get('filtered_cum_return',0),\n",
        "          'Total_Sharpe': ua.get('total_sharpe',0),\n",
        "          'Sharpe_after_2000': ua.get('filtered_sharpe',0),\n",
        "          **trial.params\n",
        "      }\n",
        "      gb_optuna_log.append(log_entry)\n",
        "      pd.DataFrame(gb_optuna_log).to_csv(results_filename, sep=\";\", decimal=\",\", index=False)\n",
        "\n",
        "\n",
        "  # -------------------\n",
        "  # Run the Optuna study\n",
        "  # -------------------\n",
        "  study = optuna.create_study(\n",
        "      direction=\"maximize\",\n",
        "      sampler=optuna.samplers.TPESampler(seed=seed)\n",
        "  )\n",
        "  study.optimize(objective, n_trials=n_trials, callbacks=[logging_callback])\n",
        "  print(\"Optuna optimization completed.\")\n",
        "\n",
        "  # -------------------\n",
        "  # Visualize the results\n",
        "  # -------------------\n",
        "  opt_history_fig    = vis.plot_optimization_history(study)\n",
        "  opt_importance_fig = vis.plot_param_importances(study)\n",
        "  opt_history_fig.show()\n",
        "  opt_importance_fig.show()\n",
        "\n",
        "  # Display the best trial\n",
        "  best = study.best_trial\n",
        "  print(\"Best trial:\")\n",
        "  print(f\"  Value: {best.value:.4f}\")\n",
        "  for k, v in best.params.items():\n",
        "      print(f\"    {k}: {v}\")\n"
      ],
      "metadata": {
        "id": "K6JoZwTdQ8lL"
      },
      "id": "K6JoZwTdQ8lL",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hybrid / tÃ¤Ã¤ sÃ¤ilyttÃ¤Ã¤ random forestin dataframen mut averagee painot ja laskee allocated returns nistÃ¤"
      ],
      "metadata": {
        "id": "0HZuBVFOW8qu"
      },
      "id": "0HZuBVFOW8qu"
    },
    {
      "cell_type": "code",
      "source": [
        "if Hybrid:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from functools import reduce\n",
        "\n",
        "    # names of the two resultâ€DataFrames in your namespace\n",
        "    MODEL_DF_NAMES = ['results_df_rf', 'results_df_rf2']\n",
        "\n",
        "    # 1) load raw factorâ€return sheet & rename its date column to match the models\n",
        "    df_returns = xls_file.parse(SHEET_NAME)\n",
        "    df_returns.rename(columns={'Date': 'Predicted_month'}, inplace=True)\n",
        "    # FACTORS should already be defined as your list of factorâ€return columns\n",
        "    df_factor = df_returns[['Predicted_month'] + FACTORS].copy()\n",
        "\n",
        "    # 2) extract each modelâ€™s month + prob vector\n",
        "    prob_dfs = []\n",
        "    for name in MODEL_DF_NAMES:\n",
        "        tmp = globals()[name][['Predicted_month', 'Predicted_Probabilities']].copy()\n",
        "        tmp.rename(\n",
        "            columns={'Predicted_Probabilities': f'Prob_{name}'},\n",
        "            inplace=True\n",
        "        )\n",
        "        prob_dfs.append(tmp)\n",
        "\n",
        "    # 3) innerâ€‘join on Predicted_month\n",
        "    df_probs = reduce(\n",
        "        lambda left, right: pd.merge(left, right, on='Predicted_month', how='inner'),\n",
        "        prob_dfs\n",
        "    )\n",
        "\n",
        "    # 4) bring in the Actual_Winner from your first RF run\n",
        "    df_probs = pd.merge(\n",
        "        df_probs,\n",
        "        results_df_rf[['Predicted_month', 'Actual_Winner']],\n",
        "        on='Predicted_month',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # 5) compute the averaged (â€œhybridâ€) probabilities\n",
        "    df_probs['Hybrid_Predicted_Probabilities'] = df_probs.apply(\n",
        "        lambda row: np.mean([row[f'Prob_{n}'] for n in MODEL_DF_NAMES], axis=0),\n",
        "        axis=1\n",
        "    )\n",
        "    # rename to match the other DataFramesâ€™ column\n",
        "    df_probs.rename(\n",
        "        columns={'Hybrid_Predicted_Probabilities': 'Predicted_Probabilities'},\n",
        "        inplace=True\n",
        "    )\n",
        "\n",
        "    # 6) merge in the factor returns\n",
        "    df_hybrid = pd.merge(\n",
        "        df_probs,\n",
        "        df_factor,\n",
        "        on='Predicted_month',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # 7) compute the hybrid allocated return\n",
        "    df_hybrid['Allocated_Return'] = df_hybrid.apply(\n",
        "        lambda row: np.dot(row['Predicted_Probabilities'], row[FACTORS].values),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # 8) keep only date, actual winner, predicted probabilities, and the allocated return\n",
        "    df_hybrid = df_hybrid[\n",
        "        ['Predicted_month', 'Actual_Winner', 'Predicted_Probabilities', 'Allocated_Return']\n",
        "    ]"
      ],
      "metadata": {
        "id": "JKYtkk2MWPC0"
      },
      "id": "JKYtkk2MWPC0",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model evaluation"
      ],
      "metadata": {
        "id": "A1BqWL_QXA8e"
      },
      "id": "A1BqWL_QXA8e"
    },
    {
      "cell_type": "code",
      "source": [
        "# CellÂ 3 â€” collect both RF and RF2 (and others) into your dict\n",
        "results_dfs = {}\n",
        "\n",
        "if RF:\n",
        "    results_dfs[\"Random Forest\"] = results_df_rf.copy()\n",
        "    print(\"Results from Random Forest added.\")\n",
        "\n",
        "if RF2:\n",
        "    results_dfs[\"Random Forest 2\"] = results_df_rf2.copy()\n",
        "    print(\"Results from Random ForestÂ 2 added.\")\n",
        "\n",
        "if GB:\n",
        "    results_dfs[\"Gradient Boosting\"] = results_df_gb.copy()\n",
        "    print(\"Results from Gradient Boosting added.\")\n",
        "\n",
        "if Hybrid:\n",
        "    results_dfs[\"Hybrid\"] = df_hybrid.copy()\n",
        "    print(\"Results from Hybrid Model added.\")\n",
        "\n",
        "if not results_dfs:\n",
        "    raise ValueError(\"No valid model was selected; set at least one of [RF, RF2, GB, Hybrid] to True.\")\n",
        "\n",
        "print(\"\\nAvailable model results:\")\n",
        "for name, df in results_dfs.items():\n",
        "    print(f\" â€¢ {name}: {df.shape[0]} rows Ã— {df.shape[1]} cols\")\n",
        "\n",
        "from IPython.display import display\n",
        "for name, df in results_dfs.items():\n",
        "    print(f\"\\n=== {name} (first 5 rows) ===\")\n",
        "    display(df.head())"
      ],
      "metadata": {
        "id": "FOzCGJrxXKUm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "a631b295-2ec9-4255-be38-a0695e560246"
      },
      "id": "FOzCGJrxXKUm",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from Random Forest added.\n",
            "Results from Gradient Boosting added.\n",
            "\n",
            "Available model results:\n",
            " â€¢ Random Forest: 632 rows Ã— 23 cols\n",
            " â€¢ Gradient Boosting: 632 rows Ã— 23 cols\n",
            "\n",
            "=== Random Forest (first 5 rows) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "0  NoRegime      1972-04-30       1967-04-30     1972-03-30           60   \n",
              "1  NoRegime      1972-05-30       1967-05-30     1972-04-30           60   \n",
              "2  NoRegime      1972-06-30       1967-06-30     1972-05-30           60   \n",
              "3  NoRegime      1972-07-30       1967-07-30     1972-06-30           60   \n",
              "4  NoRegime      1972-08-30       1967-08-30     1972-07-30           60   \n",
              "\n",
              "                                 Feature_Importances  \\\n",
              "0  [0.0016694269625703924, 0.001192447830407423, ...   \n",
              "1  [0.0, 0.09659533073929963, 0.4639834630350199,...   \n",
              "2  [0.008956019546868041, 0.09718347401155038, 0....   \n",
              "3  [0.11361302276336678, 0.01685740410991866, 0.4...   \n",
              "4  [0.0019706136560069232, 0.0, 0.379809853068280...   \n",
              "\n",
              "                             Predicted_Probabilities Predicted_Winner  \\\n",
              "0  [0.39999999999999925, 0.0, 0.05800000000000002...              RMW   \n",
              "1  [0.39999999999999925, 0.0, 0.0, 0.600000000000...              RMW   \n",
              "2  [0.39999999999999925, 0.0, 0.0, 0.600000000000...              RMW   \n",
              "3  [0.2857142857142854, 0.0, 0.0, 0.7142857142857...              RMW   \n",
              "4                               [0.0, 0.0, 0.0, 1.0]              RMW   \n",
              "\n",
              "   Allocated_Return  Equal_Weight_Return  ... Max_Tree_Depth  \\\n",
              "0         -0.001954            -0.002750  ...              6   \n",
              "1          0.001640            -0.013525  ...              5   \n",
              "2          0.009560            -0.003475  ...              5   \n",
              "3          0.000229            -0.004075  ...              5   \n",
              "4         -0.019600             0.004875  ...              6   \n",
              "\n",
              "   Prediction_Horizon_Months  Feature_Level_CPI%  Feature_Level_T10Y3  \\\n",
              "0                          1             0.48544                 2.39   \n",
              "1                          1             0.00000                 2.43   \n",
              "2                          1             0.24155                 2.36   \n",
              "3                          1             0.24096                 2.24   \n",
              "4                          1             0.24038                 2.14   \n",
              "\n",
              "   Feature_Level_CFNAI  Feature_Level_GARCH_1M  Feature_Level_SMB_MA12  \\\n",
              "0                 0.39                0.506612                0.003183   \n",
              "1                 1.04                0.464483                0.000942   \n",
              "2                 0.74                0.501311                0.001433   \n",
              "3                 0.51                0.345143               -0.000225   \n",
              "4                 0.51                0.474954                0.000650   \n",
              "\n",
              "   Feature_Level_HML_MA12  Feature_Level_CMA_MA12  Feature_Level_RMW_MA12  \n",
              "0               -0.008283               -0.003433                0.008025  \n",
              "1               -0.006333               -0.001325                0.007867  \n",
              "2               -0.006808               -0.002908                0.008742  \n",
              "3               -0.007858               -0.004742                0.009525  \n",
              "4               -0.008367               -0.003675                0.009817  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2045ea7b-4897-4f8f-9df1-8c9af5d8bfd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>1967-04-30</td>\n",
              "      <td>1972-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0016694269625703924, 0.001192447830407423, ...</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.05800000000000002...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.001954</td>\n",
              "      <td>-0.002750</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.48544</td>\n",
              "      <td>2.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>-0.008283</td>\n",
              "      <td>-0.003433</td>\n",
              "      <td>0.008025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>1967-05-30</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.09659533073929963, 0.4639834630350199,...</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.0, 0.600000000000...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.001640</td>\n",
              "      <td>-0.013525</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.464483</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.001325</td>\n",
              "      <td>0.007867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>1967-06-30</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.008956019546868041, 0.09718347401155038, 0....</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.0, 0.600000000000...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.009560</td>\n",
              "      <td>-0.003475</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24155</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.501311</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>-0.006808</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.008742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>1967-07-30</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11361302276336678, 0.01685740410991866, 0.4...</td>\n",
              "      <td>[0.2857142857142854, 0.0, 0.0, 0.7142857142857...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24096</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.345143</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>-0.007858</td>\n",
              "      <td>-0.004742</td>\n",
              "      <td>0.009525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-08-30</td>\n",
              "      <td>1967-08-30</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0019706136560069232, 0.0, 0.379809853068280...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019600</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24038</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.474954</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>-0.008367</td>\n",
              "      <td>-0.003675</td>\n",
              "      <td>0.009817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2045ea7b-4897-4f8f-9df1-8c9af5d8bfd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2045ea7b-4897-4f8f-9df1-8c9af5d8bfd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2045ea7b-4897-4f8f-9df1-8c9af5d8bfd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-73446803-2e5c-4133-99de-c5dea5879460\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73446803-2e5c-4133-99de-c5dea5879460')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-73446803-2e5c-4133-99de-c5dea5879460 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Gradient Boosting (first 5 rows) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "0  NoRegime      1972-04-30       1967-04-30     1972-03-30           60   \n",
              "1  NoRegime      1972-05-30       1967-05-30     1972-04-30           60   \n",
              "2  NoRegime      1972-06-30       1967-06-30     1972-05-30           60   \n",
              "3  NoRegime      1972-07-30       1967-07-30     1972-06-30           60   \n",
              "4  NoRegime      1972-08-30       1967-08-30     1972-07-30           60   \n",
              "\n",
              "                                 Feature_Importances  \\\n",
              "0  [0.13265955, 0.11483573, 0.15405597, 0.1370685...   \n",
              "1  [0.11419878, 0.12536857, 0.16869505, 0.1602756...   \n",
              "2  [0.117514886, 0.11859358, 0.17367934, 0.133065...   \n",
              "3  [0.11001509, 0.13787535, 0.15580742, 0.1411137...   \n",
              "4  [0.11902304, 0.1257567, 0.14709407, 0.14186145...   \n",
              "\n",
              "                             Predicted_Probabilities Predicted_Winner  \\\n",
              "0  [0.2881610691547394, 0.04178425297141075, 0.06...              RMW   \n",
              "1  [0.6372771859169006, 0.016957221552729607, 0.0...              SMB   \n",
              "2  [0.24325895309448242, 0.018556561321020126, 0....              RMW   \n",
              "3  [0.4472165107727051, 0.02042347937822342, 0.04...              RMW   \n",
              "4  [0.26450541615486145, 0.02227671444416046, 0.0...              RMW   \n",
              "\n",
              "   Allocated_Return  Equal_Weight_Return  ... Max_Tree_Depth  \\\n",
              "0         -0.002515            -0.002750  ...           None   \n",
              "1         -0.014409            -0.013525  ...           None   \n",
              "2          0.011564            -0.003475  ...           None   \n",
              "3         -0.007065            -0.004075  ...           None   \n",
              "4         -0.019916             0.004875  ...           None   \n",
              "\n",
              "   Prediction_Horizon_Months Feature_Level_CPI% Feature_Level_T10Y3  \\\n",
              "0                          1            0.48544                2.39   \n",
              "1                          1            0.00000                2.43   \n",
              "2                          1            0.24155                2.36   \n",
              "3                          1            0.24096                2.24   \n",
              "4                          1            0.24038                2.14   \n",
              "\n",
              "   Feature_Level_CFNAI  Feature_Level_GARCH_1M  Feature_Level_SMB_MA12  \\\n",
              "0                 0.39                0.506612                0.003183   \n",
              "1                 1.04                0.464483                0.000942   \n",
              "2                 0.74                0.501311                0.001433   \n",
              "3                 0.51                0.345143               -0.000225   \n",
              "4                 0.51                0.474954                0.000650   \n",
              "\n",
              "   Feature_Level_HML_MA12  Feature_Level_CMA_MA12  Feature_Level_RMW_MA12  \n",
              "0               -0.008283               -0.003433                0.008025  \n",
              "1               -0.006333               -0.001325                0.007867  \n",
              "2               -0.006808               -0.002908                0.008742  \n",
              "3               -0.007858               -0.004742                0.009525  \n",
              "4               -0.008367               -0.003675                0.009817  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61801e3b-7af9-41ec-b621-1cdc4a6a8cd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>1967-04-30</td>\n",
              "      <td>1972-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13265955, 0.11483573, 0.15405597, 0.1370685...</td>\n",
              "      <td>[0.2881610691547394, 0.04178425297141075, 0.06...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.002515</td>\n",
              "      <td>-0.002750</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.48544</td>\n",
              "      <td>2.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>-0.008283</td>\n",
              "      <td>-0.003433</td>\n",
              "      <td>0.008025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>1967-05-30</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11419878, 0.12536857, 0.16869505, 0.1602756...</td>\n",
              "      <td>[0.6372771859169006, 0.016957221552729607, 0.0...</td>\n",
              "      <td>SMB</td>\n",
              "      <td>-0.014409</td>\n",
              "      <td>-0.013525</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.464483</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.001325</td>\n",
              "      <td>0.007867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>1967-06-30</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.117514886, 0.11859358, 0.17367934, 0.133065...</td>\n",
              "      <td>[0.24325895309448242, 0.018556561321020126, 0....</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.011564</td>\n",
              "      <td>-0.003475</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24155</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.501311</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>-0.006808</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.008742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>1967-07-30</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11001509, 0.13787535, 0.15580742, 0.1411137...</td>\n",
              "      <td>[0.4472165107727051, 0.02042347937822342, 0.04...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.007065</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24096</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.345143</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>-0.007858</td>\n",
              "      <td>-0.004742</td>\n",
              "      <td>0.009525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-08-30</td>\n",
              "      <td>1967-08-30</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11902304, 0.1257567, 0.14709407, 0.14186145...</td>\n",
              "      <td>[0.26450541615486145, 0.02227671444416046, 0.0...</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019916</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24038</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.474954</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>-0.008367</td>\n",
              "      <td>-0.003675</td>\n",
              "      <td>0.009817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61801e3b-7af9-41ec-b621-1cdc4a6a8cd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61801e3b-7af9-41ec-b621-1cdc4a6a8cd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61801e3b-7af9-41ec-b621-1cdc4a6a8cd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5554c2f-42d1-49ba-b4e0-97b9e4ab7967\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5554c2f-42d1-49ba-b4e0-97b9e4ab7967')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5554c2f-42d1-49ba-b4e0-97b9e4ab7967 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Increase column width so no text is truncated\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Define the date range\n",
        "start_date = pd.to_datetime('1968-08-01')\n",
        "end_date   = pd.to_datetime('2025-01-01')\n",
        "\n",
        "# Dictionary to store filtered results for each model using the new naming format.\n",
        "filtered_results_dfs = {}\n",
        "\n",
        "# Loop through each model's results dataframe in results_dfs and add numbering.\n",
        "for i, (model_name, df) in enumerate(results_dfs.items(), 1):\n",
        "    new_model_name = f\"ML{i}: {model_name}\"\n",
        "\n",
        "    # Convert 'Predicted_month' to datetime if not already\n",
        "    df['Predicted_month'] = pd.to_datetime(df['Predicted_month'])\n",
        "\n",
        "    # Filter the DataFrame within the specified date range and sort by date.\n",
        "    filtered_df = df[(df['Predicted_month'] >= start_date) & (df['Predicted_month'] <= end_date)].copy().sort_values('Predicted_month')\n",
        "\n",
        "    # Store the filtered dataframe in our new dictionary using the new model name.\n",
        "    filtered_results_dfs[new_model_name] = filtered_df\n",
        "\n",
        "    # Display the filtered results with a header showing the new model name.\n",
        "    print(f\"\\n=== Filtered Results for Model '{new_model_name}' ===\")\n",
        "    display(filtered_df)\n",
        "\n",
        "# Reset column width option to default after display.\n",
        "pd.reset_option('display.max_colwidth')\n"
      ],
      "metadata": {
        "id": "JmpzyRpGWP0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a55fa17f-7439-48a0-efa3-2b63b0ee339c"
      },
      "id": "JmpzyRpGWP0n",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Filtered Results for Model 'ML1: Random Forest' ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "0    NoRegime      1972-04-30       1967-04-30     1972-03-30           60   \n",
              "1    NoRegime      1972-05-30       1967-05-30     1972-04-30           60   \n",
              "2    NoRegime      1972-06-30       1967-06-30     1972-05-30           60   \n",
              "3    NoRegime      1972-07-30       1967-07-30     1972-06-30           60   \n",
              "4    NoRegime      1972-08-30       1967-08-30     1972-07-30           60   \n",
              "..        ...             ...              ...            ...          ...   \n",
              "627  NoRegime      2024-07-30       2019-07-30     2024-06-30           60   \n",
              "628  NoRegime      2024-08-30       2019-08-30     2024-07-30           60   \n",
              "629  NoRegime      2024-09-30       2019-09-30     2024-08-30           60   \n",
              "630  NoRegime      2024-10-30       2019-10-30     2024-09-30           60   \n",
              "631  NoRegime      2024-11-30       2019-11-30     2024-10-30           60   \n",
              "\n",
              "                                                                                                                                                             Feature_Importances  \\\n",
              "0    [0.0016694269625703924, 0.001192447830407423, 0.28023865732787645, 0.0017886717456111346, 0.23096696246918766, 0.272984097912103, 0.13025877516926948, 0.08090096058297434]   \n",
              "1                                         [0.0, 0.09659533073929963, 0.4639834630350199, 0.15485958382676332, 0.0711332684824901, 0.12445624807188983, 0.08897210584453709, 0.0]   \n",
              "2                      [0.008956019546868041, 0.09718347401155038, 0.5001513670691822, 0.18130545405379744, 0.0, 0.12128744826113078, 0.08798163021606746, 0.003134606841403815]   \n",
              "3       [0.11361302276336678, 0.01685740410991866, 0.40401623433915645, 0.2539119623979339, 0.04605340728620241, 0.031683430386447865, 0.04247750132345156, 0.09138703739352229]   \n",
              "4                    [0.0019706136560069232, 0.0, 0.37980985306828036, 0.0019706136560069232, 0.10121843787408898, 0.15999734060235365, 0.15730004298411407, 0.1977330981591491]   \n",
              "..                                                                                                                                                                           ...   \n",
              "627                                                     [0.033400804348786825, 0.0, 0.5214319012013514, 0.024353206346400345, 0.14861434755403982, 0.2721997405494218, 0.0, 0.0]   \n",
              "628                                                      [0.0, 0.0, 0.39146147166441136, 0.10286200950498363, 0.1611536358665937, 0.19403081079342605, 0.0, 0.15049207217058533]   \n",
              "629                                                       [0.09967845659163997, 0.3370695964671346, 0.14193844740468542, 0.12423268050277696, 0.0, 0.2970808190337631, 0.0, 0.0]   \n",
              "630                                                        [0.1272924710424714, 0.31321027193621065, 0.11133407843934164, 0.0, 0.252714052985792, 0.19544912559618427, 0.0, 0.0]   \n",
              "631  [0.13392007817204687, 0.2817468067595945, 0.14261035552374152, 0.0019470293486041589, 0.2386609230228459, 0.1981369975811842, 0.0018324982104509736, 0.0011453113815318582]   \n",
              "\n",
              "                                                                 Predicted_Probabilities  \\\n",
              "0                   [0.39999999999999925, 0.0, 0.058000000000000024, 0.5420000000000004]   \n",
              "1                                     [0.39999999999999925, 0.0, 0.0, 0.600000000000001]   \n",
              "2                                     [0.39999999999999925, 0.0, 0.0, 0.600000000000001]   \n",
              "3                                     [0.2857142857142854, 0.0, 0.0, 0.7142857142857142]   \n",
              "4                                                                   [0.0, 0.0, 0.0, 1.0]   \n",
              "..                                                                                   ...   \n",
              "627                 [0.39999999999999925, 0.19999999999999962, 0.0, 0.39999999999999925]   \n",
              "628                                                                 [0.5, 0.0, 0.0, 0.5]   \n",
              "629                                  [0.3333333333333329, 0.0, 0.16666666666666646, 0.5]   \n",
              "630                                                                 [0.0, 0.0, 0.0, 1.0]   \n",
              "631  [0.11111111111111088, 0.11111111111111088, 0.44444444444444353, 0.3333333333333329]   \n",
              "\n",
              "    Predicted_Winner  Allocated_Return  Equal_Weight_Return  ...  \\\n",
              "0                RMW         -0.001954            -0.002750  ...   \n",
              "1                RMW          0.001640            -0.013525  ...   \n",
              "2                RMW          0.009560            -0.003475  ...   \n",
              "3                RMW          0.000229            -0.004075  ...   \n",
              "4                RMW         -0.019600             0.004875  ...   \n",
              "..               ...               ...                  ...  ...   \n",
              "627              RMW          0.045480             0.036675  ...   \n",
              "628              RMW         -0.014000            -0.007675  ...   \n",
              "629              RMW         -0.003633            -0.009575  ...   \n",
              "630              RMW         -0.013800            -0.000850  ...   \n",
              "631              CMA         -0.013122            -0.000150  ...   \n",
              "\n",
              "    Max_Tree_Depth  Prediction_Horizon_Months  Feature_Level_CPI%  \\\n",
              "0                6                          1             0.48544   \n",
              "1                5                          1             0.00000   \n",
              "2                5                          1             0.24155   \n",
              "3                5                          1             0.24096   \n",
              "4                6                          1             0.24038   \n",
              "..             ...                        ...                 ...   \n",
              "627              5                          1             0.03961   \n",
              "628              5                          1            -0.00287   \n",
              "629              7                          1             0.13892   \n",
              "630              6                          1             0.18019   \n",
              "631              6                          1             0.22920   \n",
              "\n",
              "     Feature_Level_T10Y3  Feature_Level_CFNAI  Feature_Level_GARCH_1M  \\\n",
              "0                   2.39                 0.39                0.506612   \n",
              "1                   2.43                 1.04                0.464483   \n",
              "2                   2.36                 0.74                0.501311   \n",
              "3                   2.24                 0.51                0.345143   \n",
              "4                   2.14                 0.51                0.474954   \n",
              "..                   ...                  ...                     ...   \n",
              "627                -0.88                 0.15                0.327046   \n",
              "628                -1.11                -0.17                1.087011   \n",
              "629                -1.14                -0.30                0.641443   \n",
              "630                -0.91                -0.05                0.396629   \n",
              "631                -0.23                -0.21                0.684819   \n",
              "\n",
              "     Feature_Level_SMB_MA12  Feature_Level_HML_MA12  Feature_Level_CMA_MA12  \\\n",
              "0                  0.003183               -0.008283               -0.003433   \n",
              "1                  0.000942               -0.006333               -0.001325   \n",
              "2                  0.001433               -0.006808               -0.002908   \n",
              "3                 -0.000225               -0.007858               -0.004742   \n",
              "4                  0.000650               -0.008367               -0.003675   \n",
              "..                      ...                     ...                     ...   \n",
              "627               -0.006250                0.005908               -0.008275   \n",
              "628               -0.011025                0.003317               -0.008408   \n",
              "629               -0.006492                0.004675               -0.008567   \n",
              "630               -0.006467                0.004633               -0.005875   \n",
              "631               -0.005825                0.001267               -0.005392   \n",
              "\n",
              "     Feature_Level_RMW_MA12  \n",
              "0                  0.008025  \n",
              "1                  0.007867  \n",
              "2                  0.008742  \n",
              "3                  0.009525  \n",
              "4                  0.009817  \n",
              "..                      ...  \n",
              "627                0.005992  \n",
              "628                0.004525  \n",
              "629                0.005183  \n",
              "630                0.003042  \n",
              "631                0.001533  \n",
              "\n",
              "[632 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c998456-698a-45f1-93fc-86cbbc9a04eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>1967-04-30</td>\n",
              "      <td>1972-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0016694269625703924, 0.001192447830407423, 0.28023865732787645, 0.0017886717456111346, 0.23096696246918766, 0.272984097912103, 0.13025877516926948, 0.08090096058297434]</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.058000000000000024, 0.5420000000000004]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.001954</td>\n",
              "      <td>-0.002750</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.48544</td>\n",
              "      <td>2.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>-0.008283</td>\n",
              "      <td>-0.003433</td>\n",
              "      <td>0.008025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>1967-05-30</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.09659533073929963, 0.4639834630350199, 0.15485958382676332, 0.0711332684824901, 0.12445624807188983, 0.08897210584453709, 0.0]</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.0, 0.600000000000001]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.001640</td>\n",
              "      <td>-0.013525</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.464483</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.001325</td>\n",
              "      <td>0.007867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>1967-06-30</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.008956019546868041, 0.09718347401155038, 0.5001513670691822, 0.18130545405379744, 0.0, 0.12128744826113078, 0.08798163021606746, 0.003134606841403815]</td>\n",
              "      <td>[0.39999999999999925, 0.0, 0.0, 0.600000000000001]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.009560</td>\n",
              "      <td>-0.003475</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24155</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.501311</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>-0.006808</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.008742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>1967-07-30</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11361302276336678, 0.01685740410991866, 0.40401623433915645, 0.2539119623979339, 0.04605340728620241, 0.031683430386447865, 0.04247750132345156, 0.09138703739352229]</td>\n",
              "      <td>[0.2857142857142854, 0.0, 0.0, 0.7142857142857142]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24096</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.345143</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>-0.007858</td>\n",
              "      <td>-0.004742</td>\n",
              "      <td>0.009525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-08-30</td>\n",
              "      <td>1967-08-30</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0019706136560069232, 0.0, 0.37980985306828036, 0.0019706136560069232, 0.10121843787408898, 0.15999734060235365, 0.15730004298411407, 0.1977330981591491]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019600</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24038</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.474954</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>-0.008367</td>\n",
              "      <td>-0.003675</td>\n",
              "      <td>0.009817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>2019-07-30</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.033400804348786825, 0.0, 0.5214319012013514, 0.024353206346400345, 0.14861434755403982, 0.2721997405494218, 0.0, 0.0]</td>\n",
              "      <td>[0.39999999999999925, 0.19999999999999962, 0.0, 0.39999999999999925]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.045480</td>\n",
              "      <td>0.036675</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03961</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.327046</td>\n",
              "      <td>-0.006250</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>-0.008275</td>\n",
              "      <td>0.005992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>2019-08-30</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.0, 0.0, 0.39146147166441136, 0.10286200950498363, 0.1611536358665937, 0.19403081079342605, 0.0, 0.15049207217058533]</td>\n",
              "      <td>[0.5, 0.0, 0.0, 0.5]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.014000</td>\n",
              "      <td>-0.007675</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.00287</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.087011</td>\n",
              "      <td>-0.011025</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>-0.008408</td>\n",
              "      <td>0.004525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.09967845659163997, 0.3370695964671346, 0.14193844740468542, 0.12423268050277696, 0.0, 0.2970808190337631, 0.0, 0.0]</td>\n",
              "      <td>[0.3333333333333329, 0.0, 0.16666666666666646, 0.5]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.003633</td>\n",
              "      <td>-0.009575</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13892</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.641443</td>\n",
              "      <td>-0.006492</td>\n",
              "      <td>0.004675</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.005183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>2019-10-30</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1272924710424714, 0.31321027193621065, 0.11133407843934164, 0.0, 0.252714052985792, 0.19544912559618427, 0.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.013800</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.18019</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.396629</td>\n",
              "      <td>-0.006467</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>-0.005875</td>\n",
              "      <td>0.003042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-11-30</td>\n",
              "      <td>2019-11-30</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13392007817204687, 0.2817468067595945, 0.14261035552374152, 0.0019470293486041589, 0.2386609230228459, 0.1981369975811842, 0.0018324982104509736, 0.0011453113815318582]</td>\n",
              "      <td>[0.11111111111111088, 0.11111111111111088, 0.44444444444444353, 0.3333333333333329]</td>\n",
              "      <td>CMA</td>\n",
              "      <td>-0.013122</td>\n",
              "      <td>-0.000150</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22920</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.684819</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>-0.005392</td>\n",
              "      <td>0.001533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>632 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c998456-698a-45f1-93fc-86cbbc9a04eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c998456-698a-45f1-93fc-86cbbc9a04eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c998456-698a-45f1-93fc-86cbbc9a04eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6203d659-3a76-4a76-8bec-22df0557222d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6203d659-3a76-4a76-8bec-22df0557222d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6203d659-3a76-4a76-8bec-22df0557222d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_47439f1f-a526-4e07-9932-b0ba8a1c62af\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('filtered_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47439f1f-a526-4e07-9932-b0ba8a1c62af button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('filtered_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Filtered Results for Model 'ML2: Gradient Boosting' ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Regime Predicted_month Train_Start_Date Train_End_Date  Train_Count  \\\n",
              "0    NoRegime      1972-04-30       1967-04-30     1972-03-30           60   \n",
              "1    NoRegime      1972-05-30       1967-05-30     1972-04-30           60   \n",
              "2    NoRegime      1972-06-30       1967-06-30     1972-05-30           60   \n",
              "3    NoRegime      1972-07-30       1967-07-30     1972-06-30           60   \n",
              "4    NoRegime      1972-08-30       1967-08-30     1972-07-30           60   \n",
              "..        ...             ...              ...            ...          ...   \n",
              "627  NoRegime      2024-07-30       2019-07-30     2024-06-30           60   \n",
              "628  NoRegime      2024-08-30       2019-08-30     2024-07-30           60   \n",
              "629  NoRegime      2024-09-30       2019-09-30     2024-08-30           60   \n",
              "630  NoRegime      2024-10-30       2019-10-30     2024-09-30           60   \n",
              "631  NoRegime      2024-11-30       2019-11-30     2024-10-30           60   \n",
              "\n",
              "                                                                                    Feature_Importances  \\\n",
              "0       [0.13265955, 0.11483573, 0.15405597, 0.13706857, 0.10857568, 0.14532444, 0.09348169, 0.1139984]   \n",
              "1      [0.11419878, 0.12536857, 0.16869505, 0.16027565, 0.11076321, 0.11490902, 0.104420155, 0.1013696]   \n",
              "2     [0.117514886, 0.11859358, 0.17367934, 0.1330651, 0.10695293, 0.11638159, 0.115542494, 0.11827003]   \n",
              "3     [0.11001509, 0.13787535, 0.15580742, 0.14111379, 0.100608364, 0.12751155, 0.11326879, 0.11379969]   \n",
              "4      [0.11902304, 0.1257567, 0.14709407, 0.14186145, 0.101651914, 0.15038754, 0.10045576, 0.11376953]   \n",
              "..                                                                                                  ...   \n",
              "627     [0.1383057, 0.14141065, 0.13999258, 0.11885134, 0.10662638, 0.11319606, 0.11032533, 0.13129194]   \n",
              "628    [0.1258053, 0.14109226, 0.13648534, 0.12625147, 0.105386406, 0.12662788, 0.11649264, 0.12185874]   \n",
              "629    [0.13950507, 0.12203448, 0.12051911, 0.1360373, 0.11461053, 0.12811199, 0.122269385, 0.11691212]   \n",
              "630  [0.13405606, 0.1448167, 0.117900446, 0.10775757, 0.118681684, 0.15233774, 0.09967649, 0.124773234]   \n",
              "631     [0.15408151, 0.1483383, 0.10167967, 0.12251943, 0.10730645, 0.14806342, 0.10309636, 0.11491494]   \n",
              "\n",
              "                                                                  Predicted_Probabilities  \\\n",
              "0      [0.2881610691547394, 0.04178425297141075, 0.06780713051557541, 0.6022475361824036]   \n",
              "1     [0.6372771859169006, 0.016957221552729607, 0.05328664183616638, 0.2924789786338806]   \n",
              "2    [0.24325895309448242, 0.018556561321020126, 0.03605775162577629, 0.7021267414093018]   \n",
              "3     [0.4472165107727051, 0.02042347937822342, 0.048946645110845566, 0.4834133982658386]   \n",
              "4      [0.26450541615486145, 0.02227671444416046, 0.04690293222665787, 0.666314959526062]   \n",
              "..                                                                                    ...   \n",
              "627    [0.21670712530612946, 0.1424505114555359, 0.06401261687278748, 0.5768297910690308]   \n",
              "628    [0.5750421285629272, 0.02234901487827301, 0.04351596161723137, 0.3590928614139557]   \n",
              "629    [0.30214813351631165, 0.0692986324429512, 0.11077828705310822, 0.5177749991416931]   \n",
              "630   [0.09118417650461197, 0.07643740624189377, 0.07767794281244278, 0.7547004818916321]   \n",
              "631  [0.17551875114440918, 0.16604794561862946, 0.22592058777809143, 0.43251273036003113]   \n",
              "\n",
              "    Predicted_Winner  Allocated_Return  Equal_Weight_Return  ...  \\\n",
              "0                RMW         -0.002515            -0.002750  ...   \n",
              "1                SMB         -0.014409            -0.013525  ...   \n",
              "2                RMW          0.011564            -0.003475  ...   \n",
              "3                RMW         -0.007065            -0.004075  ...   \n",
              "4                RMW         -0.019916             0.004875  ...   \n",
              "..               ...               ...                  ...  ...   \n",
              "627              RMW          0.027664             0.036675  ...   \n",
              "628              SMB         -0.017815            -0.007675  ...   \n",
              "629              RMW         -0.004958            -0.009575  ...   \n",
              "630              RMW         -0.009737            -0.000850  ...   \n",
              "631              RMW         -0.007928            -0.000150  ...   \n",
              "\n",
              "    Max_Tree_Depth  Prediction_Horizon_Months Feature_Level_CPI%  \\\n",
              "0             None                          1            0.48544   \n",
              "1             None                          1            0.00000   \n",
              "2             None                          1            0.24155   \n",
              "3             None                          1            0.24096   \n",
              "4             None                          1            0.24038   \n",
              "..             ...                        ...                ...   \n",
              "627           None                          1            0.03961   \n",
              "628           None                          1           -0.00287   \n",
              "629           None                          1            0.13892   \n",
              "630           None                          1            0.18019   \n",
              "631           None                          1            0.22920   \n",
              "\n",
              "    Feature_Level_T10Y3  Feature_Level_CFNAI  Feature_Level_GARCH_1M  \\\n",
              "0                  2.39                 0.39                0.506612   \n",
              "1                  2.43                 1.04                0.464483   \n",
              "2                  2.36                 0.74                0.501311   \n",
              "3                  2.24                 0.51                0.345143   \n",
              "4                  2.14                 0.51                0.474954   \n",
              "..                  ...                  ...                     ...   \n",
              "627               -0.88                 0.15                0.327046   \n",
              "628               -1.11                -0.17                1.087011   \n",
              "629               -1.14                -0.30                0.641443   \n",
              "630               -0.91                -0.05                0.396629   \n",
              "631               -0.23                -0.21                0.684819   \n",
              "\n",
              "     Feature_Level_SMB_MA12  Feature_Level_HML_MA12  Feature_Level_CMA_MA12  \\\n",
              "0                  0.003183               -0.008283               -0.003433   \n",
              "1                  0.000942               -0.006333               -0.001325   \n",
              "2                  0.001433               -0.006808               -0.002908   \n",
              "3                 -0.000225               -0.007858               -0.004742   \n",
              "4                  0.000650               -0.008367               -0.003675   \n",
              "..                      ...                     ...                     ...   \n",
              "627               -0.006250                0.005908               -0.008275   \n",
              "628               -0.011025                0.003317               -0.008408   \n",
              "629               -0.006492                0.004675               -0.008567   \n",
              "630               -0.006467                0.004633               -0.005875   \n",
              "631               -0.005825                0.001267               -0.005392   \n",
              "\n",
              "     Feature_Level_RMW_MA12  \n",
              "0                  0.008025  \n",
              "1                  0.007867  \n",
              "2                  0.008742  \n",
              "3                  0.009525  \n",
              "4                  0.009817  \n",
              "..                      ...  \n",
              "627                0.005992  \n",
              "628                0.004525  \n",
              "629                0.005183  \n",
              "630                0.003042  \n",
              "631                0.001533  \n",
              "\n",
              "[632 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d24cf4dc-0795-4476-a6cd-24979b41687b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regime</th>\n",
              "      <th>Predicted_month</th>\n",
              "      <th>Train_Start_Date</th>\n",
              "      <th>Train_End_Date</th>\n",
              "      <th>Train_Count</th>\n",
              "      <th>Feature_Importances</th>\n",
              "      <th>Predicted_Probabilities</th>\n",
              "      <th>Predicted_Winner</th>\n",
              "      <th>Allocated_Return</th>\n",
              "      <th>Equal_Weight_Return</th>\n",
              "      <th>...</th>\n",
              "      <th>Max_Tree_Depth</th>\n",
              "      <th>Prediction_Horizon_Months</th>\n",
              "      <th>Feature_Level_CPI%</th>\n",
              "      <th>Feature_Level_T10Y3</th>\n",
              "      <th>Feature_Level_CFNAI</th>\n",
              "      <th>Feature_Level_GARCH_1M</th>\n",
              "      <th>Feature_Level_SMB_MA12</th>\n",
              "      <th>Feature_Level_HML_MA12</th>\n",
              "      <th>Feature_Level_CMA_MA12</th>\n",
              "      <th>Feature_Level_RMW_MA12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>1967-04-30</td>\n",
              "      <td>1972-03-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13265955, 0.11483573, 0.15405597, 0.13706857, 0.10857568, 0.14532444, 0.09348169, 0.1139984]</td>\n",
              "      <td>[0.2881610691547394, 0.04178425297141075, 0.06780713051557541, 0.6022475361824036]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.002515</td>\n",
              "      <td>-0.002750</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.48544</td>\n",
              "      <td>2.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>-0.008283</td>\n",
              "      <td>-0.003433</td>\n",
              "      <td>0.008025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>1967-05-30</td>\n",
              "      <td>1972-04-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11419878, 0.12536857, 0.16869505, 0.16027565, 0.11076321, 0.11490902, 0.104420155, 0.1013696]</td>\n",
              "      <td>[0.6372771859169006, 0.016957221552729607, 0.05328664183616638, 0.2924789786338806]</td>\n",
              "      <td>SMB</td>\n",
              "      <td>-0.014409</td>\n",
              "      <td>-0.013525</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.43</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.464483</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-0.006333</td>\n",
              "      <td>-0.001325</td>\n",
              "      <td>0.007867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>1967-06-30</td>\n",
              "      <td>1972-05-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.117514886, 0.11859358, 0.17367934, 0.1330651, 0.10695293, 0.11638159, 0.115542494, 0.11827003]</td>\n",
              "      <td>[0.24325895309448242, 0.018556561321020126, 0.03605775162577629, 0.7021267414093018]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.011564</td>\n",
              "      <td>-0.003475</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24155</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.501311</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>-0.006808</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.008742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>1967-07-30</td>\n",
              "      <td>1972-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11001509, 0.13787535, 0.15580742, 0.14111379, 0.100608364, 0.12751155, 0.11326879, 0.11379969]</td>\n",
              "      <td>[0.4472165107727051, 0.02042347937822342, 0.048946645110845566, 0.4834133982658386]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.007065</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24096</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.345143</td>\n",
              "      <td>-0.000225</td>\n",
              "      <td>-0.007858</td>\n",
              "      <td>-0.004742</td>\n",
              "      <td>0.009525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>1972-08-30</td>\n",
              "      <td>1967-08-30</td>\n",
              "      <td>1972-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.11902304, 0.1257567, 0.14709407, 0.14186145, 0.101651914, 0.15038754, 0.10045576, 0.11376953]</td>\n",
              "      <td>[0.26450541615486145, 0.02227671444416046, 0.04690293222665787, 0.666314959526062]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.019916</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24038</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.474954</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>-0.008367</td>\n",
              "      <td>-0.003675</td>\n",
              "      <td>0.009817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>2019-07-30</td>\n",
              "      <td>2024-06-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1383057, 0.14141065, 0.13999258, 0.11885134, 0.10662638, 0.11319606, 0.11032533, 0.13129194]</td>\n",
              "      <td>[0.21670712530612946, 0.1424505114555359, 0.06401261687278748, 0.5768297910690308]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.036675</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03961</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.327046</td>\n",
              "      <td>-0.006250</td>\n",
              "      <td>0.005908</td>\n",
              "      <td>-0.008275</td>\n",
              "      <td>0.005992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>2019-08-30</td>\n",
              "      <td>2024-07-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.1258053, 0.14109226, 0.13648534, 0.12625147, 0.105386406, 0.12662788, 0.11649264, 0.12185874]</td>\n",
              "      <td>[0.5750421285629272, 0.02234901487827301, 0.04351596161723137, 0.3590928614139557]</td>\n",
              "      <td>SMB</td>\n",
              "      <td>-0.017815</td>\n",
              "      <td>-0.007675</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.00287</td>\n",
              "      <td>-1.11</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.087011</td>\n",
              "      <td>-0.011025</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>-0.008408</td>\n",
              "      <td>0.004525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13950507, 0.12203448, 0.12051911, 0.1360373, 0.11461053, 0.12811199, 0.122269385, 0.11691212]</td>\n",
              "      <td>[0.30214813351631165, 0.0692986324429512, 0.11077828705310822, 0.5177749991416931]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.004958</td>\n",
              "      <td>-0.009575</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13892</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.641443</td>\n",
              "      <td>-0.006492</td>\n",
              "      <td>0.004675</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.005183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>2019-10-30</td>\n",
              "      <td>2024-09-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.13405606, 0.1448167, 0.117900446, 0.10775757, 0.118681684, 0.15233774, 0.09967649, 0.124773234]</td>\n",
              "      <td>[0.09118417650461197, 0.07643740624189377, 0.07767794281244278, 0.7547004818916321]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.009737</td>\n",
              "      <td>-0.000850</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.18019</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.396629</td>\n",
              "      <td>-0.006467</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>-0.005875</td>\n",
              "      <td>0.003042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>NoRegime</td>\n",
              "      <td>2024-11-30</td>\n",
              "      <td>2019-11-30</td>\n",
              "      <td>2024-10-30</td>\n",
              "      <td>60</td>\n",
              "      <td>[0.15408151, 0.1483383, 0.10167967, 0.12251943, 0.10730645, 0.14806342, 0.10309636, 0.11491494]</td>\n",
              "      <td>[0.17551875114440918, 0.16604794561862946, 0.22592058777809143, 0.43251273036003113]</td>\n",
              "      <td>RMW</td>\n",
              "      <td>-0.007928</td>\n",
              "      <td>-0.000150</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22920</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.684819</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>-0.005392</td>\n",
              "      <td>0.001533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>632 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d24cf4dc-0795-4476-a6cd-24979b41687b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d24cf4dc-0795-4476-a6cd-24979b41687b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d24cf4dc-0795-4476-a6cd-24979b41687b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-239e53bc-52a3-4bb4-b812-cae395624701\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-239e53bc-52a3-4bb4-b812-cae395624701')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-239e53bc-52a3-4bb4-b812-cae395624701 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_be85dd5e-e9ed-48de-a0ad-1db25ef3700a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('filtered_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_be85dd5e-e9ed-48de-a0ad-1db25ef3700a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('filtered_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PDP"
      ],
      "metadata": {
        "id": "GK6qRmzu5X1K"
      },
      "id": "GK6qRmzu5X1K"
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Cell: combined PDP heatmaps for RF and GB â”€â”€\n",
        "if RF and GB and compute_pdp:\n",
        "\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  # 1) Settings\n",
        "  z_grid    = np.array([-2, -1, 0, 1, 2])\n",
        "  eq_w      = 1.0 / len(FACTORS)    # e.g. 0.25 if 4 factors\n",
        "  eq_w_pct  = eq_w * 100            # e.g. 25.0%\n",
        "\n",
        "# â”€â”€ RF PDP â”€â”€\n",
        "    # prepare empty DataFrames: one per factor\n",
        "  pdp_dfs = {\n",
        "        fac: pd.DataFrame(index=FEATURES, columns=z_grid, dtype=float)\n",
        "        for fac in FACTORS\n",
        "    }\n",
        "\n",
        "    # compute raw PDP probabilities\n",
        "    for feat in FEATURES:\n",
        "        Î¼, Ïƒ = X_train[feat].mean(), X_train[feat].std()\n",
        "        for z in z_grid:\n",
        "            x_val = Î¼ + z * Ïƒ\n",
        "            X_tmp = X_train.copy()\n",
        "            X_tmp[feat] = x_val\n",
        "            avg_p = rf_model.predict_proba(X_tmp).mean(axis=0)\n",
        "            for cls, p in zip(rf_model.classes_, avg_p):\n",
        "                pdp_dfs[cls].at[feat, z] = p\n",
        "\n",
        "    # convert to %-point deviations\n",
        "    pdp_dev = {\n",
        "        fac: (df.subtract(eq_w)) * 100\n",
        "        for fac, df in pdp_dfs.items()\n",
        "    }\n",
        "    annot_dfs = {\n",
        "        fac: df_dev.applymap(lambda v: f\"{v:+.1f}%\")\n",
        "        for fac, df_dev in pdp_dev.items()\n",
        "    }\n",
        "    vlim = max(df_dev.abs().values.max() for df_dev in pdp_dev.values())\n",
        "\n",
        "    # plot 2Ã—2 heatmaps\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
        "    axes = axes.flatten()\n",
        "    for ax, fac in zip(axes, FACTORS):\n",
        "        sns.heatmap(\n",
        "            pdp_dev[fac], ax=ax,\n",
        "            cmap=\"vlag\", center=0.0,\n",
        "            vmin=-vlim, vmax=+vlim,\n",
        "            annot=annot_dfs[fac], fmt=\"\",\n",
        "            cbar=(ax is axes[-1]),\n",
        "            annot_kws={\"fontsize\":\"small\"}\n",
        "        )\n",
        "        ax.set_aspect(1 / 1.5)\n",
        "        ax.set_title(f\"{fac}\\nDeviation from {eq_w_pct:.0f}% equal weight\")\n",
        "        ax.set_xlabel(\"Feature z-value\")\n",
        "        ax.set_ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# â”€â”€ GB PDP â”€â”€\n",
        "if GB and compute_pdp:\n",
        "    # build mapping from numeric code â†’ factor name\n",
        "    y_cat   = y_train.astype('category')\n",
        "    mapping = dict(enumerate(y_cat.cat.categories))\n",
        "\n",
        "    # prepare empty DataFrames: one per factor\n",
        "    pdp_dfs = {\n",
        "        fac: pd.DataFrame(index=FEATURES, columns=z_grid, dtype=float)\n",
        "        for fac in mapping.values()\n",
        "    }\n",
        "\n",
        "    # compute raw PDP probabilities\n",
        "    for feat in FEATURES:\n",
        "        Î¼, Ïƒ = X_train[feat].mean(), X_train[feat].std()\n",
        "        for z in z_grid:\n",
        "            x_val = Î¼ + z * Ïƒ\n",
        "            X_tmp = X_train.copy()\n",
        "            X_tmp[feat] = x_val\n",
        "            avg_p = gb_model.predict_proba(X_tmp).mean(axis=0)\n",
        "            for ci, code in enumerate(gb_model.classes_):\n",
        "                fac = mapping[code]\n",
        "                pdp_dfs[fac].at[feat, z] = avg_p[ci]\n",
        "\n",
        "    # convert to %-point deviations\n",
        "    pdp_dev = {\n",
        "        fac: (df.subtract(eq_w)) * 100\n",
        "        for fac, df in pdp_dfs.items()\n",
        "    }\n",
        "    annot_dfs = {\n",
        "        fac: df_dev.applymap(lambda v: f\"{v:+.1f}%\")\n",
        "        for fac, df_dev in pdp_dev.items()\n",
        "    }\n",
        "    vlim = max(df_dev.abs().values.max() for df_dev in pdp_dev.values())\n",
        "\n",
        "    # plot 2Ã—2 heatmaps\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
        "    axes = axes.flatten()\n",
        "    for ax, fac in zip(axes, pdp_dfs.keys()):\n",
        "        sns.heatmap(\n",
        "            pdp_dev[fac], ax=ax,\n",
        "            cmap=\"vlag\", center=0.0,\n",
        "            vmin=-vlim, vmax=+vlim,\n",
        "            annot=annot_dfs[fac], fmt=\"\",\n",
        "            cbar=(ax is axes[-1]),\n",
        "            annot_kws={\"fontsize\":\"small\"}\n",
        "        )\n",
        "        ax.set_aspect(1 / 1.5)\n",
        "        ax.set_title(f\"{fac}\\nDeviation from {eq_w_pct:.0f}% equal weight\")\n",
        "        ax.set_xlabel(\"Feature z-value\")\n",
        "        ax.set_ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3l55ULwS5hA7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a1df11a5-c0c0-4418-8b60-4ff8950e2330"
      },
      "id": "3l55ULwS5hA7",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-23-1b6e150d14b0>, line 16)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-1b6e150d14b0>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    pdp_dfs = {\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###By feature plots"
      ],
      "metadata": {
        "id": "4UfR4mCrCDCh"
      },
      "id": "4UfR4mCrCDCh"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF and compute_pdp:\n",
        "  fig, axes = plt.subplots(2, 4, figsize=(16, 8), sharex=True, sharey=True)\n",
        "  axes = axes.flatten()\n",
        "  for ax, feat in zip(axes, FEATURES):\n",
        "      for fac, df in pdp_dfs.items():\n",
        "          # Convert to %â€‘pt dev:\n",
        "          dev = (df.loc[feat] - eq_w) * 100\n",
        "          ax.plot(z_grid, dev, marker='o', label=fac)\n",
        "      ax.set_title(feat)\n",
        "      ax.axhline(0, color='gray', lw=0.8)\n",
        "      if feat == FEATURES[0]:\n",
        "          ax.legend(fontsize='small', ncol=2)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "BBoTmWBICBo3"
      },
      "id": "BBoTmWBICBo3",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SHAP\n"
      ],
      "metadata": {
        "id": "Iaxe_3vM5Zc3"
      },
      "id": "Iaxe_3vM5Zc3"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Build the long DataFrame from shap_data\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "records = []\n",
        "for rec in shap_data:\n",
        "    month = rec['month']\n",
        "    mat   = rec['shap_values']  # shape = (n_factors, n_features)\n",
        "    for i, fac in enumerate(FACTORS):\n",
        "        for j, feat in enumerate(FEATURES):\n",
        "            records.append({\n",
        "                'month':      pd.to_datetime(month),\n",
        "                'factor':     fac,\n",
        "                'feature':    feat,\n",
        "                'shap_value': mat[i, j]\n",
        "            })\n",
        "shap_df = pd.DataFrame(records)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) Interactive controls\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "start_picker = widgets.DatePicker(\n",
        "    description=\"Start:\",\n",
        "    value=shap_df['month'].min().date()\n",
        ")\n",
        "end_picker = widgets.DatePicker(\n",
        "    description=\"End:\",\n",
        "    value=shap_df['month'].max().date()\n",
        ")\n",
        "agg_dropdown = widgets.Dropdown(\n",
        "    options=['average', 'mean', 'sum'],\n",
        "    value='average',\n",
        "    description='Aggregate:'\n",
        ")\n",
        "\n",
        "controls = widgets.HBox([start_picker, end_picker, agg_dropdown])\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Plot function\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def update_plot(start_date, end_date, agg):\n",
        "    df = shap_df[\n",
        "        (shap_df['month'] >= pd.to_datetime(start_date)) &\n",
        "        (shap_df['month'] <= pd.to_datetime(end_date))\n",
        "    ]\n",
        "    if df.empty:\n",
        "        print(\"No data in that range.\")\n",
        "        return\n",
        "\n",
        "    grouped = df.groupby(['factor','feature'], observed=True)['shap_value']\n",
        "    if agg in ('average', 'mean'):\n",
        "        df_agg = grouped.mean().reset_index()\n",
        "    else:  # 'sum'\n",
        "        df_agg = grouped.sum().reset_index()\n",
        "\n",
        "    pivot = (\n",
        "        df_agg\n",
        "          .pivot(index='factor', columns='feature', values='shap_value')\n",
        "          .reindex(index=FACTORS, columns=FEATURES)\n",
        "          .fillna(0)\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, len(FACTORS)*0.5))\n",
        "    left = np.zeros(len(pivot))\n",
        "    for feat in FEATURES:\n",
        "        vals = pivot[feat].values\n",
        "        ax.barh(pivot.index, vals, left=left, label=feat)\n",
        "        left += vals\n",
        "\n",
        "    ax.set_xlabel(f\"SHAP {agg}\")\n",
        "    ax.set_title(f\"SHAP {agg} from {start_date} to {end_date}\")\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Display everything\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "out = widgets.interactive_output(\n",
        "    update_plot,\n",
        "    {\n",
        "      'start_date': start_picker,\n",
        "      'end_date':   end_picker,\n",
        "      'agg':        agg_dropdown\n",
        "    }\n",
        ")\n",
        "\n",
        "display(controls, out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "c56a5d6e7319430dabb0a7aef63c11ad",
            "f89a04c7f1184887945ccbede683e49b",
            "c9a86301b74e4ccc8455e3f5720988c0",
            "4274eea20031495c9f1caf81b06f9f12",
            "ba1e634ff1334faabb25f755491b84e6",
            "e416a2d9a6f640a085cfa0e9dc05ef0c",
            "5807ba9bf83f40858e183e8c7bd69601",
            "637624cb29e540c3b1f0100c25fc9adc",
            "f6cb411b573c425bb396d126043044cf",
            "0962c0db8b5346b0b3da451fc70b08ec",
            "7a83ccaaf44b454b81d427a779723cfa",
            "6249650a411d4a269fe4b23b0377d880",
            "fc59347eb9134218825334d9ce887c8a"
          ]
        },
        "id": "TiYIWNkh5uZz",
        "outputId": "42bea99e-dd0d-4778-ca85-8e03010f6e4e"
      },
      "id": "TiYIWNkh5uZz",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(DatePicker(value=datetime.date(1972, 4, 30), description='Start:'), DatePicker(value=datetime.dâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c56a5d6e7319430dabb0a7aef63c11ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6249650a411d4a269fe4b23b0377d880"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Permutation"
      ],
      "metadata": {
        "id": "iXT0B_ar5dM4"
      },
      "id": "iXT0B_ar5dM4"
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Cell 2: Interactive Permutation Importance (choose dateâ€range & agg metric)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if RF and compute_permutation_importance:\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import ipywidgets as widgets\n",
        "  from IPython.display import display\n",
        "\n",
        "  # build DataFrame of permutation importances\n",
        "  perm_df = pd.DataFrame(\n",
        "      perm_importances_list,\n",
        "      index=months_list,\n",
        "      columns=RF1_FEATURES\n",
        "  )\n",
        "  perm_df.sort_index(inplace=True)\n",
        "\n",
        "  # widgets: start date, end date, aggregation\n",
        "  date_options   = list(perm_df.index)\n",
        "  start_widget   = widgets.Dropdown(options=date_options, description='Start:')\n",
        "  end_widget     = widgets.Dropdown(options=date_options,   description='End:')\n",
        "  agg_widget     = widgets.RadioButtons(options=['mean','median'], description='Agg.')\n",
        "\n",
        "  def plot_perm_range(start, end, agg):\n",
        "      # select slice (inclusive)\n",
        "      try:\n",
        "          block = perm_df.loc[start:end]\n",
        "      except KeyError:\n",
        "          print(\"Invalid range.\")\n",
        "          return\n",
        "      if block.empty:\n",
        "          print(\"No data for this range.\")\n",
        "          return\n",
        "\n",
        "      if agg == 'mean':\n",
        "          imp  = block.mean(axis=0)\n",
        "          title = f'Mean Permutation Importance\\n{start} â†’ {end}'\n",
        "      else:\n",
        "          imp  = block.median(axis=0)\n",
        "          title = f'Median Permutation Importance\\n{start} â†’ {end}'\n",
        "\n",
        "      plt.figure(figsize=(10,6))\n",
        "      imp.sort_values(ascending=True).plot.barh()\n",
        "      plt.title(title)\n",
        "      plt.xlabel('Importance')\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  ui = widgets.interactive(\n",
        "      plot_perm_range,\n",
        "      start=start_widget,\n",
        "      end=end_widget,\n",
        "      agg=agg_widget\n",
        "  )\n",
        "  display(ui)"
      ],
      "metadata": {
        "id": "IOVk3YXd51uv"
      },
      "id": "IOVk3YXd51uv",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Confusion Matrix"
      ],
      "metadata": {
        "id": "-C0khzZW57a_"
      },
      "id": "-C0khzZW57a_"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "88d0f495-1290-403b-86a2-7bd1c2c12814",
      "metadata": {
        "tags": [],
        "id": "88d0f495-1290-403b-86a2-7bd1c2c12814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c67196a5-0391-4a5c-e10f-e5b869c5979b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion matrix for Random Forest (row %):\n",
            "     SMB  HML  CMA  RMW\n",
            "SMB 32.1 25.3 12.6 30.0\n",
            "HML 26.4 30.8 13.2 29.6\n",
            "CMA 28.3 23.9 13.0 34.8\n",
            "RMW 28.3 23.6 15.7 32.5\n",
            "\n",
            "Confusion matrix for Gradient Boosting (row %):\n",
            "     SMB  HML  CMA  RMW\n",
            "SMB 37.9 22.1 10.0 30.0\n",
            "HML 30.8 34.6  5.7 28.9\n",
            "CMA 28.3 19.6 10.9 41.3\n",
            "RMW 31.4 23.6  9.4 35.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAHpCAYAAADzgOcVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAt11JREFUeJzs3XdYFNcaBvB3l957U0AQkSJg74K9x957i8YENdaoSUzUaFDT9Nq7RkVjb7E3xN57QwRFmvTed+4fxNWlKOjCwvL+nmef586ZM2fOQK778c0pIkEQBBARERERERERUYUhVnQHiIiIiIiIiIiodDEhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRERERERERERUwTAhRET5DB8+HHZ2doruRoVz7do1qKur4+XLl4ruSono378/+vbtq+huEBGRHBUUM4hEIsyePVsh/VFGiv55Mj4hUl5MCBEp0KZNmyASiaQfVVVVVK5cGcOHD0doaKiiu1dm5P05vf+ZMWOGortXoF9//RX79+8v1jU//PADBgwYgCpVqpRMpz5TfHw8Bg0aBCMjI1StWhXr16/PV+fGjRvQ1tZGUFBQvnPTp0/Hnj17cPfu3dLoLhGRUgsKCsK4ceNQvXp1aGtrQ1tbG66urvD29sa9e/cU3b0S5+vri8WLFxe5vp2dnUz8oKmpCUdHR0ybNg2xsbEl19EiOnLkSJlNojE+IVJeqoruABEBc+fOhb29PdLT03HlyhVs2rQJFy5cwIMHD6Cpqano7pUZb39O73Nzc1NQbz7s119/Re/evdG9e/ci1b9z5w5OnTqFS5culWzHPsPUqVNx7tw5zJkzB8+fP8fo0aPh4uKCJk2aAAAEQcCECRMwceLEfL8nAKhduzbq1auHP/74A3///Xdpd5+ISGkcPnwY/fr1g6qqKgYNGoSaNWtCLBbjyZMn2Lt3L1auXImgoCCF/QGflpYGVdWS/TPD19cXDx48wMSJE4t8Ta1atTBlyhQAQHp6Om7evInFixfDz88P165dK6GeFs2RI0ewfPnyApNCpfHzLAzjEyLlxoQQURnQsWNH1KtXDwDw5ZdfwtTUFAsXLsTBgwc5hPU97/+c5CklJQU6Ojpyb7c4Nm7cCFtbWzRq1OiD9QRBQHp6OrS0tEqpZ+8cPnwYixYtwtChQwEA9+7dw6FDh6QB17Zt2/Dy5Ut8//33hbbRt29f/Pzzz1ixYgV0dXVLpd9ERMokMDAQ/fv3R5UqVXD69GlYWVnJnF+4cCFWrFgBsfjDEwFK8ruvrL7Mqly5MgYPHiw9/vLLL6Grq4vff/8dAQEBcHR0VGDvCqfInyfjEyLlxiljRGWQp6cngNyg763MzEz89NNPqFu3LgwMDKCjowNPT0+cPXtW5trg4GCIRCL8/vvvWLNmDRwcHKChoYH69evj+vXr+e61f/9+uLm5QVNTE25ubti3b1+BfUpJScGUKVNgY2MDDQ0NODk54ffff4cgCDL1RCIRxo0bh127dsHV1RVaWlpo3Lgx7t+/DwBYvXo1qlWrBk1NTbRo0QLBwcGf86OScebMGXh6ekJHRweGhobo1q0bHj9+LFNn9uzZEIlEePToEQYOHAgjIyM0a9ZMen7r1q2oW7cutLS0YGxsjP79+yMkJESmjYCAAPTq1QuWlpbQ1NSEtbU1+vfvj4SEBOnPICUlBZs3b5YOTR8+fPgH+75//360atUKIpFIptzOzg5ffPEFjh8/jnr16kFLSwurV68GALx48QJ9+vSBsbExtLW10ahRI/z777/SawVBgKmpKSZPniwtk0gkMDQ0hIqKCuLj46XlCxcuhKqqKpKTkwvtY1paGoyMjKTHxsbGSE1NBZD738eMGTPg4+PzwUCqbdu2SElJwcmTJz/48yAiooItWrQIKSkp2LhxY75kEACoqqpiwoQJsLGxkZYNHz4curq6CAwMRKdOnaCnp4dBgwYBAPz9/dGnTx/Y2tpCQ0MDNjY2mDRpEtLS0vK1XdSYoaA1b0JDQzFy5EhYWFhAQ0MDNWrUwIYNG2TqnDt3DiKRCDt37sT8+fNhbW0NTU1NtG7dGs+fP5fWa9GiBf7991+8fPlS+j37qWsfWlpaAkC+EThFiSkA4Pbt2+jYsSP09fWhq6uL1q1b48qVKzJ1srKyMGfOHDg6OkJTUxMmJiZo1qyZ9Ltw+PDhWL58ufRn9/bzVt6f59tY5vnz5xg+fDgMDQ1hYGCAESNGSL+X30pLS8OECRNgamoKPT09dO3aFaGhoUVel4jxCZFy4wghojLobZLk/S+3xMRErFu3DgMGDMDo0aORlJSE9evXo3379rh27Rpq1aol04avry+SkpLw1VdfQSQSYdGiRejZsydevHgBNTU1AMCJEyfQq1cvuLq6wsfHBzExMRgxYgSsra1l2hIEAV27dsXZs2cxatQo1KpVC8ePH8e0adMQGhqKv/76S6a+v78/Dh48CG9vbwCAj48PvvjiC3z33XdYsWIFvvnmG8TFxWHRokUYOXIkzpw5U6SfS0JCAqKjo2XKTE1NAQCnTp1Cx44dUbVqVcyePRtpaWlYunQpmjZtilu3buULFPv06QNHR0f8+uuv0qTW/PnzMWvWLPTt2xdffvkloqKisHTpUnh5eeH27dswNDREZmYm2rdvj4yMDIwfPx6WlpYIDQ3F4cOHER8fDwMDA2zZsgVffvklGjRogDFjxgAAHBwcCn2u0NBQvHr1CnXq1Cnw/NOnTzFgwAB89dVXGD16NJycnBAZGYkmTZogNTUVEyZMgImJCTZv3oyuXbti9+7d6NGjB0QiEZo2bYrz589L27p37x4SEhIgFotx8eJFdO7cWfo7q1279geDpfr16+PPP/+Es7MzXrx4gWPHjmHt2rUAcqfIVa5cGUOGDCn0egDSJOHFixfRo0ePD9YlIqL8Dh8+jGrVqqFhw4bFui47Oxvt27dHs2bN8Pvvv0NbWxsAsGvXLqSmpuLrr7+GiYkJrl27hqVLl+L169fYtWuX9PqixgwFiYyMRKNGjaQvjczMzHD06FGMGjUKiYmJ+aZ9LViwAGKxGFOnTkVCQgIWLVqEQYMG4erVqwBy17RJSEjA69evpTFIUUZ1ZGVlSeOI9PR03L59G3/++Se8vLxkphIVNaZ4+PAhPD09oa+vj++++w5qampYvXo1WrRoAT8/P+nvaPbs2fDx8ZHGBomJibhx4wZu3bqFtm3b4quvvkJYWBhOnjyJLVu2fPQ53urbty/s7e3h4+ODW7duYd26dTA3N8fChQuldYYPH46dO3diyJAhaNSoEfz8/KTf/R/D+ISoAhCISGE2btwoABBOnTolREVFCSEhIcLu3bsFMzMzQUNDQwgJCZHWzc7OFjIyMmSuj4uLEywsLISRI0dKy4KCggQAgomJiRAbGystP3DggABAOHTokLSsVq1agpWVlRAfHy8tO3HihABAqFKlirRs//79AgBh3rx5Mvfv3bu3IBKJhOfPn0vLAAgaGhpCUFCQtGz16tUCAMHS0lJITEyUls+cOVMAIFP3Qz+ngj7vP4u5ubkQExMjLbt7964gFouFoUOHSst+/vlnAYAwYMAAmXsEBwcLKioqwvz582XK79+/L6iqqkrLb9++LQAQdu3a9cE+6+joCMOGDftgnbdOnTqV73fzVpUqVQQAwrFjx2TKJ06cKAAQ/P39pWVJSUmCvb29YGdnJ+Tk5AiCIAi//faboKKiIv25/+9//xOqVKkiNGjQQJg+fbogCIKQk5MjGBoaCpMmTfpgP+/duydYW1tLf/a9evUScnJyhBcvXghaWlrC5cuXi/S81atXFzp27FikukRE9E5CQoIAQOjevXu+c3FxcUJUVJT0k5qaKj03bNgwAYAwY8aMfNe9X+8tHx8fQSQSCS9fvpSWFTVmEITcWODnn3+WHo8aNUqwsrISoqOjZer1799fMDAwkPbh7NmzAgDBxcVFJuZZsmSJAEC4f/++tKxz58757vshb79P836aNm2ar19FjSm6d+8uqKurC4GBgdKysLAwQU9PT/Dy8pKW1axZU+jcufMH++ft7S0T17wv78/zbSzzfvwnCILQo0cPwcTERHp88+ZNAYAwceJEmXrDhw/P12ZBGJ8QKT9OGSMqA9q0aQMzMzPY2Nigd+/e0NHRwcGDB2XeuqmoqEBdXR1A7rDa2NhYZGdno169erh161a+Nvv16yczwujtNLQXL14AAMLDw3Hnzh0MGzYMBgYG0npt27aFq6urTFtHjhyBiooKJkyYIFM+ZcoUCIKAo0ePypS3bt1aZkTO2zdkvXr1gp6eXr7yt336mOXLl+PkyZMyn/efZfjw4TA2NpbW9/DwQNu2bXHkyJF8bY0dO1bmeO/evZBIJOjbty+io6OlH0tLSzg6Okqn5r39WR0/fjzfsOxPFRMTA0B2RNj77O3t0b59e5myI0eOoEGDBjLT3XR1dTFmzBgEBwfj0aNHAHJ/7zk5OdLFIP39/eHp6QlPT0/4+/sDAB48eID4+HjpfyOFcXd3R0BAAK5fv46AgADs3r0bYrEYU6ZMQa9evdCoUSPs3bsXNWvWhL29PebOnZtvSuHb58w70ouIiD4uMTERQMGjYVq0aAEzMzPp5+0UpPd9/fXX+creX/MlJSUF0dHRaNKkCQRBwO3btwEUL2bISxAE7NmzB126dIEgCDLfse3bt0dCQkK+OGbEiBHSmAfIH8N8qoYNG0rjh8OHD2P+/Pl4+PAhunbtKp0iV9SYIicnBydOnED37t1RtWpVaT0rKysMHDgQFy5ckP6+DA0N8fDhQwQEBHxW//PKG8t4enoiJiZGet9jx44BAL755huZeuPHjy9S+4xPiJQfp4wRlQHLly9H9erVkZCQgA0bNuD8+fPQ0NDIV2/z5s34448/8OTJE2RlZUnLC9oxwdbWVub47Zd5XFwcAODly5cAUOACik5OTjLB2cuXL1GpUiWZZA4AuLi4yLRV2L3fBo/vr2fwfvnbPn1MgwYNClxU+u39nZyc8p1zcXHB8ePH8y2emfdnFhAQAEEQCl1Q8u00O3t7e0yePBl//vkntm3bBk9PT3Tt2hWDBw+WCZI/RUHBSUF9BXKfuaDpAu//Ttzc3FCnTh1oa2vD398f7du3h7+/P+bMmQNLS0ssXboU6enp0sDr/eCtMJqamjK/gzNnzuDEiRN4+vQpnj59iv79+2P16tWws7PDgAEDYGNjgxEjRuR7zrxrERAR0ce9/R4uaD2V1atXIykpCZGRkTILJ7+lqqpa4PSuV69e4aeffsLBgwfzfR+/XRuvODFDXlFRUYiPj8eaNWuwZs2aAuu8efNG5vhjMcynMjU1RZs2baTHnTt3hpOTE3r37o1169Zh/PjxRY4pkpKSkJqaWmg9iUSCkJAQ1KhRA3PnzkW3bt1QvXp1uLm5oUOHDhgyZAg8PDw+63k+9HPS19fHy5cvIRaL88UR1apVK9Z9GJ8QKS8mhIjKgPcTHd27d0ezZs0wcOBAPH36VPoWcOvWrRg+fDi6d++OadOmwdzcHCoqKvDx8ZFZfPotFRWVAu9V2Je6PBV2b0X2Ka+8u2BIJBKIRCIcPXq0wH6+/zb2jz/+wPDhw3HgwAGcOHECEyZMgI+PD65cuVKktRTyMjExAVB4oPs5O3aoqamhYcOGOH/+PJ4/f46IiAh4enrCwsICWVlZuHr1Kvz9/eHs7AwzM7NitZ2Tk4Nvv/0WM2bMQOXKlfHLL7+gSZMm0gDrq6++wrZt2/IFXHFxcWV2JxciorLMwMAAVlZWePDgQb5zb/8IL2yzBg0NjXw7j+Xk5KBt27aIjY3F9OnT4ezsDB0dHYSGhmL48OGQSCSf3ee3bQwePBjDhg0rsE7exEhpxgutW7cGAJw/f77II2eKy8vLC4GBgdK4Yd26dfjrr7+watUqfPnll5/cbkn/nBifECk/JoSIypi3SZ6WLVti2bJlmDFjBgBg9+7dqFq1Kvbu3Svz9uLnn3/+pPtUqVIFAAocvvz06dN8dU+dOoWkpCSZUUJPnjyRaUtR3t4/b7+B3D6ampp+dGtdBwcHCIIAe3t7VK9e/aP3dHd3h7u7O3788UdcunQJTZs2xapVqzBv3jwAKNYbJmdnZwBAUFBQka+pUqVKoc/79vxbnp6eWLhwIU6dOgVTU1M4OztDJBKhRo0a8Pf3h7+/P7744osi3/utlStXIikpCVOnTgUAhIWFoVKlStLzlSpVQmhoqMw12dnZCAkJQdeuXYt9PyIiyh3Vsm7dOly7dg0NGjT4rLbu37+PZ8+eYfPmzdItuwHk22mpODFDXmZmZtDT00NOTo7M6JzPJa+RHNnZ2QDejboqakyhqakJbW3tQuuJxWKZkdHGxsYYMWIERowYgeTkZHh5eWH27NnShFBJjEypUqUKJBIJgoKCZBId7+/Y9iGMT4iUH9cQIiqDWrRogQYNGmDx4sVIT08H8O4t0Ptvfa5evYrLly9/0j2srKxQq1YtbN68WTokHMgNAt/O736rU6dOyMnJwbJly2TK//rrL4hEInTs2PGT+iAv7z/L+1uVPnjwACdOnECnTp0+2kbPnj2hoqKCOXPm5HuzJgiCdB59YmKiNHh8y93dHWKxGBkZGdIyHR0dmb58SOXKlWFjY4MbN24UqT6Q+zu5du2azO8/JSUFa9asgZ2dncyaDp6ensjIyMDixYvRrFkzadDp6emJLVu2ICws7KPz8/OKjY3Fzz//jN9++w2ampoAAAsLC2nABwCPHz+Wbuf71qNHj5Ceno4mTZoU635ERJTru+++g7a2NkaOHInIyMh854szOqSg2EIQBCxZskSmXnFihoLu0atXL+zZs6fAkU1RUVFF7u/7dHR0ZPryqQ4dOgQAqFmzJoCixxQqKipo164dDhw4IDMqKzIyEr6+vmjWrBn09fUBvFuL5y1dXV1Uq1YtX9wAoMixQ1G8Xd9nxYoVMuVLly4t0vWMT4iUH0cIEZVR06ZNQ58+fbBp0yaMHTsWX3zxBfbu3YsePXqgc+fOCAoKwqpVq+Dq6lrgWgJF4ePjg86dO6NZs2YYOXIkYmNjsXTpUtSoUUOmzS5duqBly5b44YcfEBwcjJo1a+LEiRM4cOAAJk6c+MEt1UvLb7/9ho4dO6Jx48YYNWqUdItYAwMDzJ49+6PXOzg4YN68eZg5cyaCg4PRvXt36OnpISgoCPv27cOYMWMwdepUnDlzBuPGjUOfPn1QvXp1ZGdnY8uWLdKA9626devi1KlT+PPPP1GpUiXY29t/cIvgbt26Yd++fUWevz5jxgxs374dHTt2xIQJE2BsbIzNmzcjKCgIe/bskZkW0LhxY6iqquLp06cYM2aMtNzLywsrV64EgGIHXLNmzYK7uzv69OkjLevVqxfmzp2Lr7/+GlWqVMHq1avx559/ylx38uRJaGtro23btsW6HxER5XJ0dISvry8GDBgAJycnDBo0CDVr1oQgCAgKCoKvry/EYnGRpjA7OzvDwcEBU6dORWhoKPT19bFnz54CpwgVNWYoyIIFC3D27Fk0bNgQo0ePhqurK2JjY3Hr1i2cOnUKsbGxxf451K1bF//88w8mT56M+vXrQ1dXF126dPngNaGhodi6dSsAIDMzE3fv3sXq1athamoqM12sqDHFvHnzcPLkSTRr1gzffPMNVFVVsXr1amRkZGDRokXSeq6urmjRogXq1q0LY2Nj3LhxA7t378a4ceNkngcAJkyYgPbt20NFRQX9+/cv9s8l78+oV69eWLx4MWJiYqTbzj979gxA0UYlMT4hUnKltp8ZEeXzdjv169ev5zuXk5MjODg4CA4ODkJ2drYgkUiEX3/9VahSpYqgoaEh1K5dWzh8+LAwbNgwmW1X3247/9tvv+VrEwVsMbpnzx7BxcVF0NDQEFxdXYW9e/fma1MQcrcMnTRpklCpUiVBTU1NcHR0FH777TdBIpHku4e3t7dMWWF9eru97Me2cP/Qz+l9p06dEpo2bSpoaWkJ+vr6QpcuXYRHjx7J1Hm7VWtUVFSBbezZs0do1qyZoKOjI+jo6AjOzs6Ct7e38PTpU0EQBOHFixfCyJEjBQcHB0FTU1MwNjYWWrZsKZw6dUqmnSdPngheXl6ClpaWAOCjW9DfunUr3zatgpC7rWthW9UGBgYKvXv3FgwNDQVNTU2hQYMGwuHDhwusW79+fQGAcPXqVWnZ69evBQCCjY3NB/uW17179wR1dXXh9u3b+c5t2rRJsLOzE0xMTITJkycL2dnZMucbNmwoDB48uFj3IyKi/J4/fy58/fXXQrVq1QRNTU1BS0tLcHZ2FsaOHSvcuXNHpu6wYcMEHR2dAtt59OiR0KZNG0FXV1cwNTUVRo8eLdy9e1cAIGzcuFGmblFjhoLijcjISMHb21uwsbER1NTUBEtLS6F169bCmjVrpHUKiwvexhHv9yc5OVkYOHCgYGhoKAD46Bb0ebedF4vFgrm5uTBgwADh+fPn+eoXJaYQhNzv7/bt2wu6urqCtra20LJlS+HSpUsydebNmyc0aNBAMDQ0lP6e5s+fL2RmZkrrZGdnC+PHjxfMzMwEkUgkswV93p9nYbHM23gpKChIWpaSkiJ4e3sLxsbGgq6urtC9e3fh6dOnAgBhwYIFH/yZvX0+xidEykskCApYzZWIiPJp3bo1KlWqhC1btii6KyXizp07qFOnDm7duoVatWopujtEREQV0p07d1C7dm1s3boVgwYN+mh9xidEyosJISKiMuLq1avw9PREQECAwhfqLgn9+/eHRCLBzp07Fd0VIiKiCiEtLS3fbmDDhw/Hli1bEBwcLLPwdWEYnxApLyaEiIiIiIiIlNCcOXNw8+ZNtGzZEqqqqjh69CiOHj2KMWPGYPXq1YruHhEpGBNCRERERERESujkyZOYM2cOHj16hOTkZNja2mLIkCH44YcfoKrK/YWIKjomhIiIiIiIiIiIKhjxx6sQEREREREREZEyYUKIiIiIiIiIiKiCYUKIiIiIiIiIiKiCYUKIiOg9p06dQqtWrWBgYAA9PT3UrVsX//zzj0ydSZMmoU6dOjA2Noa2tjZcXFwwe/ZsJCcny9S7fv06xo0bhxo1akBHRwe2trbo27cvnj17VpqPRERERGUIYw0iKiu4qDQR0X82btyIUaNGoW3btujatStUVFTw9OlTVK5cGVOnTpXWa9asGerWrYtq1apBU1MTt2/fxoYNG1CvXj2cP38eYnFurr137964ePEi+vTpAw8PD0RERGDZsmVITk7GlStX4ObmpqhHJSIiIgVgrEFEZQkTQkREAIKDg+Hq6orRo0djyZIlxb7+jz/+wNSpU3H58mU0atQIAHDp0iXUq1cP6urq0noBAQFwd3dH7969sXXrVrn1n4iIiMo2xhpEVNZwyhgRKczs2bMhEonw/PlzDB8+HIaGhjAwMMCIESOQmppaqn1ZtWoVcnJyMHfuXABAcnIyipMvt7OzAwDEx8dLy5o0aSIToAGAo6MjatSogcePH392n4mIiOjDGGsQERWOCSEiUri+ffsiKSkJPj4+6Nu3LzZt2oQ5c+Z89LrU1FRER0d/9BMXF/fRtk6dOgVnZ2ccOXIE1tbW0NPTg4mJCWbNmgWJRJKvfnZ2NqKjoxEWFoYTJ07gxx9/hJ6eHho0aPDB+wiCgMjISJiamn60T0RERCQfjDWIiPJTVXQHiIhq166N9evXS49jYmKwfv16LFy48IPXLVq0qEjBXJUqVRAcHPzBOgEBAVBRUcGIESPw3XffoWbNmti7dy/mzZuH7Oxs+Pj4yNS/ceMGGjduLD12cnLCwYMHYWxs/MH7bNu2DaGhodK3g0RERFTyGGsQEeXHhBARKdzYsWNljj09PbFv3z4kJiZCX1+/0OuGDh2KZs2afbR9LS2tj9ZJTk6GRCLBggULMH36dABAr169EBsbiyVLluD777+Hnp6etL6rqytOnjyJlJQUXLp0CadOncq380deT548gbe3Nxo3boxhw4Z9tE9EREQkH4w1iIjyY0KIiBTO1tZW5tjIyAgAEBcX98EgrWrVqqhatapc+qClpYWUlBQMGDBApnzAgAE4duwYbt++DS8vL2m5vr4+2rRpAwDo1q0bfH190a1bN9y6dQs1a9bM135ERAQ6d+4MAwMD7N69GyoqKnLpNxEREX0cYw0iovyYECIihSssYPnYQovJyckffVP2tn0zM7MP1qlUqRICAgJgYWEhU25ubg4AH10boGfPnhgyZAh27NiRL0hLSEhAx44dER8fD39/f1SqVOmjfSYiIiL5YaxBRJQfE0JEVG79/vvvcpvXX7duXQQEBCA0NFTmTWBYWBgAfDTIy8jIgEQiQUJCgkx5eno6unTpgmfPnuHUqVNwdXX9aH+JiIiobGCsQUTKjAkhIiq35Dmvv1+/ftixYwfWr1+P+fPnAwAkEgk2btwIY2Nj1K1bF0DuVq86OjpQU1OTuX7dunUAgHr16knLcnJy0K9fP1y+fBkHDhyQWRiSiIiIyj7GGkSkzJgQIqJyS57z+rt164bWrVvDx8cH0dHRqFmzJvbv348LFy5g9erV0NDQAACcO3cOEyZMQO/eveHo6IjMzEz4+/tj7969qFevHgYPHixtc8qUKTh48CC6dOmC2NhYbN26Veae79clIiKisoexBhEpMyaEiIgAiEQi7N+/Hz/++CP++ecfbNq0CU5OTti6dSsGDRokrefu7o6WLVviwIEDCA8PhyAIcHBwwE8//YRp06ZBXV1dWvfOnTsAgEOHDuHQoUP57skgjYiIqOJgrEFEZY1I+NhKakREREREREREpFTEiu4AERERERERERGVLiaEiIiIiIiIiIgqGCaEiIiIiIiIiIgqGCaEiIiIiIiIiIgqGCaEiIiIiIiIiIgqGCaEiIiIiIiIiIgqGFVFd6AkaHVfo+guUBn0Rfd6iu4ClTFbBtdRdBeoDHIYv0/RXaAyKHRlD0V3oVRodVqi6C5QEU0e31HRXaAiGF3fVtFdoCLqveqyortARXTjx5aldi+t2uPk1lba7WVya0teOEKIiIiIiIiIiKiCUcoRQkREREREREREn0Wk3GNomBAiIiIiIiIiIspLJFJ0D0qUcqe7iIiIiIiIiIgoH44QIiIiIiIiIiLKi1PGiIiIiIiIiIgqGE4ZIyIiIiIiIiIiZcIRQkREREREREREeXHKGBERERERERFRBcMpY0REREREREREpEyYECIiIiIiIiIiyksklt/nEy1YsAAikQgTJ06UlqWnp8Pb2xsmJibQ1dVFr169EBkZWey2mRAiIiIiIiIiIspLJJLf5xNcv34dq1evhoeHh0z5pEmTcOjQIezatQt+fn4ICwtDz549i90+E0JERERERERERCUoIyMDiYmJMp+MjIxC6ycnJ2PQoEFYu3YtjIyMpOUJCQlYv349/vzzT7Rq1Qp169bFxo0bcenSJVy5cqVYfWJCiIiIiIiIiIgoLzlOGfPx8YGBgYHMx8fHp9Bbe3t7o3PnzmjTpo1M+c2bN5GVlSVT7uzsDFtbW1y+fLlYj8ddxoiIiIiIiIiI8pLjLmMzZ87E5MmTZco0NDQKrLtjxw7cunUL169fz3cuIiIC6urqMDQ0lCm3sLBAREREsfrEhBARERERERERUQnS0NAoNAH0vpCQEHz77bc4efIkNDU1S7RPnDJGRERERERERJSXAnYZu3nzJt68eYM6depAVVUVqqqq8PPzw//+9z+oqqrCwsICmZmZiI+Pl7kuMjISlpaWxXo8jhAiIiIiIiIiIspLjlPGiqp169a4f/++TNmIESPg7OyM6dOnw8bGBmpqajh9+jR69eoFAHj69ClevXqFxo0bF+teTAgREREREREREZUBenp6cHNzkynT0dGBiYmJtHzUqFGYPHkyjI2Noa+vj/Hjx6Nx48Zo1KhRse7FhBARERERERERUV7FmOpVmv766y+IxWL06tULGRkZaN++PVasWFHsdpgQIiIiIiIiIiLKq4wkhM6dOydzrKmpieXLl2P58uWf1W7ZeDoiIiIiIiIiIio1HCFERERERERERJSXuPQXlS5NTAgREREREREREeVVRqaMlRTlfjoiIiIiIiIiIsqHI4SIiIiIiIiIiPISccoYEREREREREVHFwiljRERERERERESkTDhCiIiIiIiIiIgoL04ZIyIiIiIiIiKqYDhljIiIiIiIiIiIlAlHCBERERERERER5cUpY0REREREREREFQynjBERERERERERkTLhCCEiIiIiIiIiorw4Zaz0CIKAs2fPIi0tDU2aNIGRkZGiu0RERERU5jGGIiIiKgGcMlYy4uPjMWzYMLi7u2P06NFITEyEp6cn2rRpgy5dusDFxQX37t1TVPeIiIiIyiTGUERERCQPCksITZ06FZcvX0b//v1x//59dOjQATk5Obh8+TKuXr0KFxcX/PDDD4rqHhEREVGZxBiKiIiolIhE8vuUQQqbMnb06FH4+vqiefPmGD58OGxsbHDmzBk0bNgQALBw4UJ07dpVUd0jIiIiKpMYQxEREZUSThkrGZGRkahevToAoHLlytDU1ISNjY30vK2tLaKiohTVPSIiIqIyiTEUERERyYPCRghJJBKoqKhIj1VUVCB6bxiVqIwOqSIiIiJSJMZQREREpUTJRwgpdJexdevWQVdXFwCQnZ2NTZs2wdTUFACQlJSkyK4RERERlVmMoYiIiEqBkr9kUVhCyNbWFmvXrpUeW1paYsuWLfnqUK7RHVwwuoMrqpjrAQAev4rDrztv4cStEBjpamDWgLpoXcsaNqa6iE5Mx6GrwZjjex2JqVmFttmtkR2+7OCK2lVNYaKviYaT9uBeUExpPRJ9pu7uFmhYxRCVDTSRmS3B06gUbLsRirDEDGmd2R0cUcNST+a6E0+jsPZySKHt9qllhab2RjDRVkO2RMCLmFRsvxWG59GpJfYsJD83b1zHpg3r8fjRA0RFReGv/y1Hq9ZtAABZWVlY9r/FuOB/Hq9fh0BPVxcNGzfBt5OmwNzc4oPtRkZGYvGfv+Givz/S09NgY1sFc+f9ihpu7qXxWPQZhnrZY4inPWxMtAEAz8KT8NeRJzj7MBIAoKEqxk+93dGtrjXUVcU49zgS32+/i+ikjA81i6lfuGBgMzvoa6nhxosYzPS9g6ColBJ/Hqq4MdToTu4Y3dkDVSz+i4VexuLX7Vdx4sZL2Jrr4emmkQVeN+jXf7H3wvMCz5kbamPeiKZoU8cWBjoauPAgFJNX+SEwLL6kHqNCeHJyF0LvXULSm1CoqKnDxM4Z7l2GQ8/CGgCQmZKEh8d8EfnkNlLjo6Cho4/K7o1Qo9NgqGnpFNpu6N1LCLx0FPEhgchMTUKbqUtgaF21tB5LKd2/cxO7fDch4MljxMZE4Wefv9DEq5X0vCAI+HvdChw7tBfJSUlw9aiFCVN/QGWbKh9s9+CeHdjtuxmxsdGoWq06vpk0A86ujBk+Va86ldC7bmVYGWoCAF5EpWCdfzAuBcYCANRVxJjY1gHtXC2grirClcBYLDj2DLEphf8tCABfNbdHj1pW0NVUxd3XCVhw5BlC4tJK/Hmo7FBYQig4OFhRty6XQmNSMGvLNTwPS4BIJMLgltWxa2Y7NJq8FyIRYGWsg5mbruBxSBxszfSwdGwzWBlrY+CiU4W2qa2phkuPIrDnQiBWjmteik9D8lDDUhfHn0TheXQqVEQiDKxTCT+2q4ZJ+x8jI1sirXfqaTT+uRMmPX7/XEHCE9Kx/koIIpMyoK4qxheu5pjVzhHj9zxEYkZ2iT0PyUdaWiqcnJzQvWcvTP52nMy59PR0PHn8CGPGfg0nJ2ckJiZioc98fDvua2zfubfQNhMTEjB88ADUa9AQy1ethZGxEV69fAl9fYOSfhySg/C4NPjsf4igN8kQiUTo08gWG8Y2Qvtfz+BZeBJm93FHazdLfLXuKhLTsjG/X02s+6ohuv9+vtA2v2nniJEtq2Li5lsIiUnBtC6u2DahKVrOOfXRf2Po81XUGCo0OhmzNl7E87B4iETA4NYu2DWrCxqN98XT13GwG7RWpv7IDm6Y1Ksujt94WWibO2d9gawcCfrMPYzE1AxM6FEHR37tgdpfbUEqv/M+WVTgAzg06wwjW0cIEgke/Ps3/Ff9hHYzVkBVQxNpibFIT4iBR7eR0Le0QWrsG9zatQJpibFoPGJmoe1mZ6bD1N4VNrWa4eY/y0rxiZRXeloaqlZzQvvO3TH3+8n5zu/cthEHdm/H1B9/gaVVZWxeuxzfT/4aa7fug7qGRoFtnjt1DGuW/o7x036Es6s79u3chh8mf4312w/A0MikpB9JKb1JysCyM4F4FZsGkQj4wsMSf/R1x6C11/EiOhWT21VDs2ommLH3AZLTs/Fdh+r4rbc7Rm2+VWibwxrbon/9yph98AlC49PwdXN7LB1YE31XXUNmDr/LpThljMqCI9dfyRzP3nYdozu4oIGTOTafeooBC09KzwVFJGH2tuvYMKkVVMQi5EiEAtvcfi4AAGBrrltyHacSM/9koMzx8gsvsX6AB6qaaONxZLK0PCNHgvi0oge1F4LiZI43X3+N1tVNYWushQfhnIZQ1jXzbI5mngUnePX09LB63UaZspk/zMKg/n0QHhYGq0qVCrxuw/q1sLC0xC/zfaRl1tY2Bdalsufk/QiZ44UHH2GIlz3q2BsjPC4N/ZvYYdyG67j4NBoAMOnvmzg/uy3q2BvhVp5/D976slU1LDn6FCfuhQMAvt10A3cWdUL7WlY4eCO0ZB+IKqwj14Jkjmf/fRmjO3uggbMVHr+KRWSc7EjWrk0csMc/ACnpBb8hr1bZEA1drFBn7BY8fpX7ln3C8jMI3jYafVs4YdPxhyXzIBWA59g5Msf1B07EoR8HI+71c5g5uMHAqgoaj/xeel7X1ApunYfg2pY/IMnJgfi9NbLeV6V+7siVlJjIkut8BVO/cTPUb9yswHOCIGD/zm0YMGw0mni2BAB8N2se+nVphUv+Z9CiTccCr9v7zxZ06NIT7Tt3BwBMmPYjrl06j+OH96PfkFEl8hzKzj9AdhbHinNB6FW3MtytDRCZlIFutazw475HuBEcDwCYc+gJ9nzdEG6V9fEgNLHANgc0sMb6Cy/h9yz3+/+ng49xYlJTtHAyxYlHb0r0ecoVThkrGX///XeR6g0dOrSEe1L+iMUi9GpSFTqaarj6pOAvRH1tdSSmZhaaDCLlo62eGzwl53mj6VnVCJ5VjRGfloWbIQnYfTccmTlF++9CVSxCm+qmSMnMxstYThlTRsnJuaNG9PT1C63jd/YMmjRthqmTJuDGjeswN7dAv/4D0atP31LsKcmDWAR8UbcytNVVcPNFLDyqGEJdVQz/J+92pAqMTMbrmFTUtTcuMCFka6oNCwNNXHjvmqT0bNwOikNde2MmhEoBY6j/YqFmjtDRVMXVx+H5zteuZo5aDuaYtOJcoW1oqOV+b6Zn5kjLBAHIzMpBE9dKTAjJUVZa7nRSdW29D9ZR1dQuNBlEpS8iLBSxMdGoU6+htExHVw/Oru54/OBegQmhrKwsBDx9jP7vJX7EYjFq12uERw/ulUq/lZ1YBLRxMYeWmgruvU6Ai5Ue1FTEuPred/bLmFSEJ6TDo5CEUGVDTZjqaeDae9ekZOTgQWgS3K31mRCqQBSWEBo+fDh0dXWhqqoKQSj4j1ORSPTRYCYjIwMZGbLrHAg5WRCpqMmtr2VFjSpGOLegOzTVVZCcnoV+C07gyev4fPVM9DQws28dbDjxpPQ7SQohAjC8gTWeRCYjJD5dWn7hRSyikjMRl5oFW2MtDK5bGZUMNPH72RcfbK+OtT4mNbeHuqoY8alZ+OX4cyRl5HzwGip/MjIysPjP39GxU2fp4rQFef06BDv/2Y4hw0Zg1JixeHj/Phb6zIOamhq6du9Rij2mT+VcSR8HpzWHhpoYKRnZ+HL1VQREJKGGjQEysnKQmCY7giIqKR1m+poFtmX+X3lUYrpMeXRSuvQclaySjaGyIVIpuwPIa9iZ4NwffaGprorktCz0++VfPAmJzVdvWLsaePwqBlcKSBa99TQkDq/eJOKXEU0wbukZpKRnYUL32rA204OlceHr2FDxCBIJ7uxbCxN7FxhYFbzuTEZyAh6f+AdVm7Qv5d7Rh8TG5o4cMTSWneZlaGyC2JjoAq9JjI+DJCcn3zVGxiYIeRVU4DVUNA5mOtg4og7UVcVIy8zBtF33ERSdiuoWusjMluR7KRybnAkTXfUC23pbHpOSKXtNSiZMdAq+psJS8iljCns6FxcXqKurY+jQofDz80NcXFy+T2xs/i/4vHx8fGBgYCDzyQ44VgpPUPqehSag4aQ98PpuP9YefYS1E1rA2dpQpo6elhr2zeqIxyFxmLfjhmI6SqXuy0Y2sDHSxF9+sl+0p57F4G5YEl7Fp+PCizgs8w9GwyqGsND78D/0DyOSMe3gE/x45CnuhCZicgt76GuW3T8QqPiysrIwbfK3EAQBP/w054N1JRIBLq41MGHiZLi4uKJ3337o2bsvdu3cUUq9pc8VGJmEdr+ewReL/PD3+SAsHlYXjpaFv6mnsq1EY6gXJz96nSI9ex2HhuN84TXpH6w9cg9rp7SFs42xTB1NdRX0a+GEzR8Z4ZOdI0H/ef+iWiUjhO8ci9h93vDysMax68GQFJJoo+K7vXsVEsNfoeGw7wo8n5Weigtr5kLPwgauHQaWcu+Iyo+XMakYuPYGhm+4id03wzC7qwvsTbUV3S3lJxLJ71MGKSwh9PDhQ/z7779IS0uDl5cX6tWrh5UrVyIxseA5joWZOXMmEhISZD6qjh1KqNeKlZUtwYuIRNwOjMZPW6/jfnAMvLu8W61fV1MNB3/uiKS0TPRbcBLZRZwWROXbqIbWqGNjgDnHAhD7gV3lACDgv53CLPUKXgTwrYxsCSKSMhAQlYqVl14hRxDQypGLACqLrKwsTJsyEeFhYVi9bsMHRwcBgJmZGao6OMiUVa1aFeHhYYVcQWVNVo6A4KgU3H8VjwUHHuFRaAK+bOWAqMR0aKipQF9LdlStmZ5mvhFAb735rzzvCCJTPU3pOSpZJRpDVW1bQr2Wj6xsCV6EJ+D28zf4adMl3H8RDe9utWTq9GjmCG0NVWw7/fGR0refv0Gj8b6w6L0S9oPWodtPB2Cir4mgiIQSeoKK5fbuVQh/dB3Nx82HtqFpvvNZ6anwX/Uz1DS10GTUDxCX4dFpFZGxce7vLD5Wdv2a+NgYGJvk/30CgL6hEcQqKvmuiYuNgZFxwddQ0WRLBLyOS8OTiGQsP/sCz94kY0ADa8SkZEJdVQxdDdn//xjrqiMmObPAtt6W5x0NZKyjnm/UECk3hY5/atiwIVavXo3w8HBMmDABO3fuhJWVFQYNGpRvCHNhNDQ0oK+vL/NRxuliBRGLRNBQy/0V6mmp4fDsTsjMlqD3/OPIyOL0nopgVENrNLA1xJxjAXhTyD/477Mz1gIAxBVjkWkAEEEENRXlHi5ZUbxNBr16+RKr12+CoaHRR6+pVbsOgoNkR5+9DA5GpUqVS6qbVMLEIhHUVcW49zIemdkSNHM2k55zsNCFtYk2bgYVPMLkVXQqIhPS0czp3TW6mqqobW9U6DUkfyUXQ5WvP8jFYpF0LaC3hrergX+vvkB0YtG3Tk5MzUR0YhocKhmiTjVzHL784anV9GGCIOD27lUIvX8ZXt7zoWNima9OVnoq/Ff+BLGKKpp8+SNU1DhNpayxrFQZxiamuH3zqrQsJSUZTx7dh4ubR4HXqKmpwdHJBbdvvLtGIpHgzs2rcC3kGvo0YlFufP44PAlZORI0sH8X01Ux1oKVgSbuFbKgdGh8OqKTMlDf7t01OuoqcKush/uvi/dyQdmJRCK5fcqiMvEXnpaWFoYOHYo5c+agQYMG2LFjB1JTuYDt++YOro+mrpawNddFjSpGmDu4PrzcKmGH33NpMkhbUxVjl/lBX1sdFoZasDDUglj87j+8O8v6omtDO+mxka4GPOxN4GKT+w9B9UoG8LA3gYWhVmk/Hn2CLxvZwNPBGEvOByM9OweGWqow1FKFukru79xCTx29PCxR1UQLZrrqqGdjgHHN7PAoIgmv4t4FyYt7uKKBbe724RqqYgyoUwmOZtow1VFHVRMtfN3UFsY6argcXPBuQ1S2pKak4Mnjx3jy+DEAIPT1azx5/BjhYWHIysrC1EkT8OjhA/gs/B2SnBxER0UhOioKWZnvEoqjRw7D9m1bpceDhw7D/Xt3sW7NKrx6+RJHDh/C7t070W8Ah/aXBzO6uaJhNRNYG2vDuZI+ZnRzRWNHU+y9FoKk9GzsuBSMn3u5o0l1U7jbGuLPIXVwIzBGZkFpv5/boENNK+nxujPPMaGTE9p6WMK5kj6WDKuLyIR0HL9T+HotVDIqUgw1d3gTNHWrBFtzPdSwM8Hc4U3g5W6NHeeeSutUtTJAM7fK2FjIdLE7q4ega+N3Ix57NqsGT/fKsLPUxxeNquLf+T1w6MoLnL79qsDrqWhu716JVzfOoeGQqVDT0EJ6YhzSE+OQk5mbrHybDMrJzEC9AROQnZ4mrSNI3r3UPP7rWITeuyw9zkxJQvzrF0iMDAEAJL0JRfzrF0hPZIzyqdJSUxH47AkCn+WOqIsIC0Xgsyd4ExEOkUiE7n0HYfvmtbjsfw5BgQH47ZcfYWJqhiaeraRtTJ8wGgd2b5ce9+w3BEcP7cXJIwfxKvgFlv4+D+npaWj3365jVHzeLauitq0BrAw04WCmA++WVVG3iiGOPYhESkYODtwJx6S21VC3iiGcLXXxUxcX3A1JkFlQevfYBmjh9G6U1vZrrzGqWRV4OZrAwUwHc7q5ICopE+eeFrw+VEWl7Akhhb8GCg0NxebNm7Fx40akpKRg8ODBWLlyJYyMPv7WuiIxM9TC+oktYWmkjYSUTDx4GYMuc47gzN1QeLpZoYGTBQDg0aoBMtc5jfHFqze5W5A7WRtC/71hgZ0bVMHaCS2kx1umtQEAzNtxE/N33CzhJ6LP1f6/N/pzOlaXKV9+IRjnnsciO0eARyU9dHY1h4aaGDEpmbj6Mh577sn+wVbZQFO6Q5lEEFDZQBMtHKpCT1MVSRnZCIxOxU9HnuF1PKeClAcPHz7AlyPeLST7+6LcreK7duuBsd7jcO7sGQBA317dZK5bt/Fv1G+Qu4vI65AQxMe/C67d3D3w55Jl+N/iP7F65XJUtrbGd9O/R+cvupb045AcmOppYMnwujDX10RSejYehyZg4NKL0p3FZu+6D4kArBnTEBqqYpx79Abf77gj00Y1Sz2ZaWUrTgRAW10ViwbWhr62Gq4HxmDw0kvIyJaU5qNVeBUthjIz0Mb6Ke1hafxfLBQUjS6z9uPMe8mbYe1qIDQ6GaduvSywDScbY5lYyNJYBwtHe8HcUBsRcSnYdvoxfLZfK/FnUXYvLh4FAPgt+16mvN6Ab2HXsA3iQgIR+zI3kXds3hiZOh1nrYOOSW5cm/QmVLpDGQCEPbiKG9uXSI+v/r0IAODSfgBqdORLik/x7MlDfDf+S+nx6qW/AwDaduyKqT/+gr6DRiA9LQ1LFs1FcnISanjUxvw/VkBd493yA+Ghr5GYEC89btGmAxLi4/D3uhWIi41GVUcnzP9jBYyMufzApzLWUcOcri4w1dVAckY2At4kY7zvXenOYn+eeA6JIGBRbzeoq4hx+UUsFh59JtOGnamOzLSyzZdfQVNdBd93doKepiruhCRgwva7yMzhd3lFIhIK256ihO3cuRMbN26En58f2rdvjxEjRqBz585QkcNWk1rd18ihh6RsvuheT9FdoDJmy+A6iu4ClUEO4/cpugtUBoWuLDs76pVoDNVpyccrUZkweXz+Lb+p7Bld31bRXaAi6r3q8scrUZlw48eWpXYvnT4b5dZWyq4RcmtLXhQ2Qqh///6wtbXFpEmTYGFhgeDgYCxfvjxfvQkTJiigd0RERERlE2MoIiKi0lFWp3rJi8ISQra2thCJRPD19S20jkgkYjBDRERE9B7GUERERCQPCksIBQcHK+rWREREROUWYygiIqLSoewjhBS2y9jly5dx+PBhmbK///4b9vb2MDc3x5gxY4q8bSoRERFRRcEYioiIqHQo+y5jCksIzZkzBw8fvtsS9P79+xg1ahTatGmDGTNm4NChQ/Dx8VFU94iIiIjKJMZQREREJA8KSwjdvXsXrVu3lh7v2LEDDRs2xNq1azF58mT873//w86dOxXVPSIiIqIyiTEUERFR6VD2EUIKW0MoLi4OFhYW0mM/Pz907Phu+8z69esjJCREEV0jIiIiKrMYQxEREZWSspnHkRuFjRCysLBAUFAQACAzMxO3bt1Co0aNpOeTkpKgpqamqO4RERERlUmMoYiIiEgeFJYQ6tSpE2bMmAF/f3/MnDkT2tra8PT0lJ6/d+8eHBwcFNU9IiIiojKJMRQREVHp4JSxEvLLL7+gZ8+eaN68OXR1dbF582aoq6tLz2/YsAHt2rVTVPeIiIiIyiTGUERERKWjrCZy5EVhCSFTU1OcP38eCQkJ0NXVhYqKisz5Xbt2QVdXV0G9IyIiIiqbGEMREREpt5UrV2LlypUIDg4GANSoUQM//fSTdM3AFi1awM/PT+aar776CqtWrSrWfRSWEHrLwMCgwHJjY+NS7gkRERFR+cEYioiIqGQpaoSQtbU1FixYAEdHRwiCgM2bN6Nbt264ffs2atSoAQAYPXo05s6dK71GW1u72PdReEKIiIiIiIiIiKisUVRCqEuXLjLH8+fPx8qVK3HlyhVpQkhbWxuWlpafdR+FLSpNRERERERERFQRZGRkIDExUeaTkZHx0etycnKwY8cOpKSkoHHjxtLybdu2wdTUFG5ubpg5cyZSU1OL3ScmhIiIiIiIiIiI8hLJ7+Pj4wMDAwOZj4+PT6G3vn//PnR1daGhoYGxY8di3759cHV1BQAMHDgQW7duxdmzZzFz5kxs2bIFgwcPLvbjccoYEREREREREVEe8pwyNnPmTEyePFmmTENDo9D6Tk5OuHPnDhISErB7924MGzYMfn5+cHV1xZgxY6T13N3dYWVlhdatWyMwMBAODg5F7hMTQkREREREREREJUhDQ+ODCaC81NXVUa1aNQBA3bp1cf36dSxZsgSrV6/OV7dhw4YAgOfPnzMhRERERERERET0ORS1qHRBJBJJoWsO3blzBwBgZWVVrDaZECIiIiIiIiIiykNRCaGZM2eiY8eOsLW1RVJSEnx9fXHu3DkcP34cgYGB8PX1RadOnWBiYoJ79+5h0qRJ8PLygoeHR7Huw4QQEREREREREVEZ8ebNGwwdOhTh4eEwMDCAh4cHjh8/jrZt2yIkJASnTp3C4sWLkZKSAhsbG/Tq1Qs//vhjse/DhBARERERERERUV4KmjG2fv36Qs/Z2NjAz89PLvdhQoiIiIiIiIiIKI+ytIZQSRArugNERERERERERFS6OEKIiIiIiIiIiCgPZR8hxIQQEREREREREVEeyp4Q4pQxIiIiIiIiIqIKhiOEiIiIiIiIiIjyUPYRQkwIERERERERERHlpdz5IE4ZIyIiIiIiIiKqaDhCiIiIiIiIiIgoD04ZIyIiIiIiIiKqYJQ9IcQpY0REREREREREFQxHCBERERERERER5aHsI4SYECIiIiIiIiIiyku580GcMkZEREREREREVNFwhBARERERERERUR6cMkZEREREREREVMEoe0KIU8aIiIiIiIiIiCoYjhAiIiIiIiIiIspD2UcIMSFERERERERERJSHsieEOGWMiIiIiIiIiKiC4QghIiIiIiIiIqK8lHuAkHImhJq0dld0F6gMOnP2qaK7QGVM1oBaiu4ClUGqakr51UhUJI71aii6C1REa3fdUXQXqAhmta2u6C5QEWlo8Puf8uOUMSIiIiIiIiIiUipMgxIRERERERER5aHsI4SYECIiIiIiIiIiykPJ80GcMkZEREREREREVNFwhBARERERERERUR6cMkZEREREREREVMEoeT6IU8aIiIiIiIiIiCoajhAiIiIiIiIiIsqDU8aIiIiIiIiIiCoYJc8HccoYEREREREREVFFwxFCRERERERERER5iMXKPUSICSEiIiIiIiIiojw4ZYyIiIiIiIiIiJQKRwgREREREREREeXBXcaIiIiIiIiIiCoYJc8HccoYEREREREREVFFwxFCRERERERERER5cMoYEREREREREVEFo+wJIU4ZIyIiIiIiIiKqYDhCiIiIiIiIiIgoDyUfIMSEEBERERERERFRXpwyRkREREREREREpWLlypXw8PCAvr4+9PX10bhxYxw9elR6Pj09Hd7e3jAxMYGuri569eqFyMjIYt+HCSEiIiIiIiIiojxEIvl9isPa2hoLFizAzZs3cePGDbRq1QrdunXDw4cPAQCTJk3CoUOHsGvXLvj5+SEsLAw9e/Ys9vNxyhgRERERERERUR6KmjLWpUsXmeP58+dj5cqVuHLlCqytrbF+/Xr4+vqiVatWAICNGzfCxcUFV65cQaNGjYp8H44QIiIiIiIiIiIqQRkZGUhMTJT5ZGRkfPS6nJwc7NixAykpKWjcuDFu3ryJrKwstGnTRlrH2dkZtra2uHz5crH6xIQQEREREREREVEe8pwy5uPjAwMDA5mPj49Pofe+f/8+dHV1oaGhgbFjx2Lfvn1wdXVFREQE1NXVYWhoKFPfwsICERERxXo+ThkjIiIiIiIiIspDnlPGZs6cicmTJ8uUaWhoFFrfyckJd+7cQUJCAnbv3o1hw4bBz89Pbv0BmBAiIiIiIiIiIipRGhoaH0wA5aWuro5q1aoBAOrWrYvr169jyZIl6NevHzIzMxEfHy8zSigyMhKWlpbF6hOnjBERERERERER5aGoXcYKIpFIkJGRgbp160JNTQ2nT5+Wnnv69ClevXqFxo0bF6tNjhAiIiIiIiIiIspDUbuMzZw5Ex07doStrS2SkpLg6+uLc+fO4fjx4zAwMMCoUaMwefJkGBsbQ19fH+PHj0fjxo2LtcMYwIQQEREREREREVE+CsoH4c2bNxg6dCjCw8NhYGAADw8PHD9+HG3btgUA/PXXXxCLxejVqxcyMjLQvn17rFixotj3YUKIiIiIiIiIiKiMWL9+/QfPa2pqYvny5Vi+fPln3YcJISIiIiIiIiKiPBQ1Zay0MCFERERERERERJSHkueDuMsYEREREREREVFFwxFCRERERERERER5KPuUsTI9QujevXtQV1dXdDeIiIiIyg3GT0RERPIhEsnvUxaV6YSQIAjIyclRdDeIiIiIyg3GT0RERFQUnDJGRERERERERJSHsk8ZY0KIiIiIiIiIiCgPJoRKUGJi4gfPJyUllVJPiIiIiMoHxk9EREQkDwpNCBkaGn4w4yYIgtJn5IiIiIiKg/ETERFR6VD2r1OFJoTOnj2ryNuXKwPqVkIzBxPYGmkhI1uCRxFJWHPxJV7Hp8vUc7XUxchGtnC21IVEEBAYlYrpBx4jM0fy0Xv0r1sJo5tUwZ474VjhH1xCT0LyMqJVNYxo5QhbUx0AwJPQBPx24AFO3wsHAGioifFL/9ro0agK1FXFOHs/AtP+voGoxPRC29TRUMVPfWuiUx1rGOmq41VUCtacfIZNZ5+XyjPR57t14zq2bNqAx48fIjoqCr8vXooWrdpIz69esQwnjh1BZEQE1NTU4OLqim/GT4SbR81C29y4bg3Onj6J4KAX0NDQhEet2hg/cQrs7O1L45HoM33Ttho6eFjBwUIX6Vk5uBkUhwUHH+HFmxRpHVtTbfzQzRX1HYyhriqG3+Mo/Lz7PqKTMj/YtoWBJmZ2dUELV3NoqakgODoFU7fdwf2QhJJ+rAqtosZPfetXRt/61qhkqAUACIxKxupzQbgQEAMAUFcVY2p7R3Rwt4C6ihiXnsdi3uEniE0p/L9jLXUVTGxbDa2czWCgrYbQuDT4XgnBrhuhpfJMymp4CwcMb+kAm/9ilKehCfj90COcuR+Rr+72SZ5o7W6FYUsv4OjtsA+262ilh1m9PdDEyQwqKmI8C0vEyOWXEBqbWiLPURGtXL4Uq1Yskymzs7fHgcPHCqw/avgQ3Lh+LV+5p1dzLFu5pkT6WBENaWiN5o6mqGKihYwsCe6HJWKlXzBexaVJ6xjrqMG7uT3q2xlBW00Fr+LS8PeVVzj3LKbQdrXVVDC6WRV4OZrASFsNz96kYPGZQDyJSC6NxyoXlP0Fi0ITQs2bN1fk7csVj8oGOHgvAk/eJENFLMKoxrZY1M0VI7fdQXp2brLH1VIXPl1dsP1mKJaeD0KORICDqQ4EQfho+07mOviihgUCo1M+WpfKhrDYVMzdeQcvIpMgggj9m9lj67eeaPHTMTwNTcT8gXXQtmYljFx2EYlpmVg4pB42T2iGTvNOFdrmLwNrw9PFAmNXX8ar6BS0dLPEb0PrISI+DcduMzguD9LS0uDo5ISuPXpi2qQJ+c5XqWKH777/EZWtbZCRng7fLZvhPfZL7D98HEbGxgW2eevGdfTpPxCuNdyQk5OD5f/7C+PGjsKufYehpa1d0o9En6lhNRP87R+Eu6/ioSoW47suztjyTSO0+fUc0jJzoKWugq3fNMLj0EQMWHoZADClszPWj2mA7n9eQGFfIfpaatgzsSkuB0Rj2MqriE3OgJ25LhLSskrx6Sqmiho/RSZmYPHJ53gVkwqRSISutaywZEBN9F15FYFRKfiuQ3V4VjfF1H/uIyk9G99/4YS/Bnhg2LobhbY5rYMjGtgbY+aehwiLT0NjBxP88IUTopIycO5pdCk+nXIJi0vFL7vv4UVkMkQioF9TO/w9vilazz6Jp2Hvpjx+1bZ6of/G5GVnpoNDM1vB1z8Iiw48RHJaFpwqGyAjizvqyZtDNUesWbdReqyiqlJo3T8XL0VW1rt/9+MT4tG3Zze0bdehRPtY0dSyMcDe22F4HJH7t+BXnnb4q48bBm28ifSs3L8FZ3Vygq6GKqbvfYiEtGy0dTHD3C4uGLXlNgLeFPw33owOjqhqqo25R54iOjkT7V3NsaSvOwZtuIno5A+/FCLlwEWly4mZBx/LHC86+Rx7R9eHo7kO7oflrhXwtacd9t2NwI6b796u5B1BVBBNNTG+b+eIP8++wKB6leXbcSoxx+/IvkWbv+ceRrSqhnoOpgiLTcMgr6oYs/Iy/B9HAgDGr7uCKwu+QD0HE9wILPhNQYNqpthxIQgXn7wBAPx9LhDDWlZDnarGTAiVE009vdDU06vQ8x06fyFzPGnaDBzYtwcBz56iQaPGBV6zdNVamePZv/igbYumePzoIerUq//5naYSNWzlVZnjKdvu4Pav7eFuY4BrgbGoV9UY1sba6LToPJLTs3PrbL2News6oImjKS4+K/iP4q/bOCA8Pg3TfO9Ky0Ji0wqsSyQPfnkSNEtPB6JvfWt42BggMjEdPepUwozdD3AtKA4AMGvfIxyc0AQe1vq497rgdZdq2Rji4J1w3AjOvWbPzVD0qV8ZbtYGTAh9hhN3w2WOffY+wPAWDqjrYCJNCLnZGOLr9tXRbu4pPFjc9aNtzuzpjtP3wjF31z1pWXAUX2SWBFUVFZiamRWproGhoczxsaP/QlNTE23bMyEkT1N2P5Q5nn/0Gf4d1whOFrq4+9+/b26V9PH7yed4/N/ons1XQtCvXmU4W+gWmBBSVxWjeXVTzNj3UNrGhkuv0NTBGD1qWWHthZcl/FTlg5IPEIJYkTdXUVEp0ofy09HIzeUl/Re8G2qpwtVSD/FpWfhfbzfsHlUXf/asATcrvY+29W1ze1wJjsMtDvEvt8QiEXo0tIW2hipuPI9GLTtjqKuqwO/Ru6HZAeFJCIlOQb1qpoW2c+15NDrWrgwro9zh+M2czVHNQg9nH+Qf4k3lX1ZWJvbt3gldPT1Ud3Iu8nXJyblJaH0Dg5LqGpUgPc3c74/41Nw3uuqqYgiCgMzsd1OLM7IlkAgC6jsUPGoMANq6W+LeqwSsGFEXN+e3w5HvvNC/sW3Jdp4AMH4CALEI6OBmAS11FdwNSYBrJX2oqYpx5UWstE5wdCrC4tPgYWNYaDt3QuLRwtkU5noaAID69kaoYqKNy88Ln2JBxSMWidC9gU1ujPLfCyktdRWs/KohZmy9hTcfmMr+lkgEtK1phcDIZPwz2QsPF3fF0R9bo2PtSiXd/Qrp5auXaNOiGTq1b42Z301BeNiHp/K9b9/ePejQsTO0OYK4ROlo5P4bn/jf34IA8CAsEa2dTaGnqQoRgNbOZlBXERf6N56qSARVsQiZ2bLD9DKyJfCorF9ifS9vRCKR3D5lkUJHCAmCgCpVqmDYsGGoXbv2J7WRkZGBjIwMmTJJVibEaury6GKZJALg7WmH+2GJCP7vbayVviYAYFgDa6y6+BKBUSlo62yG33q44sttdxGaUPCXbUtHE1Qz08U3O+8VeJ7KNhdrAxyb1RaaaipISc/G0P/542lYItxsjZCRlYPEVNmpG1GJ6bAw0Cy0vRlbbuKvEQ3wYHF3ZP33B+Gkjddw+WlUST8KlSJ/v7P4/rupSE9Pg6mZGZavXg9DI6MiXSuRSPDHIh/UrF0H1Ryrl3BPSd5EIuDnnm64HhiLZ+G5ib3bwXFIzczBjK4uWHToCUQiYEYXF6iqiGGuX/i/FzYm2hjcrArWnX2B5ScD4GFriDm93JCVI8Gea69L65EqJHnET0AhMVR2JsSqZTeGcjTXwZbR9aGuKkZqZg4mbr+LF1EpcLbURWa2RPqi7K2Y5EyY6hb+PD7/PsXPXV1waponsnIkEARgzoHHuPkyvoSfRPm5VDbAkR9aQUNNBSkZ2Ri+7CKe/Tc66Jf+tXD9eQyO3SlaosFMTxO6mmoY38kZC/Y+wC+77qGluyU2ejdFj0XncPkZ4xR5cffwwC/zfWBnZ4+oqCisXrkcI4YOwp4Dh6Cjo/vBa+/fu4fnAc8we+78UuptxSQC8G2rqrj7OgFB0e/Wz5p18DHmdnHBsfGNkZ0jQXq2BN8feITQQmaMpGbl4H5oIoY3tsHLmFTEpmaijYsZ3CrpIzSeI34rCoUmhK5du4b169djyZIlsLe3x8iRIzFo0CAYFfEPEwDw8fHBnDlzZMrsOoxE1U5fyru7ZcaEFvawM9HCt+8NHXybcDz8MBLHH+d+KT6/8BJ1bAzQwdUc6y+/yteOma46vL3s8N3+x8jKKeIEbipTnocnocWsY9DXVkPX+rZYProRuvqc/uT2RretjnoOJhj4lx9CYlLRxMkMi4bUQ0RcGvweRcqx56RI9eo3hO+uvYiPi8O+vbswc+okbNr2D4xNTD567cL5cxH4PADrNm0rhZ6SvP3Sxx3VrfTQe8lFaVlscia+2XgT8/u6Y4SXPSSCgIO3wnA/JB6SDyzuIRaJcD8kHr8dfgIAePg6EU5WehjctAoTQiVMHvETUHAMZe41BBbNh8qzu3IVFJOKPiuvQldDFW1rmGNezxoYueHmJ7c3sJENPGwMMH7bHYTFp6NuFUN8/4UT3iRl4Op7o42o+J5HJKHV7JPQ01JDl3rWWPplA3RfeA725rpo5mKO1rNPFrkt0X9zGo7dDsXqk88AAA9C4lHfwQTDWjowISRHzTzfrVFW3ckZ7h410bFtSxw/dhQ9e/X54LX79u6GY/XqcPfwKOluVmhT2lZDVVMdfP3elG0AGN3MDroaKpjwz30kpGXB09EEc7u44Jvtd/EiuuCF13858hQzO1THgW8aIlsi4FlkMk49iYKTxYeTfxVJGR3YIzcKTQjVq1cP9erVw19//YXdu3dj48aNmD59Orp06YJRo0ahbdu2H21j5syZmDx5skxZt3W3S6rLCje+uT0a2Rlh0t6HiH5v14zY/0aCvMyzfsPLuDSY6xX8Zqy6uQ6MtNWxqv+7f7RVxCJ4VNZHdw9LdFhxBRLmicq0rBwJgt7kzhO+GxyH2vbGGNPOCfuvvoKGmgr0tdVkRgmZ6WsispDRYppqKvixtweG/u8CTt7NfWP3KCQebrZG8O7owoSQEtHS1oaNbRXY2FaBe81a6PFFexzYtwcjvhzzwesW/voLLpz3w5qNW2BhaVlKvSV5mdvbDa1rWKDvkouIyPO20P9JFLzmnoGRjjpyJBIkpmXj+ry2CCkkgASAN4npCIhIkil7HpmMjjWtSqT/9I484ieg4BiqyYILJdFlucnOEaRrVT0OT4JbZX0MamSD4w8ioa4qhp6mqswoIRNd9UIXRtVQFWNC62qYuOMu/P/bhScgMhnOVnoY3tSWCaHP9H6Mcu/lfzFKG0ekZeXAzkwXAcu6y9Tf4N0EV55Fo8eic/naik3KRFa2RDrC6K2A8CQ0dCx8Kjx9Pn19fVSpYoeQV/lfLr8vNTUVx4/+i2/G5d/QguRncmsHNKlqDO8ddxH13r9tlQ010btOJQzecBNBMbnf3c+jUlDTWh+9alfCbycL3jE4ND4d43bcg6aaGDrqKohJycLcLs4IK8I6tBWFWMkzQmViUWlNTU0MHjwYgwcPRlBQEEaNGoUOHTogKioKxoXsevOWhoYGNDQ0ZMqUdbrY+Ob2aFbVGJP3PkREouwQ74jEDEQnZ8L6v61Y37I21ML1l3EFtncrJAGjtt2RKZvWphpC4tKw42Yok0HlkFgkgoaqGHeCY5GZnYPmrhY4dCP3TX01Sz3YmOrgxvOCF8lUUxFBXVUl34iAHIkAsUJXG6OSJpEIyMwsfCcJQRCwyGcezp05hdXrN6OytXUp9o7kYW5vN7T3sES/pZc/uPBz3H8vGpo4msBUVwMnP7B+2M0XsahqLvsG0d5MF6FxHGZeWj4nfgIKiaHK8HSxgohFIqirivEoLBFZ2RI0rGqMU49yN0awM9FGJUMt3AuJL/BaVRUR1FTF+Xa5ypEIZXath/JMJMpds2zR/ofYdv6FzLnzv3TArB13caKQKWRZORLcCY5FNUvZtTEdLHUREsOFpUtSakoKQkJC0LnrhxeZPnn8GDIzM9G5y8cXCKdPM7m1A7wcTTBuxz2EJ8j+Laihmhus543jJZKijXBJz5IgPUsCPQ1VNLAzwgq/ILn1m8q2MpEQAoDXr19j06ZN2LRpE1JTUzFt2jTo63Mxq7cmNLdHaydTzDr8FKlZOTDSVgMApGTkIDMndyHQf26FYlhDG7yITsHz6FS0czaDrZEW5hx5Km3nt+6uuPAiFgfuRSAtSyJdg+it9KwcJKZn5yunsmdWn5o4dS8Mr2NSoaupit6N7dDU2Rx9fj+HpLQsbDv/Ar8MqIO45EwkpWdhweC6uBYQJbPD2BWfzvhl9138e/M1ktKzceFxJOb0q4X0zByERKegqbM5+jW1w6ztyjvqTtmkpqbIvMULDX2Np08ew8DAAAYGhtiwdjW8WrSEqZkZ4uPjsXOHL6LeRKJNu/bSa77+cgRatG6DfgMGAcidJnbs6L/4Y8kyaOvoIDo6d2i+rq4eNDULX2OGyoZ5fdzRtW5ljF53HSnp2TD7b/HcxPQsZPy3VW2fhjZ4HpmEmORM1LUzws+93LD+3Au8eG9XEl/vRjh+LwKb/YMBAOvOvcDeSc3g3bYaDt8OQ60qRhjYxBYz/+GadKWpIsVPE9o44GJADMIT0qGjroKOHpaoZ2eEsVtuIzkjB/tuhWFqB0ckpGUhOT0bMzs74c6reJkdxg6Mb4wlp57jzOMopGTk4HpQHCa3c0R6lgTh8Wmoa2eELrWs8PuxZwp80vLvh17uOH0/HKExqdDVVEPPRrZo6mSOfn+ex5vE9AIXkg6NScGr6Hf/5lyc3wHz99zHkVu5u5wuP/YUa8Y2wuVn0bj45A1aulmiXc1KBY4ook/3x28L0bxFS1hVqoSoN2+wcvlSqKiI0bFT7i6lP8z8DubmFvh20hSZ6/bt3Y2WrdvA0LB4U1epaKa0cUBbF3PM2PcIqVk5MNbJ/VswOSMHmdkSvIxNQ0hcGr5r54hl514gMT0bntVMUN/OEN/tebfMyJK+7jgfEI09t3N3AmxgZwgRRHgVlwprQy14t7DHq9hU/PuAMwPeUvb3AwpNCGVmZmLfvn1Yv349/P390bFjRyxevBgdO3ZU+t0xiqubR+70jL961ZApX3TyOY4/yf3jbO/dCKirivG1px30NFXxIjoV3+1/hPD3RhNVMtCAgWaZyQPSZzDV08CK0Y1gYaiFxLQsPAqJR5/fz+Hcw9w3+j/43oJEImDT+GZQV1PB2fvhmPb3DZk2HCvpQ19LTXo8euUlzOpTE6vHNoahjjpeR6di/u572Him4GGmVPY8evgQY0cNkx7/9dtCAMAXXbtj5qzZCA5+gcNT9iM+Lg4GhoZwreGOtZu2wqGao/Sa169fIT7u3cjC3Tt3AAC+GvmuXQD4+Zdf0aVbj5J8HJKDIZ52AICdE5rIlE/Zehu7/1vrp6q5Dr7r4gxDbXW8jk3FshMBWHdW9g2+rakOjN5bnPfeqwSMWXcd07u4YEKH6ngdk4o5ex9i/43Qkn0gqrDxk7GOOub1rAEzPQ0kp2fjWWQSxm65jSuBuVO7Fh17BongiD/7eUBdVYyLz2Mw/781rt6yN9OBrsa7OOi7XffxbZtq8OldAwZaagiPT8fS04HYeZ3/HX8OU30NLPuyISwMNJGYloXHrxPQ78/zxZp+7milD733YpQjt0Ix7e9b+LazM+YPrIXAiCSMXH4JVwMKHvlMnyYyMgIzpk1GfHw8jIyNUbtOXWzx3SkddRgRHg6xSHboeHDQC9y+dROr1m5QRJcrhJ7/7ai3fIDs+kzzjzzFkYdvkCMRMHX3A3zd3B6LetaAlpoKXsenYd6RZ7gc9C6mq2yoCYP3/n+lq6GKsV52MNPVQGJ6NvyeRWO1fzByOFVEStlHjIoE4QMrRpYwExMT6OnpYdiwYRgyZAjMzc0LrFfcN12tl16WR/dIydy5EazoLlAZE7ymn6K7QGWQ27R/Fd0FKoNe/q+LorsgVVLxEwB4/HTqc7tHpSTiNdc4Kg9eremr6C5QEbX+y1/RXaAiujjNs9Tu1X7FVbm1dfybhnJrS14UOlQkLi4OcXFx+OWXXzBv3rx85wUhdw53Tk6OAnpHREREVPYwfiIiIiodYuUeIKTYhNDZs2cVeXsiIiKicofxExERUelQ9iljCk0I1a5dW5G3JyIiIip3GD8RERGRPBQrIZSVlQVnZ2ccPnwYLi4un31zQ0PDImXcOOSZiIiIyjN5xlCMn4iIiEqHkg8QKl5CSE1NDenp+beJ/FTvD3kWBAGdOnXCunXrULlyZbndg4iIiEjR5BlDMX4iIiIqHSIod0ao2FPGvL29sXDhQqxbtw6qqp8346x58+YyxyoqKmjUqBGqVq36We0SERERlTXyiqEYPxEREZE8FDsauX79Ok6fPo0TJ07A3d0dOjo6Muf37t0rt84RERERKQvGUEREROULdxnLw9DQEL169SqJvhAREREpLcZQRERE5Qt3Gctj48aNJdEPKWX/gRMREVHFVJIxFOMnIiIiKq5PmsCenZ2Nc+fOITAwEAMHDoSenh7CwsKgr68PXV3dIrfTs2dPmeP09HSMHTuWQ6iJiIhIKckjhmL8REREVDqU/X1LsRNCL1++RIcOHfDq1StkZGSgbdu20NPTw8KFC5GRkYFVq1YVuS0DAwOZ48GDBxe3O0RERETlgrxiKMZPREREpUOs5BmhYieEvv32W9SrVw93796FiYmJtLxHjx4YPXp0sdoq6elnRERERGWFvGIoxk9EREQkD8VOCPn7++PSpUtQV1eXKbezs0NoaKjcOkZERESkTBhDERERlS9KPkCo+AkhiUSCnJycfOWvX7+Gnp6eXDpFREREpGwYQxEREZUvyr5pg7i4F7Rr1w6LFy+WHotEIiQnJ+Pnn39Gp06d5Nk3IiIiIqXBGIqIiIjKkmKPEPrjjz/Qvn17uLq6Ij09HQMHDkRAQABMTU2xffv2kugjERERUbnHGIqIiKh8UfIBQsVPCFlbW+Pu3bvYsWMH7t27h+TkZIwaNQqDBg2ClpZWSfSRiIiIqNxjDEVERFS+cJexgi5SVeUWp0RERETFxBiKiIiIyopPSggFBATg7NmzePPmDSQSicy5n376SS4dIyIiIlI2jKGIiIjKD+UeH/QJCaG1a9fi66+/hqmpKSwtLWVW3RaJRAxmiIiIiArAGIqIiKh8UfZdxoqdEJo3bx7mz5+P6dOnl0R/iIiIiJQSYygiIiIqS4qdEIqLi0OfPn1Koi9ERERESosxFBERUfkiVu4BQhAX94I+ffrgxIkTJdEXIiIiIqXFGIqIiKh8EYlEcvsUh4+PD+rXrw89PT2Ym5uje/fuePr0qUydFi1a5LvH2LFji3WfYo8QqlatGmbNmoUrV67A3d0dampqMucnTJhQ3CaJiIiIlB5jKCIiIioKPz8/eHt7o379+sjOzsb333+Pdu3a4dGjR9DR0ZHWGz16NObOnSs91tbWLtZ9ip0QWrNmDXR1deHn5wc/Pz+ZcyKRiMEMERERUQEYQxEREZUvilpT+tixYzLHmzZtgrm5OW7evAkvLy9puba2NiwtLT/5PsVOCAUFBX3yzYiIiIgqKsZQRERE5Ys8dxnLyMhARkaGTJmGhgY0NDQ+em1CQgIAwNjYWKZ827Zt2Lp1KywtLdGlSxfMmjWrWKOEir2GEBERERERERERFZ2Pjw8MDAxkPj4+Ph+9TiKRYOLEiWjatCnc3Nyk5QMHDsTWrVtx9uxZzJw5E1u2bMHgwYOL1adijxDKycnBpk2bcPr0abx58wYSiUTm/JkzZ4rbJBEREZHSYwxFRERUvshzl7GZM2di8uTJMmVFGR3k7e2NBw8e4MKFCzLlY8aMkf5vd3d3WFlZoXXr1ggMDISDg0OR+lTshNC3336LTZs2oXPnznBzc5PrECoiIiIiZcUYioiIqHyR53d1UaeHvW/cuHE4fPgwzp8/D2tr6w/WbdiwIQDg+fPnJZcQ2rFjB3bu3IlOnToV91IiIiKiCosxFBERERWFIAgYP3489u3bh3PnzsHe3v6j19y5cwcAYGVlVeT7FDshpK6ujmrVqhX3MiIiIqIKjTEUERFR+aKosbze3t7w9fXFgQMHoKenh4iICACAgYEBtLS0EBgYCF9fX3Tq1AkmJia4d+8eJk2aBC8vL3h4eBT5PsVeVHrKlClYsmQJBEEo7qVEREREFRZjKCIiovJFLBLJ7VMcK1euREJCAlq0aAErKyvp559//gGQ+5Lp1KlTaNeuHZydnTFlyhT06tULhw4dKtZ9ij1C6MKFCzh79iyOHj2KGjVqQE1NTeb83r17i9skERERkdJjDEVERERF8bGXRzY2NvDz8/vs+xQ7IWRoaIgePXp89o2JiIiIKhLGUEREROWLsu//UOyE0MaNG0uiH0RERERKjTEUERFR+aLsO4IWew0hIiIiIiIiIiIq34o0QqhOnTo4ffo0jIyMULt27Q9myW7duiW3zhERERGVZ4yhiIiIyi8lHyBUtIRQt27doKGhIf3fyj5sioiIiEgeGEMRERGVX8XdHay8KVJC6Oeff5b+79mzZ5dUX4iIiIiUCmMoIiIiKquKvYbQTz/9hLNnzyI9Pb0k+kNERESklBhDERERlS8ikfw+ZVGxE0KXL19Gly5dYGhoCE9PT/z44484deoU0tLSSqJ/REREREqBMRQREVH5IhKJ5PYpi4qdEDp58iTi4+Nx+vRpdOrUCTdu3EDPnj1haGiIZs2alUQfiYiIiMo9xlBERERUlhRpDaF8F6mqomnTpjAzM4OxsTH09PSwf/9+PHnyRN79+yRRUSmK7gKVQX271lR0F6iMUfZF4ujTvPE/ruguUJnURS6tlPUYythYW9FdoCIa18lR0V2gIgiJ4QjA8uKW7z+K7gIV1TTPUrtVsUfQlDPFfr41a9Zg4MCBqFy5Mpo0aYJjx46hWbNmuHHjBqKiokqij0RERETlHmMoIiKi8kXZp4wVe4TQ2LFjYWZmhilTpuCbb76Brq5uSfSLiIiISKkwhiIiIqKypNgjhPbu3YtBgwZhx44dMDMzQ5MmTfD999/jxIkTSE1NLYk+EhEREZV7jKGIiIjKF7FIfp+yqNgjhLp3747u3bsDABISEuDv749du3bhiy++gFgs5laqRERERAVgDEVERFS+lNVEjrx80qLSMTEx8PPzw7lz53Du3Dk8fPgQRkZG8PQsvcWdiIiIiMobxlBERERUVhQ7IeTu7o7Hjx/DyMgIXl5eGD16NJo3bw4PD4+S6B8RERGRUmAMRUREVL6U1cWg5eWTFpVu3rw53NzcSqI/REREREqJMRQREVH5wiljeXh7e5dEP4iIiIiUGmMoIiIiKks+aQ0hIiIiIiIiIiJlpuQzxpgQIiIiIiIiIiLKS6zkGSGxojtARERERERERESliyOEiIiIiIiIiIjyUPYRNJ/0fP7+/hg8eDAaN26M0NBQAMCWLVtw4cIFuXaOiIiISJkwhiIiIio/RCL5fcqiYieE9uzZg/bt20NLSwu3b99GRkYGACAhIQG//vqr3DtIREREpAwYQxEREVFZUuyE0Lx587Bq1SqsXbsWampq0vKmTZvi1q1bcu0cERERkbJgDEVERFS+iEUiuX3KomKvIfT06VN4eXnlKzcwMEB8fLw8+kRERESkdBhDERERlS9lNI8jN8UeIWRpaYnnz5/nK79w4QKqVq0ql04RERERKRvGUERERFSWFDshNHr0aHz77be4evUqRCIRwsLCsG3bNkydOhVff/11SfSRiIiIqNxjDEVERFS+iEXy+5RFxZ4yNmPGDEgkErRu3Rqpqanw8vKChoYGpk6divHjx5dEH4mIiIjKPcZQRERE5UtZXftHXoqdEBKJRPjhhx8wbdo0PH/+HMnJyXB1dYWurm5J9I+IiIhIKTCGIiIiorKk2Amht9TV1eHq6irPvhAREREpPcZQRERE5YOSDxAqfkKoZcuWEH3gp3LmzJnP6hARERGRMmIMRUREVL6U1bV/5KXYCaFatWrJHGdlZeHOnTt48OABhg0bJq9+ERERESkVxlBERERUlhQ7IfTXX38VWD579mwkJyd/doeIiIiIlBFjKCIiovJFBOUeIlTsbecLM3jwYGzYsEFezRERERFVCIyhiIiIyiZl33Zebgmhy5cvQ1NTU17NEREREVUIjKGIiIhIEYo9Zaxnz54yx4IgIDw8HDdu3MCsWbPk1jEiIiIiZcIYioiIqHwpqyN75KXYCSEDAwOZY7FYDCcnJ8ydOxft2rWTW8eIiIiIlAljKCIiovLlQ7uDKoNiJYRycnIwYsQIuLu7w8jIqKT6RERERKRUGEMRERFRWVOsNYRUVFTQrl07xMfHl1B3iIiIiJQPYygiIqLyh4tK5+Hm5oYXL16URF+IiIiIlBZjKCIiovJFJJLfpywqdkJo3rx5mDp1Kg4fPozw8HAkJibKfIiIiIgoP8ZQREREVJYUeQ2huXPnYsqUKejUqRMAoGvXrjILLAmCAJFIhJycHPn3koiIiKicYgxFRERUPonL6tAeOSlyQmjOnDkYO3Yszp49W5L9ISIiIlIqjKGIiIjKJ0Wt/ePj44O9e/fiyZMn0NLSQpMmTbBw4UI4OTlJ66Snp2PKlCnYsWMHMjIy0L59e6xYsQIWFhZFvk+RE0KCIAAAmjdvXozH+Dw5OTlQUVEptfsRERERyRtjKCIiIioOPz8/eHt7o379+sjOzsb333+Pdu3a4dGjR9DR0QEATJo0Cf/++y927doFAwMDjBs3Dj179sTFixeLfJ9ibTsvKqXhUs+ePcO6deuwZcsWhIeHl8o9iYiIiEoKYygiIqLyR55f3xkZGcjIyJAp09DQgIaGRr66x44dkznetGkTzM3NcfPmTXh5eSEhIQHr16+Hr68vWrVqBQDYuHEjXFxccOXKFTRq1KhIfSrWotLVq1eHsbHxBz+fKjU1FRs3boSnpydcXV1x/vx5TJ48+ZPbIyIiIiorGEMRERGVP2KI5Pbx8fGBgYGBzMfHx6dI/UhISAAAabxw8+ZNZGVloU2bNtI6zs7OsLW1xeXLl4v8fMUaITRnzhwYGBgU55KPunLlCtatW4ddu3bB1tYWjx8/xtmzZ+Hp6SnX+xAREREpCmMoIiKiim3mzJn5XtgUNDooL4lEgokTJ6Jp06Zwc3MDAEREREBdXR2GhoYydS0sLBAREVHkPhUrIdS/f3+Ym5sX55JC/fHHH9iwYQMSEhIwYMAAnD9/HjVr1oSamhpMTEzkcg8iIiKisoAxFBERUfkjzyljhU0P+xhvb288ePAAFy5ckF9n/lPkhJC8575Pnz4d06dPx9y5c7noIRERESktxlBERETlk6J2GXtr3LhxOHz4MM6fPw9ra2tpuaWlJTIzMxEfHy8zSigyMhKWlpZFbr/Iawi93SFDXn755Rfs2rUL9vb2mD59Oh48eCDX9omIiIjKAsZQREREVByCIGDcuHHYt28fzpw5A3t7e5nzdevWhZqaGk6fPi0te/r0KV69eoXGjRsX+T5FTghJJBK5DXUGcufPPXv2DFu2bEFERAQaNmyImjVrQhAExMXFye0+RERERIrEGIqIiKh8EotEcvsUh7e3N7Zu3QpfX1/o6ekhIiICERERSEtLAwAYGBhg1KhRmDx5Ms6ePYubN29ixIgRaNy4cZF3GAOKuYZQSWjevDmaN2+OZcuWwdfXFxs2bEDz5s3RoEED9O7dm7tk/GeUpx1au5rB3lQHGVkS3AmJx+ITzxEckyqtY6KrjsntHNHYwRg6GqoIjk7B2vPBOPXoTaHt9q1fGX3rW6OSoRYAIDAqGavPBeFCQEyJPxN9nvZOJqhVSR+WeurIyhEQGJuK/fffIDI5U1pnYG0rOJvrwEBLFRnZEryIScO+B5GITMostF09DRX0cLOAi4UOtNVUEBCdin/uRiAqufBrqOy4eeM6/t60Ho8fPUR0VBT+WLwMLVu/231g1YqlOHH0CCIiI6CmqgYX1xrwnjAR7h41P9juP9u34e9N6xETHY3qTs74buaPcHP3KOnHITkY3acZRvf2RJVKubtSPH4RgV/XHMWJi4/y1d2/7Gu0b1oDfSetwaFz9wptU0dLHfMmdEOXlh4wNtBBcFgMVmz3w7rd8p/bToWraDHUwPqV4eVgAltjLWRkS/AwPBGrL7xESFy6tI6xthrGelZBPVtDaKmrICQuDVuvvcb557GFttvVwwLd3C1hqZ+7rkNwbBo2Xw3BteD4kn4kpfX6yT1cP7oLkcEBSImPRdcJP8OxblPp+ZSEOPjvXIfgBzeRkZoCayd3tBrsDSPLyh9sNz0lGRf2bMTzGxeRnpIEfRNztBj0NarWbFDSj6S0Hty5iT07NiPw6WPExkThh/l/orFnK+l5QRCwbcNKHD+0FynJSXBxr4VvJn+PyjZVCm0zNTUFW9ctx2X/s0iIi0VVRyeMmfAdqru4lcYjVQhTR7TFLxO6Ydm2s5j2+x4AwMieTdGvYz3UcraGvq4WLD2nISE57YPtFCdGqKjkPOu7yFauXAkAaNGihUz5xo0bMXz4cADAX3/9BbFYjF69eiEjIwPt27fHihUrinWfYm07X5L09PTw1Vdf4erVq7h9+zYaNGiABQsWKLpbZUY9O0PsuPoag9dcx5jNt6CqIsaqYbWhpfbuVzi/Zw3YmWpjgu9d9Fx+BaceR+G3vu5wttQrtN3IxAwsPvkc/VddxYDV13DtRRyWDKgJBzOd0ngs+gyOpjrwexGLRWeDseTCS6iIRBjfzBbqKu/+1XoVn4a/b4ZhzolALL3wCiIAE5pVwYf+XRvb2AamOmpYdTkEv55+gdjULHybp10qu9LT0lC9ujNm/PBTgeerVLHD9O9nYeeeg9jw9zZUqlwZ3l+NQlxs4X8sHT92BH/+tgBjxnrDd+deOFZ3gvdXXyI2honj8iA0Mh6zlh5Ak0GL0HTQbzh37Rl2/TUGLlVl55ePH9QSRZ3ZtHBKL7Rt4ooRP/yNWj3nYdm2c/hreh90bu5eAk9AH1NRYqhalfWx/144vtlxD1P3PoSKWIzfetSApuq7WGhme0fYGGnh+4NPMHLLHfg/j8XPnZxQ7QNxTVRSJtZcfIkx2+/hq+33cCskAfO7OMPOWKs0HkspZWWkw8ymKloPGZfvnCAIOLBkNuLfhKP7t3MwZO4K6JuYY9ei6cjKKPyP15zsLOz+bQYSoyPRZdwsjFiwHm1HToKuERdS/xzp6Wmo6lAdYyfNLPD8Ht9NOLTHF95TfsAfq7dAU1MLP039BpkZGYW2uXThHNy5cQVTfpiHZZt2oXb9xvhx8lhER0WW1GNUKHVdbTGqV1Pce/ZaplxbUw0nLz3CbxtOFLmtosYIVPoEQSjw8zYZBACamppYvnw5YmNjkZKSgr179xZr/SCgDCWE3ufu7o7FixcjNDRU0V0pM77ecgcH74QjMCoFzyKTMWvvQ1Qy1IJrJX1pnVo2Bth+NQQPQhMRGpeGtX5BSErPgmulwhNCfk+jcSEgBq9i0/AyJhVLTwciNTMHHjby3RqX5G/ZxVe48jIB4UkZCE3IwN83wmCiow5bo3cB7IWgeDyPTkVsahZC4tNx8OEbGGurwURHrcA2zXXVUdVEG9tvR+BlXDoikzOx/XY41FXEqM//JsqFpp5e8J4wEa1aty3wfMfOXdCwcRNY29jAoZojJk+bgeTkZDx79rTQNrf9vQk9evVBtx69UNWhGn74aQ40tTRxYN+eknoMkqMj5x/g+IVHCHwVheev3mD28kNITs1AA493c9E9qlfGt0NaYezsrUVqs1FNe2w9fBX+NwPwKjwWG/ZexL1noahXo/A3xlQ6lDmG+m7/Yxx7FIXg2DQERqdiwYkAWOproLqFrrSOm5Ue9t6JwJPIZIQnZmDLtddIzsiGk3nhCaHLQXG4GhyP0Ph0vI5Px/pLr5CWlQNXq8LjJ/ow+5oN0Kz3CDjWa5bvXFxkKMIDH6PNsAmwrOoEYysbtBk2AdmZGXh8+VyhbT44fxzpyUnoNmE2KlevAQMzS9g4e8Dc1qEEn0T51WvUDENGj0MTr1b5zgmCgAO7tqHfkNFo5NkS9g7VMfmHXxAbE4XLF84W2F5GRjounj+NEV9PhFutuqhkbYtBI7+GVWUbHN2/q6QfR+npaKlj46/D8c0v2xGfKJtAXeZ7Dr9vPImr94KL3F5RYoSKTlFTxkqLwqaM/f333x+tIxKJMGTIkFLoTfmjq5n7q0tIy5KW3QlJQHs3C5x/Fo2k9Gy0r2EBDVUVXA8u2noCYhHQroYFtNRVcDckoUT6TSXn7Wix1MycAs+rq4jQ2M4Q0SmZiEvNKrCO6n/L6GdJJNIyAUCWRICDiTYucvi8UsnKysTe3f9AV08P1Z2cC63z+NFDjBg1RlomFovRsFFj3Lt7p5R6SvIiFovQq20d6Gip4+q9IACAlqYaNvkMx8QFOxEZk1Skdq7cDcIXzd3x9/7LCItKgFc9RzhWMcd3fzBJWBoYQ+XSVc+NhZLSs6VlD8KT0Kq6Ca4ExSE5Ixstq5tAXVWMO68Ti9SmWAS0cDSBpqoKHoYX7f8PVDw5WbkxiKqaurRMJBZDRU0NYQEP4NGiY4HXBd6+jErVXHD676UIvH0ZWnoGcGncCvU794VYzN32SkJkeCjiYqNRq15DaZmOrh6cXNzx5MFdNG/dId81OTk5kOTkQE1ddmttDQ0NPLx/u8T7rOwWz+yHY/4PcPbqU8z4Mv/P/3MUFCOQ4qaMlRaFJYSGDx8OXV1dqKqqFrr7RlGCmYyMDGTkGbIoyc6EWFW9kCvKP5EI+K5jddx6GY/nb1Kk5dN23seivu64MLMFsnIkSM+SYOL2uwiJ/fDcUUdzHWwZXR/qqmKkZuZg4va7eBGV8sFrqGwRAehT0xLPo1MRlij7/wevqkbo4W4BTVUxIpIysMT/JXIKmRYSkZSBmJRMdHczh++tcGRkS9Da0QTG2mow0FL4kmMkJ+f9zmLmtClIT0+DqZkZVq7ZACMjowLrxsfFIScnB8YmskPyjU1MERzEYKG8qFGtEs5tngJNdVUkp2Wg35S1ePIiAgCwaEovXLkbhMPn7he5vckLd2H5rAEIPDEfWVk5kAgSfPPLdly8FVhSj0DvYQyV+703rrkd7ocmIui99RTnHHmKnzpVx6GvGyA7R4L0bAlmHXqC0IT0whsDYG+ijRX93KGuKkZaVg5mHX6Clx+Jn+jTGFvZQM/EHP67NqDtiG+hpqGJm8f3Ijk2GsnxhU9fjo8KR+LjO3Bp3Ao9J89D3JswnN68FDnZ2WjSQ7mTn4oSFxMNADDMMy3P0NgY8bEFTxvX1taBcw0P7Ni8BjZV7GFoZILzp4/hycN7sKpsU+J9VmZ92tdFLWcbNBu8SK7tfihGIOWnsCljLi4uUFdXx9ChQ+Hn54e4uLh8n9gPrGnxlo+PDwwMDGQ+URd3lMITKM4PnZ1RzVwX03fJBu/erRygr6mK0ZtuYsCqa9hy6SV+6+sOxw8MkwaAoJhU9Fl5FYPWXMfO668xr2cNVOUaQuVK/9qWqKSvgfXXXuc7d+1VAn49/QJ/+AXjTVImRje0lo4EyksiAGuuvIa5rgb+6OqMJd1dUN1MBw8ikoq8tgiVffXrN8T23fuwcct2NGnqielTJ3I9ICX3LDgSDfv7wGvo71i76wLWzh0C56qW6NzcHS0aVMe033YXq71v+jdHA3c79Pp2FZoMWogZf+7D4hl90bKhUwk9Ab2vJGOoV6e2lMITfL6JrarC3lQbc48+kykf2dgWuhqqmLznIb7afg+7boVhdmcn2Jtof7C9kLg0fLntLr7ecQ8H7kVgZjtHVOEaQiVCRVUV3cb/hLjI11j+TS8sGd0FIY/vwt6jPkQfehUvEaCtZ4i2IybCwr46nBu2QMOuA3Dv7L+l13kqkik/zgcEYFjPdujRpgEO7vaFV+sOEInK5Gol5YK1hSF+m9YLI37YhIzM7I9fUAyFxQiUSyzHT1mksFf+Dx8+xNWrV7FhwwZ4eXmhWrVqGDVqFAYNGgR9ff2PN/CfmTNn5ttFo8kC5d3lZGZnJ3g5mWLE+huIfG8kiLWRFgY2skGPpZcR+N/onmeRyahTxRD9Gtpg3qEnhbaZnSNIRxE9Dk+CW2V9DGpkg18+cA2VHf1qWcLNUg9/+gUjPi3/F0R6tgTpyZmISs5EUEwq/ujqjFqV9HCjkOHzr+LT8evpF9BUFUNVLEJyZg6+a2mPV3F8U6ostLS1YWtbBba2VeBRsxa6dW6P/ft2Y+SXX+Wra2hkBBUVlXwJo9iYaJiYmJZWl+kzZWXn4EVI7pve249DULeGLbwHtEB6RhaqWpsi4vxvMvW3//4lLt4ORPvRS/K1pamhhjnju6Df5LU4duEhAOBBQBg8nKwxcUhrnL1a+HpUJB8lGUN9seaWvLsrd9+2sEdjeyNM2PVAZgfMSgYa6FnLCsP/vo3g/+KawOhUeFTWR4+alvjzzItC28yWCNJRRM/epMDZQhe9alvhz9OFX0OfzsK+Oob+sgoZqSnIyc6Ctr4hts0ZDwv76oVeo2NoDLGKqsz0MBMrW6QkxCInOwsqqgWvj0ifzui/7/n4uBgYm5pJy+NjY2FfrfDflVVlGyxYuh7paWlITUmGsakZFv78HSwrfXgXOSpcbRdbWJjo47LvdGmZqqoKmtVxwNh+XjBoOBESyae9vS0sRhg/X7kHWRTVBxPVSkChiaqGDRti9erVCA8Px4QJE7Bz505YWVlh0KBB+YYwF0ZDQwP6+voyn/Iw1PlTzOzshFYuZvhy402ExssOfX67fowkzzCOHCF3PnxxiEUiqKuW1Rwmva9fLUvUqqSHxf4vEVPIukDvE4lEEAFQLcKOYenZEiRn5sBMVx1VjDRxN4xrKSgrQSJBZmZmgefU1NTh4loD165elpZJJBJcu3IFHjVrlVIPSd7EIhE01FXx+8YTqN/XBw37L5B+AOC7P/ZgzM8FLzCtpqoCdTXV/N83ORKIi/uFQ5+sosZQ37awR7Nqxpi05yEi8kyR1lDNTRTk/ZsoRxCKvQaESCSCugpjoZKmoa0DbX1DxEWEIjIoANVqNy60biXHGoh/EwbhvXUO4yJDoWNozGRQCbGwqgwjY1PcuXlNWpaakoynj+/D2a3mR6/X1NKCsakZkpMScev6JTRq1qIEe6vczl57irq958t8X998+BI7jtxAw/4LPjkZVJC3MQJVDGXiN62lpYWhQ4fCzs4OP//8M3bs2IFly5ZBQ0Pj4xdXED984YSO7pb4dvtdpGTmwEQ3N2BLTs9GRrYEQdGpeBmTip+6uuCP4wGIT81CKxczNK5qjHHb7kjbWTu8Dk4/eoMd/00tmtDGARcDYhCekA4ddRV09LBEPTsjjN3CRd/Kuv61LFHfxgCrLocgIysH+hq5gXBalgRZEgGmOmqoa62Px5EpSMrIhpGWGto7mSIzR4KHEcnSdn5u54D9D95IEz51KushKSMHcWlZqKSvgb41LXE3LAmP33BdqfIgNTUFIa9eSY9DQ1/j6ZPH0DcwgKGBIdatXYXmLVrB1MwM8XFx2LnDF2/eRKJtu3cLE3715XC0bNUG/QcOBgAMGjocP/8wA6413FDD3QO+WzYjLS0NXbv3LPXno+KbO74rjl98iJDwOOjpaKJfx3rwqueILt+sQGRMUoELSYeEx+Fl2LtRYXf2/oiflh7EwbP3kJSSjvM3AvDrxO5IS8/Cq/BYeNathkFfNMD0P/eW5qMRKlYMNbFlVbRxNsUPB58gLTMHxtq5SYDkjBxk5kjwKi4Nr+PSMKV1Vaz0f4nE9Cw0czBBPVtDzDzwWNrOHz1dcSEwFvvu5q6RMbqpLa4Gx+NNUga01FTQxtkUtaz1MW3fI4U8pzLITE9DfGSY9DgxKgJvXgZCU1cP+ibmeHrtPLT1DKBnYo7o10E4u20lqtVtAjv3etJrjq5eBF0jE3j2HQUAqNnqC9w5dRBntq1E7bbdEB8RiquHtqN22+6l/XhKJS01FeGh7+KGyPBQvAh4Al19A5hbWKFbn0H45++1qGxtCwuryti6fjmMTczQuFlL6TXfTxyDxp6t0KVXfwDAzWuXAEFAZRs7hIe+woaVf8Ha1h5tOnUr9edTFsmpGXgUGC5TlpKWidiEFGm5hYkeLEz04WCbO7LLzbESklLSERIRh7jE3LXWjqwaj4Nn72LVP+cBfDhGoFzK/qpL4Qmh0NBQbN68GRs3bkRKSgoGDx6MlStXFrrAaUXVr0HuImwbR9aTKf9x70McvBOObIkA7y23MbGtI5YOqgltdVW8ik3Fj/se4kLAu6De2kgLRjrv3v4Z66hjXs8aMNPTQHJ6Np5FJmHsltu4EvjxtQdIsZo7GAMAJje3kynffCMUV14mICtHQDVTbbSqZgJtdRUkpmfjeXQqfj8XjKSMdzuRWeppSEeYAYCBphp6eVhCX1MVCWlZuPoqAUceR5XKM9Hne/TwAcaMHCY9/vO33BEfXbp2x/c/zUFwUBAOH5yA+Lg4GBgaokYNd6zfvA0O1Ryl17wOeYX4+He7E7bv0AlxsbFYuXwpYqKj4OTsgmWr1sLElFPGygMzY12s/2UoLE31kZCcjgcBoejyzQqcuVr0acFO9pbQ1323nsrQGRswd3w3bPp1GIz0tfEqPBazlx/G2l3KO2W7LKpoMVT3mrlrWizp4yZTvuBEAI49ikKORMD0A48xpmkV/NrVGVrqKgiNT4fP8ee4+t4umZUNNWGg9W5EiaGWGr5vXw3G2upIyczBi+gUTNv3CDdfccfVTxUZ9Aw7F0yTHp/bvhoAUKNZW3QYPQ0p8TE4t30VUhPioWNojBpN26BRt0EybSTGvoHovVGH+ibm6DXtV5zzXYW/f/wKuoamqNOuB+p37ls6D6WkAp4+xPffjpYer1v2BwCgdYcumPT9L+g1cDjS09Ow9PdfkJKcBFf32pj7+wqov5d0jggLQWLCu7ghNTkJm9csRXRUJPT0DNCkeWsMHT0OqhzJVaK+7O2JH8d2kh6f2jAJADD6py3YeugqAKCqjSlMDHWldeQRIyi7srpdvLyIhMK2pyhhO3fuxMaNG+Hn54f27dtjxIgR6Ny5M1RUPn/bSI+fTsmhh6RsmtaspOguUBnzexcXRXeByiDThuMV3QUqg9JuL1N0F6RKMoZqsfiSHHpIpWFgI67HUh60tDdXdBeoiDw6TPt4JSoTSvM7eevN/Jv2fKrBda3l1pa8KGyEUP/+/WFra4tJkybBwsICwcHBWL58eb56EyZMUEDviIiIiMomxlBERESlQ7nHBykwIWRrawuRSARfX99C64hEIgYzRERERO9hDEVERFQ6lHzGmOISQsHBwYq6NREREVG5xRiKiIiI5EFh+2meOXMGrq6uSExMzHcuISEBNWrUgL+/vwJ6RkRERFR2MYYiIiIqHSKRSG6fskhhCaHFixdj9OjR0NfXz3fOwMAAX331Ff78808F9IyIiOj/7d15XJTl/v/x97ANu2zKJiruu6m5l0ChgmvlUeuoYXo8v8yOR81MSzO18lSnsuMx65SEtmidFr9mHctK3JfUcN/ABVRcEQUERJjfH+bUsCgmMMC8nj7m8eC+7+u+5rqdYebD574WoPIihgIAoGLYleGjMrJau3bu3KmoqKgSj/fs2VPbt2+vwBYBAABUfsRQAACgLFhtDqEzZ87I0dGxxOMODg46d+5cBbYIAACg8iOGAgCgYlTWoV5lxWo9hIKDg7Vnz54Sj+/atUuBgYEV2CIAAIDKjxgKAICKYSjDR2VktYRQ7969NX36dOXk5BQ5lp2drRkzZqhv375WaBkAAEDlRQwFAADKgtWGjE2bNk1ffvmlGjdurCeffFJNmjSRJB04cEDz589Xfn6+nnvuOWs1DwAAoFIihgIAoGJU9yFjVksI+fv7a+PGjRozZoymTp0qk8kk6fp/eK9evTR//nz5+/tbq3kAAACVEjEUAAAVo7KuDlZWrJYQkqS6devq22+/1cWLF5WYmCiTyaRGjRrJ29vbms0CAACo1IihAADAnbJqQugGb29vdejQwdrNAAAAqFKIoQAAKD8MGQMAAAAAALAx1TsdVP2HxAEAAAAAAKAQeggBAAAAAAAUUs1HjJEQAgAAAAAAKMyumg8aY8gYAAAAAACAjaGHEAAAAAAAQCEMGQMAAAAAALAxBoaMAQAAAAAAoDqhhxAAAAAAAEAhDBkDAAAAAACwMawyBgAAAAAAgGqFHkIAAAAAAACFMGQMAAAAAADAxlT3hBBDxgAAAAAAAGwMPYQAAAAAAAAKMVTzSaVJCAEAAAAAABRiV73zQQwZAwAAAAAAsDX0EAIAAAAAACiEIWMAAAAAAAA2hlXGAAAAAAAAUK3QQwgAAAAAAKCQ6j5kjB5CAAAAAAAAhdgZyu5xO9auXat+/fopKChIBoNBy5Ytszg+YsQIGQwGi0dUVNTtX99tnwEAAAAAAIBykZWVpTZt2mj+/PkllomKilJqaqr5sWTJktt+HoaMAQAAAAAAFFKWQ8Zyc3OVm5trsc9oNMpoNBYpGx0drejo6JvWZzQaFRAQcEdtoocQAAAAAABAIQZD2T3mzJmjGjVqWDzmzJnzh9sWHx+vWrVqqUmTJhozZowuXLhw23XQQwgAAAAAAKAcTZ06VRMnTrTYV1zvoNKIiorSQw89pNDQUCUlJenZZ59VdHS0Nm3aJHt7+1LXQ0IIAAAAAACgkLJcY6yk4WF/xMMPP2z+uVWrVmrdurUaNGig+Ph43X///aWuhyFjAAAAAAAAhdgZDGX2KE/169eXn5+fEhMTb+s8EkIAAAAAAABV1IkTJ3ThwgUFBgbe1nkMGYPNcLQn/wlLp9NzrN0EVEbBTa3dAsBqzp7NtHYTUEo7U69YuwkohejGxJ9VhVOzTtZuAiqh8u3XU7LMzEyL3j5Hjx5VQkKCfHx85OPjo5kzZ2rgwIEKCAhQUlKSJk+erIYNG6pXr1639TwkhAAAAAAAAAqzUkZo27ZtioiIMG/fmIw6JiZGCxYs0K5du7Ro0SKlp6crKChIPXv21OzZs297jiISQgAAAAAAAJVEeHi4TCZTice/++67MnkeEkIAAAAAAACFGKw2aKxikBACAAAAAAAopJwXB7M6ZjkDAAAAAACwMfQQAgAAAAAAKKSadxAiIQQAAAAAAFBENc8IMWQMAAAAAADAxtBDCAAAAAAAoBBWGQMAAAAAALAxrDIGAAAAAACAaoUeQgAAAAAAAIVU8w5CJIQAAAAAAACKqOYZIYaMAQAAAAAA2Bh6CAEAAAAAABTCKmMAAAAAAAA2hlXGAAAAAAAAUK3QQwgAAAAAAKCQat5BiIQQAAAAAABAEdU8I8SQMQAAAAAAABtDDyEAAAAAAIBCWGUMAAAAAADAxrDKGAAAAAAAAKoVeggBAAAAAAAUUs07CJEQAgAAAAAAKKKaZ4QYMgYAAAAAAGBj6CEEAAAAAABQCKuMAQAAAAAA2BhWGQMAAAAAAEC1Qg8hAAAAAACAQqp5ByESQgAAAAAAAEVU84wQQ8YAAAAAAABsDD2EAAAAAAAACmGVsXIUFham+++/X+Hh4erSpYscHR2t2RwAAIBKj/gJAICKwSpj5Sg0NFQffPCBwsPD5eXlpcjISL300kvatGmT8vPzrdk0AACASon4CQAAlAWrJoTi4uJ09OhRHTlyRPPmzVNwcLD+85//qFu3bvL29lZ0dLRee+01azYRAACgUiF+AgCgYhjK8FEZVYpJpevVq6eRI0dq0aJFOn78uBITEzVu3Dht3LhRU6ZMsXbzAAAAKh3iJwAAylk1zwhVmkmljx8/rvj4ePPj7Nmz6ty5s8LCwqzdNAAAgEqJ+AkAAPxRVk0ILV682BzAnD9/Xl27dlVYWJhGjx6tDh06MEkiAABAIcRPAABUDFYZK0cjRoxQnTp1NGXKFI0aNYoABgAA4BaInwAAqBisMlaO3n77bXXu3FkzZ85UrVq11K9fP73++uvatm2bTCaTNZsGAABQKRE/AQCAsmDVhNDjjz+upUuXKjU1VRs2bFDv3r21detW9enTR97e3urTp4/++c9/WrOJAAAAlQrxEwAAFaOazyldeSaVbt68uZo3b64xY8bo1KlTevvttzVv3jytXLlSkyZNsnbzrG7UvfV0f/OaCvVzU25egRJS0jX3+0Qdu3DFXMbX3UkTezZSlwY+cjM66Nj5LL239ph+2He2xHoHdwjW4A61FeTlIklKOpepd+OPav3hC+V+TbgzPRr5qHWQh/zdnZRXYNLRtGwt33tOZzOvmssMaeOvJrXc5OnsoKvXCnQ0LVv/V6hMcfzdndS/RU019HOVncGg0xm5it16Uhezr5X3ZeEO7U7Yri+WLFLiwf1Ku3BO0156Q12732c+/sZL0/XDyq8tzmnfsatmv/52iXWOGBSts6dTi+zv8+BgjZ34bNk1HuVidHRLje7dUnX9PSVJ+5PT9PKSrfp+e7K83Y2aPrST7m8bopCaHjp/KVtfbz6imR9t0eUrJX9O/Gf8/Roe2cxi3/fbj2vAjK9LOAPlxZbipyGdauvhjiEK9r4esySezdSCn45o3aHzkqRBHYLVp02gmgd5yt3ZQZ1m/aSMnNJ/b/2lez1NjGqsxRuO6x/fHCyXa7AVPRv76q7fxShHLmRr2d6zFvHHI3cFqElNN9VwcVDurzHKsj1ndeZWMYqHkx5oUUuNfhejvLflBDFKGbqSlaW4//xb69f+pPS0NDVs3FRPTHhGTZu3vOW5e3b+ooljRyq0fkO9u/i/FdBa2zAqsrFGRjZWHT83SdKBk5f0ype79MPOU5KkFdN66N7mARbnxP5wSBNit9y03sZBnpr5SDt1a+YvBzs7HTyZruFz1+jE7/7GtHmVNZNTRipFQujs2bNavXq1eYLEQ4cOydHRUZ07d1ZERIS1m1cp3F3PS0u3nNDek5dlb2fQuB4N9U5MWz04b5Oy8wokSS891EIezg4a98lOXbySp96tA/Ta4FZ65J2tOnA6o9h6z1zO1dxViUq+cEUGg0H97wrUW4+00eAFW5R0LqsiLxG3qaGfq9YdTVfyxWzZGQzq17ymnugaopd/PKKr+deHDKSk52jbicu6mH1Nro52im7qpye6hmjm90kqaVCBn6ujxnevq03H0/W/A+eVk1egAE+j8vIZhlAV5ORkK7RhY/Xs84BefG5isWXad+qmCVNnmrcdnZxuWudb//lY+QUF5u3jRxP13ITHdW9Ej7JpNMrVyQuZmr5okxJPpcsgg4bd31T/ndZHnf/+qQwGKdDHTVNjN2h/cprq1PLQvLERCvR105/nrLxpvd9tO67/N/dH83ZuXn55XwoKsbX46cylXL353WEd//UPlQfaBenfw+7SwH9vUuLZLDk72mv9ofNaf+i8JkY1vq26WwZ7anDHEB1ILT5ewu1p5OeqtUcu6vivMUr/FrX0t251NPuHJHOMkpyeo59TLikt+5rcHO3Vu5mfnuxWR89/l1hyjOLmqInd62rTsUv6Zv855VwrUKAHMUpZe33OCzp2JFFTnn9Jvn619MN3KzR53F8V+8lX8qvlX+J5mRmX9crs59T27k5KT+Pmclk6mXZFLyzdoaTTGTJI+nP3BlryVLjunfqNDpy8JEmK++mwXvpvgvmc7Ks3/14OreWu72ZE6cP4RM35fKcysvPUtLaXcvIKbnoeqherJoSeeOIJxcfH6+DBg3JwcFDHjh31pz/9SREREerataucnZ2t2bxKZcyHCRbb07/cqzVTwtQ8yFPbj6dLku4KqaEXVxzQnpOXJUnvrTmq4V1C1DzIo8SE0JqD5y225/2YpMEdaqt1SA0SQpXcgk0nLLY/3pGql3s3UoiXs5IuZEuSNh6/ZD6eJumb/ec15b5Q+bo66vyVvGLr7dO8pvadydTyvefM+0oqi8qnQ+d71KHzPTct4+joKB9fv1LXWcPbx2L7vx/HKjA4RK3uuvsPtREV69utxyy2X/hws0b3bqmOTfy1aNV+PTLnf+ZjR09f1guLNyl2Uk/Z2xmUX1DyH1lX8/J1Jp07iNZgq/FT/IFzFttvrUrUw51C1DrES4lns/ThxmRJUodQ79uq19XJXq8OaaUZX+3V/4uoX2bttWXzN6ZYbH+4/ZRe6dNYdbyclfhrjLLhWLr5eJry9PW+c3ru/vrydXPU+azi445+zWtq3+ksLdv7W+/3ksrij8nNydG6+B8065W31Lrt9e/5mL88oc3r12j5V59p5P/7W4nnzn31Rd3Xo7fs7O20ce3qimqyTVi5wzLun/1ZgkZFNlaHRjXNCaErudd09lJOqeucPqStvk84qeeX7DDvO3o2s2waXI2wylg5+uWXX/TAAw8oIiJC3bp1k6urqzWbU6W4O19/6S5l//YlmJBySb1a+mvtofPKyLmmXi38ZXSw18/HLpaqTjuD1LOFv1yc7LUz5dKtT0Cl4ux4fUqwKyXcDXCyN6hTnRo6n3VVF7OLD54Mklr4u+nHxDSN6VJbtb2cdSErT6sOX9DuVL4gqovdCdv0SL8IuXt4qk27jnp09Fh51vAq1bl5eXla/f23enDwMBmq+7IL1ZCdnUED72koN2dHbTlwutgynm5GXb5y9abJIEm6t1Wwjn80UumZuYrfdUIzP9yitIzSB6L444ifrscsvVoF/BqzpN9RXdP6N9OaA+e1KSmNhFA5cfk1Rsm6WnzPAyd7g7rU/TVGKeEmlEFSS393rTqcprFdQxTya4zy3aHz2kWMUmby8/NVkJ8vp0K9h52Mztqz85cSz1u5YplST57Q1Bkv66O4/5R3M22ancGgBzvXlavRQVsP/5YoH9wtVEPuCdWZ9Byt3HFCr361q8ReQgaD1POuYL21Yq++nHK/Wtf10fFzmXpj+R59sy2l2HNslbXC3bVr1+q1117T9u3blZqaqq+++koPPPCA+bjJZNKMGTP03nvvKT09Xd26ddOCBQvUqFGj23oeqyaENm3adMd15ObmKjc312JfwbWrsnO4+RCIqsxgkCZHN9aO4+lKPPtbL56nP9utVwe30vqp4crLL1BOXoHGL9mplLTsm9bXqJabPhzdQU4OdrpyNV/jl+zUEXoHVSkGSQ+18lfShStKzbAce39PqJcGtKglo4OdzmTk6u0NKSqpZ7W70V7OjvaKbOSrb/af0/J959SslptGdQzWv9cnm+/qoepq36mbuobdL//AYKWeTNGi//xbzz89Vq8vWCx7e/tbnr9p3U/KzMxQZO/+FdBalJUWdX0V/8+BcnZyUGZ2noa89K0OpBS9WeDr6aypD9+t2JV7b1rfqh3J+r+NSTp2JkP1Az0189Eu+r+Z/RQ26XMV3CKRhDtXFvGTVDVjqEb+7lryeEdzzDLuowQlnf3jMUt06wA1D/LQ4LdvPs8G/jiDpIGtb8Qolu+3e0O99WDL6zHK6YxczduQXGKM4vFrjNKzsa++3ndO/7f3rJr5u2t0p9p6a12yEpnzpEy4urmpecs2+uiD/6hOvfry9vHV6lX/0/49OxVUO6TYc06kHNf7b8/V3HfiZO9QKWYkqZaah3hp1cwoOTvaKzPnmoa+Ga+Dv/YO+nzjMaWcz1TqxWy1qOOtmQ+3VaNATw2bu6bYump6OsvDxVET+rXUi/9N0IwlOxTZOkgfjQ9T3xe/14YDJc9Bi4qRlZWlNm3aaOTIkXrooYeKHH/11Vf1r3/9S4sWLVJoaKimT5+uXr16ad++fbfVU9iqv7Fr164tVbnu3buXeGzOnDmaOXOmxb5a3YfLP+zRO2pbZfZcn6ZqWMtdIxZus9g/9r4G8nR20Oi47bqYlaf7mtXUa4Nb6bGF23T4JsHS0QtXNGjBFrkbHdSjRS29+FALjYzdTlKoChnUxl+Bnka9tfZ4kWPbUi7r4NkseTo76L6GPnqsY7DeXHtc14r5o+1Gj4/dqRmKT7r+x+LJS7kK9XFRt1BvEkLVQFhklPnn0AaNFNqwsUYN6avdv2zTXXd3uuX5369Yprs7dZOvX63ybCbK2KGTF9Vp3Keq4eqkB+9pqPcmRKrnlC8tkkIeLo76akZf7U++qBc/2XrT+v679rD5573HL2j30Qvav/BRdW8VrPidJ25yJspCWcRPUvExlN89w1Tz3uF/uG3l7dj5LD00b5PcnR3Uq6W/Xh7UUjHv/fyHkkIBNYya2reJ/hK7XVevMWdGeRnSJkBBHka9UUyM8nPKJR04m6kazg66v5GvRnUI1uu3iFF2pWZodVKaJOnEpVzV93HRvaFeJITK0JQZL+ufLz2vh/tHys7eXo0aN1NEj2gdPrCvSNn8/Hy9PGOKYv7yhGrXqVfxjbUhh09d1r1Tv5Gnq6MGdKyrdx7vpt6zv9fBk5cU99Nv38v7UtJ15mK2vp7WQ6G13IsdBmb36+/Tt9tT9Pb/9kuSdh+/qI6Na2pkZGMSQr9Tlh2EirsRYzQaZTQai5SNjo5WdHR0sfWYTCbNnTtX06ZN04ABAyRJixcvlr+/v5YtW6aHH3641G2yakIoPDzc/OFuMhV/O8BgMCg/v+QJsaZOnaqJEy0nTu36j/Vl18hKZmqfJurexE+PLdymM5d/ezPV9nbRnzuH6MF5m8xz/xw6k6l2db00pFOIXvz6QIl1Xss3mXsR7U/NUMtgTw3tHKLZNzkHlcefWvurhb+73lqfrPRiVlPJuVagnGsFOpeVp2NpJ/WPPo3VOtBdO04WnVcqK/ea8gtMOl2ol9GZjKuq7+tSbtcA6wkMqi3PGt46dTLllgmhM6dPKWH7Fj334usV1DqUlbxrBTqSev0u4i9J59S+US2N7d9Gf5sfL0lyd3HU8ln9lfFr76Fr+bf3x/GxM5d17lK2GgTWICFUAcoifpKKj6E6vli6ZJO15OWblPxrzLLvVIZa1q6h4V3r6IVl+2+7rhZBnvJzN+rzsZ3N+xzs7XR3PW/9uXOI7nr+B9Hh7c4Mbu2vlgHuenPd8VvGKEfTTui1vk3UJshD209cLlI20xyjWP4xdTojVw18bW/YZHkKqh2iNxZ8oOzsK7qSlSVfv5qaPe1pBQTXLlI2+0qWDu3fq8RDBzTvjTmSJFNBgUwmk3re01avzH1HbUtxwwm3lpdfoCNnrsfvCUfT1K6Br8ZENdX4hUV7OG5Luj5PbP0Aj2ITQhcycpV3rcA8/9ANh05eUucm3PSzUIYZoeJuxMyYMUMvvPDCbdVz9OhRnT59WpGRkeZ9NWrUUKdOnbRp06aqkxDy9vaWh4eHRowYoeHDh8vPr/STnN5QXEatMnd1vhNT+zTRfc1qalTsdp1Mt5yn4cbY7IJCgWG+6fo4+9thZzDIycHujtqKivGn1v5qHeiueeuTlVaKiZ8NhuvTojnYF//65puk5IvZ8vew/B2q6e5UqvpR9Zw/e0YZl9NLNcn0qm//TzW8fNSxy70V0DKUJzuDQUbH60MEPVwc9fXsAcrNy9efZn/zh1YLC/Z1k6+Hs06n0bO0IpRF/CRVjxjKYDDIsYTvtFvZlJSm/m9ttNj30sAWOnouS++vPUYy6A4Nbu2vNkEemrvuuC7cRoziWELgmm+Sjl/Mlr+75Xu2lruRGKWcuLi4ysXFVRmXL2vblo0aPXZCkTKubu5676MvLPYt//JTJWzbqudffl0BQcEV1Vybc/1vtuKH+7eqe31y/dMXi+/dn5dfoB1HzqtRoKfF/gaBnko5z3d5eSnuRkxxvYNu5fTp6/NA+vtbrvrn7+9vPlZaVv2rPzU1Va+88oo2bdqkVq1aadSoUdq4caM8PT1Vo0YN8wPSc32bqE/rAE35fI+yrubL191Jvu5OMv6auDl6/oqOX7ii5/s3U8tgT9X2dtGjXeuoS30f/bT/t8nG3hvRTg93/C27Py6ygdrX9VKQl7Ma1XLTuMgGuruet77ZdXtvJFS8Qa39dXeIpxZvO6WcawXyMNrLw2hvDqR8XR3Vo5GPQmoY5e3ioFAfFz3WIUh5BSbtO/3bnYLn7g9V60B38/aPiWlqG+ypLnVryM/NUfeGeqllgLvWH02v6EvEH5B95YqSDh9Q0uHrPfzOpJ5U0uEDOnsmVdlXrmjh/Dd0YO8unUk9qYRtWzRr6ngFBoeofceu5jqm/v2v+vqLpRb1FhQUaNW3yxUZ3Y/5AaqYWTFd1K1FkOrU8lCLur6aFdNF3VsFa2n8IXm4OGrF7AFyNTro8bd+lKeLk/y9XOXv5Sq73/1RlrBgqPp3uT7Zrpuzo15+rKs6NvFXnVoeCm9TW59N76Ok1EtatSPZWpdpU2w1fprQs6Ha1/O+HrP4u2tCz4bqGOqtFTtTJUl+7k5qGuihOr/2Fmkc4K6mgR6q4fLbZ1bsqPb6c+fr86BcuZqvxDOZFo/sq/lKv5KnxDNMUnwnhrQJUIeQGvrg51PKvVYgT6O9PAvFKD0b+yrEy9kco4zqGKyrBQXa87sYZXpkfbUJ9DBv/3A4Te1qe6prPS/VdHNUWH1vtQpw17qjpVtABaXz8+YN2rppvVJPndD2rZs06clRCqlbT1F9rw9Nef/tt/SPmc9Kkuzs7K4PQf/dw8vbR05Go0IbNJKLC723ysKMIW3VtWkt1fFzU/MQL80Y0lb3NPPXfzccVWgtdz39YCvdFeqjOn5uim5XW++O6ab1+89o7+8m3f/5n/3V9+7f5oH614p9eqhLXcVENFR9fw+N7tlE0e1q6/0fDlrhCisvQxn+MxqN8vT0tHj8kYRQWbJqVO/k5KQhQ4ZoyJAhSk5OVlxcnJ588knl5uYqJiZGM2fOlAN/eEiShnS8/sv7wUjLZZ6nfblXyxNSda3ApLEf/qLxPRpp3tA2cnVyUHLaFU37aq/WH75gLl/b20Xebr/d/fNxc9KLD7VQTQ+jMnOu6dCZDD3+4S/a/OvYbFRe99a/nvkfd29di/0f7UjV1uRLyiswqb6vq8Ia+MjVyV4ZOdeUdOGK3lx7XJm/W3HA38MoZ8ff7i7sSs3UZwmnFdnYVwNb++ts5lXFbj2pI7eYnByVw+GDezVl3Gjz9nv/vj68KzKqn8ZOek5Hkw7rh5VfKyszQz5+NdWuQxcN/8tYOf5uNZHUUym6dMkyuE7YtlnnzqSqR+8HKuQ6UHZq1nDRwomRCvBx06WsXO05dkH9nl+unxJSdG+rYHVsGiBJ2ve+5dx7TUYuUvLZ613Tm4R4y9P1+nskv6BALUP9NPT+pvJyMyo1LUs//JKiWR9tZh6WCmKr8ZOPu5P+MailanoYlZFzTYdOZ2h03HZtSrweswzpFKKx9zcwl//wrx0lSc9+vkfLdpySJIX4uFrEQSgf3X+NUSZ0t4xRPtx+SpuTL+lagUkNfV0V8bsYJfHCFb2+xjJGCfAwmnvBS9LO1AwtTUhVz8Z+GtTaX2czrur9rSeUxByHZSorM1ML33lL58+ekYdnDd0bHqnHHv+bHBwcJUlpF87p7BluHlekmp7OemdMNwV4uejylTztTbmoh/7xo1bvSVWwj6vCWwbqiahmcjU66GRalpZvTdZry3Zb1NE4qIY8XR3N2yu2pWjCwi2aOKClXonpoMOnLmv43DXafPBc4ae3aZVxUd2AgOux25kzZxQYGGjef+bMGd111123VZfBVNLgcys5evSoRo0apTVr1ujcuXPy8fG57TpaP/9DObQMVV14u6LjnmHb/t617q0Lwea0HLnQ2k1AJZS94klrN+GmyiJ+kqTmz35fxi1DeYnoUPyKT6hcpoTVt3YTUEotn/zM2k1AKV36pOIWP0hOy711oVKq4/PHegMZDAaLZedNJpOCgoI0adIkPfXUU5Kky5cvq1atWoqLi7utOYQqxUQxubm5+uSTTxQZGamWLVvKz89P33zzzR8OZgAAAKo74icAAMqXoQwftyMzM1MJCQlKSEiQdP3GT0JCgpKTk2UwGDR+/Hi9+OKLWr58uXbv3q1HH31UQUFB5qRRaVm1P/HWrVv1wQcfaOnSpapXr54ee+wxffbZZwQyAAAAJSB+AgCgYlhryNi2bdsUERFh3r4xGXVMTIzi4uI0efJkZWVl6a9//avS09N1zz33aOXKlXJ2dr6t57FqQqhz586qU6eOxo0bp/bt20uS1q8vumR8//79K7ppAAAAlRLxEwAA1Vt4eLhuNruPwWDQrFmzNGvWrDt6HqvPOJicnKzZs2eXeNxgMCg///aXwAUAAKiuiJ8AAKgIlXBW6TJk1YRQQcGtVyO5cuVKBbQEAACgaiB+AgCgYlTGVcbKUqWYVLo4ubm5euONN1S/PjPzAwAAlAbxEwAAKC2rJoRyc3M1depU3X333eratauWLVsmSYqNjVVoaKjefPNNTZgwwZpNBAAAqFSInwAAqBjWWmWsolh1yNjzzz+vd999V5GRkdq4caMGDRqkxx57TJs3b9Ybb7yhQYMGyd7e3ppNBAAAqFSInwAAqBjVfciYVRNC//3vf7V48WL1799fe/bsUevWrXXt2jXt3LlThur+Pw8AAPAHED8BAICyYNWE0IkTJ8zLpbZs2VJGo1ETJkwgmAEAACgB8RMAABXDUGkHe5UNqyaE8vPz5eTkZN52cHCQu7u7FVsEAABQuRE/AQBQQap3Psi6CSGTyaQRI0bIaDRKknJycvT444/Lzc3NotyXX35pjeYBAABUOsRPAACgLFg1IRQTE2OxPWzYMCu1BAAAoGogfgIAoGJU8w5C1k0IffDBB9Z8egAAgCqH+AkAgIpR3afns7N2AwAAAAAAAFCxrNpDCAAAAAAAoDJilTEAAAAAAABbU73zQQwZAwAAAAAAsDX0EAIAAAAAACikmncQIiEEAAAAAABQGKuMAQAAAAAAoFqhhxAAAAAAAEAhrDIGAAAAAABgYxgyBgAAAAAAgGqFhBAAAAAAAICNYcgYAAAAAABAIQwZAwAAAAAAQLVCDyEAAAAAAIBCWGUMAAAAAADAxjBkDAAAAAAAANUKPYQAAAAAAAAKqeYdhEgIAQAAAAAAFFHNM0IMGQMAAAAAALAx9BACAAAAAAAohFXGAAAAAAAAbAyrjAEAAAAAAKBaoYcQAAAAAABAIdW8gxAJIQAAAAAAgCKqeUaIIWMAAAAAAAA2hh5CAAAAAAAAhbDKGAAAAAAAgI1hlTEAAAAAAABUKwaTyWSydiNQPnJzczVnzhxNnTpVRqPR2s1BJcH7AoXxnkBxeF+gOuB9XHXwWlUdvFZVB68VboWEUDV2+fJl1ahRQ5cuXZKnp6e1m4NKgvcFCuM9geLwvkB1wPu46uC1qjp4raoOXivcCkPGAAAAAAAAbAwJIQAAAAAAABtDQggAAAAAAMDGkBCqxoxGo2bMmMEEYrDA+wKF8Z5AcXhfoDrgfVx18FpVHbxWVQevFW6FSaUBAAAAAABsDD2EAAAAAAAAbAwJIQAAAAAAABtDQggAAAAAAMDGkBACAAAAAACwMSSEqpBz585pzJgxqlOnjoxGowICAtSrVy9t2LBBklSvXj0ZDAYtXbq0yLktWrSQwWBQXFyced+N8gaDQfb29goKCtKoUaN08eLFirok3KERI0bogQceKLI/Pj5eBoNB6enp5p+9vb2Vk5NjUe7nn382vweKOxdV0+nTp/W3v/1N9evXl9FoVEhIiPr166cff/xR0u1/VtwwZ84c2dvb67XXXivvS0AZGDFihPn329HRUaGhoZo8ebLF58CN45s3b7Y4Nzc3V76+vjIYDIqPj5ckde7cWY8//rhFuXfeeafY98uIESN07733lst1wbYRC1UNxCdVC3FD5cV3OcobCaEqZODAgfrll1+0aNEiHTp0SMuXL1d4eLguXLhgLhMSEqIPPvjA4rzNmzfr9OnTcnNzK1LnrFmzlJqaquTkZH388cdau3atxo0bV+7Xgorn4eGhr776ymLfwoULVadOHSu1COXh2LFjat++vX766Se99tpr2r17t1auXKmIiAiNHTvWXO52PyskKTY2VpMnT1ZsbGy5XgPKTlRUlFJTU3XkyBG9+eabevfddzVjxgyLMsW9F7766iu5u7tb7IuIiDAHlDesXr1aISEhRfbHx8frvvvuK7PrAG4gFqp+iE+si7ih8uO7HOWJhFAVkZ6ernXr1umVV15RRESE6tatq44dO2rq1Knq37+/udzQoUO1Zs0apaSkmPfFxsZq6NChcnBwKFKvh4eHAgICFBwcrIiICMXExGjHjh0Vck2oWDExMRZfyNnZ2Vq6dKliYmKs2CqUtSeeeEIGg0Fbt27VwIED1bhxY7Vo0UITJ060uHN0u58Va9asUXZ2tmbNmqXLly9r48aNFXI9uDM3elCEhITogQceUGRkpFatWmVRJiYmRkuXLlV2drZ5X2xsbJHPhoiICB08eFCnT58271uzZo2mTJliEUQePXpUx48fV0RERPlcFGwWsVD1RHxiXcQNlR/f5ShPJISqCHd3d7m7u2vZsmXKzc0tsZy/v7969eqlRYsWSZKuXLmiTz/9VCNHjrzlc5w8eVJff/21OnXqVGbtRuUxfPhwrVu3TsnJyZKkL774QvXq1VO7du2s3DKUlbS0NK1cuVJjx44t9m6dl5eX+efb/axYuHChHnnkETk6OuqRRx7RwoULy+UaUH727NmjjRs3ysnJyWJ/+/btVa9ePX3xxReSpOTkZK1du1bDhw+3KNetWzc5Ojpq9erVkqR9+/YpOztbo0aN0oULF3T06FFJ1+80Ojs7q0uXLhVwVbAlxELVE/GJ9RA3VD18l6OskRCqIhwcHBQXF6dFixbJy8tL3bp107PPPqtdu3YVKTty5EjFxcXJZDLp888/V4MGDXTXXXcVW+8zzzwjd3d3ubi4qHbt2jIYDHrjjTfK+WpQllasWGEOkm88oqOji5SrVauWoqOjzeODY2NjSxUco+pITEyUyWRS06ZNS1W+tJ8Vly9f1ueff65hw4ZJkoYNG6bPPvtMmZmZZdl8lIMbnw/Ozs5q1aqVzp49q6effrpIuZEjR5rv0MfFxal3796qWbOmRRk3Nzd17NjRfAcxPj5e99xzj4xGo7p27Wqxv0uXLjIajeV6bbA9xEJVC/FJ5UfcUDXwXY7yREKoChk4cKBOnTql5cuXKyoqSvHx8WrXrl2RCcD69OmjzMxMrV279pZfqk8//bQSEhK0a9cu88Rxffr0UX5+fnleCspQRESEEhISLB7vv/9+sWVvfJEfOXJEmzZt0tChQyu4tShPJpPptsqX9rNiyZIlatCggdq0aSNJuuuuu1S3bl19+umnd9xmlK8bnw9btmxRTEyMHnvsMQ0cOLBIuWHDhmnTpk06cuSI4uLiSnwvhIeHWwSL4eHhkqSwsDCL/XQxR3khFqo6iE8qP+KGqoHvcpQnEkJVjLOzs3r06KHp06dr48aNGjFiRJFJxRwcHDR8+HDNmDFDW7ZsuemXqp+fnxo2bKhGjRrpvvvu09y5c7Vx40ZzN0JUfm5ubmrYsKHFIzg4uNiy0dHR5m6h/fr1k6+vbwW3FuWpUaNGMhgMOnDgQKnKl/azYuHChdq7d68cHBzMj3379jFJZBVw4/OhTZs2io2N1ZYtW4rttu/r66u+fftq1KhRysnJKfYuvnQ9KD106JBOnjyp+Ph4hYWFSfotiExKSlJKSgqTUKJcEQtVDcQnlR9xQ9XAdznKEwmhKq558+bKysoqsn/kyJFas2aNBgwYIG9v71LXZ29vL0kWE5Kh+nBwcNCjjz6q+Ph4umNXQz4+PurVq5fmz59f7OdCcUv13uqzYvfu3dq2bZvi4+Mt7vLGx8dr06ZNpQ4iYX12dnZ69tlnNW3atGI/40eOHKn4+Hg9+uij5u+Cwrp27SonJye9/fbbysnJUfv27SVJHTp00Llz5xQbG2vujg5UFGKhqo/4xDqIG6oevstR1opOCY9K6cKFCxo0aJBGjhyp1q1by8PDQ9u2bdOrr76qAQMGFCnfrFkznT9/Xq6urjetNyMjQ6dPn5bJZFJKSoomT56smjVrqmvXruV1KbCy2bNn6+mnn77l3bfdu3fLw8PDvG0wGMxdf1F5zZ8/X926dVPHjh01a9YstW7dWteuXdOqVau0YMEC7d+/36L8rT4rFi5cqI4dO6p79+5FjnXo0EELFy7Ua6+9Vi7XgrI3aNAgPf3005o/f74mTZpkcSwqKkrnzp2Tp6dniee7uLioc+fOmjdvnrp162YONp2cnCz2Ozo6lut1wDYRC1VvxCfWQdxQ9fBdjrJED6Eqwt3dXZ06ddKbb76p7t27q2XLlpo+fbpGjx6tf//738We4+vrKxcXl5vW+/zzzyswMFBBQUHq27ev3Nzc9P3339NVtxpzcnKSn5+fDAbDTct1795dbdu2NT9u3D1A5Va/fn3t2LFDEREReuqpp9SyZUv16NFDP/74oxYsWFDsOSV9Vly9elUfffRRsePUpetzeSxevFh5eXlleg0oPw4ODnryySf16quvFrkbbDAY5OfnV2TlksIiIiKUkZFhnnPghrCwMGVkZDDnAMoNsVD1RnxiHcQNVQ/f5ShLBtPtziYGAAAAAACAKo0eQgAAAAAAADaGhBAAAAAAAICNISEEAAAAAABgY0gIAQAAAAAA2BgSQgAAAAAAADaGhBAAAAAAAICNISEEAAAAAABgY0gIAQAAAAAA2BgSQgCsbsSIEXrggQfM2+Hh4Ro/fnyFtyM+Pl4Gg0Hp6ellUl/h6wIAANZBrAEARZEQAlCsESNGyGAwyGAwyMnJSQ0bNtSsWbN07dq1cn/uL7/8UrNnzy5V2bIOrMrSW2+9pbi4OGs3AwCASolY484RawC4Ew7WbgCAyisqKkoffPCBcnNz9e2332rs2LFydHTU1KlTi5S9evWqnJycyuR5fXx8yqQea6tRo4a1myCpbF8bAADKErHGnSHWAHAn6CEEoERGo1EBAQGqW7euxowZo8jISC1fvlzSb12UX3rpJQUFBalJkyaSpJSUFA0ePFheXl7y8fHRgAEDdOzYMXOd+fn5mjhxory8vOTr66vJkyfLZDJZPG/hbty5ubl65plnFBISIqPRqIYNG2rhwoU6duyYIiIiJEne3t4yGAwaMWKEJKmgoEBz5sxRaGioXFxc1KZNG33++ecWz/Ptt9+qcePGcnFxUUREhEU7izNp0iT17dvXvD137lwZDAatXLnSvK9hw4Z6//33Lf6Pfn9d48aN0+TJk+Xj46OAgAC98MILFs9hMBj0/vvv68EHH5Srq6saNWpk/j+/Yc+ePYqOjpa7u7v8/f01fPhwnT9/3uJ5nnzySY0fP15+fn7q1avXTa8LAABrIdawRKwBoCKREAJQai4uLrp69ap5+8cff9TBgwe1atUqrVixQnl5eerVq5c8PDy0bt06bdiwQe7u7oqKijKf9/rrrysuLk6xsbFav3690tLS9NVXX930eR999FEtWbJE//rXv7R//369++67cnd3V0hIiL744gtJ0sGDB5Wamqq33npLkjRnzhwtXrxY77zzjvbu3asJEyZo2LBhWrNmjaTrweRDDz2kfv36KSEhQX/5y180ZcqUm7YjLCxM69evV35+viRpzZo18vPzU3x8vCTp5MmTSkpKUnh4eIl1LFq0SG5ubtqyZYteffVVzZo1S6tWrbIoM3PmTA0ePFi7du1S7969NXToUKWlpUmS0tPTdd9996lt27batm2bVq5cqTNnzmjw4MFFnsfJyUkbNmzQO++8c9PrAgCgsiDWINYAUIFMAFCMmJgY04ABA0wmk8lUUFBgWrVqlcloNJomTZpkPu7v72/Kzc01n/Phhx+amjRpYiooKDDvy83NNbm4uJi+++47k8lkMgUGBppeffVV8/G8vDxT7dq1zc9lMplMYWFhpr///e8mk8lkOnjwoEmSadWqVcW2c/Xq1SZJposXL5r35eTkmFxdXU0bN260KDtq1CjTI488YjKZTKapU6eamjdvbnH8mWeeKVLX7128eNFkZ2dn+vnnn00FBQUmHx8f05w5c0ydOnUymUwm00cffWQKDg4u9v/wxnXdc889FnV26NDB9Mwzz5i3JZmmTZtm3s7MzDRJMv3vf/8zmUwm0+zZs009e/a0qCMlJcUkyXTw4EHz87Rt27bYawAAoLIg1iiKWANARWIOIQAlWrFihdzd3ZWXl6eCggL9+c9/tuh23KpVK4vx4jt37lRiYqI8PDws6snJyVFSUpIuXbqk1NRUderUyXzMwcFBd999d5Gu3DckJCTI3t5eYWFhpW53YmKirly5oh49eljsv3r1qtq2bStJ2r9/v0U7JKlLly43rdfLy0tt2rRRfHy8nJyc5OTkpL/+9a+aMWOGMjMztWbNmlu2s3Xr1hbbgYGBOnv2bIll3Nzc5OnpaS6zc+dOrV69Wu7u7kXqTkpKUuPGjSVJ7du3v2k7AACoDIg1LBFrAKhIJIQAlCgiIkILFiyQk5OTgoKC5OBg+ZHh5uZmsZ2Zman27dvr448/LlJXzZo1/1AbXFxcbvuczMxMSdI333yj4OBgi2NGo/EPteOG8PBwxcfHy2g0KiwsTD4+PmrWrJnWr1+vNWvW6Kmnnrrp+Y6OjhbbBoNBBQUFpS6TmZmpfv366ZVXXilSd2BgoPnnwq8NAACVEbFGUcQaACoKCSEAJXJzc1PDhg1LXb5du3b69NNPVatWLXl6ehZbJjAwUFu2bFH37t0lSdeuXdP27dvVrl27Ysu3atVKBQUFWrNmjSIjI4scv3HX8MZYe0lq3ry5jEajkpOTS7yL1qxZsyITKG7evPmW1xgWFqbY2Fg5ODgoKipK0vXAbcmSJTp06NBNx/SXhXbt2umLL75QvXr1igTNAABUNcQaRRFrAKgoTCoNoMwMHTpUfn5+GjBggNatW6ejR48qPj5e48aN04kTJyRJf//73/WPf/xDy5Yt04EDB/TEE08oPT29xDrr1aunmJgYjRw5UsuWLTPX+dlnn0mS6tatK4PBoBUrVujcuXPKzMyUh4eHJk2apAkTJmjRokVKSkrSjh07NG/ePC1atEiS9Pjjj+vw4cN6+umndfDgQX3yySeKi4u75TV2795dGRkZWrFihTkgCw8P18cff6zAwEBzN+ryMnbsWKWlpemRRx7Rzz//rKSkJH333Xd67LHHLAJVAACqI2INYg0AZYeEEIAy4+rqqrVr16pOnTp66KGH1KxZM40aNUo5OTnmu3hPPfWUhg8frpiYGHXp0kUeHh568MEHb1rvggUL9Kc//UlPPPGEmjZtqtGjRysrK0uSFBwcrJkzZ2rKlCny9/fXk08+KUmaPXu2pk+frjlz5qhZs2aKiorSN998o9DQUElSnTp19MUXX2jZsmVq06aN3nnnHb388su3vEZvb2+1atVKNWvWVNOmTSVdD9wKCgpua+6BPyooKEgbNmxQfn6+evbsqVatWmn8+PHy8vKSnR0f6QCA6o1Yg1gDQNkxmEqaXQ0AAAAAAADVEileAAAAAAAAG0NCCAAAAAAAwMaQEAIAAAAAALAxJIQAAAAAAABsDAkhAAAAAAAAG0NCCAAAAAAAwMaQEAIAAAAAALAxJIQAAAAAAABsDAkhAAAAAAAAG0NCCAAAAAAAwMaQEAIAAAAAALAx/x8b5r5ToVF1+wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Per-Factor Metrics: Random Forest vs Gradient Boosting\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79535c507810>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_32ae3 th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_32ae3 th.col_heading.level0 {\n",
              "  border-bottom: 1pt solid black;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_32ae3\" class=\"dataframe\">\n",
              "  <caption>Per-Factor Metrics (Combined)</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Model</th>\n",
              "      <th id=\"T_32ae3_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">Random Forest</th>\n",
              "      <th id=\"T_32ae3_level0_col3\" class=\"col_heading level0 col3\" colspan=\"3\">Gradient Boosting</th>\n",
              "      <th id=\"T_32ae3_level0_col6\" class=\"col_heading level0 col6\" ></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level1\" >Metric</th>\n",
              "      <th id=\"T_32ae3_level1_col0\" class=\"col_heading level1 col0\" >Precision</th>\n",
              "      <th id=\"T_32ae3_level1_col1\" class=\"col_heading level1 col1\" >Recall</th>\n",
              "      <th id=\"T_32ae3_level1_col2\" class=\"col_heading level1 col2\" >F1-score</th>\n",
              "      <th id=\"T_32ae3_level1_col3\" class=\"col_heading level1 col3\" >Precision</th>\n",
              "      <th id=\"T_32ae3_level1_col4\" class=\"col_heading level1 col4\" >Recall</th>\n",
              "      <th id=\"T_32ae3_level1_col5\" class=\"col_heading level1 col5\" >F1-score</th>\n",
              "      <th id=\"T_32ae3_level1_col6\" class=\"col_heading level1 col6\" >Samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row0\" class=\"row_heading level0 row0\" >SMB</th>\n",
              "      <td id=\"T_32ae3_row0_col0\" class=\"data row0 col0\" >33.3%</td>\n",
              "      <td id=\"T_32ae3_row0_col1\" class=\"data row0 col1\" >32.1%</td>\n",
              "      <td id=\"T_32ae3_row0_col2\" class=\"data row0 col2\" >32.7%</td>\n",
              "      <td id=\"T_32ae3_row0_col3\" class=\"data row0 col3\" >34.8%</td>\n",
              "      <td id=\"T_32ae3_row0_col4\" class=\"data row0 col4\" >37.9%</td>\n",
              "      <td id=\"T_32ae3_row0_col5\" class=\"data row0 col5\" >36.3%</td>\n",
              "      <td id=\"T_32ae3_row0_col6\" class=\"data row0 col6\" >190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row1\" class=\"row_heading level0 row1\" >HML</th>\n",
              "      <td id=\"T_32ae3_row1_col0\" class=\"data row1 col0\" >29.9%</td>\n",
              "      <td id=\"T_32ae3_row1_col1\" class=\"data row1 col1\" >30.8%</td>\n",
              "      <td id=\"T_32ae3_row1_col2\" class=\"data row1 col2\" >30.3%</td>\n",
              "      <td id=\"T_32ae3_row1_col3\" class=\"data row1 col3\" >34.4%</td>\n",
              "      <td id=\"T_32ae3_row1_col4\" class=\"data row1 col4\" >34.6%</td>\n",
              "      <td id=\"T_32ae3_row1_col5\" class=\"data row1 col5\" >34.5%</td>\n",
              "      <td id=\"T_32ae3_row1_col6\" class=\"data row1 col6\" >159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row2\" class=\"row_heading level0 row2\" >CMA</th>\n",
              "      <td id=\"T_32ae3_row2_col0\" class=\"data row2 col0\" >13.8%</td>\n",
              "      <td id=\"T_32ae3_row2_col1\" class=\"data row2 col1\" >13.0%</td>\n",
              "      <td id=\"T_32ae3_row2_col2\" class=\"data row2 col2\" >13.4%</td>\n",
              "      <td id=\"T_32ae3_row2_col3\" class=\"data row2 col3\" >17.9%</td>\n",
              "      <td id=\"T_32ae3_row2_col4\" class=\"data row2 col4\" >10.9%</td>\n",
              "      <td id=\"T_32ae3_row2_col5\" class=\"data row2 col5\" >13.5%</td>\n",
              "      <td id=\"T_32ae3_row2_col6\" class=\"data row2 col6\" >92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row3\" class=\"row_heading level0 row3\" >RMW</th>\n",
              "      <td id=\"T_32ae3_row3_col0\" class=\"data row3 col0\" >31.3%</td>\n",
              "      <td id=\"T_32ae3_row3_col1\" class=\"data row3 col1\" >32.5%</td>\n",
              "      <td id=\"T_32ae3_row3_col2\" class=\"data row3 col2\" >31.9%</td>\n",
              "      <td id=\"T_32ae3_row3_col3\" class=\"data row3 col3\" >32.5%</td>\n",
              "      <td id=\"T_32ae3_row3_col4\" class=\"data row3 col4\" >35.6%</td>\n",
              "      <td id=\"T_32ae3_row3_col5\" class=\"data row3 col5\" >34.0%</td>\n",
              "      <td id=\"T_32ae3_row3_col6\" class=\"data row3 col6\" >191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row4\" class=\"row_heading level0 row4\" >macro avg</th>\n",
              "      <td id=\"T_32ae3_row4_col0\" class=\"data row4 col0\" >27.1%</td>\n",
              "      <td id=\"T_32ae3_row4_col1\" class=\"data row4 col1\" >27.1%</td>\n",
              "      <td id=\"T_32ae3_row4_col2\" class=\"data row4 col2\" >27.1%</td>\n",
              "      <td id=\"T_32ae3_row4_col3\" class=\"data row4 col3\" >29.9%</td>\n",
              "      <td id=\"T_32ae3_row4_col4\" class=\"data row4 col4\" >29.7%</td>\n",
              "      <td id=\"T_32ae3_row4_col5\" class=\"data row4 col5\" >29.6%</td>\n",
              "      <td id=\"T_32ae3_row4_col6\" class=\"data row4 col6\" >632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_32ae3_level0_row5\" class=\"row_heading level0 row5\" >weighted avg</th>\n",
              "      <td id=\"T_32ae3_row5_col0\" class=\"data row5 col0\" >29.0%</td>\n",
              "      <td id=\"T_32ae3_row5_col1\" class=\"data row5 col1\" >29.1%</td>\n",
              "      <td id=\"T_32ae3_row5_col2\" class=\"data row5 col2\" >29.1%</td>\n",
              "      <td id=\"T_32ae3_row5_col3\" class=\"data row5 col3\" >31.5%</td>\n",
              "      <td id=\"T_32ae3_row5_col4\" class=\"data row5 col4\" >32.4%</td>\n",
              "      <td id=\"T_32ae3_row5_col5\" class=\"data row5 col5\" >31.8%</td>\n",
              "      <td id=\"T_32ae3_row5_col6\" class=\"data row5 col6\" >632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Overall Performance Summary ###\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79535c337510>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_300f5\" class=\"dataframe\">\n",
              "  <caption>Overall Performance Summary</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_300f5_level0_col0\" class=\"col_heading level0 col0\" >Accuracy (%)</th>\n",
              "      <th id=\"T_300f5_level0_col1\" class=\"col_heading level0 col1\" >Precision (wtd %)</th>\n",
              "      <th id=\"T_300f5_level0_col2\" class=\"col_heading level0 col2\" >Recall  (wtd %)</th>\n",
              "      <th id=\"T_300f5_level0_col3\" class=\"col_heading level0 col3\" >F1 (wtd %)</th>\n",
              "      <th id=\"T_300f5_level0_col4\" class=\"col_heading level0 col4\" >Samples</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Model</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_300f5_level0_row0\" class=\"row_heading level0 row0\" >Random Forest</th>\n",
              "      <td id=\"T_300f5_row0_col0\" class=\"data row0 col0\" >29.1%</td>\n",
              "      <td id=\"T_300f5_row0_col1\" class=\"data row0 col1\" >29.0%</td>\n",
              "      <td id=\"T_300f5_row0_col2\" class=\"data row0 col2\" >29.1%</td>\n",
              "      <td id=\"T_300f5_row0_col3\" class=\"data row0 col3\" >29.1%</td>\n",
              "      <td id=\"T_300f5_row0_col4\" class=\"data row0 col4\" >632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_300f5_level0_row1\" class=\"row_heading level0 row1\" >Gradient Boosting</th>\n",
              "      <td id=\"T_300f5_row1_col0\" class=\"data row1 col0\" >32.4%</td>\n",
              "      <td id=\"T_300f5_row1_col1\" class=\"data row1 col1\" >31.5%</td>\n",
              "      <td id=\"T_300f5_row1_col2\" class=\"data row1 col2\" >32.4%</td>\n",
              "      <td id=\"T_300f5_row1_col3\" class=\"data row1 col3\" >31.8%</td>\n",
              "      <td id=\"T_300f5_row1_col4\" class=\"data row1 col4\" >632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "Comprehensive evaluation script\n",
        "===============================\n",
        "\n",
        "Outputs\n",
        "-------\n",
        "1.  Row-normalised **confusion-matrix heat-maps** + a printed numeric table\n",
        "    for each model\n",
        "2.  **Single combined per-factor table** with a merged header row\n",
        "    (Random Forest vs Gradient Boosting)\n",
        "3.  Headline **Overall-Performance Summary** table\n",
        "\"\"\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0. Imports and expected inputs\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "from IPython.display import display\n",
        "\n",
        "# The notebook/environment must already provide:\n",
        "#   FACTORS      : list[str]   â€“ the four factor names in display order\n",
        "#   results_dfs  : dict[str â†’ DataFrame] with columns\n",
        "#                   â€¢ â€œActual_Winnerâ€\n",
        "#                   â€¢ â€œPredicted_Winnerâ€\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "labels = FACTORS\n",
        "items  = list(results_dfs.items())              # [('Random Forest', df), ('Gradient Boosting', df)]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. Confusion-matrix heat-maps **and** printed tables\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, len(items), figsize=(6 * len(items), 5), squeeze=False)\n",
        "axes = axes[0]\n",
        "\n",
        "for idx, (model_name, df_res) in enumerate(items):\n",
        "    cm     = confusion_matrix(df_res.Actual_Winner, df_res.Predicted_Winner, labels=labels)\n",
        "    cm_pct = (cm / cm.sum(axis=1, keepdims=True)) * 100\n",
        "\n",
        "    # Heat-map\n",
        "    sns.heatmap(\n",
        "        cm_pct, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
        "        cbar=(idx == len(items) - 1),\n",
        "        xticklabels=labels, yticklabels=labels,\n",
        "        ax=axes[idx]\n",
        "    )\n",
        "    axes[idx].set_title(f\"{model_name} (row %)\\nn = {len(df_res)}\")\n",
        "    axes[idx].set_xlabel(\"Predicted winner\")\n",
        "    axes[idx].set_ylabel(\"True winner\")\n",
        "\n",
        "    # Printed numeric table\n",
        "    print(f\"\\nConfusion matrix for {model_name} (row %):\")\n",
        "    print(pd.DataFrame(cm_pct, index=labels, columns=labels)\n",
        "            .to_string(float_format=lambda x: f\"{x:.1f}\"))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. Combined per-factor metrics table (RF vs GB)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "per_factor_tables = {}\n",
        "\n",
        "for model_name, df_res in items:\n",
        "    y_true, y_pred = df_res.Actual_Winner, df_res.Predicted_Winner\n",
        "\n",
        "    rep = classification_report(\n",
        "        y_true, y_pred,\n",
        "        labels=labels, target_names=labels,\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "\n",
        "    df_cr = (pd.DataFrame(rep).T\n",
        "               .drop('accuracy', errors='ignore')\n",
        "               .rename(columns={'support': 'Samples'}))\n",
        "\n",
        "    for col in ['precision', 'recall', 'f1-score']:\n",
        "        df_cr[col] = (df_cr[col] * 100).round(1)\n",
        "    df_cr['Samples'] = df_cr['Samples'].astype(int)\n",
        "\n",
        "    df_cr = (df_cr.rename(columns={'precision':'Precision',\n",
        "                                   'recall':'Recall',\n",
        "                                   'f1-score':'F1-score'})\n",
        "                   [['Precision', 'Recall', 'F1-score', 'Samples']])\n",
        "\n",
        "    per_factor_tables[model_name] = df_cr\n",
        "\n",
        "# Concatenate side-by-side â†’ MultiIndex columns: level-0=model, level-1=metric\n",
        "combined = pd.concat(\n",
        "    {m: tbl.drop(columns='Samples') for m, tbl in per_factor_tables.items()},\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Single shared Samples column\n",
        "combined[('', 'Samples')] = next(iter(per_factor_tables.values()))['Samples']\n",
        "combined = combined.reindex(\n",
        "    columns=[c for c in combined.columns if c[1] != 'Samples'] + [('', 'Samples')]\n",
        ")\n",
        "combined.columns.set_names(['Model', 'Metric'], inplace=True)\n",
        "\n",
        "print(\"\\n## Per-Factor Metrics: Random Forest vs Gradient Boosting\\n\")\n",
        "display(\n",
        "    combined.style\n",
        "            .format(lambda x: f\"{x:.1f}%\" if isinstance(x, (float, np.floating))\n",
        "                                   else \"{:d}\".format(x))\n",
        "            .set_caption(\"Per-Factor Metrics (Combined)\")\n",
        "            .set_table_styles(\n",
        "                [\n",
        "                    {'selector': 'th', 'props': [('text-align', 'center')]},\n",
        "                    {'selector': 'th.col_heading.level0',\n",
        "                     'props': [('border-bottom', '1pt solid black')]}\n",
        "                ]\n",
        "            )\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. Overall-performance summary\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "summary_rows = []\n",
        "for model_name, df_res in items:\n",
        "    y_true, y_pred = df_res.Actual_Winner, df_res.Predicted_Winner\n",
        "    summary_rows.append({\n",
        "        'Model':              model_name,\n",
        "        'Accuracy (%)':       round(accuracy_score(y_true, y_pred) * 100, 1),\n",
        "        'Precision (wtd %)':  round(precision_score(y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'Recall  (wtd %)':    round(recall_score   (y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'F1 (wtd %)':         round(f1_score       (y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'Samples':            len(y_true)\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows).set_index('Model')\n",
        "\n",
        "print(\"\\n### Overall Performance Summary ###\\n\")\n",
        "display(\n",
        "    summary_df.style\n",
        "              .format({\n",
        "                  'Accuracy (%)':      '{:.1f}%',\n",
        "                  'Precision (wtd %)': '{:.1f}%',\n",
        "                  'Recall  (wtd %)':   '{:.1f}%',\n",
        "                  'F1 (wtd %)':        '{:.1f}%',\n",
        "                  'Samples':           '{:d}'\n",
        "              })\n",
        "              .set_caption(\"Overall Performance Summary\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature importance"
      ],
      "metadata": {
        "id": "-U5ovbRVPoPM"
      },
      "id": "-U5ovbRVPoPM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5",
      "metadata": {
        "tags": [],
        "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume FEATURES is defined (e.g., FEATURES = ['CPI%', 'T10YFF', 'LEI%', 'Amihud', 'GARCH_1M'])\n",
        "# and results_dfs is a dictionary with keys like \"RF\", \"GB\", (and maybe \"Hybrid\")\n",
        "# where each value is a DataFrame that has a column \"Feature_Importances\" (an array).\n",
        "\n",
        "# 1. Compute overall average feature importances for each model.\n",
        "model_importances = {}\n",
        "for model_key, df in results_dfs.items():\n",
        "    # Stack the arrays from the \"Feature_Importances\" column and average over predictions.\n",
        "    model_importances[model_key] = np.vstack(df['Feature_Importances'].values).mean(axis=0)\n",
        "\n",
        "# 2. Create a DataFrame from the computed importances.\n",
        "# Rows: features, Columns: model keys.\n",
        "importance_df = pd.DataFrame(model_importances, index=FEATURES)\n",
        "\n",
        "# Optional: sort features by overall mean importance (averaged across models) so that\n",
        "# the most important features appear on top.\n",
        "importance_df['Mean'] = importance_df.mean(axis=1)\n",
        "importance_df = importance_df.sort_values(by='Mean', ascending=False)\n",
        "sorted_features = importance_df.index.tolist()\n",
        "importance_df = importance_df.drop(columns=['Mean'])\n",
        "\n",
        "# 3. Plot a grouped horizontal bar chart.\n",
        "models = importance_df.columns.tolist()\n",
        "n_models = len(models)\n",
        "n_features = len(sorted_features)\n",
        "y = np.arange(n_features)  # base positions for each feature group\n",
        "bar_height = 0.8 / n_models  # total group thickness is 0.8\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, max(4, n_features * 0.6)))\n",
        "for i, model in enumerate(models):\n",
        "    # Calculate an offset for each model in the group.\n",
        "    offset = (i - n_models/2) * bar_height + bar_height/2\n",
        "    ax.barh(y + offset, importance_df.loc[sorted_features, model], height=bar_height, label=model)\n",
        "\n",
        "ax.set_yticks(y)\n",
        "ax.set_yticklabels(sorted_features)\n",
        "ax.invert_yaxis()  # so the top feature is at the top\n",
        "ax.set_xlabel(\"Average Feature Importance\")\n",
        "ax.set_title(\"Comparison of Overall Average Feature Importances Across Models\")\n",
        "ax.legend(title=\"Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Allocation chart"
      ],
      "metadata": {
        "id": "bhRxmOoFPtEI"
      },
      "id": "bhRxmOoFPtEI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8",
      "metadata": {
        "tags": [],
        "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Determine how many models to plot\n",
        "num_models = len(results_dfs)\n",
        "\n",
        "# Create subplots: one row per model, sharing the x-axis\n",
        "fig, axes = plt.subplots(nrows=num_models, ncols=1, figsize=(12, 6 * num_models), sharex=True)\n",
        "if num_models == 1:\n",
        "    axes = [axes]  # Ensure iterable if only one model\n",
        "\n",
        "# Loop through each model's result dataframe\n",
        "for ax, (model_key, df_model) in zip(axes, results_dfs.items()):\n",
        "    df_temp = df_model.copy()\n",
        "\n",
        "    # 1) Convert Predicted_month to datetime (robust handling)\n",
        "    df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors='coerce')\n",
        "\n",
        "    # 2) Drop rows with invalid dates\n",
        "    df_temp = df_temp.dropna(subset=[\"Predicted_month\"])\n",
        "    df_temp = df_temp.sort_values(\"Predicted_month\").reset_index(drop=True)\n",
        "\n",
        "    # 3) Stack probabilities\n",
        "    full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "    probability_df = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "    probability_df[\"Date\"] = df_temp[\"Predicted_month\"]\n",
        "\n",
        "    # 4) Sort by date again (just in case)\n",
        "    probability_df = probability_df.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "    # 5) Plot stackplot\n",
        "    ax.stackplot(\n",
        "        probability_df[\"Date\"],\n",
        "        [probability_df[col] for col in FACTORS],\n",
        "        labels=FACTORS,\n",
        "        alpha=0.8\n",
        "    )\n",
        "\n",
        "    # âœ… Legend: top right, inside chart, solid white background\n",
        "    ax.legend(\n",
        "        loc=\"upper right\",\n",
        "        fontsize=\"small\",\n",
        "        title=\"Factors\",\n",
        "        frameon=True,\n",
        "        framealpha=1.0,      # fully opaque\n",
        "        facecolor='white',   # solid background\n",
        "        edgecolor='black'    # optional: to match style\n",
        "    )\n",
        "\n",
        "    # Set title, axes, and formatting\n",
        "    ax.set_title(f\"{model_key} Outperforming Probabilities\", fontsize=14)\n",
        "    ax.set_ylabel(\"Probability\", fontsize=12)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Trim x-axis to data range\n",
        "    ax.set_xlim(probability_df[\"Date\"].min(), probability_df[\"Date\"].max())\n",
        "\n",
        "# Final x-axis label and formatting\n",
        "plt.xlabel(\"Date\", fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Factor weight analysis"
      ],
      "metadata": {
        "id": "PY247n9MPyWG"
      },
      "id": "PY247n9MPyWG"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Toggle:\n",
        "combine_all_models = False  # Set to True to combine all models into the same charts; False for individual charts per model\n",
        "\n",
        "# Set the date range for viewing.\n",
        "start_date = pd.to_datetime(\"1968-07-30\")\n",
        "end_date   = pd.to_datetime(\"2024-11-30\")\n",
        "\n",
        "# Define static equal weight value.\n",
        "equal_weight = 1 / len(FACTORS)  # e.g., for 5 factors equal_weight = 0.20\n",
        "\n",
        "if combine_all_models:\n",
        "    # Combined charts: One set of subplots (one per factor) for all models.\n",
        "    n_factors = len(FACTORS)\n",
        "    fig, axs = plt.subplots(n_factors, 1, figsize=(12, 4 * n_factors), sharex=False)\n",
        "    if n_factors == 1:\n",
        "        axs = [axs]  # ensure axs is iterable\n",
        "\n",
        "    for i, factor in enumerate(FACTORS):\n",
        "        ax = axs[i]\n",
        "        min_dates = []\n",
        "        max_dates = []\n",
        "\n",
        "        # Loop through each model's results\n",
        "        for model_key, df_model in results_dfs.items():\n",
        "            df_temp = df_model.copy()\n",
        "            df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors='coerce')\n",
        "            df_temp = df_temp.dropna(subset=[\"Predicted_month\"]).sort_values(\"Predicted_month\").reset_index(drop=True)\n",
        "\n",
        "            # Stack predicted probabilities into a DataFrame.\n",
        "            full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "            probability_df = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "            probability_df[\"Date\"] = df_temp[\"Predicted_month\"]\n",
        "\n",
        "            # Filter to desired date range.\n",
        "            mask = (probability_df[\"Date\"] >= start_date) & (probability_df[\"Date\"] <= end_date)\n",
        "            filtered_df = probability_df.loc[mask].reset_index(drop=True)\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                continue\n",
        "\n",
        "            ax.plot(filtered_df[\"Date\"], filtered_df[factor],\n",
        "                    label=f\"{factor}_{model_key}\", linewdth=0.6)\n",
        "\n",
        "            min_dates.append(filtered_df[\"Date\"].min())\n",
        "            max_dates.append(filtered_df[\"Date\"].max())\n",
        "\n",
        "        # Set x-axis limits to exactly the data span (if any data exist)\n",
        "        if min_dates and max_dates:\n",
        "            ax.set_xlim(min(min_dates), max(max_dates))\n",
        "\n",
        "        # Draw the static equal weight horizontal line.\n",
        "        ax.axhline(equal_weight, color='black', linestyle='--',\n",
        "                   label=f\"Equal Weight ({equal_weight:.2%})\")\n",
        "\n",
        "        ax.set_title(f\"{factor} Predicted Probabilities Across Models\", fontsize=14)\n",
        "        ax.set_ylabel(\"Probability\", fontsize=12)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        ax.legend(loc='best', fontsize='small')\n",
        "\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    # Separate charts: Loop over each model and for each factor create individual charts.\n",
        "    for model_key, df_model in results_dfs.items():\n",
        "        for factor in FACTORS:\n",
        "            df_temp = df_model.copy()\n",
        "            df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors='coerce')\n",
        "            df_temp = df_temp.dropna(subset=[\"Predicted_month\"]).sort_values(\"Predicted_month\").reset_index(drop=True)\n",
        "\n",
        "            full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "            probability_df = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "            probability_df[\"Date\"] = df_temp[\"Predicted_month\"]\n",
        "\n",
        "            # Filter to desired date range.\n",
        "            mask = (probability_df[\"Date\"] >= start_date) & (probability_df[\"Date\"] <= end_date)\n",
        "            filtered_df = probability_df.loc[mask].reset_index(drop=True)\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                continue\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.plot(filtered_df[\"Date\"], filtered_df[factor],\n",
        "                     label=f\"{factor} Predicted Probability\", color='blue', linewidth=0.6)\n",
        "\n",
        "            plt.axhline(equal_weight, color='black', linestyle='--',\n",
        "                        label=f\"Equal Weight ({equal_weight:.2%})\")\n",
        "\n",
        "            plt.fill_between(filtered_df[\"Date\"],\n",
        "                             filtered_df[factor],\n",
        "                             equal_weight,\n",
        "                             where=(filtered_df[factor] > equal_weight),\n",
        "                             interpolate=True, color='green', alpha=0.3, label='Overweight')\n",
        "            plt.fill_between(filtered_df[\"Date\"],\n",
        "                             filtered_df[factor],\n",
        "                             equal_weight,\n",
        "                             where=(filtered_df[factor] < equal_weight),\n",
        "                             interpolate=True, color='red', alpha=0.3, label='Underweight')\n",
        "\n",
        "            plt.title(f\"{model_key} - Over/Under Weight for {factor}\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Probability\")\n",
        "            plt.ylim(0, 1)\n",
        "            # Set x-axis limits to exactly where data exists.\n",
        "            plt.xlim(filtered_df[\"Date\"].min(), filtered_df[\"Date\"].max())\n",
        "            plt.legend(loc='best')\n",
        "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "5My7U6ny7GAJ"
      },
      "id": "5My7U6ny7GAJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total outperforming probabilities"
      ],
      "metadata": {
        "id": "6wkhRaZrP6aF"
      },
      "id": "6wkhRaZrP6aF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. Compute average predicted probabilities per model\n",
        "# ----------------------------------------------------\n",
        "avg_probs_dict = {}\n",
        "avg_highest_factor_weight_dict = {}\n",
        "\n",
        "for model_key, df_model in results_dfs.items():\n",
        "    full_probs = np.vstack(df_model[\"Predicted_Probabilities\"].values)\n",
        "\n",
        "    # 1a. Compute the average probabilities across all rows\n",
        "    avg = full_probs.mean(axis=0)\n",
        "    avg_probs_dict[model_key] = pd.Series(avg, index=FACTORS)\n",
        "\n",
        "    # 1b. Compute the average of the highest weight factor\n",
        "    #     (for each time step, pick the max factor weight, then average those)\n",
        "    avg_highest_factor_weight_dict[model_key] = full_probs.max(axis=1).mean()\n",
        "\n",
        "# Create a DataFrame where rows = models, columns = factors\n",
        "avg_probs_df = pd.DataFrame(avg_probs_dict).T\n",
        "avg_probs_df.index.name = \"Model\"\n",
        "avg_probs_df = avg_probs_df.round(4)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. Generate consistent factor colors from stackplot\n",
        "# ----------------------------------------------------\n",
        "# Use a dummy stackplot to extract the assigned factor colors\n",
        "_, ax_dummy = plt.subplots()\n",
        "dummy_data = np.random.rand(10, len(FACTORS))\n",
        "dummy_dates = pd.date_range(\"2000-01-01\", periods=10)\n",
        "stack = ax_dummy.stackplot(dummy_dates, dummy_data.T, labels=FACTORS, alpha=0.8)\n",
        "plt.close()  # We donâ€™t want to display this\n",
        "\n",
        "# Build color map: factor name â†’ RGBA color\n",
        "factor_colors = {factor: poly.get_facecolor()[0] for factor, poly in zip(FACTORS, stack)}\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3. Display HTML Table of average probabilities\n",
        "# ----------------------------------------------------\n",
        "html_table = avg_probs_df.reset_index().to_html(index=False, classes=\"table table-striped table-bordered\", border=0)\n",
        "display(HTML(\"<h3>Average Outperforming Probabilities by Model</h3>\" + html_table))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. Print average of the highest factor weight by model\n",
        "# ----------------------------------------------------\n",
        "display(HTML(\"<h4>Average of the Highest Factor Weight by Model</h4>\"))\n",
        "for model_key, avg_highest in avg_highest_factor_weight_dict.items():\n",
        "    display(HTML(f\"<p><strong>{model_key}:</strong> {avg_highest:.4f}</p>\"))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 5. Stacked Bar Chart with Consistent Colors and Labels\n",
        "# ----------------------------------------------------\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "bottom = np.zeros(len(avg_probs_df))\n",
        "x = np.arange(len(avg_probs_df))\n",
        "\n",
        "for factor in FACTORS:\n",
        "    values = avg_probs_df[factor].values\n",
        "    bars = ax.bar(x, values, bottom=bottom,\n",
        "                  label=factor,\n",
        "                  color=factor_colors[factor],\n",
        "                  edgecolor=\"white\",\n",
        "                  linewidth=0.5)\n",
        "\n",
        "    # Centered labels\n",
        "    for bar, val in zip(bars, values):\n",
        "        if val > 0.03:\n",
        "            ax.text(\n",
        "                bar.get_x() + bar.get_width() / 2,\n",
        "                bar.get_y() + bar.get_height() / 2,\n",
        "                f\"{val * 100:.1f}%\",\n",
        "                ha=\"center\", va=\"center\", fontsize=9, color=\"white\"\n",
        "            )\n",
        "\n",
        "    bottom += values\n",
        "\n",
        "# Final touches\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(avg_probs_df.index)\n",
        "ax.set_ylabel(\"Strategy average factor weights\")\n",
        "ax.set_title(\"Strategy average factor weights\")\n",
        "ax.legend(title=\"Factor\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7GvhTSes34Ci"
      },
      "id": "7GvhTSes34Ci",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Return data"
      ],
      "metadata": {
        "id": "M0sRKlsm6Yja"
      },
      "id": "M0sRKlsm6Yja"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 0: Define column orders based on your requirements\n",
        "# ------------------------------------------------------------------------------\n",
        "# Common columns that are identical across all models.\n",
        "common_cols = ['Predicted_month', 'Mkt', 'RF', 'Mkt-RF', 'Us_standard'] + FACTORS + ['Equal_Weight_Return', 'Actual_Winner']\n",
        "\n",
        "# Model-specific columns that will be renamed.\n",
        "model_specific_cols = ['Allocated_Return', 'Predicted_Winner']\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 1. Build a base common DataFrame from one model's merged results.\n",
        "# ------------------------------------------------------------------------------\n",
        "# Take the first model as the base to extract common columns.\n",
        "base_key, base_df = list(results_dfs.items())[0]\n",
        "base_df = base_df.copy()\n",
        "base_df['Predicted_month'] = pd.to_datetime(base_df['Predicted_month'], errors='coerce')\n",
        "\n",
        "# Merge with df_sorted (the master DataFrame sorted by date) on date.\n",
        "base_df_local = base_df.merge(df_sorted, left_on='Predicted_month', right_on='Date', how='left')\n",
        "common_df = base_df_local[[c for c in common_cols if c in base_df_local.columns]].copy()\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 2. Process each model individually to extract the model-specific columns.\n",
        "# ------------------------------------------------------------------------------\n",
        "# We'll assign a new display name using numbering such that each model gets:\n",
        "# \"ML{number}: {Model Name}\"\n",
        "model_dfs = []         # Will hold one DataFrame per model.\n",
        "new_model_names = []   # To store new model names.\n",
        "for i, (model_key, df_model) in enumerate(results_dfs.items(), 1):\n",
        "    new_model_name = f\"ML{i}: {model_key}\"  # New display name.\n",
        "    new_model_names.append(new_model_name)\n",
        "\n",
        "    df_temp = df_model.copy()\n",
        "    df_temp['Predicted_month'] = pd.to_datetime(df_temp['Predicted_month'], errors='coerce')\n",
        "\n",
        "    # Merge with df_sorted on 'Predicted_month' = 'Date'\n",
        "    df_temp_local = df_temp.merge(df_sorted, left_on='Predicted_month', right_on='Date', how='left')\n",
        "\n",
        "    # Keep only the 'Predicted_month' plus the model-specific columns.\n",
        "    subset_cols = ['Predicted_month'] + [col for col in model_specific_cols if col in df_temp_local.columns]\n",
        "    df_subset = df_temp_local[subset_cols].copy()\n",
        "\n",
        "    # Rename model-specific columns with the new model name.\n",
        "    rename_dict = {}\n",
        "    for col in model_specific_cols:\n",
        "        if col in df_subset.columns:\n",
        "            rename_dict[col] = f\"{new_model_name} {col}\"\n",
        "    df_subset.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "    model_dfs.append(df_subset)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 3. Merge each model-specific DataFrame with the common DataFrame.\n",
        "# ------------------------------------------------------------------------------\n",
        "combined_df = common_df.copy()\n",
        "for df_sub in model_dfs:\n",
        "    combined_df = combined_df.merge(df_sub, on='Predicted_month', how='left')\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 4. Reorder the columns to match the desired order.\n",
        "# ------------------------------------------------------------------------------\n",
        "benchmark_cols = ['Mkt', 'RF', 'Mkt-RF', 'Us_standard']\n",
        "common_order = ['Predicted_month'] + benchmark_cols + FACTORS\n",
        "# Model-specific allocated return columns.\n",
        "allocated_cols = [f\"{name} Allocated_Return\" for name in new_model_names]\n",
        "# Model-specific predicted winner columns.\n",
        "predicted_cols = [f\"{name} Predicted_Winner\" for name in new_model_names]\n",
        "\n",
        "final_order = common_order + ['Equal_Weight_Return'] + allocated_cols + ['Actual_Winner'] + predicted_cols\n",
        "final_order = [col for col in final_order if col in combined_df.columns]\n",
        "\n",
        "combined_df = combined_df[final_order].sort_values('Predicted_month').reset_index(drop=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 5. Display the final combined results table.\n",
        "# ------------------------------------------------------------------------------\n",
        "display(combined_df)\n",
        "print(\"\\nFirst date in 'Predicted_month':\", pd.to_datetime(combined_df['Predicted_month']).min())\n",
        "print(\"Last date in 'Predicted_month':\", pd.to_datetime(combined_df['Predicted_month']).max())\n"
      ],
      "metadata": {
        "id": "rA982P5EGhj4"
      },
      "id": "rA982P5EGhj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "# Define your date range\n",
        "start_date = pd.to_datetime('2000-01-01')\n",
        "end_date   = pd.to_datetime('2024-12-30')\n",
        "\n",
        "# Create a filtered copy of combined_df (so the original data isn't lost)\n",
        "filtered_df = combined_df.loc[\n",
        "    (combined_df['Predicted_month'] >= start_date) &\n",
        "    (combined_df['Predicted_month'] <= end_date)\n",
        "].copy()\n",
        "\n",
        "# Ensure \"Year\" column exists in filtered_df\n",
        "if 'Year' not in filtered_df.columns:\n",
        "    filtered_df['Year'] = filtered_df['Predicted_month'].dt.year\n",
        "\n",
        "# Identify ML return columns and create a name map to remove \"Allocated_Return\"\n",
        "ml_return_cols = [c for c in filtered_df.columns if 'Allocated_Return' in c]\n",
        "ml_name_map = {ml: ml.replace(\"Allocated_Return\", \"\").strip() for ml in ml_return_cols}\n",
        "\n",
        "# Helper: Compute annual metrics (RF-adjusted)\n",
        "def compute_annual_metrics(returns: pd.Series, rf: pd.Series):\n",
        "    returns = returns.dropna()\n",
        "    if returns.empty:\n",
        "        return np.nan, np.nan, np.nan\n",
        "    rf = rf.reindex(returns.index)\n",
        "    ann_ret = (1 + returns).prod() - 1\n",
        "    ann_rf  = (1 + rf).prod() - 1\n",
        "    ann_ex_ret = ann_ret - ann_rf\n",
        "    ann_vol = (returns - rf).std() * np.sqrt(12)\n",
        "    ann_sharpe = ann_ex_ret / ann_vol if ann_vol else np.nan\n",
        "    return ann_ret, ann_vol, ann_sharpe\n",
        "\n",
        "# Build df_metrics (raw values) and df_excess (excess over Equal Weight)\n",
        "metrics_rows, excess_rows = [], []\n",
        "for year, grp in filtered_df.groupby('Year'):\n",
        "    ew_ret, ew_vol, ew_sharpe = compute_annual_metrics(grp['Equal_Weight_Return'], grp['RF'])\n",
        "    row_m = {'Year': year,\n",
        "             'Equal_Weight Return': ew_ret,\n",
        "             'Equal_Weight Vol':    ew_vol,\n",
        "             'Equal_Weight Sharpe': ew_sharpe}\n",
        "    row_e = {'Year': year}\n",
        "\n",
        "    for ml in ml_return_cols:\n",
        "        ml_short = ml_name_map[ml]\n",
        "        ml_ret, ml_vol, ml_sharpe = compute_annual_metrics(grp[ml], grp['RF'])\n",
        "        row_m[f\"{ml_short} Return\"]  = ml_ret\n",
        "        row_m[f\"{ml_short} Vol\"]     = ml_vol\n",
        "        row_m[f\"{ml_short} Sharpe\"]  = ml_sharpe\n",
        "\n",
        "        row_e[f\"{ml_short} Excess Return\"]  = ml_ret - ew_ret\n",
        "        row_e[f\"{ml_short} Excess Vol\"]     = ml_vol - ew_vol\n",
        "        row_e[f\"{ml_short} Excess Sharpe\"]  = ml_sharpe - ew_sharpe\n",
        "\n",
        "    metrics_rows.append(row_m)\n",
        "    excess_rows.append(row_e)\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics_rows).set_index('Year').sort_index()\n",
        "df_excess  = pd.DataFrame(excess_rows).set_index('Year').sort_index()\n",
        "\n",
        "# Function: Insert newline breaks for column names longer than max_width characters.\n",
        "def wrap_colname(colname, max_width=15):\n",
        "    lines = textwrap.wrap(colname, width=max_width)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Apply wrapping to all column names\n",
        "df_metrics.columns = [wrap_colname(col) for col in df_metrics.columns]\n",
        "df_excess.columns  = [wrap_colname(col) for col in df_excess.columns]\n",
        "\n",
        "# Function: Style dataframe to enable multiline headers and format numbers with a max of 3 decimals.\n",
        "def style_with_wrapping_and_format(df):\n",
        "    styled = df.style.set_table_styles([\n",
        "        {\n",
        "            'selector': 'th',\n",
        "            'props': [\n",
        "                ('white-space', 'pre-wrap'),  # allow multiline\n",
        "                ('word-wrap', 'break-word')   # break long words\n",
        "            ]\n",
        "        }\n",
        "    ]).format(lambda x: f\"{x:.3f}\" if isinstance(x, float) else x)\n",
        "    return styled\n",
        "\n",
        "# Display the raw metrics and excess metrics with formatted output.\n",
        "display(style_with_wrapping_and_format(df_metrics))\n",
        "display(style_with_wrapping_and_format(df_excess))\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Summary: Count how often each ML strategy \"beats\" Equal Weight.\n",
        "#  - Excess Return is \"better\" if > 0.\n",
        "#  - Excess Volatility is \"better\" if < 0.\n",
        "#  - Excess Sharpe is \"better\" if > 0.\n",
        "#\n",
        "# Average excess metrics are now calculated from all observations.\n",
        "# -----------------------------------------------------------------\n",
        "summary_rows = []\n",
        "total_years = len(df_excess)\n",
        "\n",
        "def w(ml_short, suffix):\n",
        "    return wrap_colname(f\"{ml_short} {suffix}\")\n",
        "\n",
        "for ml in ml_return_cols:\n",
        "    ml_short = ml_name_map[ml]\n",
        "    ret_series    = df_excess[w(ml_short, \"Excess Return\")]\n",
        "    vol_series    = df_excess[w(ml_short, \"Excess Vol\")]\n",
        "    sharpe_series = df_excess[w(ml_short, \"Excess Sharpe\")]\n",
        "\n",
        "    ret_pos_count    = (ret_series > 0).sum()\n",
        "    vol_neg_count    = (vol_series < 0).sum()\n",
        "    sharpe_pos_count = (sharpe_series > 0).sum()\n",
        "\n",
        "    # Average excess metrics now computed over all observations:\n",
        "    avg_ret    = ret_series.mean()\n",
        "    avg_vol    = vol_series.mean()\n",
        "    avg_sharpe = sharpe_series.mean()\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Strategy\": ml_short,\n",
        "        \"Excess Return (Positive) Count\": f\"{ret_pos_count}/{total_years}\",\n",
        "        \"Avg Excess Return\":   avg_ret,\n",
        "        \"Excess Vol (Negative) Count\":    f\"{vol_neg_count}/{total_years}\",\n",
        "        \"Avg Excess Vol\":      avg_vol,\n",
        "        \"Excess Sharpe (Positive) Count\": f\"{sharpe_pos_count}/{total_years}\",\n",
        "        \"Avg Excess Sharpe\":   avg_sharpe\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.columns = [wrap_colname(col) for col in summary_df.columns]\n",
        "\n",
        "display(style_with_wrapping_and_format(summary_df))\n"
      ],
      "metadata": {
        "id": "j8ieygX5yPei"
      },
      "id": "j8ieygX5yPei",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cumulative returns table"
      ],
      "metadata": {
        "id": "E3Xi_BH1iwiv"
      },
      "id": "E3Xi_BH1iwiv"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Toggle settings\n",
        "show_50_50_strategy = False  # Toggle for the 50%/50% predicted winner weighted strategy line.\n",
        "show_benchmark        = False  # Toggle for showing benchmark cumulative return(s).\n",
        "use_log_scale         = True   # Now default to logâ€scale for demonstration.\n",
        "\n",
        "# Copy and shift each cumulativeâ€return series by +1\n",
        "df_plot = cumulative_table.copy()\n",
        "shifted = df_plot.set_index('Predicted_month').copy()\n",
        "for col in shifted.columns:\n",
        "    if 'Cumulative' in col:\n",
        "        shifted[col] = shifted[col] + 1.0\n",
        "\n",
        "# Determine date range\n",
        "start_date = shifted.index.min()\n",
        "end_date   = shifted.index.max()\n",
        "print(f\"Plotting from {start_date.date()} to {end_date.date()}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.clf()\n",
        "\n",
        "# Plot each shifted series\n",
        "for col in shifted.columns:\n",
        "    if 'Cumulative Allocated Return' in col:\n",
        "        plt.plot(shifted.index, shifted[col], label=col)\n",
        "\n",
        "if 'Equal Factor Weight Cumulative Return' in shifted.columns:\n",
        "    plt.plot(shifted.index,\n",
        "             shifted['Equal Factor Weight Cumulative Return'],\n",
        "             label='Equal Factor Weight Cumulative Return')\n",
        "\n",
        "if show_benchmark:\n",
        "    if 'Benchmark Cumulative Return' in shifted.columns:\n",
        "        plt.plot(shifted.index,\n",
        "                 shifted['Benchmark Cumulative Return'],\n",
        "                 label='Benchmark Cumulative Return')\n",
        "    for col in shifted.columns:\n",
        "        if ((\"Mkt\" in col or \"Us_standard\" in col)\n",
        "            and \"Cumulative Return\" in col\n",
        "            and \"Mkt-RF\" not in col\n",
        "            and col != 'Benchmark Cumulative Return'):\n",
        "            plt.plot(shifted.index, shifted[col], label=col)\n",
        "\n",
        "if show_50_50_strategy and 'Predicted Winner Weighted Cumulative Return' in shifted.columns:\n",
        "    plt.plot(shifted.index,\n",
        "             shifted['Predicted Winner Weighted Cumulative Return'],\n",
        "             label='50%/50% Predicted Winner Strategy')\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Growth ofÂ 1Â â‚¬ Investment' + (' (log scale)' if use_log_scale else ''))\n",
        "plt.title('Cumulative Returns Comparison (From 1Â â‚¬ Base)')\n",
        "plt.xlim(start_date, end_date)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Log or linear\n",
        "plt.yscale('log' if use_log_scale else 'linear')\n",
        "# If you like, force bottom of yâ€axis at 1\n",
        "if use_log_scale:\n",
        "    plt.ylim(1, None)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wm06N1gjGjVr"
      },
      "id": "wm06N1gjGjVr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cumulative returns chart"
      ],
      "metadata": {
        "id": "W-uq2G9iPQwD"
      },
      "id": "W-uq2G9iPQwD"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# â”€â”€â”€ User Inputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# combined_df: your merged table of actual & predicted returns\n",
        "# BENCHMARK:   list of benchmark column names (e.g. [\"Mkt\"] or [\"S&P500\"])\n",
        "# FACTORS:     list of factor column names (e.g. [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"])\n",
        "# results_dfs: dict of modelâ€specific DataFrames or placeholders; keys are model names\n",
        "\n",
        "# Example placeholders (remove/comment these in your real code):\n",
        "# combined_df = pd.read_csv(\"your_merged.csv\", parse_dates=[\"Predicted_month\"])\n",
        "# BENCHMARK    = [\"Mkt\"]\n",
        "# FACTORS      = [\"Mkt-RF\", \"SMB\", \"HML\", \"RMW\", \"CMA\"]\n",
        "# results_dfs  = {\"Random Forest\": None, \"Gradient Boosting\": None}\n",
        "\n",
        "\n",
        "df = combined_df[\n",
        "    (combined_df['Predicted_month'] >= start_date) &\n",
        "    (combined_df['Predicted_month'] <= end_date)\n",
        "].copy()\n",
        "\n",
        "# If your benchmark column matches BENCHMARK[0], rename it:\n",
        "if BENCHMARK[0] in df.columns:\n",
        "    df.rename(columns={BENCHMARK[0]: 'Benchmark Return'}, inplace=True)\n",
        "\n",
        "# Exclude RF from factors\n",
        "factors = [f for f in FACTORS if f.upper() != 'RF']\n",
        "\n",
        "# â”€â”€â”€ 2) EQUALâ€‘WEIGHT FACTOR STRATEGY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if all(f in df.columns for f in factors):\n",
        "    df['Equal Factor Weight Strategy Return'] = df[factors].mean(axis=1)\n",
        "\n",
        "# â”€â”€â”€ 3) PREDICTEDâ€‘WINNER STRATEGY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "base_key = list(results_dfs.keys())[0]\n",
        "col_pred = f\"ML1: {base_key} Predicted_Winner\"\n",
        "df['Predicted_Winner'] = df[col_pred]\n",
        "\n",
        "def calc_winner(row):\n",
        "    pick = row['Predicted_Winner']\n",
        "    if pick in factors:\n",
        "        others = [f for f in factors if f != pick]\n",
        "        if others:\n",
        "            return 0.5 * row[pick] + 0.5 * row[others].mean()\n",
        "        return row[pick]\n",
        "    return row[factors].mean()\n",
        "\n",
        "df['Predicted Winner Weighted Strategy Return'] = df.apply(calc_winner, axis=1)\n",
        "\n",
        "# â”€â”€â”€ 4) BUILD CUMULATIVE SERIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "cum = df.copy()\n",
        "\n",
        "# a) Each modelâ€™s allocated return â†’ cumulative\n",
        "allocated_cols = []\n",
        "for i, model in enumerate(results_dfs.keys(), 1):\n",
        "    name = f\"ML{i}: {model}\"\n",
        "    col = f\"{name} Allocated_Return\"\n",
        "    if col in cum:\n",
        "        cum[f\"{name} Cumulative Allocated Return\"] = (1 + cum[col]).cumprod() - 1\n",
        "        allocated_cols.append(f\"{name} Cumulative Allocated Return\")\n",
        "\n",
        "# b) Equalâ€‘weight factor\n",
        "if 'Equal Factor Weight Strategy Return' in cum:\n",
        "    cum['Equal Factor Weight Cumulative Return'] = \\\n",
        "        (1 + cum['Equal Factor Weight Strategy Return']).cumprod() - 1\n",
        "\n",
        "# c) Benchmark(s)\n",
        "bench_cols = []\n",
        "if 'Benchmark Return' in cum:\n",
        "    col = f\"{BENCHMARK[0]} Cumulative Return\"\n",
        "    cum[col] = (1 + cum['Benchmark Return']).cumprod() - 1\n",
        "    bench_cols.append(col)\n",
        "for other in [\"Mkt\", \"Mkt-RF\", \"Us_standard\"]:\n",
        "    if other in cum.columns:\n",
        "        col = f\"{other} Cumulative Return\"\n",
        "        cum[col] = (1 + cum[other]).cumprod() - 1\n",
        "        bench_cols.append(col)\n",
        "\n",
        "# d) Predictedâ€‘winner\n",
        "if 'Predicted Winner Weighted Strategy Return' in cum:\n",
        "    cum['Predicted Winner Weighted Cumulative Return'] = \\\n",
        "        (1 + cum['Predicted Winner Weighted Strategy Return']).cumprod() - 1\n",
        "\n",
        "# e) Factorâ€byâ€factor cumulative returns\n",
        "factor_cums = []\n",
        "for f in factors:\n",
        "    if f in cum:\n",
        "        name = f + \" Cumulative\"\n",
        "        cum[name] = (1 + cum[f]).cumprod() - 1\n",
        "        factor_cums.append(name)\n",
        "\n",
        "# Assemble final table (optional, if you want to inspect)\n",
        "final_cols = (\n",
        "    ['Predicted_month'] +\n",
        "    bench_cols +\n",
        "    factor_cums +\n",
        "    ['Equal Factor Weight Cumulative Return'] +\n",
        "    allocated_cols +\n",
        "    ['Predicted Winner Weighted Cumulative Return']\n",
        ")\n",
        "cumulative_table = cum.loc[:, [c for c in final_cols if c in cum.columns]]\\\n",
        "                      .sort_values('Predicted_month')\\\n",
        "                      .reset_index(drop=True)\n",
        "\n",
        "# â”€â”€â”€ 5) PLOT THE THREE STRATEGIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def plot_three_strategies(df_ct, log_scale=True):\n",
        "    dates = df_ct['Predicted_month']\n",
        "    eq  = df_ct['Equal Factor Weight Cumulative Return'] + 1\n",
        "    ml1 = df_ct['ML1: Random Forest Cumulative Allocated Return'] + 1\n",
        "    ml2 = df_ct['ML2: Gradient Boosting Cumulative Allocated Return'] + 1\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(dates, eq,  label='Equal Factor Weight',       linewidth=2)\n",
        "    ax.plot(dates, ml1, label='ML1: Random Forest',        linewidth=2)\n",
        "    ax.plot(dates, ml2, label='ML2: Gradient Boosting',    linewidth=2)\n",
        "\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Growth of â‚¬1 Invested')\n",
        "    ax.set_title(f\"Growth of â‚¬1 on a {'Log' if log_scale else 'Linear'} Scale\")\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "    ax.set_yscale('log' if log_scale else 'linear')\n",
        "    ax.margins(x=0)\n",
        "    ax.set_xlim(dates.min(), dates.max())\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the plot function\n",
        "plot_three_strategies(cumulative_table, log_scale=use_log_scale)"
      ],
      "metadata": {
        "id": "wqfmAhDk3KBx"
      },
      "id": "wqfmAhDk3KBx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PERFORMANCE METRICS"
      ],
      "metadata": {
        "id": "-YjFAG1ePN-9"
      },
      "id": "-YjFAG1ePN-9"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "print(\"\\n=== PERFORMANCE METRICS ===\")\n",
        "\n",
        "def annualized_metrics(monthly_returns):\n",
        "    \"\"\"\n",
        "    Compute the annualized return, volatility, and Sharpe ratio from monthly returns.\n",
        "    Assumes monthly returns.\n",
        "    \"\"\"\n",
        "    # Fill missing values with 0 to avoid issues.\n",
        "    monthly_returns = monthly_returns.fillna(0)\n",
        "    mean_m = monthly_returns.mean()\n",
        "    std_m = monthly_returns.std()\n",
        "    ann_ret = mean_m * 12\n",
        "    ann_vol = std_m * np.sqrt(12)\n",
        "    sharpe = ann_ret / ann_vol if ann_vol != 0 else np.nan\n",
        "    return ann_ret, ann_vol, sharpe\n",
        "\n",
        "def max_drawdown(monthly_returns):\n",
        "    \"\"\"\n",
        "    Compute the maximum drawdown from a series of monthly returns.\n",
        "    \"\"\"\n",
        "    wealth = (1 + monthly_returns.fillna(0)).cumprod()\n",
        "    dd_series = wealth / wealth.cummax() - 1\n",
        "    return dd_series.min()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Determine the raw return columns from combined_df.\n",
        "# We assume:\n",
        "# â€¢ \"Predicted_month\" is the date column.\n",
        "# â€¢ Raw (monthly) return strategy columns either contain \"Return\"\n",
        "#   (e.g. \"ML1: Random Forest Allocated_Return\")\n",
        "#   OR exactly match BENCHMARK[0] (e.g. \"Mkt\") or \"Benchmark Return\"\n",
        "# We exclude any column that contains \"Cumulative\" as well as non-return columns.\n",
        "# ---------------------------------------------------------------------\n",
        "all_columns = combined_df.columns.tolist()\n",
        "# Include columns that (a) have \"Return\" in them (but not \"Cumulative\"), OR\n",
        "# are exactly equal to BENCHMARK[0] or \"Benchmark Return\"\n",
        "strategy_cols = [\n",
        "    col for col in all_columns\n",
        "    if (\n",
        "         ((\"Return\" in col) or (col == BENCHMARK[0]) or (col == \"Benchmark Return\"))\n",
        "         and (\"Cumulative\" not in col)\n",
        "         and (col not in [\"Actual_Winner\", \"Predicted_month\"])\n",
        "       )\n",
        "]\n",
        "\n",
        "# Display the list of strategy columns for debugging.\n",
        "print(\"Strategy columns used for performance metrics:\")\n",
        "print(strategy_cols)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Loop through each selected strategy column and compute performance metrics.\n",
        "# ---------------------------------------------------------------------\n",
        "metrics_list = []\n",
        "for col in strategy_cols:\n",
        "    monthly_ret_series = combined_df[col]\n",
        "    ann_ret, ann_vol, sharpe = annualized_metrics(monthly_ret_series)\n",
        "    mdd = max_drawdown(monthly_ret_series)\n",
        "\n",
        "    metrics_list.append({\n",
        "         \"Strategy\": col,\n",
        "         \"Annualized Return\": f\"{ann_ret*100:.2f}%\",\n",
        "         \"Annualized Volatility\": f\"{ann_vol*100:.2f}%\",\n",
        "         \"Sharpe Ratio\": f\"{sharpe:.2f}\",\n",
        "         \"Max Drawdown\": f\"{mdd*100:.2f}%\"\n",
        "    })\n",
        "\n",
        "# Create a DataFrame with the performance metrics.\n",
        "metrics_df = pd.DataFrame(metrics_list).sort_values(\"Strategy\").reset_index(drop=True)\n",
        "\n",
        "# Optionally, sort by another metric (e.g., Sharpe Ratio) if desired.\n",
        "# metrics_df = metrics_df.sort_values(\"Sharpe Ratio\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display the performance metrics as an HTML table.\n",
        "display(HTML(metrics_df.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "1o0tq56K64bL"
      },
      "id": "1o0tq56K64bL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drawdown chart"
      ],
      "metadata": {
        "id": "YXD3cJKFO_sE"
      },
      "id": "YXD3cJKFO_sE"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1. TOGGLE OPTIONS\n",
        "# -------------------------------------------------------------------------\n",
        "show_benchmark_drawdown = True           # Toggle benchmark drawdown\n",
        "show_equal_weight_drawdown = True        # Toggle Equal Weight (single) drawdown\n",
        "show_winner_weighted_drawdown = False     # Toggle Winner Weighted drawdown\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2. COPY cumulative_table (assumed computed previously)\n",
        "# -------------------------------------------------------------------------\n",
        "drawdown_df = cumulative_table.copy()\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 3. CALCULATE DRAWDOWNS USING WEALTH INDEX (Wealth = 1 + Cumulative Return)\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# a) For each ML model's cumulative allocated return column:\n",
        "ml_alloc_cols = [col for col in drawdown_df.columns if \"Cumulative Allocated Return\" in col]\n",
        "for col in ml_alloc_cols:\n",
        "    wealth = 1 + drawdown_df[col]\n",
        "    drawdown_name = col.replace(\"Cumulative Allocated Return\", \"Drawdown\")\n",
        "    drawdown_df[drawdown_name] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# b) For Benchmark:\n",
        "# Use the benchmark name from BENCHMARK[0]\n",
        "benchmark_name = BENCHMARK[0]  # for example, \"Mkt\"\n",
        "benchmark_cum_col = f\"{benchmark_name} Cumulative Return\"\n",
        "if benchmark_cum_col in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[benchmark_cum_col]\n",
        "    drawdown_df[f\"{benchmark_name} Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "elif \"Mkt Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Mkt Cumulative Return\"]\n",
        "    drawdown_df[\"Mkt Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "else:\n",
        "    print(\"WARNING: No benchmark cumulative return column found.\")\n",
        "\n",
        "# c) For Equal Weight (single version):\n",
        "if \"Equal Factor Weight Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Equal Factor Weight Cumulative Return\"]\n",
        "    drawdown_df[\"Equal Weight Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# d) For Predicted Winner Weighted:\n",
        "if \"Predicted Winner Weighted Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Predicted Winner Weighted Cumulative Return\"]\n",
        "    drawdown_df[\"Winner Weighted Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4. FILTER BY DATE RANGE\n",
        "# -------------------------------------------------------------------------\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "drawdown_df[\"Predicted_month\"] = pd.to_datetime(drawdown_df[\"Predicted_month\"])\n",
        "plot_df = drawdown_df[(drawdown_df[\"Predicted_month\"] >= start_date) &\n",
        "                      (drawdown_df[\"Predicted_month\"] <= end_date)]\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5. PLOT THE DRAWDOWNS\n",
        "# -------------------------------------------------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.clf()  # Clear any existing figure\n",
        "\n",
        "# a) Plot each ML model's drawdown (those columns that start with \"ML\" and contain \"Drawdown\")\n",
        "for col in plot_df.columns:\n",
        "    if col.startswith(\"ML\") and \"Drawdown\" in col:\n",
        "        plt.plot(plot_df[\"Predicted_month\"], plot_df[col], label=col)\n",
        "\n",
        "# b) Plot Benchmark Drawdown if toggled on\n",
        "if show_benchmark_drawdown:\n",
        "    # Look for the benchmark drawdown column with the actual benchmark name (e.g., \"Mkt Drawdown\")\n",
        "    bench_drawdown_col = f\"{benchmark_name} Drawdown\"\n",
        "    if bench_drawdown_col in plot_df.columns:\n",
        "        plt.plot(plot_df[\"Predicted_month\"], plot_df[bench_drawdown_col], label=bench_drawdown_col)\n",
        "\n",
        "# c) Plot Equal Weight Drawdown if available\n",
        "if show_equal_weight_drawdown and \"Equal Weight Drawdown\" in plot_df.columns:\n",
        "    plt.plot(plot_df[\"Predicted_month\"], plot_df[\"Equal Weight Drawdown\"], label=\"Equal Weight Drawdown\")\n",
        "\n",
        "# d) Plot Winner Weighted Drawdown if toggled on\n",
        "if show_winner_weighted_drawdown and \"Winner Weighted Drawdown\" in plot_df.columns:\n",
        "    plt.plot(plot_df[\"Predicted_month\"], plot_df[\"Winner Weighted Drawdown\"], label=\"Winner Weighted Drawdown\")\n",
        "\n",
        "# Format the y-axis as percentages.\n",
        "plt.gca().yaxis.set_major_formatter(\n",
        "    mticker.FuncFormatter(lambda val, _: f\"{val*100:.0f}%\")\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 6. ENSURE THE X-AXIS SPANS EXACTLY THE DEFINED DATE RANGE\n",
        "# -------------------------------------------------------------------------\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Drawdown\")\n",
        "plt.title(\"Drawdowns of Strategies\")\n",
        "plt.xlim(start_date, end_date)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FK-XFzpv4SXo"
      },
      "id": "FK-XFzpv4SXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regression"
      ],
      "metadata": {
        "id": "S244JpMyoSVe"
      },
      "id": "S244JpMyoSVe"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from IPython.display import display\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "subtract_rf    = True\n",
        "reg_start_date = pd.to_datetime('1950-01-01')\n",
        "reg_end_date   = pd.to_datetime('2025-01-01')\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. LOAD FAMAâ€“FRENCH DATA\n",
        "# -----------------------------------------------------------------------------\n",
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_2ND_latest.xlsx\")\n",
        "df_factors = xls_file.parse(\"FF5\", dtype=str)\n",
        "df_factors[\"Date\"] = pd.to_datetime(df_factors[\"Date\"])\n",
        "\n",
        "factors      = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
        "all_ff5_cols = factors + ['RF']\n",
        "\n",
        "for col in all_ff5_cols:\n",
        "    df_factors[col] = (\n",
        "        df_factors[col]\n",
        "          .str.replace(\",\", \".\", regex=False)\n",
        "          .astype(float)\n",
        "          .div(100)    # now in decimal\n",
        "    )\n",
        "\n",
        "df_factors = df_factors.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. PREPARE MODEL NAMES AND STORAGE\n",
        "# -----------------------------------------------------------------------------\n",
        "new_model_names        = [f\"ML{i}: {k}\" for i, k in enumerate(results_dfs.keys(), 1)]\n",
        "regression_summary_list = []\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. RUN REGRESSIONS FOR EACH MODEL\n",
        "# -----------------------------------------------------------------------------\n",
        "for new_model_name in new_model_names:\n",
        "    col = f\"{new_model_name} Allocated_Return\"\n",
        "    if col not in combined_df.columns:\n",
        "        print(f\"Skipping {new_model_name}: no column '{col}'\")\n",
        "        continue\n",
        "\n",
        "    # filter & rename\n",
        "    df_model = (\n",
        "        combined_df.loc[\n",
        "            (pd.to_datetime(combined_df['Predicted_month']) >= reg_start_date) &\n",
        "            (pd.to_datetime(combined_df['Predicted_month']) <= reg_end_date),\n",
        "            ['Predicted_month', col]\n",
        "        ]\n",
        "        .rename(columns={col: \"Allocated_Return\"})\n",
        "    )\n",
        "    df_model['Predicted_month'] = pd.to_datetime(df_model['Predicted_month'])\n",
        "\n",
        "    # merge factors\n",
        "    merged = (\n",
        "        pd.merge(df_model,\n",
        "                 df_factors[['Date'] + all_ff5_cols],\n",
        "                 left_on=\"Predicted_month\", right_on=\"Date\", how=\"inner\")\n",
        "          .drop(columns=[\"Date\"])\n",
        "    )\n",
        "\n",
        "    # subtract RF?\n",
        "    if subtract_rf:\n",
        "        merged['Y'] = merged['Allocated_Return'] - merged['RF']\n",
        "    else:\n",
        "        merged['Y'] = merged['Allocated_Return']\n",
        "\n",
        "    # regress\n",
        "    X     = sm.add_constant(merged[factors])\n",
        "    y     = merged['Y']\n",
        "    model = sm.OLS(y, X, missing='drop').fit()\n",
        "\n",
        "    # extract\n",
        "    alpha_dec   = model.params.get('const', np.nan)\n",
        "    alpha_t     = model.tvalues.get('const', np.nan)\n",
        "    beta_mkt    = model.params.get('Mkt-RF', np.nan)\n",
        "    r2          = model.rsquared\n",
        "    r2_adj      = model.rsquared_adj\n",
        "    pval        = model.f_pvalue\n",
        "\n",
        "    # print in percent\n",
        "    print(f\"\\n=== {new_model_name} vs. FF5 ===\")\n",
        "    print(model.summary())\n",
        "    print(f\"MonthlyÂ Alpha:    {alpha_dec*100:.3f}%\")\n",
        "    print(f\"Alpha tâ€‘stat:     {alpha_t:.3f}\")\n",
        "    print(f\"MarketÂ Beta:      {beta_mkt:.3f}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # store decimals for table, we'll convert later\n",
        "    regression_summary_list.append({\n",
        "        \"Model\":           new_model_name,\n",
        "        \"Alpha (dec)\":     alpha_dec,\n",
        "        \"Alpha tâ€‘stat\":    alpha_t,\n",
        "        \"Market Beta\":     beta_mkt,\n",
        "        \"R-squared\":       r2,\n",
        "        \"Adj. R-squared\":  r2_adj,\n",
        "        \"p-value\":         pval\n",
        "    })\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. EQUALâ€‘WEIGHT STRATEGY\n",
        "# -----------------------------------------------------------------------------\n",
        "eq = (\n",
        "    combined_df.loc[\n",
        "        (pd.to_datetime(combined_df['Predicted_month']) >= reg_start_date) &\n",
        "        (pd.to_datetime(combined_df['Predicted_month']) <= reg_end_date),\n",
        "        ['Predicted_month', 'Equal_Weight_Return']\n",
        "    ]\n",
        "    .rename(columns={'Equal_Weight_Return':'EW_Return'})\n",
        ")\n",
        "eq['Predicted_month'] = pd.to_datetime(eq['Predicted_month'])\n",
        "\n",
        "eqm = (\n",
        "    pd.merge(eq,\n",
        "             df_factors[['Date'] + all_ff5_cols],\n",
        "             left_on=\"Predicted_month\", right_on=\"Date\", how=\"inner\")\n",
        "      .drop(columns=[\"Date\"])\n",
        ")\n",
        "if subtract_rf:\n",
        "    eqm['Y'] = eqm['EW_Return'] - eqm['RF']\n",
        "else:\n",
        "    eqm['Y'] = eqm['EW_Return']\n",
        "\n",
        "X_eq    = sm.add_constant(eqm[factors])\n",
        "y_eq    = eqm['Y']\n",
        "model_eq = sm.OLS(y_eq, X_eq, missing='drop').fit()\n",
        "\n",
        "alpha_eq_dec = model_eq.params.get('const', np.nan)\n",
        "alpha_eq_t   = model_eq.tvalues.get('const', np.nan)\n",
        "beta_eq      = model_eq.params.get('Mkt-RF', np.nan)\n",
        "\n",
        "print(\"\\n=== Equal-Weight vs. FF5 ===\")\n",
        "print(model_eq.summary())\n",
        "print(f\"MonthlyÂ Alpha:    {alpha_eq_dec*100:.3f}%\")\n",
        "print(f\"Alpha tâ€‘stat:     {alpha_eq_t:.3f}\")\n",
        "print(f\"MarketÂ Beta:      {beta_eq:.3f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "regression_summary_list.append({\n",
        "    \"Model\":           \"Equal-Weight\",\n",
        "    \"Alpha (dec)\":     alpha_eq_dec,\n",
        "    \"Alpha tâ€‘stat\":    alpha_eq_t,\n",
        "    \"Market Beta\":     beta_eq,\n",
        "    \"R-squared\":       model_eq.rsquared,\n",
        "    \"Adj. R-squared\":  model_eq.rsquared_adj,\n",
        "    \"p-value\":         model_eq.f_pvalue\n",
        "})\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. SUMMARY TABLE (with % conversions)\n",
        "# -----------------------------------------------------------------------------\n",
        "df_sum = pd.DataFrame(regression_summary_list)\n",
        "\n",
        "# convert decimals to percent in new columns\n",
        "df_sum['Alpha (%)']           = df_sum['Alpha (dec)'] * 100\n",
        "df_sum['Ann. Alpha (%) comp'] = (1 + df_sum['Alpha (dec)'])**12 - 1\n",
        "df_sum['Ann. Alpha (%) comp'] = df_sum['Ann. Alpha (%) comp'] * 100\n",
        "df_sum['Ann. Alpha (%) lin']  = df_sum['Alpha (dec)'] * 12 * 100\n",
        "\n",
        "# round\n",
        "df_sum = df_sum.rename(columns={\n",
        "    'Alpha tâ€‘stat':   'Alpha tâ€‘stat',\n",
        "    'Market Beta':    'Market Beta',\n",
        "    'R-squared':      'RÂ²',\n",
        "    'Adj. R-squared': 'Adj. RÂ²',\n",
        "    'p-value':        'pâ€‘value'\n",
        "}).round({\n",
        "    'Alpha (%)':           3,\n",
        "    'Alpha tâ€‘stat':        3,\n",
        "    'Ann. Alpha (%) comp': 3,\n",
        "    'Ann. Alpha (%) lin':  3,\n",
        "    'Market Beta':         3,\n",
        "    'RÂ²':                  3,\n",
        "    'Adj. RÂ²':             3,\n",
        "    'pâ€‘value':             3\n",
        "})\n",
        "\n",
        "print(\"\\n=== Summary of All Models (in percent) ===\")\n",
        "display(df_sum[[\n",
        "    'Model',\n",
        "    'Alpha (%)',\n",
        "    'Alpha tâ€‘stat',\n",
        "    'Market Beta',\n",
        "    'RÂ²',\n",
        "    'Adj. RÂ²',\n",
        "    'pâ€‘value',\n",
        "    'Ann. Alpha (%) comp',\n",
        "    'Ann. Alpha (%) lin'\n",
        "]])"
      ],
      "metadata": {
        "id": "MOb-rnOzH_4W"
      },
      "id": "MOb-rnOzH_4W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "print(\"\\n=== PERFORMANCE METRICS ===\")\n",
        "\n",
        "def annual_sharpe(series):\n",
        "    \"\"\"\n",
        "    Calculate the annual Sharpe ratio from a monthly return Series.\n",
        "    - Annual return = (product(1 + monthly returns)) - 1\n",
        "    - Annual volatility = std(monthly returns) * sqrt(12)\n",
        "    - Sharpe = annual return / annual volatility (assuming risk-free rate = 0)\n",
        "    \"\"\"\n",
        "    annual_return = (1 + series).prod() - 1\n",
        "    annual_vol = series.std() * np.sqrt(12)\n",
        "    if annual_vol == 0:\n",
        "        return np.nan\n",
        "    return annual_return / annual_vol\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Define the date range and filter combined_df accordingly.\n",
        "# ---------------------------------------------------------------------\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "\n",
        "# Filter the merged DataFrame for the desired date range.\n",
        "df_filtered = combined_df[(combined_df['Predicted_month'] >= start_date) &\n",
        "                            (combined_df['Predicted_month'] <= end_date)].copy()\n",
        "\n",
        "# Create a \"Year\" column from Predicted_month.\n",
        "df_filtered[\"Year\"] = df_filtered[\"Predicted_month\"].dt.year\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Identify Strategy Columns for Regression Metrics:\n",
        "#    - ML strategy columns: Expected to have names like \"ML1: Random Forest Allocated_Return\", etc.\n",
        "#    - Benchmark: \"Benchmark Return\"\n",
        "#    - Equal Weight: \"Equal_Weight_Return\"\n",
        "# ---------------------------------------------------------------------\n",
        "ml_strategy_cols = [col for col in df_filtered.columns\n",
        "                    if col.startswith(\"ML\") and \"Allocated_Return\" in col and \"Cumulative\" not in col]\n",
        "\n",
        "bench_col = \"Benchmark Return\" if \"Benchmark Return\" in df_filtered.columns else None\n",
        "eq_col    = \"Equal_Weight_Return\" if \"Equal_Weight_Return\" in df_filtered.columns else None\n",
        "\n",
        "print(\"Strategy columns used for annual Sharpe calculation:\")\n",
        "print(\"ML Strategy Columns:\", ml_strategy_cols)\n",
        "if bench_col:\n",
        "    print(\"Benchmark Column:\", bench_col)\n",
        "if eq_col:\n",
        "    print(\"Equal Weight Column:\", eq_col)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Compute Annual Sharpe Ratios for Each Strategy\n",
        "# ---------------------------------------------------------------------\n",
        "annual_sharpe_dict = {}\n",
        "\n",
        "# Compute for each ML model column.\n",
        "for col in ml_strategy_cols:\n",
        "    annual_sharpe_dict[col] = df_filtered.groupby(\"Year\")[col].apply(annual_sharpe)\n",
        "\n",
        "# Compute for benchmark (if available).\n",
        "if bench_col is not None:\n",
        "    annual_sharpe_dict[bench_col] = df_filtered.groupby(\"Year\")[bench_col].apply(annual_sharpe)\n",
        "\n",
        "# Compute for equal weight (if available).\n",
        "if eq_col is not None:\n",
        "    annual_sharpe_dict[eq_col] = df_filtered.groupby(\"Year\")[eq_col].apply(annual_sharpe)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Combine the Results into One DataFrame and Round to 3 Decimals\n",
        "# ---------------------------------------------------------------------\n",
        "annual_sharpe_table = pd.DataFrame(annual_sharpe_dict)\n",
        "annual_sharpe_table = annual_sharpe_table.round(3)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Display the Annual Sharpe Ratios as a Neatly Formatted HTML Table\n",
        "# ---------------------------------------------------------------------\n",
        "display(HTML(\"<h3>Annual Sharpe Ratios by Year and Strategy</h3>\" + annual_sharpe_table.to_html(index=True)))\n"
      ],
      "metadata": {
        "id": "E0cAJzowyqZn"
      },
      "id": "E0cAJzowyqZn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ============================================================================\n",
        "# 1) Prepare Annual Return Data\n",
        "# ============================================================================\n",
        "\n",
        "# Define the date range for annual analysis.\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "\n",
        "# Filter the merged DataFrame (combined_df) for the desired date range.\n",
        "# (combined_df comes from your earlier multiâ€‘model merging steps.)\n",
        "df_annual = combined_df[(combined_df['Predicted_month'] >= start_date) &\n",
        "                          (combined_df['Predicted_month'] <= end_date)].copy()\n",
        "\n",
        "# Create a \"Year\" column.\n",
        "df_annual['Year'] = df_annual['Predicted_month'].dt.year\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Identify columns:\n",
        "#   â€¢ ML strategy columns: they contain \"Allocated_Return\" (e.g., \"ML1: Random Forest Allocated_Return\")\n",
        "#   â€¢ Benchmark: assume the column is \"Benchmark Return\" (or use what was defined earlier).\n",
        "#   â€¢ Equal Weight: assume \"Equal_Weight_Return\"\n",
        "#   â€¢ Factor columns: using the global FACTORS (e.g., ['SMB', 'HML', 'CMA', 'RMW'])\n",
        "# ---------------------------------------------------------------------\n",
        "ml_cols = [col for col in df_annual.columns if (\"Allocated_Return\" in col) and (\"Cumulative\" not in col)]\n",
        "benchmark_col = \"Benchmark Return\" if \"Benchmark Return\" in df_annual.columns else None\n",
        "equal_weight_col = \"Equal_Weight_Return\" if \"Equal_Weight_Return\" in df_annual.columns else None\n",
        "factor_cols = [fac for fac in FACTORS if fac in df_annual.columns]\n",
        "\n",
        "print(\"ML Strategy Columns:\", ml_cols)\n",
        "print(\"Benchmark Column:\", benchmark_col)\n",
        "print(\"Equal Weight Column:\", equal_weight_col)\n",
        "print(\"Factor Columns:\", factor_cols)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Function to compute annual return as the compounded return over the year.\n",
        "# ---------------------------------------------------------------------\n",
        "def annual_return(group, col):\n",
        "    \"\"\"Compound return over the group: product(1 + r) - 1.\"\"\"\n",
        "    return (1 + group[col]).prod() - 1\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Compute annual returns for each strategy.\n",
        "# We'll build a dictionary where keys are strategy names and values are Series indexed by Year.\n",
        "annual_returns = {}\n",
        "\n",
        "# For each ML model column.\n",
        "for col in ml_cols:\n",
        "    annual_returns[col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, col))\n",
        "\n",
        "# For benchmark.\n",
        "if benchmark_col is not None:\n",
        "    annual_returns[benchmark_col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, benchmark_col))\n",
        "\n",
        "# For equal weight strategy.\n",
        "if equal_weight_col is not None:\n",
        "    annual_returns[equal_weight_col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, equal_weight_col))\n",
        "\n",
        "# For each factor.\n",
        "for fac in factor_cols:\n",
        "    annual_returns[fac] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, fac))\n",
        "\n",
        "# Combine the computed annual returns into one DataFrame.\n",
        "annual_returns_df = pd.DataFrame(annual_returns)\n",
        "annual_returns_df = annual_returns_df.round(3)\n",
        "\n",
        "# Display the Annual Returns Table.\n",
        "display(HTML(\"<h3>Annual Returns Table</h3>\" + annual_returns_df.to_html()))\n",
        "\n",
        "# ============================================================================\n",
        "# 2) Compute Excess Returns and Plot by Factor\n",
        "# ============================================================================\n",
        "\n",
        "# For each factor, compute excess return for each ML model relative to that factor.\n",
        "# We define excess return as: (ML Annual Return) - (Factor Annual Return)\n",
        "excess_returns = {}\n",
        "for fac in factor_cols:\n",
        "    # Create a DataFrame of excess returns for all ML models for factor 'fac'\n",
        "    excess_df = pd.DataFrame()\n",
        "    for ml in ml_cols:\n",
        "        excess_df[ml] = annual_returns_df[ml] - annual_returns_df[fac]\n",
        "    excess_returns[fac] = excess_df\n",
        "\n",
        "# Now plot excess returns by factor.\n",
        "n_factors = len(factor_cols)\n",
        "if n_factors > 0:\n",
        "    # Create one subplot per factor.\n",
        "    fig, axes = plt.subplots(1, n_factors, figsize=(6 * n_factors, 5), sharex=True)\n",
        "    if n_factors == 1:\n",
        "        axes = [axes]\n",
        "    for i, fac in enumerate(factor_cols):\n",
        "        ax = axes[i]\n",
        "        # Plot a line for each ML model excess return for this factor.\n",
        "        for ml in ml_cols:\n",
        "            ax.plot(excess_returns[fac].index, excess_returns[fac][ml],\n",
        "                    marker='o', label=f'{ml} - {fac}')\n",
        "        ax.set_title(f'Excess Return: ML - {fac}')\n",
        "        ax.set_xlabel(\"Year\")\n",
        "        ax.set_ylabel(\"Excess Return\")\n",
        "        ax.grid(True, linestyle='--', alpha=0.7)\n",
        "        ax.legend(fontsize='small')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# 3) (Optional) Compute and Plot Annual Returns for Benchmark and Equal Weight\n",
        "# ============================================================================\n",
        "\n",
        "# For convenience, let's display the annual returns for benchmark and equal weight strategies.\n",
        "if benchmark_col is not None:\n",
        "    print(\"\\nAnnual Returns - Benchmark:\")\n",
        "    display(annual_returns_df[[benchmark_col]])\n",
        "if equal_weight_col is not None:\n",
        "    print(\"\\nAnnual Returns - Equal Weight Strategy:\")\n",
        "    display(annual_returns_df[[equal_weight_col]])\n"
      ],
      "metadata": {
        "id": "Lo1wj3nU3ceD"
      },
      "id": "Lo1wj3nU3ceD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Return comparison by period"
      ],
      "metadata": {
        "id": "tC8mxG1Ynm-j"
      },
      "id": "tC8mxG1Ynm-j"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1) Create a \"Year\" Column in the Merged DataFrame\n",
        "# -------------------------------------------------\n",
        "combined_df['Year'] = pd.to_datetime(combined_df['Predicted_month']).dt.year\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2) Define a Function to Calculate Annual Return\n",
        "# -------------------------------------------------\n",
        "def annual_return(series):\n",
        "    \"\"\"\n",
        "    Compute the annual compounded return from a monthly return series.\n",
        "    \"\"\"\n",
        "    return (1 + series).prod() - 1\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) Compute Annual Returns for Each Strategy:\n",
        "#    a) For each ML model's allocated return.\n",
        "#    b) For Benchmark Return.\n",
        "#    c) For Equal Weight Return.\n",
        "# -------------------------------------------------\n",
        "# a) For ML models: we assume these columns start with \"ML\" and contain \"Allocated_Return\"\n",
        "ml_cols = [col for col in combined_df.columns\n",
        "           if col.startswith(\"ML\") and \"Allocated_Return\" in col and \"Cumulative\" not in col]\n",
        "annual_returns_ml = {col: combined_df.groupby(\"Year\")[col].apply(annual_return) for col in ml_cols}\n",
        "\n",
        "# b) For Benchmark:\n",
        "annual_return_bench = None\n",
        "if \"Benchmark Return\" in combined_df.columns:\n",
        "    annual_return_bench = combined_df.groupby(\"Year\")[\"Benchmark Return\"].apply(annual_return)\n",
        "\n",
        "# c) For Equal Weight:\n",
        "annual_return_eq = None\n",
        "if \"Equal_Weight_Return\" in combined_df.columns:\n",
        "    annual_return_eq = combined_df.groupby(\"Year\")[\"Equal_Weight_Return\"].apply(annual_return)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4) Compute Annual Returns for Each Factor in FACTORS:\n",
        "# -------------------------------------------------\n",
        "annual_returns_factors = {}\n",
        "for factor in FACTORS:\n",
        "    if factor in combined_df.columns:\n",
        "        annual_returns_factors[factor] = combined_df.groupby(\"Year\")[factor].apply(annual_return)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5) Compute Excess Returns for each ML model relative to each factor.\n",
        "#    Excess = (ML Model Annual Return) - (Factor Annual Return)\n",
        "# -------------------------------------------------\n",
        "excess_returns = {}\n",
        "for ml_col, ml_series in annual_returns_ml.items():\n",
        "    df_excess = pd.DataFrame(index=ml_series.index)\n",
        "    for factor, factor_series in annual_returns_factors.items():\n",
        "        df_excess[f\"Excess ({ml_col} - {factor})\"] = ml_series - factor_series\n",
        "    excess_returns[ml_col] = df_excess\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 6) Build a Summary Table of Annual Returns for all Strategies\n",
        "# -------------------------------------------------\n",
        "years = sorted(combined_df['Year'].unique())\n",
        "annual_summary = pd.DataFrame(index=years)\n",
        "\n",
        "# Add ML model returns.\n",
        "for ml_col, series in annual_returns_ml.items():\n",
        "    annual_summary[ml_col] = series\n",
        "\n",
        "# Add benchmark return if available.\n",
        "if annual_return_bench is not None:\n",
        "    annual_summary[\"Benchmark Return\"] = annual_return_bench\n",
        "\n",
        "# Add equal weight return if available.\n",
        "if annual_return_eq is not None:\n",
        "    annual_summary[\"Equal_Weight_Return\"] = annual_return_eq\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 7) Display the Summary Table and (optionally) Excess Returns for the First ML Model\n",
        "# -------------------------------------------------\n",
        "print(\"Annual Returns Summary:\")\n",
        "display(annual_summary.round(3))\n",
        "\n",
        "# Optionally, display excess returns for the first ML model.\n",
        "first_ml_col = ml_cols[0] if ml_cols else None\n",
        "if first_ml_col is not None:\n",
        "    print(f\"\\nExcess Returns for {first_ml_col}:\")\n",
        "    display(excess_returns[first_ml_col].round(3))\n"
      ],
      "metadata": {
        "id": "_KfEgK83EKLT"
      },
      "id": "_KfEgK83EKLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corr Heat map & regiimi sharpet\n"
      ],
      "metadata": {
        "id": "WnQxAZGgWuKt"
      },
      "id": "WnQxAZGgWuKt"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = xls_file.parse(SHEET_NAME)\n",
        "df = df[[\"Date\"] + FACTORS]\n",
        "\n",
        "# Calculate correlations\n",
        "correlation_matrix = df[FACTORS].corr()\n",
        "\n",
        "# Show regular correlation table\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap of Factors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "trQUVO-yLcAS"
      },
      "id": "trQUVO-yLcAS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1) Clone or pull your repo ---\n",
        "repo_url  = \"https://github.com/Elkkujou/Gradu.git\"\n",
        "repo_name = \"Gradu\"\n",
        "\n",
        "if os.path.exists(repo_name):\n",
        "    subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "\n",
        "# --- 2) Load the Excel sheet into data_ff5 ---\n",
        "xlsx_path = os.path.join(repo_name, \"THE_2ND_latest.xlsx\")\n",
        "xls_file  = pd.ExcelFile(xlsx_path)\n",
        "\n",
        "SHEET_NAME  = \"ajodata_FF5\"\n",
        "data_ff5    = xls_file.parse(SHEET_NAME)\n",
        "\n",
        "# --- 3) Parse the date column (assumed to be the first column) ---\n",
        "date_col = data_ff5.columns[0]\n",
        "data_ff5[date_col] = pd.to_datetime(data_ff5[date_col])\n",
        "\n",
        "# --- 4) Compute zâ€‘scores for your four features ---\n",
        "FEATURES = ['CPI%','T10Y3', 'CFNAI', 'GARCH_1M']\n",
        "z_cols   = [f + '_z' for f in FEATURES]\n",
        "\n",
        "# Crossâ€‘sample zâ€‘score: (x â€“ mean) / std\n",
        "data_ff5[z_cols] = data_ff5[FEATURES].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "# --- 5) Quick check ---\n",
        "print(data_ff5.loc[:, FEATURES + z_cols].head(10))"
      ],
      "metadata": {
        "id": "Nbkz9QHj6yph"
      },
      "id": "Nbkz9QHj6yph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Make sure your Date column is datetime and set as index\n",
        "data_ff5['Date'] = pd.to_datetime(data_ff5.iloc[:, 0])\n",
        "data_ff5.set_index('Date', inplace=True)\n",
        "\n",
        "# 2) Define features and their zâ€‘score column names\n",
        "\n",
        "z_cols   = [f + '_z' for f in FEATURES]\n",
        "\n",
        "# 3) (Reâ€‘)compute zâ€‘scores if you havenâ€™t yet\n",
        "data_ff5[z_cols] = data_ff5[FEATURES].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "# 4) Plot each in its own figure\n",
        "for feat, zc in zip(FEATURES, z_cols):\n",
        "    median_val = data_ff5[zc].median()\n",
        "\n",
        "    plt.figure()                          # new figure for each chart\n",
        "    plt.plot(data_ff5.index, data_ff5[zc], label=f'{feat} Zâ€‘Score')\n",
        "    plt.axhline(0,        linewidth=1,   label='Zero')\n",
        "    plt.axhline(median_val, linestyle='--', linewidth=1, label=f'Median = {median_val:.2f}')\n",
        "\n",
        "    plt.title(f'{feat} Zâ€‘Score Over Time')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Zâ€‘Score')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BqHRQ1Fk7ujB"
      },
      "id": "BqHRQ1Fk7ujB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Define your features and factors\n",
        "\n",
        "ZCOLS    = [f + '_z' for f in FEATURES]\n",
        "FACTORS  = ['SMB', 'HML', 'CMA', 'RMW']\n",
        "\n",
        "# 2) Prepare an empty DataFrame to hold Sharpe ratios\n",
        "cols = []\n",
        "for feat in FEATURES:\n",
        "    cols += [f\"{feat} > 0 SR\", f\"{feat} < 0 SR\"]\n",
        "sharpe_df = pd.DataFrame(index=FACTORS, columns=cols, dtype=float)\n",
        "\n",
        "# 3) Compute annualized Sharpe = âˆš12 * mean(return) / std(return)\n",
        "for feat, zcol in zip(FEATURES, ZCOLS):\n",
        "    for fac in FACTORS:\n",
        "        mask_pos = data_ff5[zcol] > 0\n",
        "        mask_neg = ~mask_pos\n",
        "\n",
        "        r_pos = data_ff5.loc[mask_pos, fac]\n",
        "        r_neg = data_ff5.loc[mask_neg, fac]\n",
        "\n",
        "        # avoid division by zero\n",
        "        sr_pos = np.sqrt(12) * r_pos.mean() / r_pos.std() if r_pos.std() != 0 else np.nan\n",
        "        sr_neg = np.sqrt(12) * r_neg.mean() / r_neg.std() if r_neg.std() != 0 else np.nan\n",
        "\n",
        "        sharpe_df.loc[fac, f\"{feat} > 0 SR\"] = sr_pos\n",
        "        sharpe_df.loc[fac, f\"{feat} < 0 SR\"] = sr_neg\n",
        "\n",
        "# 4) Round and display\n",
        "sharpe_df = sharpe_df.round(3)\n",
        "print(sharpe_df)"
      ],
      "metadata": {
        "id": "2HuD8lXC8Z2X"
      },
      "id": "2HuD8lXC8Z2X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell X: Combined avg factorâ€weights per featureâ€level, across all models\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# 1) Compute avg_weight_results for each model (if you haven't already)\n",
        "avg_weight_results = {}\n",
        "for model_name, df in results_dfs.items():\n",
        "    df = df.copy()\n",
        "    # find your featureâ€level cols & compute their zâ€scores\n",
        "    feat_lvl_cols = [c for c in df.columns if c.startswith(\"Feature_Level_\")]\n",
        "    z_cols        = [c + \"_z\" for c in feat_lvl_cols]\n",
        "    df[z_cols]    = df[feat_lvl_cols].apply(lambda x: (x - x.mean())/x.std())\n",
        "\n",
        "    # explode the probabilityâ€lists into a DataFrame\n",
        "    probs = pd.DataFrame(\n",
        "        df[\"Predicted_Probabilities\"].tolist(),\n",
        "        index=df.index,\n",
        "        columns=FACTORS\n",
        "    )\n",
        "\n",
        "    # build perâ€feature tables\n",
        "    feature_tables = {}\n",
        "    for lvl_col, zcol in zip(feat_lvl_cols, z_cols):\n",
        "        avg_high = probs[df[zcol] > 0].mean()\n",
        "        avg_low  = probs[df[zcol] <= 0].mean()\n",
        "        feature_tables[lvl_col] = pd.DataFrame({\n",
        "            \"Above_0_z\":       avg_high,\n",
        "            \"Below_or_eq_0_z\": avg_low\n",
        "        })\n",
        "    avg_weight_results[model_name] = feature_tables\n",
        "\n",
        "# 2) Get the list of feature-level keys from any one model\n",
        "feat_lvl_cols = list(next(iter(avg_weight_results.values())).keys())\n",
        "\n",
        "# 3) For each featureâ€level, stitch together all models into one table\n",
        "for lvl_col in feat_lvl_cols:\n",
        "    combined = pd.DataFrame(index=FACTORS)\n",
        "    for model_name, tables in avg_weight_results.items():\n",
        "        tbl = tables[lvl_col].rename(columns={\n",
        "            \"Above_0_z\":       f\"{model_name} Above_0_z\",\n",
        "            \"Below_or_eq_0_z\": f\"{model_name} Below_or_eq_0_z\"\n",
        "        })\n",
        "        combined = combined.join(tbl, how=\"outer\")\n",
        "\n",
        "    print(f\"\\n=== {lvl_col} ===\")\n",
        "    display(combined)\n"
      ],
      "metadata": {
        "id": "M_VwB7Mw6WI7"
      },
      "id": "M_VwB7Mw6WI7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Regime-wise Correlation Heatmaps\n",
        "#\n",
        "# For the selected return columns, compute and plot the correlation matrix\n",
        "# for each market regime as a heatmap.\n",
        "\n",
        "# %%\n",
        "# Use the global FACTORS instead of redefining returns_columns\n",
        "unique_regimes = df[REGIMES_COLUMN].unique()\n",
        "for regime in unique_regimes:\n",
        "    regime_data = df[df[REGIMES_COLUMN] == regime][FACTORS]\n",
        "    corr = regime_data.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "    plt.title(f\"Return Correlation Heatmap - {regime}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4GbzDKk2FZYH"
      },
      "id": "4GbzDKk2FZYH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Sharpe Ratios by Market Regime\n",
        "#\n",
        "# Compute and visualize Sharpe ratios for selected factors across each regime,\n",
        "# as well as the unconditional (all-data) values, using a bar chart.\n",
        "# The numeric regime codes are converted back to their original names using the regime_mapping,\n",
        "# and then further shortened using regime_short_mapping.\n",
        "\n",
        "# %%\n",
        "# Define factors and regime columns (using global variables if already defined)\n",
        "factors_columns = FACTORS\n",
        "regimes_column = REGIMES_COLUMN   # Assumes REGIMES_COLUMN was defined earlier\n",
        "\n",
        "# Use the previously created regime_short_mapping to convert numeric codes back to short names.\n",
        "# (If a code is not in regime_short_mapping, it will default to \"Regime <code>\")\n",
        "regime_short_names = {reg: regime_short_mapping.get(reg, f\"Regime {reg}\")\n",
        "                      for reg in df[regimes_column].unique()}\n",
        "\n",
        "sharpe_ratios = {\n",
        "    regime_short_names[regime]: (\n",
        "        df[df[regimes_column] == regime][factors_columns].mean() /\n",
        "        df[df[regimes_column] == regime][factors_columns].std()\n",
        "    )\n",
        "    for regime in df[regimes_column].unique()\n",
        "}\n",
        "\n",
        "# Calculate the \"Unconditional\" Sharpe ratios (using all data)\n",
        "sharpe_ratios[\"Unconditional\"] = df[factors_columns].mean() / df[factors_columns].std()\n",
        "\n",
        "# Convert the dictionary to a DataFrame and set column names\n",
        "sharpe_ratios_df = pd.DataFrame(sharpe_ratios).T\n",
        "sharpe_ratios_df.columns = factors_columns\n",
        "\n",
        "# Plot the Sharpe ratios using the same styling as before.\n",
        "plt.figure(figsize=(14, 8))\n",
        "sharpe_ratios_df.plot(\n",
        "    kind=\"bar\",\n",
        "    grid=True,\n",
        "    colormap=\"viridis\",\n",
        "    title=\"Sharpe Ratios by Regime and Unconditional\",\n",
        "    figsize=(14, 8)\n",
        ")\n",
        "plt.ylabel(\"Sharpe Ratio\", fontsize=12)\n",
        "plt.xlabel(\"Market Regimes\", fontsize=12)\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.legend(title=\"Factors\", fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GCkBikW6A2o0"
      },
      "id": "GCkBikW6A2o0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature importance by period"
      ],
      "metadata": {
        "id": "SwsjcsWyoH2Z"
      },
      "id": "SwsjcsWyoH2Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======= USER-DEFINED DATE RANGE =======\n",
        "# Adjust these dates to view feature importances for a specific period\n",
        "start_date = pd.to_datetime('2020-01-01')\n",
        "end_date   = pd.to_datetime('2022-12-31')\n",
        "\n",
        "# ======= Filter the Data =======\n",
        "# Filter the results_df for the specified date range based on the 'Predicted_month' column\n",
        "filtered_results_df = results_df[\n",
        "    (results_df['Predicted_month'] >= start_date) &\n",
        "    (results_df['Predicted_month'] <= end_date)\n",
        "]\n",
        "\n",
        "# ======= Get Unique Regimes and Feature Count =======\n",
        "existing_regimes = filtered_results_df['Regime'].unique()\n",
        "n_regimes = len(existing_regimes)\n",
        "n_features = len(filtered_results_df['Feature_Importances'].iloc[0])  # Assumes each entry is a vector\n",
        "\n",
        "# ======= Robust Feature Naming =======\n",
        "try:\n",
        "    # Validate if the predefined FEATURES list matches the actual feature count\n",
        "    if len(FEATURES) != n_features:\n",
        "        print(f\"âš ï¸ Warning: FEATURES list length ({len(FEATURES)}) doesn't match model features ({n_features}).\")\n",
        "        print(\"Using auto-generated feature names instead.\")\n",
        "        raise ValueError\n",
        "    feature_names = FEATURES\n",
        "except (NameError, ValueError):\n",
        "    # Generate default feature names if there's a mismatch or if FEATURES is undefined\n",
        "    feature_names = [f'Feature {i+1}' for i in range(n_features)]\n",
        "    print(f\"Using auto-generated feature names for {n_features} features.\")\n",
        "\n",
        "# ======= Compute Overall Average Feature Importances =======\n",
        "overall_avg_fi = np.vstack(filtered_results_df['Feature_Importances'].values).mean(axis=0)\n",
        "\n",
        "# ======= Compute Regime-Specific Average Feature Importances =======\n",
        "regime_avg_fi = {}\n",
        "for regime_name in existing_regimes:\n",
        "    regime_df = filtered_results_df[filtered_results_df['Regime'] == regime_name]\n",
        "    regime_fi_array = np.vstack(regime_df['Feature_Importances'].values)\n",
        "    regime_avg_fi[regime_name] = regime_fi_array.mean(axis=0)\n",
        "\n",
        "# ======= Sort Features by Overall Importance (Descending) =======\n",
        "sorted_idx = overall_avg_fi.argsort()[::-1]\n",
        "sorted_idx = sorted_idx[sorted_idx < len(feature_names)]  # Ensure index bounds\n",
        "sorted_features = [feature_names[i] for i in sorted_idx]\n",
        "\n",
        "# ======= Plotting =======\n",
        "if n_regimes > 1:\n",
        "    total_plots = 1 + n_regimes  # One overall plot plus one for each regime\n",
        "    row_height = max(0.3 * n_features, 4)\n",
        "    fig, axs = plt.subplots(\n",
        "        total_plots,\n",
        "        1,\n",
        "        figsize=(19.5, total_plots * row_height),\n",
        "        gridspec_kw={'hspace': 0.4}\n",
        "    )\n",
        "    if total_plots == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    # --- Overall Feature Importances ---\n",
        "    axs[0].barh(\n",
        "        np.arange(n_features),\n",
        "        overall_avg_fi[sorted_idx],\n",
        "        color='steelblue',\n",
        "        edgecolor='black'\n",
        "    )\n",
        "    axs[0].set_yticks(np.arange(n_features))\n",
        "    axs[0].set_yticklabels(sorted_features)\n",
        "    axs[0].set_title(\"Overall Average Feature Importances\", pad=12)\n",
        "    axs[0].set_xlabel(\"Average Importance\")\n",
        "    axs[0].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # --- Regime-Specific Feature Importances ---\n",
        "    for idx, (regime_name, avg_fi) in enumerate(regime_avg_fi.items(), start=1):\n",
        "        sorted_regime_fi = avg_fi[sorted_idx]\n",
        "        axs[idx].barh(\n",
        "            np.arange(n_features),\n",
        "            sorted_regime_fi,\n",
        "            color='salmon',\n",
        "            edgecolor='black'\n",
        "        )\n",
        "        axs[idx].set_yticks(np.arange(n_features))\n",
        "        axs[idx].set_yticklabels(sorted_features)\n",
        "        axs[idx].set_title(f\"Feature Importances: {regime_name} Regime\", pad=12)\n",
        "        axs[idx].set_xlabel(\"Average Importance\")\n",
        "        axs[idx].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "else:\n",
        "    # If zero or one regime, show only the overall chart\n",
        "    row_height = max(0.3 * n_features, 4)\n",
        "    fig, ax = plt.subplots(\n",
        "        1, 1, figsize=(19.5, row_height),\n",
        "        gridspec_kw={'hspace': 0.4}\n",
        "    )\n",
        "    ax.barh(\n",
        "        np.arange(n_features),\n",
        "        overall_avg_fi[sorted_idx],\n",
        "        color='steelblue',\n",
        "        edgecolor='black'\n",
        "    )\n",
        "    ax.set_yticks(np.arange(n_features))\n",
        "    ax.set_yticklabels(sorted_features)\n",
        "    ax.set_title(\"Overall Average Feature Importances (No Multiple Regimes)\", pad=12)\n",
        "    ax.set_xlabel(\"Average Importance\")\n",
        "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout(pad=4.0)\n",
        "plt.subplots_adjust(left=0.3)  # Extra space for feature labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XgeSIiAu-M2b"
      },
      "id": "XgeSIiAu-M2b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e48b8849ed8d4c6f8bf5e37d00360566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efd11c641b61473db4347b0d90c95e9b",
              "IPY_MODEL_6ca13ab2bbd74e6ba8ce6a3c35f9124b",
              "IPY_MODEL_4bd7ecbf6ea84721ba80762657f1727d"
            ],
            "layout": "IPY_MODEL_846a31c1bcb64bfaa434e1912df3c121"
          }
        },
        "efd11c641b61473db4347b0d90c95e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "1972-04-30",
              "1972-05-30",
              "1972-06-30",
              "1972-07-30",
              "1972-08-30",
              "1972-09-30",
              "1972-10-30",
              "1972-11-30",
              "1972-12-30",
              "1973-01-30",
              "1973-02-28",
              "1973-03-30",
              "1973-04-30",
              "1973-05-30",
              "1973-06-30",
              "1973-07-30",
              "1973-08-30",
              "1973-09-30",
              "1973-10-30",
              "1973-11-30",
              "1973-12-30",
              "1974-01-30",
              "1974-02-28",
              "1974-03-30",
              "1974-04-30",
              "1974-05-30",
              "1974-06-30",
              "1974-07-30",
              "1974-08-30",
              "1974-09-30",
              "1974-10-30",
              "1974-11-30",
              "1974-12-30",
              "1975-01-30",
              "1975-02-28",
              "1975-03-30",
              "1975-04-30",
              "1975-05-30",
              "1975-06-30",
              "1975-07-30",
              "1975-08-30",
              "1975-09-30",
              "1975-10-30",
              "1975-11-30",
              "1975-12-30",
              "1976-01-30",
              "1976-02-29",
              "1976-03-30",
              "1976-04-30",
              "1976-05-30",
              "1976-06-30",
              "1976-07-30",
              "1976-08-30",
              "1976-09-30",
              "1976-10-30",
              "1976-11-30",
              "1976-12-30",
              "1977-01-30",
              "1977-02-28",
              "1977-03-30",
              "1977-04-30",
              "1977-05-30",
              "1977-06-30",
              "1977-07-30",
              "1977-08-30",
              "1977-09-30",
              "1977-10-30",
              "1977-11-30",
              "1977-12-30",
              "1978-01-30",
              "1978-02-28",
              "1978-03-30",
              "1978-04-30",
              "1978-05-30",
              "1978-06-30",
              "1978-07-30",
              "1978-08-30",
              "1978-09-30",
              "1978-10-30",
              "1978-11-30",
              "1978-12-30",
              "1979-01-30",
              "1979-02-28",
              "1979-03-30",
              "1979-04-30",
              "1979-05-30",
              "1979-06-30",
              "1979-07-30",
              "1979-08-30",
              "1979-09-30",
              "1979-10-30",
              "1979-11-30",
              "1979-12-30",
              "1980-01-30",
              "1980-02-29",
              "1980-03-30",
              "1980-04-30",
              "1980-05-30",
              "1980-06-30",
              "1980-07-30",
              "1980-08-30",
              "1980-09-30",
              "1980-10-30",
              "1980-11-30",
              "1980-12-30",
              "1981-01-30",
              "1981-02-28",
              "1981-03-30",
              "1981-04-30",
              "1981-05-30",
              "1981-06-30",
              "1981-07-30",
              "1981-08-30",
              "1981-09-30",
              "1981-10-30",
              "1981-11-30",
              "1981-12-30",
              "1982-01-30",
              "1982-02-28",
              "1982-03-30",
              "1982-04-30",
              "1982-05-30",
              "1982-06-30",
              "1982-07-30",
              "1982-08-30",
              "1982-09-30",
              "1982-10-30",
              "1982-11-30",
              "1982-12-30",
              "1983-01-30",
              "1983-02-28",
              "1983-03-30",
              "1983-04-30",
              "1983-05-30",
              "1983-06-30",
              "1983-07-30",
              "1983-08-30",
              "1983-09-30",
              "1983-10-30",
              "1983-11-30",
              "1983-12-30",
              "1984-01-30",
              "1984-02-29",
              "1984-03-30",
              "1984-04-30",
              "1984-05-30",
              "1984-06-30",
              "1984-07-30",
              "1984-08-30",
              "1984-09-30",
              "1984-10-30",
              "1984-11-30",
              "1984-12-30",
              "1985-01-30",
              "1985-02-28",
              "1985-03-30",
              "1985-04-30",
              "1985-05-30",
              "1985-06-30",
              "1985-07-30",
              "1985-08-30",
              "1985-09-30",
              "1985-10-30",
              "1985-11-30",
              "1985-12-30",
              "1986-01-30",
              "1986-02-28",
              "1986-03-30",
              "1986-04-30",
              "1986-05-30",
              "1986-06-30",
              "1986-07-30",
              "1986-08-30",
              "1986-09-30",
              "1986-10-30",
              "1986-11-30",
              "1986-12-30",
              "1987-01-30",
              "1987-02-28",
              "1987-03-30",
              "1987-04-30",
              "1987-05-30",
              "1987-06-30",
              "1987-07-30",
              "1987-08-30",
              "1987-09-30",
              "1987-10-30",
              "1987-11-30",
              "1987-12-30",
              "1988-01-30",
              "1988-02-29",
              "1988-03-30",
              "1988-04-30",
              "1988-05-30",
              "1988-06-30",
              "1988-07-30",
              "1988-08-30",
              "1988-09-30",
              "1988-10-30",
              "1988-11-30",
              "1988-12-30",
              "1989-01-30",
              "1989-02-28",
              "1989-03-30",
              "1989-04-30",
              "1989-05-30",
              "1989-06-30",
              "1989-07-30",
              "1989-08-30",
              "1989-09-30",
              "1989-10-30",
              "1989-11-30",
              "1989-12-30",
              "1990-01-30",
              "1990-02-28",
              "1990-03-30",
              "1990-04-30",
              "1990-05-30",
              "1990-06-30",
              "1990-07-30",
              "1990-08-30",
              "1990-09-30",
              "1990-10-30",
              "1990-11-30",
              "1990-12-30",
              "1991-01-30",
              "1991-02-28",
              "1991-03-30",
              "1991-04-30",
              "1991-05-30",
              "1991-06-30",
              "1991-07-30",
              "1991-08-30",
              "1991-09-30",
              "1991-10-30",
              "1991-11-30",
              "1991-12-30",
              "1992-01-30",
              "1992-02-29",
              "1992-03-30",
              "1992-04-30",
              "1992-05-30",
              "1992-06-30",
              "1992-07-30",
              "1992-08-30",
              "1992-09-30",
              "1992-10-30",
              "1992-11-30",
              "1992-12-30",
              "1993-01-30",
              "1993-02-28",
              "1993-03-30",
              "1993-04-30",
              "1993-05-30",
              "1993-06-30",
              "1993-07-30",
              "1993-08-30",
              "1993-09-30",
              "1993-10-30",
              "1993-11-30",
              "1993-12-30",
              "1994-01-30",
              "1994-02-28",
              "1994-03-30",
              "1994-04-30",
              "1994-05-30",
              "1994-06-30",
              "1994-07-30",
              "1994-08-30",
              "1994-09-30",
              "1994-10-30",
              "1994-11-30",
              "1994-12-30",
              "1995-01-30",
              "1995-02-28",
              "1995-03-30",
              "1995-04-30",
              "1995-05-30",
              "1995-06-30",
              "1995-07-30",
              "1995-08-30",
              "1995-09-30",
              "1995-10-30",
              "1995-11-30",
              "1995-12-30",
              "1996-01-30",
              "1996-02-29",
              "1996-03-30",
              "1996-04-30",
              "1996-05-30",
              "1996-06-30",
              "1996-07-30",
              "1996-08-30",
              "1996-09-30",
              "1996-10-30",
              "1996-11-30",
              "1996-12-30",
              "1997-01-30",
              "1997-02-28",
              "1997-03-30",
              "1997-04-30",
              "1997-05-30",
              "1997-06-30",
              "1997-07-30",
              "1997-08-30",
              "1997-09-30",
              "1997-10-30",
              "1997-11-30",
              "1997-12-30",
              "1998-01-30",
              "1998-02-28",
              "1998-03-30",
              "1998-04-30",
              "1998-05-30",
              "1998-06-30",
              "1998-07-30",
              "1998-08-30",
              "1998-09-30",
              "1998-10-30",
              "1998-11-30",
              "1998-12-30",
              "1999-01-30",
              "1999-02-28",
              "1999-03-30",
              "1999-04-30",
              "1999-05-30",
              "1999-06-30",
              "1999-07-30",
              "1999-08-30",
              "1999-09-30",
              "1999-10-30",
              "1999-11-30",
              "1999-12-30",
              "2000-01-30",
              "2000-02-29",
              "2000-03-30",
              "2000-04-30",
              "2000-05-30",
              "2000-06-30",
              "2000-07-30",
              "2000-08-30",
              "2000-09-30",
              "2000-10-30",
              "2000-11-30",
              "2000-12-30",
              "2001-01-30",
              "2001-02-28",
              "2001-03-30",
              "2001-04-30",
              "2001-05-30",
              "2001-06-30",
              "2001-07-30",
              "2001-08-30",
              "2001-09-30",
              "2001-10-30",
              "2001-11-30",
              "2001-12-30",
              "2002-01-30",
              "2002-02-28",
              "2002-03-30",
              "2002-04-30",
              "2002-05-30",
              "2002-06-30",
              "2002-07-30",
              "2002-08-30",
              "2002-09-30",
              "2002-10-30",
              "2002-11-30",
              "2002-12-30",
              "2003-01-30",
              "2003-02-28",
              "2003-03-30",
              "2003-04-30",
              "2003-05-30",
              "2003-06-30",
              "2003-07-30",
              "2003-08-30",
              "2003-09-30",
              "2003-10-30",
              "2003-11-30",
              "2003-12-30",
              "2004-01-30",
              "2004-02-29",
              "2004-03-30",
              "2004-04-30",
              "2004-05-30",
              "2004-06-30",
              "2004-07-30",
              "2004-08-30",
              "2004-09-30",
              "2004-10-30",
              "2004-11-30",
              "2004-12-30",
              "2005-01-30",
              "2005-02-28",
              "2005-03-30",
              "2005-04-30",
              "2005-05-30",
              "2005-06-30",
              "2005-07-30",
              "2005-08-30",
              "2005-09-30",
              "2005-10-30",
              "2005-11-30",
              "2005-12-30",
              "2006-01-30",
              "2006-02-28",
              "2006-03-30",
              "2006-04-30",
              "2006-05-30",
              "2006-06-30",
              "2006-07-30",
              "2006-08-30",
              "2006-09-30",
              "2006-10-30",
              "2006-11-30",
              "2006-12-30",
              "2007-01-30",
              "2007-02-28",
              "2007-03-30",
              "2007-04-30",
              "2007-05-30",
              "2007-06-30",
              "2007-07-30",
              "2007-08-30",
              "2007-09-30",
              "2007-10-30",
              "2007-11-30",
              "2007-12-30",
              "2008-01-30",
              "2008-02-29",
              "2008-03-30",
              "2008-04-30",
              "2008-05-30",
              "2008-06-30",
              "2008-07-30",
              "2008-08-30",
              "2008-09-30",
              "2008-10-30",
              "2008-11-30",
              "2008-12-30",
              "2009-01-30",
              "2009-02-28",
              "2009-03-30",
              "2009-04-30",
              "2009-05-30",
              "2009-06-30",
              "2009-07-30",
              "2009-08-30",
              "2009-09-30",
              "2009-10-30",
              "2009-11-30",
              "2009-12-30",
              "2010-01-30",
              "2010-02-28",
              "2010-03-30",
              "2010-04-30",
              "2010-05-30",
              "2010-06-30",
              "2010-07-30",
              "2010-08-30",
              "2010-09-30",
              "2010-10-30",
              "2010-11-30",
              "2010-12-30",
              "2011-01-30",
              "2011-02-28",
              "2011-03-30",
              "2011-04-30",
              "2011-05-30",
              "2011-06-30",
              "2011-07-30",
              "2011-08-30",
              "2011-09-30",
              "2011-10-30",
              "2011-11-30",
              "2011-12-30",
              "2012-01-30",
              "2012-02-29",
              "2012-03-30",
              "2012-04-30",
              "2012-05-30",
              "2012-06-30",
              "2012-07-30",
              "2012-08-30",
              "2012-09-30",
              "2012-10-30",
              "2012-11-30",
              "2012-12-30",
              "2013-01-30",
              "2013-02-28",
              "2013-03-30",
              "2013-04-30",
              "2013-05-30",
              "2013-06-30",
              "2013-07-30",
              "2013-08-30",
              "2013-09-30",
              "2013-10-30",
              "2013-11-30",
              "2013-12-30",
              "2014-01-30",
              "2014-02-28",
              "2014-03-30",
              "2014-04-30",
              "2014-05-30",
              "2014-06-30",
              "2014-07-30",
              "2014-08-30",
              "2014-09-30",
              "2014-10-30",
              "2014-11-30",
              "2014-12-30",
              "2015-01-30",
              "2015-02-28",
              "2015-03-30",
              "2015-04-30",
              "2015-05-30",
              "2015-06-30",
              "2015-07-30",
              "2015-08-30",
              "2015-09-30",
              "2015-10-30",
              "2015-11-30",
              "2015-12-30",
              "2016-01-30",
              "2016-02-29",
              "2016-03-30",
              "2016-04-30",
              "2016-05-30",
              "2016-06-30",
              "2016-07-30",
              "2016-08-30",
              "2016-09-30",
              "2016-10-30",
              "2016-11-30",
              "2016-12-30",
              "2017-01-30",
              "2017-02-28",
              "2017-03-30",
              "2017-04-30",
              "2017-05-30",
              "2017-06-30",
              "2017-07-30",
              "2017-08-30",
              "2017-09-30",
              "2017-10-30",
              "2017-11-30",
              "2017-12-30",
              "2018-01-30",
              "2018-02-28",
              "2018-03-30",
              "2018-04-30",
              "2018-05-30",
              "2018-06-30",
              "2018-07-30",
              "2018-08-30",
              "2018-09-30",
              "2018-10-30",
              "2018-11-30",
              "2018-12-30",
              "2019-01-30",
              "2019-02-28",
              "2019-03-30",
              "2019-04-30",
              "2019-05-30",
              "2019-06-30",
              "2019-07-30",
              "2019-08-30",
              "2019-09-30",
              "2019-10-30",
              "2019-11-30",
              "2019-12-30",
              "2020-01-30",
              "2020-02-29",
              "2020-03-30",
              "2020-04-30",
              "2020-05-30",
              "2020-06-30",
              "2020-07-30",
              "2020-08-30",
              "2020-09-30",
              "2020-10-30",
              "2020-11-30",
              "2020-12-30",
              "2021-01-30",
              "2021-02-28",
              "2021-03-30",
              "2021-04-30",
              "2021-05-30",
              "2021-06-30",
              "2021-07-30",
              "2021-08-30",
              "2021-09-30",
              "2021-10-30",
              "2021-11-30",
              "2021-12-30",
              "2022-01-30",
              "2022-02-28",
              "2022-03-30",
              "2022-04-30",
              "2022-05-30",
              "2022-06-30",
              "2022-07-30",
              "2022-08-30",
              "2022-09-30",
              "2022-10-30",
              "2022-11-30",
              "2022-12-30",
              "2023-01-30",
              "2023-02-28",
              "2023-03-30",
              "2023-04-30",
              "2023-05-30",
              "2023-06-30",
              "2023-07-30",
              "2023-08-30",
              "2023-09-30",
              "2023-10-30",
              "2023-11-30",
              "2023-12-30",
              "2024-01-30",
              "2024-02-29",
              "2024-03-30",
              "2024-04-30",
              "2024-05-30",
              "2024-06-30",
              "2024-07-30",
              "2024-08-30",
              "2024-09-30",
              "2024-10-30",
              "2024-11-30"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Date:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_dc4e8cb0949646bcb877d6980c46066c",
            "style": "IPY_MODEL_85dbe666241343c2820fd4410d53b580"
          }
        },
        "6ca13ab2bbd74e6ba8ce6a3c35f9124b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "Tree #:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e1f0ae204c624361bd11f6860b23e65b",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_21508da16fc3437f999fdc7b5557ec08",
            "value": 0
          }
        },
        "4bd7ecbf6ea84721ba80762657f1727d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_28028ef84fae4c7b9fbaf48524d74dab",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<Figure size 2000x1000 with 1 Axes>",
                  "image/png": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "846a31c1bcb64bfaa434e1912df3c121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4e8cb0949646bcb877d6980c46066c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85dbe666241343c2820fd4410d53b580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1f0ae204c624361bd11f6860b23e65b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21508da16fc3437f999fdc7b5557ec08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "28028ef84fae4c7b9fbaf48524d74dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56a5d6e7319430dabb0a7aef63c11ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f89a04c7f1184887945ccbede683e49b",
              "IPY_MODEL_c9a86301b74e4ccc8455e3f5720988c0",
              "IPY_MODEL_4274eea20031495c9f1caf81b06f9f12"
            ],
            "layout": "IPY_MODEL_ba1e634ff1334faabb25f755491b84e6"
          }
        },
        "f89a04c7f1184887945ccbede683e49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DatePickerModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DatePickerModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DatePickerView",
            "description": "Start:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e416a2d9a6f640a085cfa0e9dc05ef0c",
            "style": "IPY_MODEL_5807ba9bf83f40858e183e8c7bd69601",
            "value": {
              "year": 1972,
              "month": 3,
              "date": 30
            }
          }
        },
        "c9a86301b74e4ccc8455e3f5720988c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DatePickerModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DatePickerModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DatePickerView",
            "description": "End:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_637624cb29e540c3b1f0100c25fc9adc",
            "style": "IPY_MODEL_f6cb411b573c425bb396d126043044cf",
            "value": {
              "year": 2024,
              "month": 10,
              "date": 30
            }
          }
        },
        "4274eea20031495c9f1caf81b06f9f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "average",
              "mean",
              "sum"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Aggregate:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_0962c0db8b5346b0b3da451fc70b08ec",
            "style": "IPY_MODEL_7a83ccaaf44b454b81d427a779723cfa"
          }
        },
        "ba1e634ff1334faabb25f755491b84e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e416a2d9a6f640a085cfa0e9dc05ef0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5807ba9bf83f40858e183e8c7bd69601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "637624cb29e540c3b1f0100c25fc9adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cb411b573c425bb396d126043044cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0962c0db8b5346b0b3da451fc70b08ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a83ccaaf44b454b81d427a779723cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6249650a411d4a269fe4b23b0377d880": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fc59347eb9134218825334d9ce887c8a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<Figure size 1000x200 with 1 Axes>",
                  "image/png": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "fc59347eb9134218825334d9ce887c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}