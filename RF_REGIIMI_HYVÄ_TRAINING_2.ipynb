{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IDEAT: Vix takas? Joku momentum indikaattori? Sentimentti?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mqpPtrCOkXAO"
      },
      "id": "mqpPtrCOkXAO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model settings"
      ],
      "metadata": {
        "id": "k1mEzhhWXup6"
      },
      "id": "k1mEzhhWXup6"
    },
    {
      "cell_type": "code",
      "source": [
        "use_regime_split = False\n",
        "\n",
        "#Default modelsD\n",
        "RF = True # perus random forest\n",
        "RF2 = False\n",
        "GB = False # perus gradient boost\n",
        "Hybrid = False\n",
        "\n",
        "#Looping models\n",
        "RF_feature_seek = False # random forest all combinations\n",
        "seek_all = False\n",
        "gb_loop = False\n",
        "\n",
        "#DATA\n",
        "FF5 = False\n",
        "FF5_long = False\n",
        "MSCI = False\n",
        "EX_USA = False\n",
        "Bonds = True\n",
        "\n",
        "RSI = False\n",
        "\n",
        "local = False #ajetaanko colab vai oma kone\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AF3FdwvaLPp"
      },
      "id": "-AF3FdwvaLPp",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify active model flags\n",
        "active_modes = [name for name, flag in zip(\n",
        "    ['RF', 'GB', 'RF_feature_seek', 'Hybrid', 'seek_all', 'gb_loop'],\n",
        "    [RF, GB, RF_feature_seek, Hybrid, seek_all, gb_loop]\n",
        ") if flag]\n",
        "\n",
        "if active_modes:\n",
        "    print(\"âœ… Active model modes:\", \", \".join(active_modes))\n",
        "else:\n",
        "    print(\"âš ï¸ No active model mode selected.\")\n",
        "\n",
        "# Check dataset toggles: exactly one must be True\n",
        "datasets = {\n",
        "    'FF5': FF5,\n",
        "    'FF5_long': FF5_long,\n",
        "    'MSCI': MSCI,\n",
        "    'EX_USA': EX_USA,\n",
        "    'Bonds': Bonds\n",
        "\n",
        "}\n",
        "active_datasets = [name for name, flag in datasets.items() if flag]\n",
        "\n",
        "if len(active_datasets) != 1:\n",
        "    raise ValueError(\"Error: Exactly one of [FF5, FF5_long, MSCI] must be True.\")\n",
        "else:\n",
        "    print(f\"ðŸ“Š Using dataset: {active_datasets[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ktRzXgrQHYX",
        "outputId": "51cfbafe-ae21-4b53-f82c-3679603d459a"
      },
      "id": "7ktRzXgrQHYX",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Active model modes: RF\n",
            "ðŸ“Š Using dataset: Bonds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "4085d55c-e568-465c-9bcc-6013281c105d",
      "metadata": {
        "tags": [],
        "id": "4085d55c-e568-465c-9bcc-6013281c105d"
      },
      "outputs": [],
      "source": [
        "# # Import Required Libraries\n",
        "#\n",
        "# Import all necessary libraries for data manipulation, visualization,\n",
        "# machine learning, and regression analysis.\n",
        "\n",
        "# %%\n",
        "import os\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not local:\n",
        "\n",
        "  %cd /content\n",
        "  !rm -rf Gradu\n",
        "  !git clone https://github.com/Elkkujou/Gradu.git\n",
        "  %cd /content/Gradu\n",
        "  !ls\n",
        "  xls_file = pd.ExcelFile(\"/content/Gradu/THE_2ND_latest.xlsx\")\n",
        "\n",
        "else:\n",
        "\n",
        "\n",
        "\n",
        "    repo_url = \"https://github.com/Elkkujou/Gradu.git\"\n",
        "    repo_name = \"Gradu\"  # Name of the cloned folder\n",
        "\n",
        "    # Check if the directory already exists\n",
        "    if os.path.exists(repo_name):\n",
        "        print(f\"Folder '{repo_name}' already exists. Pulling latest changes...\")\n",
        "        # Change to the existing repo folder and pull the latest updates\n",
        "        subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True)\n",
        "    else:\n",
        "        print(f\"Cloning repository into '{repo_name}'...\")\n",
        "        subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "\n",
        "    # List contents of the cloned repository\n",
        "    subprocess.run([\"ls\", repo_name], check=True)\n",
        "    xls_file = pd.ExcelFile(\"Gradu/THE_2ND_latest.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "j2fmaZCMluYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b2aef8-4d6e-418d-dc2d-8651f4b9db69"
      },
      "id": "j2fmaZCMluYf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (261/261), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if FF5:\n",
        "  SHEET_NAME = \"ajodata_FF5\"\n",
        "  FEATURES = ['CPI%','T10Y3M', 'CFNAI', 'GARCH']\n",
        "  FACTORS = [\n",
        "    'SMB',\n",
        "    'HML',\n",
        "    'CMA',\n",
        "    'RMW',\n",
        "    #'RF'\n",
        "]\n",
        "  BENCHMARK = ['Mkt']\n",
        "  show_benchmark = False"
      ],
      "metadata": {
        "id": "R_dU9PNF-Puv"
      },
      "id": "R_dU9PNF-Puv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if FF5_long:\n",
        "  SHEET_NAME = \"ajodata_FF5_long\"\n",
        "  FEATURES = ['CPI%','T10Y3M', 'CFNAI', 'GARCH']\n",
        "  FACTORS = [\n",
        "    'SMB',\n",
        "    'HML',\n",
        "    'CMA',\n",
        "    'RMW',\n",
        "    #'RF'\n",
        "]\n",
        "  BENCHMARK = ['Mkt']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "wJo52ErY-v0Q"
      },
      "id": "wJo52ErY-v0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if MSCI:\n",
        "  SHEET_NAME = \"ajodata_MSCI\"\n",
        "  FEATURES = ['CPI%','T10Y3M', 'CFNAI', 'GARCH']\n",
        "  FACTORS = [\n",
        "    'Size',\n",
        "    'value',\n",
        "    'Quality',\n",
        "    'min_vola']\n",
        "  BENCHMARK = ['Us_standard']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "AT6Cf_ge_ApN"
      },
      "id": "AT6Cf_ge_ApN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if EX_USA:\n",
        "  SHEET_NAME = \"ajodata_US\"\n",
        "  FEATURES = ['CPI%','T10Y3M', 'CFNAI', 'GARCH']\n",
        "  FACTORS = [\n",
        "    'USA',\n",
        "    'EX_USA']\n",
        "  BENCHMARK = ['Us_standard']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "BFsm9ZplEyYe"
      },
      "id": "BFsm9ZplEyYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Bonds:\n",
        "  SHEET_NAME = \"ajodata_bonds\"\n",
        "  FEATURES = ['HY spread','IG Spread', 'Expected inflation', '10-yr yield', '10-yr real yield', '3 month yield']\n",
        "  FACTORS = [\n",
        "    'Treasury',\n",
        "    #'HY',\n",
        "    'IG',\n",
        "    #'TIPS',\n",
        "    'Treasury long',\n",
        "    'T-bill']\n",
        "  BENCHMARK = ['Us_standard']\n",
        "  show_benchmark = True"
      ],
      "metadata": {
        "id": "_7amlMEf35Ji"
      },
      "id": "_7amlMEf35Ji",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "myKvXyzn34U2"
      },
      "id": "myKvXyzn34U2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare data"
      ],
      "metadata": {
        "id": "ZwuAM8venlx5"
      },
      "id": "ZwuAM8venlx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc",
      "metadata": {
        "tags": [],
        "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc"
      },
      "outputs": [],
      "source": [
        "df = xls_file.parse(SHEET_NAME)\n",
        "df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "# Print headers dynamically\n",
        "print(f\"Headers in the '{SHEET_NAME}' sheet:\")\n",
        "print(df.columns)\n",
        "\n",
        "REGIMES_COLUMN = 'Predicted_reg'\n",
        "\n",
        "# Convert the leftmost column (assumed to be the date column) to datetime\n",
        "date_column = df.columns[0]\n",
        "df[date_column] = pd.to_datetime(df[date_column])\n",
        "\n",
        "# Retrieve first and last observation dates and count observations\n",
        "first_date = df[date_column].iloc[0]\n",
        "last_date = df[date_column].iloc[-1]\n",
        "n_observations = len(df)\n",
        "\n",
        "# Create a DataFrame with the information\n",
        "info_df = pd.DataFrame({\n",
        "    \"Description\": [\"First observation date\", \"Last observation date\", \"Total number of observations\"],\n",
        "    \"Value\": [first_date, last_date, n_observations]\n",
        "})\n",
        "\n",
        "# Display the results as a neat HTML table\n",
        "display(HTML(info_df.to_html(index=False, classes=\"table table-striped\", border=0)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RSI:\n",
        "\n",
        "  # --- Add lagged 12â€‘month moving average for each factor return ---\n",
        "  for f in FACTORS:\n",
        "      # shift by 1 so that MA at time t uses returns t-12â€¦t-1\n",
        "      df[f + '_MA12'] = (\n",
        "          df[f]\n",
        "          .shift(1)                          # drop â€œtodayâ€\n",
        "          .rolling(window=12, min_periods=12)\n",
        "          .mean()\n",
        "      )\n",
        "\n",
        "  # update your FEATURES list\n",
        "  FEATURES += [f + '_MA12' for f in FACTORS]\n",
        "\n",
        "  print(\"âœ¨ Added lagged 12â€‘month MA columns:\", [f + '_MA12' for f in FACTORS])\n",
        "  print(\"ðŸ§© New FEATURES list:\", FEATURES)"
      ],
      "metadata": {
        "id": "3bGFK-QXeeDR"
      },
      "id": "3bGFK-QXeeDR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1.  Inputs\n",
        "# ------------------------------------------------------------\n",
        "# df      : DataFrame of monthly total-return series (index = month-end dates)\n",
        "# FACTORS : list/tuple of column names in df you want analysed\n",
        "#\n",
        "# Example:\n",
        "# df       = pd.read_csv(\"monthly_returns.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
        "# FACTORS  = [\"Value\", \"Momentum\", \"Quality\", \"LowVol\"]\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "def annualized_return(returns: pd.Series) -> float:\n",
        "    \"\"\"Compounded annualised return from monthly series.\"\"\"\n",
        "    return (1 + returns).prod() ** (12 / len(returns)) - 1\n",
        "\n",
        "def compute_metrics(returns: pd.Series) -> tuple[float, float, float]:\n",
        "    \"\"\"Annualised return, annualised volatility, and cumulative return.\"\"\"\n",
        "    ann_ret = annualized_return(returns)\n",
        "    ann_vol = returns.std() * np.sqrt(12)          # monthly â†’ annual\n",
        "    cum_ret = (1 + returns).prod() - 1\n",
        "    return ann_ret, ann_vol, cum_ret\n",
        "\n",
        "# ---------- Win-rate (highest-return months, factors only) ----------\n",
        "monthly_winner = df[FACTORS].idxmax(axis=1)        # winner each month (benchmark excluded)\n",
        "win_rates = (\n",
        "    monthly_winner.value_counts()                  # how many wins per factor\n",
        "    .reindex(FACTORS, fill_value=0) / len(df)      # re-index ensures original order\n",
        ")\n",
        "\n",
        "# ---------- Number-format helper (space as thousands separator) ----------\n",
        "NBSP = \"\\u202F\"                                    # thin non-breaking space renders well in HTML\n",
        "\n",
        "def pct_with_space(x: float) -> str:\n",
        "    \"\"\"Format a decimal as percentage with 1-dp and thin-space thousands separator.\"\"\"\n",
        "    return f\"{x * 100:,.1f}%\".replace(\",\", NBSP)\n",
        "\n",
        "# ---------- Build the summary table ----------\n",
        "records = []\n",
        "for col in FACTORS:\n",
        "    r = df[col]\n",
        "    ann_ret, ann_vol, cum_ret = compute_metrics(r)\n",
        "    records.append({\n",
        "        \"Factor\":                   col,\n",
        "        \"Annualised Return\":        pct_with_space(ann_ret),\n",
        "        \"Annualised Volatility\":    pct_with_space(ann_vol),\n",
        "        \"Total Cumulative Return\":  pct_with_space(cum_ret),\n",
        "        \"Win rate\":                 pct_with_space(win_rates[col]),\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(records)\n",
        "\n",
        "# ---------- Display ----------\n",
        "display(HTML(metrics_df.to_html(index=False)))"
      ],
      "metadata": {
        "id": "phBSNpYXviHe"
      },
      "id": "phBSNpYXviHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6",
      "metadata": {
        "tags": [],
        "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6"
      },
      "outputs": [],
      "source": [
        "# Toggle for dropping rows with missing values in the FEATURES columns.\n",
        "drop_empty = True\n",
        "\n",
        "# 1) Print the initial number of rows.\n",
        "initial_rows = len(df)\n",
        "print(f\"Total number of rows before cleaning: {initial_rows}\")\n",
        "\n",
        "# 2) Show missingâ€value counts in FEATURES.\n",
        "missing_counts = df[FEATURES].isna().sum()\n",
        "print(\"\\nMissing values in FEATURES before cleaning:\")\n",
        "print(missing_counts)\n",
        "\n",
        "# 3) Drop any rows with NA in FEATURES, if requested.\n",
        "if drop_empty:\n",
        "    before = len(df)\n",
        "    df.dropna(subset=FEATURES, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    dropped = before - len(df)\n",
        "    print(f\"\\nDropped {dropped} rows due to missing FEATURES.\")\n",
        "else:\n",
        "    print(\"\\nKeeping all rows, including those with missing FEATURES.\")\n",
        "\n",
        "# 4) Reâ€check that FEATURES are now complete:\n",
        "print(\"\\nMissing values in FEATURES after cleaning:\")\n",
        "print(df[FEATURES].isna().sum())\n",
        "\n",
        "# 5) Compute your target column inâ€place.\n",
        "df['Winning Factor'] = df[FACTORS].idxmax(axis=1).astype('category')\n",
        "\n",
        "# 6) (Optionally) create a numeric code column\n",
        "df['Winning Factor Code'] = df['Winning Factor'].cat.codes\n",
        "\n",
        "# 7) Quick summary:\n",
        "print(f\"\\nFinal dataset now has {len(df)} rows.\")\n",
        "print(\"Target value counts:\")\n",
        "print(df['Winning Factor'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_regime_split:\n",
        "\n",
        "    # --- Regime Mapping & Conversion to Numeric Codes (Dynamic) ---\n",
        "\n",
        "    # Dynamically extract the unique values in the REGIMES_COLUMN.\n",
        "    unique_regimes = df[REGIMES_COLUMN].unique()\n",
        "\n",
        "    # Convert the Regimes column to a categorical type with the unique values, ordered alphabetically.\n",
        "    df[REGIMES_COLUMN] = pd.Categorical(df[REGIMES_COLUMN], categories=sorted(unique_regimes), ordered=True)\n",
        "\n",
        "    # Create a dictionary mapping numeric codes to the regime names based on the unique values.\n",
        "    regime_mapping = {i: cat for i, cat in enumerate(df[REGIMES_COLUMN].cat.categories)}\n",
        "\n",
        "    # Now encode the Regimes column as numeric codes.\n",
        "    df[REGIMES_COLUMN] = df[REGIMES_COLUMN].cat.codes\n",
        "\n",
        "    # Create a mapping from numeric codes to original regime names.\n",
        "    regime_short_mapping = {code: name for code, name in regime_mapping.items()}\n",
        "\n",
        "    # Calculate the number of observations for each regime using value_counts (without reindexing).\n",
        "    obs_counts = df[REGIMES_COLUMN].value_counts(sort=False)\n",
        "\n",
        "    # Create a DataFrame preview of the regime mapping, including observation counts.\n",
        "    mapping_table_data = []\n",
        "    for code in regime_mapping.keys():\n",
        "        mapping_table_data.append({\n",
        "            \"Numeric Code\": code,\n",
        "            \"Original Name\": regime_mapping.get(code, \"N/A\"),\n",
        "            \"Observations\": obs_counts.get(code, 0)\n",
        "        })\n",
        "\n",
        "    # Append a row with the total observations.\n",
        "    total_obs = obs_counts.sum()\n",
        "    mapping_table_data.append({\n",
        "        \"Numeric Code\": \"\",\n",
        "        \"Original Name\": \"Total\",\n",
        "        \"Observations\": total_obs\n",
        "    })\n",
        "\n",
        "    # Create the DataFrame for regime mapping preview and print.\n",
        "    regime_mapping_df = pd.DataFrame(mapping_table_data)\n",
        "\n",
        "    from tabulate import tabulate\n",
        "    print(\"Preview of Dynamic Regime Mapping:\")\n",
        "    print(tabulate(regime_mapping_df, headers=\"keys\", tablefmt=\"psql\", showindex=False))\n"
      ],
      "metadata": {
        "id": "wYgvlvGRUUG4"
      },
      "id": "wYgvlvGRUUG4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "0wYzowb5Xdau"
      },
      "id": "0wYzowb5Xdau"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature seek"
      ],
      "metadata": {
        "id": "KkFWbyO6XlRZ"
      },
      "id": "KkFWbyO6XlRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF_feature_seek:\n",
        "    import itertools\n",
        "    import os\n",
        "    import time\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    # --------------------------\n",
        "    # Parameters for Feature & Training Window Search\n",
        "    # --------------------------\n",
        "    min_features = 2                  # minimum number of features in a subset\n",
        "    max_features = len(FEATURES)      # maximum number of features (or set to a smaller number if desired)\n",
        "\n",
        "    # Define fixed rolling window sizes (in years) to test (assuming monthly data)\n",
        "    training_window_years = [5, 10, 15, 20]\n",
        "\n",
        "    # Also run an expanding window experiment\n",
        "    run_expanding_window = True\n",
        "\n",
        "    # Independent variable: minimum number of observations required for making a prediction.\n",
        "    # This is now decoupled from the training window calculation.\n",
        "    min_obs_for_prediction = 60  # adjust this value as desired\n",
        "\n",
        "    output_filename = \"feature_subset_results.csv\"\n",
        "    if os.path.exists(output_filename):\n",
        "        os.remove(output_filename)\n",
        "\n",
        "    # Ensure the data is sorted by date.\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # --------------------------\n",
        "    # Outer Loop: Fixed Rolling Window Modes\n",
        "    # --------------------------\n",
        "    for years in training_window_years:\n",
        "        # Convert years to number of observations (assume 12 obs per year)\n",
        "        rolling_window_size = years * 12\n",
        "        # Ensure predictions start only after both the rolling window and the independent minimum are met.\n",
        "        start_index = max(min_obs_for_prediction, rolling_window_size)\n",
        "        print(f\"\\n--- Testing fixed rolling window of {years} years \"\n",
        "              f\"({rolling_window_size} observations, starting predictions at index {start_index}) ---\")\n",
        "        outer_start_time = time.time()\n",
        "\n",
        "        # Inner loop over feature subset sizes\n",
        "        for r in range(min_features, max_features + 1):\n",
        "            # Loop over all combinations of size r\n",
        "            for comb in itertools.combinations(FEATURES, r):\n",
        "                current_features = list(comb)\n",
        "                inner_start_time = time.time()\n",
        "                print(f\"\\nTesting feature combination: {current_features}\")\n",
        "                results = []\n",
        "\n",
        "                # Loop over test rows, starting when we have enough training data\n",
        "                for i in range(start_index, len(df_sorted)):\n",
        "                    test_row = df_sorted.iloc[i]\n",
        "                    Predicted_month = test_row['Date']\n",
        "\n",
        "                    # Build fixed rolling training window (most recent rolling_window_size observations)\n",
        "                    train_window = df_sorted.iloc[i - rolling_window_size : i].copy()\n",
        "\n",
        "                    # Ensure the last training observation is strictly before test row date\n",
        "                    last_train_date = train_window['Date'].iloc[-1]\n",
        "                    if (last_train_date.year == Predicted_month.year) and \\\n",
        "                       (last_train_date.month >= Predicted_month.month):\n",
        "                        continue\n",
        "\n",
        "                    # (Optional) Regime check if use_regime_split is True:\n",
        "                    if use_regime_split:\n",
        "                        regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "                        insufficient_regimes = regime_counts[regime_counts < min_obs_regime].index.tolist()\n",
        "                        if insufficient_regimes:\n",
        "                            continue\n",
        "                        current_regime = test_row[REGIMES_COLUMN]\n",
        "                        train_window = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "                        if len(train_window) < min_obs_regime:\n",
        "                            continue\n",
        "\n",
        "                    # Prepare training data for the current feature subset.\n",
        "                    X_train = train_window[list(current_features)].dropna()\n",
        "                    y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "                    if len(X_train) < 1:\n",
        "                        continue\n",
        "\n",
        "                    # Train the RandomForest model.\n",
        "                    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                    rf_model.fit(X_train, y_train)\n",
        "\n",
        "                    # Use the last row of the training window as test data.\n",
        "                    X_test = train_window[list(current_features)].iloc[[-1]].dropna()\n",
        "                    if X_test.empty:\n",
        "                        continue\n",
        "\n",
        "                    predicted_probabilities = rf_model.predict_proba(X_test)[0]\n",
        "                    predicted_winner = rf_model.classes_[predicted_probabilities.argmax()]\n",
        "\n",
        "                    # Map the predicted probabilities to the full set of FACTORS.\n",
        "                    full_probs = np.zeros(len(FACTORS))\n",
        "                    for cls, prob in zip(rf_model.classes_, predicted_probabilities):\n",
        "                        try:\n",
        "                            idx = FACTORS.index(cls)\n",
        "                            full_probs[idx] = prob\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                    allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "\n",
        "                    # months_ahead: how many months ahead the prediction is (optional usage)\n",
        "                    months_ahead = (\n",
        "                        (Predicted_month.year - last_train_date.year) * 12 +\n",
        "                        (Predicted_month.month - last_train_date.month)\n",
        "                    )\n",
        "\n",
        "                    # Collect feature levels for logging\n",
        "                    feature_levels = {\n",
        "                        f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in current_features\n",
        "                    }\n",
        "\n",
        "                    # Create a result row\n",
        "                    result = {\n",
        "                        \"TrainingWindowYears\": years,   # <--- Record the training window\n",
        "                        \"Features_used\": str(current_features),\n",
        "                        \"Predicted_month\": Predicted_month,\n",
        "                        \"Allocated_Return\": allocated_return,\n",
        "                        \"Predicted_Winner\": predicted_winner,\n",
        "                        \"Actual_Winner\": test_row['Winning Factor'],\n",
        "                        \"Prediction_Horizon_Months\": months_ahead,\n",
        "                        **feature_levels\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "                # End of inner test row loop for this feature combination.\n",
        "                if results:\n",
        "                    df_results_comb = pd.DataFrame(results)\n",
        "                    if not os.path.exists(output_filename):\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=True, index=False)\n",
        "                    else:\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=False, index=False)\n",
        "                    elapsed_inner = time.time() - inner_start_time\n",
        "                    minutes = int(elapsed_inner // 60)\n",
        "                    seconds = int(elapsed_inner % 60)\n",
        "                    print(f\"Results for combination {current_features} appended to CSV. \"\n",
        "                          f\"Time taken: {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "        elapsed_outer = time.time() - outer_start_time\n",
        "        minutes = int(elapsed_outer // 60)\n",
        "        seconds = int(elapsed_outer % 60)\n",
        "        print(f\"Completed fixed rolling window of {years} years in {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "    # --------------------------\n",
        "    # Expanding Window Mode\n",
        "    # --------------------------\n",
        "    if run_expanding_window:\n",
        "        print(\"\\n--- Testing Expanding Window Mode ---\")\n",
        "        outer_start_time = time.time()\n",
        "        for r in range(min_features, max_features + 1):\n",
        "            for comb in itertools.combinations(FEATURES, r):\n",
        "                current_features = list(comb)\n",
        "                inner_start_time = time.time()\n",
        "                print(f\"\\nTesting feature combination (expanding): {current_features}\")\n",
        "                results = []\n",
        "\n",
        "                # In expanding mode, the training window goes from the start until the test row.\n",
        "                # Start predictions only after the minimum observation threshold is met.\n",
        "                for i in range(min_obs_for_prediction, len(df_sorted)):\n",
        "                    test_row = df_sorted.iloc[i]\n",
        "                    Predicted_month = test_row['Date']\n",
        "                    train_window = df_sorted.iloc[:i].copy()\n",
        "                    if train_window.empty:\n",
        "                        continue\n",
        "\n",
        "                    last_train_date = train_window['Date'].iloc[-1]\n",
        "                    if (last_train_date.year == Predicted_month.year) and \\\n",
        "                       (last_train_date.month >= Predicted_month.month):\n",
        "                        continue\n",
        "\n",
        "                    X_train = train_window[list(current_features)].dropna()\n",
        "                    y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "                    if len(X_train) < 1:\n",
        "                        continue\n",
        "\n",
        "                    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "                    rf_model.fit(X_train, y_train)\n",
        "\n",
        "                    X_test = train_window[list(current_features)].iloc[[-1]].dropna()\n",
        "                    if X_test.empty:\n",
        "                        continue\n",
        "\n",
        "                    predicted_probabilities = rf_model.predict_proba(X_test)[0]\n",
        "                    predicted_winner = rf_model.classes_[predicted_probabilities.argmax()]\n",
        "\n",
        "                    full_probs = np.zeros(len(FACTORS))\n",
        "                    for cls, prob in zip(rf_model.classes_, predicted_probabilities):\n",
        "                        try:\n",
        "                            idx = FACTORS.index(cls)\n",
        "                            full_probs[idx] = prob\n",
        "                        except ValueError:\n",
        "                            continue\n",
        "\n",
        "                    allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "\n",
        "                    months_ahead = (\n",
        "                        (Predicted_month.year - last_train_date.year) * 12 +\n",
        "                        (Predicted_month.month - last_train_date.month)\n",
        "                    )\n",
        "\n",
        "                    feature_levels = {\n",
        "                        f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in current_features\n",
        "                    }\n",
        "\n",
        "                    result = {\n",
        "                        \"TrainingWindowYears\": \"expanding\",  # <--- Indicate expanding window\n",
        "                        \"Features_used\": str(current_features),\n",
        "                        \"Predicted_month\": Predicted_month,\n",
        "                        \"Allocated_Return\": allocated_return,\n",
        "                        \"Predicted_Winner\": predicted_winner,\n",
        "                        \"Actual_Winner\": test_row['Winning Factor'],\n",
        "                        \"Prediction_Horizon_Months\": months_ahead,\n",
        "                        **feature_levels\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "                if results:\n",
        "                    df_results_comb = pd.DataFrame(results)\n",
        "                    if not os.path.exists(output_filename):\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=True, index=False)\n",
        "                    else:\n",
        "                        df_results_comb.to_csv(output_filename, mode='a', header=False, index=False)\n",
        "                    elapsed_inner = time.time() - inner_start_time\n",
        "                    minutes = int(elapsed_inner // 60)\n",
        "                    seconds = int(elapsed_inner % 60)\n",
        "                    print(f\"Expanding window: Results for combination {current_features} \"\n",
        "                          f\"appended to CSV. Time taken: {minutes:02d}:{seconds:02d}\")\n",
        "\n",
        "        elapsed_outer = time.time() - outer_start_time\n",
        "        minutes = int(elapsed_outer // 60)\n",
        "        seconds = int(elapsed_outer % 60)\n",
        "        print(f\"Completed Expanding Window Mode in {minutes:02d}:{seconds:02d}\")\n"
      ],
      "metadata": {
        "id": "kraj1YkNhEq4"
      },
      "id": "kraj1YkNhEq4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Seek all"
      ],
      "metadata": {
        "id": "QkeGs9s9dExF"
      },
      "id": "QkeGs9s9dExF"
    },
    {
      "cell_type": "code",
      "source": [
        "if seek_all:\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import csv\n",
        "  import itertools\n",
        "  import time\n",
        "  import math\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # Assumes `df` (with 'Date' & 'Winning Factor'),\n",
        "  # `FACTORS` (list of all factor names) and\n",
        "  # `FEATURES` (base feature list) are defined above\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # Toggle featureâ€‘looping on/off\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  loop_features = False   # False â‡’ single run on FEATURES; True â‡’ sweep always+optional\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 1) Define alwaysâ€‘on & optional features\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  always_features = [\n",
        "      \"CMA_MA12\", \"SMB_MA12\", \"RMW_MA12\", \"HML_MA12\",\n",
        "      \"CPI%\"\n",
        "  ]\n",
        "  optional_features = [\n",
        "      \"LEI%\", \"Cape\", \"Cape %\", \"TED\",\n",
        "      \"T10Y3\", \"LEI\", \"AR_Shock\", \"HV\",\n",
        "      \"EWMA_0.94\", \"T10YFF\", \"CFNAI\", \"GARCH_1M\", \"VIX\",\"BAA10Y\"\n",
        "  ]\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 1a) Control how many optional features per combo\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  min_optional = 1   # minimum number of optional features in each combo\n",
        "  max_optional = 5   # maximum number of optional features in each combo\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 2) Build feature_combinations (with new constraints)\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  volatility_features = {\"GARCH_1M\", \"VIX\", \"AR_Shock\", \"HV\", \"EWMA_0.94\"}\n",
        "  lei_group          = {\"LEI\", \"LEI%\", \"CFNAI\"}\n",
        "  cape_group         = {\"Cape\", \"Cape %\"}\n",
        "\n",
        "  if loop_features:\n",
        "      def valid_combo(combo):\n",
        "          combo = set(combo)\n",
        "          # 1) at most 2 volatility measures\n",
        "          if len(combo & volatility_features) > 2:\n",
        "              return False\n",
        "          # 2) T10Y3 and T10YFF cannot coâ€‘exist\n",
        "          if {\"T10Y3\", \"T10YFF\"} <= combo:\n",
        "              return False\n",
        "          # 3) only one of LEI, LEI%, CFNAI\n",
        "          if len(combo & lei_group) > 1:\n",
        "              return False\n",
        "          # 4) only one of Cape, Cape %\n",
        "          if len(combo & cape_group) > 1:\n",
        "              return False\n",
        "          return True\n",
        "\n",
        "      feature_combinations = [\n",
        "          always_features + list(combo)\n",
        "          for r in range(min_optional, max_optional + 1)\n",
        "          for combo in itertools.combinations(optional_features, r)\n",
        "          if valid_combo(combo)\n",
        "      ]\n",
        "  else:\n",
        "      feature_combinations = [FEATURES]\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 3) RF hyperparameter template (excluding max_features)\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  param_grid_template = {\n",
        "      'n_estimators':      [100, 300, 500],\n",
        "      'max_depth':         [None, 7, 10, 15],\n",
        "      'min_samples_split': [2, 4, 6],\n",
        "      'min_samples_leaf':  [1, 3, 5, 7],\n",
        "      'bootstrap':         [False, True],\n",
        "      'n_jobs':            [-1]\n",
        "  }\n",
        "  base_param_list = list(ParameterGrid(param_grid_template))\n",
        "\n",
        "  # compute total iterations for progress display\n",
        "  total_iterations = sum(\n",
        "      len(base_param_list) * len(range(2, len(feat_set) + 1, 2))\n",
        "      for feat_set in feature_combinations\n",
        "  )\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 4) CSV logging setup\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  csv_file = 'rf_feature_search.csv'\n",
        "  fieldnames = [\n",
        "      'Iteration','Training_Window','Features','Hyperparameters',\n",
        "      'Num_Preds','First_Pred','Last_Pred',\n",
        "      'CumAlloc_Post2000','CumEqual_Post2000',\n",
        "      'CumAlloc_Total','CumEqual_Total',\n",
        "      'Sharpe_Post2000','Win_Count_Post2000'\n",
        "  ]\n",
        "  with open(csv_file, 'w', newline='') as f:\n",
        "      writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=';')\n",
        "      writer.writeheader()\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 5) Rollingâ€‘window & data settings\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  rolling_window_size = 60   # months in each fixed window\n",
        "  min_months_train    = 60   # minimum months of history required\n",
        "  min_obs_train       = 0    # minimum non-missing rows in X_train\n",
        "  use_fixed_window    = True # True: fixed-length rolling window; False: expanding window\n",
        "\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # 6) Loop over feature sets & hyperparameters\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  iteration = 0\n",
        "  summary_records = []\n",
        "\n",
        "  for feat_set in feature_combinations:\n",
        "      n_feats = len(feat_set)\n",
        "      # for n_feats = 8, this gives [2, 4, 6, 8]\n",
        "      max_features_opts = list(range(2, n_feats + 1, 2))\n",
        "\n",
        "      # inject max_features into each base parameter combination\n",
        "      param_list = [\n",
        "          {**p, 'max_features': mf}\n",
        "          for p in base_param_list\n",
        "          for mf in max_features_opts\n",
        "      ]\n",
        "\n",
        "      for rf_params in param_list:\n",
        "          iteration += 1\n",
        "          start_time = time.perf_counter()\n",
        "\n",
        "          # --- print at start ---\n",
        "          print(f\"\\n=== Iteration {iteration}/{total_iterations} ===\")\n",
        "          if loop_features:\n",
        "              print(f\"Alwaysâ€‘on features ({len(always_features)}): {always_features}\")\n",
        "              print(f\"Optional count range: {min_optional}â€“{max_optional}\")\n",
        "          print(f\"Using features ({n_feats}): {feat_set}\")\n",
        "          print(f\"RF hyperparameters: {rf_params}\")\n",
        "\n",
        "          # drop rows with missing values in this feature set only\n",
        "          df_iter = df.dropna(subset=feat_set).copy()\n",
        "          df_sorted = df_iter.sort_values('Date').reset_index(drop=True)\n",
        "          results = []\n",
        "\n",
        "          # perâ€‘row prediction loop\n",
        "          for i in range(1, len(df_sorted)):\n",
        "              test_row = df_sorted.iloc[i]\n",
        "\n",
        "              # build training window from prior rows\n",
        "              if use_fixed_window:\n",
        "                  start_idx    = max(0, i - rolling_window_size)\n",
        "                  train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "              else:\n",
        "                  train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "              if len(train_window) < min_months_train:\n",
        "                  continue\n",
        "\n",
        "              # prepare training data\n",
        "              X_train = train_window[feat_set].dropna()\n",
        "              y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "              if len(X_train) < min_obs_train:\n",
        "                  continue\n",
        "\n",
        "              # fit RandomForest\n",
        "              rf = RandomForestClassifier(**rf_params, random_state=42)\n",
        "              rf.fit(X_train, y_train)\n",
        "\n",
        "              # predict on the last available row in train_window\n",
        "              X_test = train_window[feat_set].iloc[[-1]].dropna()\n",
        "              if X_test.empty:\n",
        "                  continue\n",
        "\n",
        "              probs      = rf.predict_proba(X_test)[0]\n",
        "              full_probs = np.zeros(len(FACTORS))\n",
        "              for cls, p in zip(rf.classes_, probs):\n",
        "                  full_probs[FACTORS.index(cls)] = p\n",
        "\n",
        "              alloc_ret = (full_probs * test_row[FACTORS].values).sum()\n",
        "              eq_ret    = test_row[FACTORS].mean()\n",
        "\n",
        "              results.append({\n",
        "                  'Date': test_row['Date'],\n",
        "                  'Allocated_Return': alloc_ret,\n",
        "                  'Equal_Weight_Return': eq_ret\n",
        "              })\n",
        "\n",
        "          # compute summary metrics\n",
        "          res_df = pd.DataFrame(results).sort_values('Date')\n",
        "          if res_df.empty:\n",
        "              summary = dict.fromkeys(fieldnames, np.nan)\n",
        "              summary.update({\n",
        "                  'Iteration': iteration,\n",
        "                  'Training_Window': rolling_window_size,\n",
        "                  'Features': \",\".join(feat_set),\n",
        "                  'Hyperparameters': \";\".join(f\"{k}={v}\" for k,v in rf_params.items()),\n",
        "                  'Num_Preds': 0\n",
        "              })\n",
        "          else:\n",
        "              post2k        = res_df[res_df['Date'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "              cum_alloc_2k  = (1 + post2k['Allocated_Return']).prod() - 1\n",
        "              cum_eq_2k     = (1 + post2k['Equal_Weight_Return']).prod()  - 1\n",
        "              cum_alloc_tot = (1 + res_df['Allocated_Return']).prod()     - 1\n",
        "              cum_eq_tot    = (1 + res_df['Equal_Weight_Return']).prod()  - 1\n",
        "\n",
        "              sharpe_2k = (post2k['Allocated_Return'].mean() /\n",
        "                          post2k['Allocated_Return'].std()) * np.sqrt(12)\n",
        "              win2k = (post2k['Allocated_Return'] > post2k['Equal_Weight_Return']).sum()\n",
        "\n",
        "              summary = {\n",
        "                  'Iteration': iteration,\n",
        "                  'Training_Window': rolling_window_size,\n",
        "                  'Features': \",\".join(feat_set),\n",
        "                  'Hyperparameters': \";\".join(f\"{k}={v}\" for k,v in rf_params.items()),\n",
        "                  'Num_Preds': len(res_df),\n",
        "                  'First_Pred': res_df['Date'].iloc[0].strftime(\"%Y-%m-%d\"),\n",
        "                  'Last_Pred':  res_df['Date'].iloc[-1].strftime(\"%Y-%m-%d\"),\n",
        "                  'CumAlloc_Post2000': cum_alloc_2k,\n",
        "                  'CumEqual_Post2000':  cum_eq_2k,\n",
        "                  'CumAlloc_Total':      cum_alloc_tot,\n",
        "                  'CumEqual_Total':       cum_eq_tot,\n",
        "                  'Sharpe_Post2000':     sharpe_2k,\n",
        "                  'Win_Count_Post2000':  win2k\n",
        "              }\n",
        "\n",
        "          # write one line to CSV\n",
        "          with open(csv_file, 'a', newline='') as f:\n",
        "              writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=';')\n",
        "              writer.writerow(summary)\n",
        "              f.flush()\n",
        "\n",
        "          # update running ranks & print end summary\n",
        "          summary_records.append(summary)\n",
        "          df_sum = pd.DataFrame(summary_records)\n",
        "          df_sum['Rank_CumAlloc_Post2000']   = df_sum['CumAlloc_Post2000'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_Sharpe_Post2000']     = df_sum['Sharpe_Post2000'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_CumAlloc_Total']      = df_sum['CumAlloc_Total'].rank(ascending=False, method='min')\n",
        "          df_sum['Rank_Win_Count_Post2000']  = df_sum['Win_Count_Post2000'].rank(ascending=False, method='min')\n",
        "\n",
        "          cur = df_sum.iloc[-1]\n",
        "          duration = time.perf_counter() - start_time\n",
        "\n",
        "          # print endâ€‘ofâ€‘iteration stats\n",
        "          print(f\"Completed iteration {iteration}/{total_iterations} in {duration:.1f}s\")\n",
        "          print(f\"  CumAlloc_Post2000: {cur['CumAlloc_Post2000']:.4f} (rank {int(cur['Rank_CumAlloc_Post2000'])}/{iteration})\")\n",
        "          print(f\"  Sharpe_Post2000:   {cur['Sharpe_Post2000']:.4f} (rank {int(cur['Rank_Sharpe_Post2000'])}/{iteration})\")\n",
        "          print(f\"  CumAlloc_Total:    {cur['CumAlloc_Total']:.4f} (rank {int(cur['Rank_CumAlloc_Total'])}/{iteration})\")\n",
        "          print(f\"  Win_Count_Post2000:{int(cur['Win_Count_Post2000'])} (rank {int(cur['Rank_Win_Count_Post2000'])}/{iteration})\")\n",
        "          print(f\"  EqualWeight_Post2000: {cur['CumEqual_Post2000']:.4f}\")\n",
        "          print(f\"  EqualWeight_Total:     {cur['CumEqual_Total']:.4f}\")\n"
      ],
      "metadata": {
        "id": "b_ac9qZ7ir9I"
      },
      "id": "b_ac9qZ7ir9I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "MrSJ4xhmDuzE"
      },
      "id": "MrSJ4xhmDuzE"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -----------------------------------------------------------------------------\n",
        "    # Assumes these are already defined:\n",
        "    #   df, FEATURES, FACTORS, REGIMES_COLUMN, regime_short_mapping\n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    RF1_FEATURES = FEATURES\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train        = 60\n",
        "    min_obs_regime          = 50\n",
        "    min_obs_train           = 0\n",
        "    use_regime_split        = False\n",
        "    default_hyperparameters = False\n",
        "\n",
        "    use_fixed_window    = True\n",
        "    rolling_window_size = 60\n",
        "    n_jobs              = -1\n",
        "\n",
        "    # Toggle on/off heavy computations\n",
        "    compute_permutation_importance = False\n",
        "    compute_pdp                     = False\n",
        "    compute_shap                    = True  # â† collect SHAP data\n",
        "\n",
        "    if default_hyperparameters:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': 'sqrt',\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'bootstrap': True,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "    else:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': None,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 5,\n",
        "            'bootstrap': False,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "\n",
        "    # -------------------\n",
        "    # prepare PDP & SHAP storage if asked\n",
        "    # -------------------\n",
        "    if compute_pdp:\n",
        "        from sklearn.inspection import partial_dependence\n",
        "        pdp_data = {feat: [] for feat in RF1_FEATURES}\n",
        "\n",
        "    if compute_shap:\n",
        "        import shap\n",
        "        shap_data = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Sort data and init containers\n",
        "    # -------------------\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results   = []\n",
        "    rf_models = []\n",
        "\n",
        "    if compute_permutation_importance:\n",
        "        from sklearn.inspection import permutation_importance\n",
        "        perm_importances_list = []\n",
        "        months_list           = []\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Main Loop\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row        = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # build train window\n",
        "        if use_fixed_window:\n",
        "            start_idx    = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        if len(train_window) < min_months_train:\n",
        "            print(f\"{Predicted_month.date()}: only {len(train_window)} rows. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        train_start_date = train_window['Date'].iloc[0]\n",
        "        train_end_date   = train_window['Date'].iloc[-1]\n",
        "\n",
        "        # optional regimeâ€‘split\n",
        "        if use_regime_split:\n",
        "            counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "            bad    = counts[counts < min_obs_regime].index.tolist()\n",
        "            if bad:\n",
        "                print(f\"{Predicted_month.date()}: insufficient regimes {bad}. Skipping.\")\n",
        "                continue\n",
        "            current_regime = test_row[REGIMES_COLUMN]\n",
        "            train_window   = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "            if len(train_window) < min_obs_regime:\n",
        "                print(f\"{Predicted_month.date()}: regime {current_regime} has {len(train_window)} rows. Skipping.\")\n",
        "                continue\n",
        "            regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "        else:\n",
        "            regime_used = 'NoRegime'\n",
        "\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            print(f\"{Predicted_month.date()}: last train {last_train_date.date()} â‰¥ test. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        X_train = train_window[RF1_FEATURES].dropna()\n",
        "        y_train = train_window.loc[X_train.index, 'Winning Factor']\n",
        "        if len(X_train) < min_obs_train:\n",
        "            print(f\"{Predicted_month.date()}: {len(X_train)} < {min_obs_train} after NA drop. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # fit RF\n",
        "        rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "        rf_models.append(rf_model)\n",
        "\n",
        "        # â”€â”€ collect PDP if toggled â”€â”€\n",
        "        if compute_pdp:\n",
        "            for feat in RF1_FEATURES:\n",
        "                pdp_res = partial_dependence(\n",
        "                    rf_model,\n",
        "                    X_train,\n",
        "                    features=[feat],\n",
        "                    grid_resolution=50,\n",
        "                    kind='average'\n",
        "                )\n",
        "                grid = pdp_res.get('values', pdp_res.get('grid_values'))[0]\n",
        "                avg  = pdp_res['average']  # shape = (n_factors, n_grid)\n",
        "                pdp_data[feat].append({\n",
        "                    'month':   Predicted_month,\n",
        "                    'values':  grid,\n",
        "                    'average': avg\n",
        "                })\n",
        "\n",
        "        # â”€â”€ collect SHAP if toggled â”€â”€\n",
        "        if compute_shap:\n",
        "            X_test = train_window[RF1_FEATURES].iloc[[-1]].dropna()\n",
        "            if not X_test.empty:\n",
        "                # try new shap.Explainer API\n",
        "                try:\n",
        "                    explainer = shap.Explainer(rf_model, X_train, feature_names=RF1_FEATURES)\n",
        "                    shap_exp  = explainer(X_test)\n",
        "                    vals      = shap_exp.values  # shape: (1, n_features, n_factors)\n",
        "                except Exception:\n",
        "                    # fallback to TreeExplainer\n",
        "                    explainer = shap.TreeExplainer(rf_model)\n",
        "                    sv_list   = explainer.shap_values(X_test)\n",
        "                    if isinstance(sv_list, list):\n",
        "                        vals = np.stack(sv_list, axis=-1)[0]  # (n_features, n_factors)\n",
        "                        vals = vals.T                          # â†’ (n_factors, n_features)\n",
        "                    else:\n",
        "                        vals = sv_list  # e.g. (1, n_features)\n",
        "                # normalize to (n_factors, n_features)\n",
        "                if vals.ndim == 3:\n",
        "                    shap_mat = vals[0].T\n",
        "                elif vals.ndim == 2 and vals.shape[0] == len(FEATURES):\n",
        "                    shap_mat = vals.T\n",
        "                elif vals.ndim == 2 and vals.shape[0] == 1:\n",
        "                    shap_mat = np.tile(vals, (len(FACTORS), 1))\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected SHAP shape {vals.shape}\")\n",
        "                shap_data.append({\n",
        "                    'month':        Predicted_month,\n",
        "                    'feature_vals': X_test.iloc[0].values,\n",
        "                    'shap_values':  shap_mat\n",
        "                })\n",
        "\n",
        "        # optional: compute permutation importance\n",
        "        if compute_permutation_importance:\n",
        "            pi = permutation_importance(\n",
        "                rf_model, X_train, y_train,\n",
        "                n_repeats=10, random_state=42, n_jobs=n_jobs\n",
        "            )\n",
        "            perm_importances_list.append(pi.importances_mean)\n",
        "            months_list.append(Predicted_month.strftime('%Y-%m-%d'))\n",
        "\n",
        "        # predict (unchanged)\n",
        "        X_test = train_window[RF1_FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            print(f\"{Predicted_month.date()}: empty test features. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        probs  = rf_model.predict_proba(X_test)[0]\n",
        "        winner = rf_model.classes_[probs.argmax()]\n",
        "\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for cls, p in zip(rf_model.classes_, probs):\n",
        "            try:\n",
        "                idx = FACTORS.index(cls)\n",
        "                full_probs[idx] = p\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "        allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = test_row[FACTORS].mean()\n",
        "\n",
        "        depths      = [e.tree_.max_depth for e in rf_model.estimators_]\n",
        "        avg_depth   = np.mean(depths)\n",
        "        max_depth   = np.max(depths)\n",
        "        months_ahead = ((Predicted_month.year - last_train_date.year)*12 +\n",
        "                        (Predicted_month.month - last_train_date.month))\n",
        "\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in RF1_FEATURES}\n",
        "\n",
        "        print(f\"{Predicted_month.date()}: trained {train_start_date.date()}â€“{train_end_date.date()} â†’ predicted\")\n",
        "\n",
        "        result = {\n",
        "            'Regime': regime_used,\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_start_date,\n",
        "            'Train_End_Date': train_end_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': rf_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': winner,\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': rf_model.n_estimators,\n",
        "            'Average_Tree_Depth': avg_depth,\n",
        "            'Max_Tree_Depth': max_depth,\n",
        "            'Prediction_Horizon_Months': months_ahead,\n",
        "            **feature_levels\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 4) Build results DataFrame\n",
        "    # -------------------\n",
        "    results_df_rf = pd.DataFrame(results)\n",
        "    print(\"Columns:\", results_df_rf.columns.tolist())\n",
        "    display(results_df_rf.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # 5) Cumulative Returns\n",
        "    # -------------------\n",
        "    filt = results_df_rf['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")\n",
        "    if filt.any():\n",
        "        cr_a = (1 + results_df_rf.loc[filt, 'Allocated_Return']).prod() - 1\n",
        "        cr_e = (1 + results_df_rf.loc[filt, 'Equal_Weight_Return']).prod() - 1\n",
        "        d0, d1 = results_df_rf.loc[filt, 'Predicted_month'].agg(['min','max'])\n",
        "        print(f\"\\nCumulative 2000-01-01â€“{d1.date()}: ML={cr_a:.4f}, EW={cr_e:.4f}\")\n",
        "    else:\n",
        "        print(\"No preds â‰¥ 2000-01-01\")\n",
        "\n",
        "    if not results_df_rf.empty:\n",
        "        cr_a = (1 + results_df_rf['Allocated_Return']).prod() - 1\n",
        "        cr_e = (1 + results_df_rf['Equal_Weight_Return']).prod() - 1\n",
        "        d0, d1 = results_df_rf['Predicted_month'].agg(['min','max'])\n",
        "        print(f\"\\nTotal {d0.date()}â€“{d1.date()}: ML={cr_a:.4f}, EW={cr_e:.4f}\")\n",
        "    else:\n",
        "        print(\"No predictions total.\")"
      ],
      "metadata": {
        "id": "aGwg80N9BmhI"
      },
      "id": "aGwg80N9BmhI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RF tree visualization"
      ],
      "metadata": {
        "id": "bDYVybt7Bcnd"
      },
      "id": "bDYVybt7Bcnd"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF:\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  # CELL: Interactive selector for prediction date & tree number\n",
        "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "  import ipywidgets as widgets\n",
        "  from IPython.display import display\n",
        "  from sklearn import tree\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # build a list of the dates you predicted on\n",
        "  prediction_dates = [\n",
        "      res['Predicted_month'].date()\n",
        "      for res in results  # or results_df_rf['Predicted_month']\n",
        "  ]\n",
        "\n",
        "  # map date â†’ model\n",
        "  model_by_date = dict(zip(prediction_dates, rf_models))\n",
        "\n",
        "  # widget for selecting date\n",
        "  date_widget = widgets.Dropdown(\n",
        "      options=prediction_dates,\n",
        "      description='Date:',\n",
        "  )\n",
        "\n",
        "  # widget for selecting tree index\n",
        "  tree_widget = widgets.IntSlider(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=rf_params['n_estimators'] - 1,\n",
        "      step=1,\n",
        "      description='Tree #:',\n",
        "  )\n",
        "\n",
        "  def plot_tree_for_selection(chosen_date, tree_idx):\n",
        "      model = model_by_date[chosen_date]\n",
        "      estimator = model.estimators_[tree_idx]\n",
        "      plt.figure(figsize=(20, 10))\n",
        "      tree.plot_tree(\n",
        "          estimator,\n",
        "          feature_names=RF1_FEATURES,\n",
        "          class_names=[str(c) for c in model.classes_],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=8,\n",
        "      )\n",
        "      plt.title(f'Tree {tree_idx} from prediction on {chosen_date}')\n",
        "      plt.show()\n",
        "\n",
        "  # wire up interactive display\n",
        "  interactive_ui = widgets.interactive(\n",
        "      plot_tree_for_selection,\n",
        "      chosen_date=date_widget,\n",
        "      tree_idx=tree_widget\n",
        "  )\n",
        "  display(interactive_ui)\n"
      ],
      "metadata": {
        "id": "oL71XtZjsJp1"
      },
      "id": "oL71XtZjsJp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RF2"
      ],
      "metadata": {
        "id": "JuCQA8Oco0kP"
      },
      "id": "JuCQA8Oco0kP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 â€” second RF run under RF2\n",
        "if RF2:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -------------------\n",
        "    # RF2: Drop _MA12 and GARCH_1M\n",
        "    # -------------------\n",
        "    RF2_FEATURES = [f for f in FEATURES if not f.endswith('_MA12') and f != 'GARCH_1M']\n",
        "    #RF2_FEATURES = [f for f in FEATURES if f not in ['Cape']]\n",
        "\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train    = 60\n",
        "    min_obs_regime      = 50\n",
        "    min_obs_train       = 0\n",
        "    use_regime_split    = False\n",
        "    default_hyperparams = False\n",
        "\n",
        "    use_fixed_window    = True\n",
        "    rolling_window_size = 60\n",
        "\n",
        "    n_jobs = -1\n",
        "\n",
        "    # -------------------\n",
        "    # Hyperparameter Settings\n",
        "    # -------------------\n",
        "    if default_hyperparams:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': 'sqrt',\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 1,\n",
        "            'bootstrap': True,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "    else:\n",
        "        rf_params = {\n",
        "            'n_estimators': 100,\n",
        "            'max_depth': None,\n",
        "            'max_features': None,\n",
        "            'min_samples_split': 2,\n",
        "            'min_samples_leaf': 5,\n",
        "            'bootstrap': False,\n",
        "            'n_jobs': n_jobs\n",
        "        }\n",
        "\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results_rf2 = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Main Loop\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # Build window\n",
        "        if use_fixed_window:\n",
        "            start_idx = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        # Skip if insufficient data or overlapping dates\n",
        "        if len(train_window) < min_months_train:\n",
        "            continue\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            continue\n",
        "\n",
        "        # Prepare X_train / y_train using RF2_FEATURES\n",
        "        X_train = train_window[RF2_FEATURES].dropna()\n",
        "        y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "        if len(X_train) < min_obs_train:\n",
        "            continue\n",
        "\n",
        "        # Train RF\n",
        "        rf_model = RandomForestClassifier(**rf_params, random_state=42)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Prepare X_test\n",
        "        X_test = train_window[RF2_FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            continue\n",
        "\n",
        "        # Predict and map probabilities\n",
        "        probs = rf_model.predict_proba(X_test)[0]\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for cls, p in zip(rf_model.classes_, probs):\n",
        "            if cls in FACTORS:\n",
        "                full_probs[FACTORS.index(cls)] = p\n",
        "\n",
        "        # Calculate returns\n",
        "        allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "        # Feature levels from RF2_FEATURES\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in RF2_FEATURES}\n",
        "\n",
        "        result = {\n",
        "            'Regime': 'NoRegime',\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_window['Date'].iloc[0],\n",
        "            'Train_End_Date': last_train_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': rf_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': rf_model.classes_[probs.argmax()],\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': rf_model.n_estimators,\n",
        "            'Average_Tree_Depth': np.mean([t.tree_.max_depth for t in rf_model.estimators_]),\n",
        "            'Max_Tree_Depth': np.max([t.tree_.max_depth for t in rf_model.estimators_]),\n",
        "            'Prediction_Horizon_Months': ((Predicted_month.year - last_train_date.year) * 12 +\n",
        "                                         (Predicted_month.month - last_train_date.month)),\n",
        "            **feature_levels\n",
        "        }\n",
        "        results_rf2.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Build RF2 results DataFrame\n",
        "    # -------------------\n",
        "    results_df_rf2 = pd.DataFrame(results_rf2)\n",
        "    print(\"Final results_df_rf2 columns:\", results_df_rf2.columns.tolist())\n",
        "    display(results_df_rf2.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # Cumulative returns (2000 onward & total)\n",
        "    # -------------------\n",
        "    filtered2 = results_df_rf2[results_df_rf2['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "    if not filtered2.empty:\n",
        "        cum_alloc2 = (1 + filtered2['Allocated_Return']).prod() - 1\n",
        "        cum_eq2    = (1 + filtered2['Equal_Weight_Return']).prod() - 1\n",
        "        print(f\"Cumulative 2000â€“present â€” RF2: {cum_alloc2:.4f}  /  Equal: {cum_eq2:.4f}\")\n",
        "\n",
        "    if not results_df_rf2.empty:\n",
        "        cum_alloc_all2 = (1 + results_df_rf2['Allocated_Return']).prod() - 1\n",
        "        cum_eq_all2    = (1 + results_df_rf2['Equal_Weight_Return']).prod() - 1\n",
        "        print(f\"Total cumulative â€” RF2: {cum_alloc_all2:.4f}  /  Equal: {cum_eq_all2:.4f}\")\n"
      ],
      "metadata": {
        "id": "CMbhV42UouKY"
      },
      "id": "CMbhV42UouKY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient boosting\n"
      ],
      "metadata": {
        "id": "MSWv9xFlDbMz"
      },
      "id": "MSWv9xFlDbMz"
    },
    {
      "cell_type": "code",
      "source": [
        "if GB:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from xgboost import XGBClassifier\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # -------------------\n",
        "    # 1) Parameters\n",
        "    # -------------------\n",
        "    min_months_train = 60     # Minimum months of data needed (5 years for monthly data)\n",
        "    min_obs_regime = 50       # Minimum observations per regime if splitting\n",
        "    min_obs_train = 0         # Minimum total observations after dropping NAs\n",
        "    use_regime_split = False  # Toggle regime-based training or not\n",
        "    default_hyperparameters = False  # If True, override manually set hyperparameters\n",
        "\n",
        "    # Toggle for training window type:\n",
        "    use_fixed_window = True   # True for fixed (rolling) window, False for expanding window\n",
        "    rolling_window_size = 60  # When using a fixed window, use this many most recent rows\n",
        "\n",
        "    df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "    results = []\n",
        "\n",
        "    # -------------------\n",
        "    # 2) Main Loop: Predict for each row in df_sorted\n",
        "    # -------------------\n",
        "    for i in range(1, len(df_sorted)):\n",
        "        test_row = df_sorted.iloc[i]\n",
        "        Predicted_month = test_row['Date']\n",
        "\n",
        "        # Build training window: either fixed-size (rolling) or expanding window\n",
        "        if use_fixed_window:\n",
        "            start_idx = max(0, i - rolling_window_size)\n",
        "            train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "        else:\n",
        "            train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "        # Check that we have enough training rows (i.e., months)\n",
        "        if len(train_window) < min_months_train:\n",
        "            print(f\"Test row date: {Predicted_month.date()} - Insufficient training rows ({len(train_window)} rows). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Get first and last training dates\n",
        "        train_start_date = train_window['Date'].iloc[0]\n",
        "        train_end_date = train_window['Date'].iloc[-1]\n",
        "\n",
        "        # Regime-based checks (if enabled)\n",
        "        if use_regime_split:\n",
        "            regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "            insufficient_regimes = regime_counts[regime_counts < min_obs_regime].index.tolist()\n",
        "            if insufficient_regimes:\n",
        "                regime_str_list = [regime_short_mapping.get(r, str(r)) for r in insufficient_regimes]\n",
        "                regime_str = \", \".join(regime_str_list)\n",
        "                print(f\"Test row date: {Predicted_month.date()}\")\n",
        "                print(f\"  Regime split active. Insufficient data in: {regime_str}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Use only training data for the current regime\n",
        "            current_regime = test_row[REGIMES_COLUMN]\n",
        "            train_window = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "            if len(train_window) < min_obs_regime:\n",
        "                regime_str = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "                print(f\"Test row date: {Predicted_month.date()}\")\n",
        "                print(f\"  Regime split active ({regime_str}). Only {len(train_window)} obs. Skipping.\")\n",
        "                continue\n",
        "            regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "        else:\n",
        "            regime_used = 'NoRegime'\n",
        "\n",
        "        # Ensure the last training date is strictly before the test date\n",
        "        last_train_date = train_window['Date'].iloc[-1]\n",
        "        if (last_train_date.year == Predicted_month.year) and (last_train_date.month >= Predicted_month.month):\n",
        "            print(f\"Test row {Predicted_month.date()}: last training date not strictly before test month. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Prepare training data\n",
        "        X_train = train_window[FEATURES].dropna()\n",
        "        y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "        if len(X_train) < min_obs_train:\n",
        "            print(f\"   -> After dropping NAs: {len(X_train)} < {min_obs_train}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Convert y_train from strings to numeric codes and save mapping\n",
        "        y_train_cat = y_train.astype('category')\n",
        "        mapping = dict(enumerate(y_train_cat.cat.categories))\n",
        "        y_train_numeric = y_train_cat.cat.codes\n",
        "\n",
        "        # -------------------\n",
        "        # Set hyperparameters based on default_hyperparameters flag\n",
        "        # -------------------\n",
        "        if default_hyperparameters:\n",
        "            xgb_params = {\n",
        "                'n_estimators': 100,\n",
        "                'max_depth': 3,\n",
        "                'learning_rate': 0.1,\n",
        "                'subsample': 1.0,\n",
        "                'colsample_bytree': 1.0,\n",
        "                'random_state': 42,\n",
        "                'eval_metric': 'mlogloss'\n",
        "            }\n",
        "        else:\n",
        "            # Use manually defined hyperparameters (from Optuna or otherwise)\n",
        "          xgb_params = {\n",
        "              'n_estimators':      200,\n",
        "              'max_depth':         15,\n",
        "              'learning_rate':     0.17,\n",
        "              'subsample':         0.75,\n",
        "              'colsample_bytree':  0.5,\n",
        "              'min_child_weight':  7,\n",
        "              'random_state':      42,\n",
        "              'n_jobs':            -1,\n",
        "              'eval_metric':       'mlogloss'\n",
        "          }\n",
        "\n",
        "\n",
        "        # Fit XGBoost gradient boosting classifier on numeric labels (full training, no early stopping)\n",
        "        xgb_model = XGBClassifier(**xgb_params)\n",
        "        xgb_model.fit(X_train, y_train_numeric)\n",
        "\n",
        "        # Prepare test data (using the last row in the training window)\n",
        "        X_test = train_window[FEATURES].iloc[[-1]].dropna()\n",
        "        if X_test.empty:\n",
        "            print(\"   -> Test features empty, skipping iteration.\")\n",
        "            continue\n",
        "\n",
        "        predicted_probabilities = xgb_model.predict_proba(X_test)[0]\n",
        "        # Get predicted numeric class and convert back to original factor name\n",
        "        predicted_numeric = xgb_model.classes_[predicted_probabilities.argmax()]\n",
        "        predicted_winner = mapping[predicted_numeric]\n",
        "\n",
        "        # Map predicted probabilities onto the full set of FACTORS\n",
        "        full_probs = np.zeros(len(FACTORS))\n",
        "        for code, prob in zip(xgb_model.classes_, predicted_probabilities):\n",
        "            factor_name = mapping[code]\n",
        "            try:\n",
        "                idx = FACTORS.index(factor_name)\n",
        "                full_probs[idx] = prob\n",
        "            except ValueError:\n",
        "                pass  # Skip if factor not found in FACTORS\n",
        "\n",
        "        # Compute allocated return and equal weight return using the test row's factor returns\n",
        "        allocated_return = (full_probs * test_row[FACTORS].values).sum()\n",
        "        equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "        # Tree depth statistics are not required for XGB; set to None\n",
        "        avg_depth = None\n",
        "        max_depth = None\n",
        "\n",
        "        # Calculate prediction horizon (months ahead)\n",
        "        months_ahead = (Predicted_month.year - last_train_date.year) * 12 + (Predicted_month.month - last_train_date.month)\n",
        "\n",
        "        # Store the actual feature levels used in X_test\n",
        "        feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in FEATURES}\n",
        "\n",
        "        print(f\"Test row date: {Predicted_month.date()} -> Model trained, prediction made (using: {train_start_date.date()} - {train_end_date.date()})\")\n",
        "\n",
        "        # Build the result dictionary for this iteration\n",
        "        result = {\n",
        "            'Regime': regime_used,\n",
        "            'Predicted_month': Predicted_month,\n",
        "            'Train_Start_Date': train_start_date,\n",
        "            'Train_End_Date': train_end_date,\n",
        "            'Train_Count': len(X_train),\n",
        "            'Feature_Importances': xgb_model.feature_importances_,\n",
        "            'Predicted_Probabilities': full_probs,\n",
        "            'Predicted_Winner': predicted_winner,\n",
        "            'Allocated_Return': allocated_return,\n",
        "            'Equal_Weight_Return': equal_weight_return,\n",
        "            'Actual_Winner': test_row['Winning Factor'],\n",
        "            'Num_Trees': xgb_model.n_estimators,\n",
        "            'Average_Tree_Depth': avg_depth,\n",
        "            'Max_Tree_Depth': max_depth,\n",
        "            'Prediction_Horizon_Months': months_ahead,\n",
        "            **feature_levels\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    # -------------------\n",
        "    # 3) Build the final results DataFrame for GB\n",
        "    # -------------------\n",
        "    results_df_gb = pd.DataFrame(results)\n",
        "    print(\"Final results_df_gb columns:\", results_df_gb.columns.tolist())\n",
        "    display(results_df_gb.tail(10))\n",
        "\n",
        "    # -------------------\n",
        "    # 4) Calculate and Print Cumulative Returns (Filtered: from 1 Jan 2000 onwards)\n",
        "    # -------------------\n",
        "    filtered_results = results_df_gb[results_df_gb['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "    if not filtered_results.empty:\n",
        "        cum_return_allocated = (1 + filtered_results['Allocated_Return']).prod() - 1\n",
        "        cum_return_equal = (1 + filtered_results['Equal_Weight_Return']).prod() - 1\n",
        "\n",
        "        first_pred_month = filtered_results.iloc[0]['Predicted_month']\n",
        "        last_pred_month = filtered_results.iloc[-1]['Predicted_month']\n",
        "\n",
        "        print(\"\\nCumulative returns {} - {} - ML strategy: {:.4f} / Equal weight: {:.4f}\".format(\n",
        "            first_pred_month.date(), last_pred_month.date(),\n",
        "            cum_return_allocated, cum_return_equal))\n",
        "    else:\n",
        "        print(\"No predictions from 1 Jan 2000 onwards.\")\n",
        "\n",
        "    # -------------------\n",
        "    # 5) Calculate and Print Cumulative Returns for Total Time\n",
        "    # -------------------\n",
        "    if not results_df_gb.empty:\n",
        "        cum_return_allocated_total = (1 + results_df_gb['Allocated_Return']).prod() - 1\n",
        "        cum_return_equal_total = (1 + results_df_gb['Equal_Weight_Return']).prod() - 1\n",
        "\n",
        "        first_total_month = results_df_gb.iloc[0]['Predicted_month']\n",
        "        last_total_month = results_df_gb.iloc[-1]['Predicted_month']\n",
        "\n",
        "        print(\"\\nCumulative returns {} - {} - ML strategy: {:.4f} / Equal weight: {:.4f}\".format(\n",
        "            first_total_month.date(), last_total_month.date(),\n",
        "            cum_return_allocated_total, cum_return_equal_total))\n",
        "    else:\n",
        "        print(\"No predictions available for total time.\")\n"
      ],
      "metadata": {
        "id": "9sWAd_BnDVlB"
      },
      "id": "9sWAd_BnDVlB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradint boosting loop"
      ],
      "metadata": {
        "id": "cqpzfBYhagcZ"
      },
      "id": "cqpzfBYhagcZ"
    },
    {
      "cell_type": "code",
      "source": [
        "if gb_loop:\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import random\n",
        "  from datetime import datetime\n",
        "  from xgboost import XGBClassifier\n",
        "  from IPython.display import display, HTML\n",
        "  import optuna\n",
        "  import optuna.visualization as vis\n",
        "  import time\n",
        "\n",
        "  # -------------------\n",
        "  # User-specified globals\n",
        "  # -------------------\n",
        "  seed = 39\n",
        "  n_trials = 350\n",
        "\n",
        "  # reproducibility\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "  min_months_train    = 60    # Minimum months of data needed (5 years for monthly data)\n",
        "  min_obs_regime      = 50    # Minimum observations per regime if splitting\n",
        "  min_obs_train       = 0     # Minimum total observations after dropping NAs\n",
        "  use_regime_split    = False # Toggle regime-based training\n",
        "  use_fixed_window    = True  # True for rolling window, False for expanding window\n",
        "  rolling_window_size = 60    # When using a fixed window, use this many most recent rows\n",
        "\n",
        "  # Ensure the data is sorted by Date\n",
        "  df_sorted = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "  # Global list to store logging entries for Optuna iterations\n",
        "  gb_optuna_log = []\n",
        "\n",
        "  # Prepare results filename\n",
        "  now = datetime.now()\n",
        "  results_filename = f\"gp_loop_results_{now.strftime('%Y%m%d')}_{now.strftime('%H%M%S')}.csv\"\n",
        "\n",
        "  # -------------------\n",
        "  # Objective Function for Optuna\n",
        "  # -------------------\n",
        "  def objective(trial):\n",
        "      start_time = time.time()\n",
        "\n",
        "      # 1) choose number of trees (either 100 or 200)\n",
        "      n_trees = trial.suggest_categorical('n_estimators', [100, 200])\n",
        "\n",
        "      # 2) single unconditional learning-rate range\n",
        "      lr = trial.suggest_float('learning_rate', 0.005, 0.2, log=True)\n",
        "\n",
        "      # 3) other hyperparameters, including subsample now being tuned\n",
        "      xgb_params = {\n",
        "          'n_estimators':     n_trees,\n",
        "          'learning_rate':    lr,\n",
        "          'max_depth':        20,\n",
        "          'subsample':        trial.suggest_float('subsample', 0.5, 1.0),\n",
        "          'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "          'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
        "          'gamma':            trial.suggest_float('gamma', 0.0, 0.7),\n",
        "          'n_jobs':           -1,\n",
        "          'random_state':     seed,\n",
        "          'eval_metric':      'mlogloss'\n",
        "      }\n",
        "\n",
        "      results = []\n",
        "\n",
        "      # Loop through each test point\n",
        "      for i in range(1, len(df_sorted)):\n",
        "          test_row      = df_sorted.iloc[i]\n",
        "          Predicted_month = test_row['Date']\n",
        "\n",
        "          # Build training window\n",
        "          if use_fixed_window:\n",
        "              start_idx    = max(0, i - rolling_window_size)\n",
        "              train_window = df_sorted.iloc[start_idx:i].copy()\n",
        "          else:\n",
        "              train_window = df_sorted.iloc[:i].copy()\n",
        "\n",
        "          # Skip if not enough data\n",
        "          if len(train_window) < min_months_train:\n",
        "              continue\n",
        "\n",
        "          train_start_date = train_window['Date'].iloc[0]\n",
        "          train_end_date   = train_window['Date'].iloc[-1]\n",
        "\n",
        "          # Regime-based filtering (if enabled)\n",
        "          if use_regime_split:\n",
        "              regime_counts = train_window[REGIMES_COLUMN].value_counts()\n",
        "              if (regime_counts < min_obs_regime).any():\n",
        "                  continue\n",
        "              current_regime = test_row[REGIMES_COLUMN]\n",
        "              train_window   = train_window[train_window[REGIMES_COLUMN] == current_regime]\n",
        "              if len(train_window) < min_obs_regime:\n",
        "                  continue\n",
        "              regime_used = regime_short_mapping.get(current_regime, str(current_regime))\n",
        "          else:\n",
        "              regime_used = 'NoRegime'\n",
        "\n",
        "          # Ensure last training date is before test date\n",
        "          last_train = train_window['Date'].iloc[-1]\n",
        "          if (last_train.year == Predicted_month.year and\n",
        "              last_train.month >= Predicted_month.month):\n",
        "              continue\n",
        "\n",
        "          # Prepare training data\n",
        "          X_train = train_window[FEATURES].dropna()\n",
        "          y_train = train_window['Winning Factor'].loc[X_train.index]\n",
        "          if len(X_train) < min_obs_train:\n",
        "              continue\n",
        "\n",
        "          # Encode labels\n",
        "          y_cat = y_train.astype('category')\n",
        "          mapping = dict(enumerate(y_cat.cat.categories))\n",
        "          y_num = y_cat.cat.codes\n",
        "\n",
        "          # Fit model\n",
        "          model = XGBClassifier(**xgb_params)\n",
        "          model.fit(X_train, y_num)\n",
        "\n",
        "          # Prepare test\n",
        "          X_test = train_window[FEATURES].iloc[[-1]].dropna()\n",
        "          if X_test.empty:\n",
        "              continue\n",
        "\n",
        "          probs        = model.predict_proba(X_test)[0]\n",
        "          pred_code    = model.classes_[probs.argmax()]\n",
        "          predicted_winner = mapping[pred_code]\n",
        "\n",
        "          # Map back to full FACTORS\n",
        "          full_probs = np.zeros(len(FACTORS))\n",
        "          for code, p in zip(model.classes_, probs):\n",
        "              factor = mapping[code]\n",
        "              if factor in FACTORS:\n",
        "                  full_probs[FACTORS.index(factor)] = p\n",
        "\n",
        "          allocated_return    = (full_probs * test_row[FACTORS].values).sum()\n",
        "          equal_weight_return = np.mean(test_row[FACTORS].values)\n",
        "\n",
        "          # Record feature levels if desired\n",
        "          feature_levels = {f\"Feature_Level_{f}\": X_test[f].iloc[0] for f in FEATURES}\n",
        "\n",
        "          results.append({\n",
        "              'Predicted_month':     Predicted_month,\n",
        "              'Allocated_Return':    allocated_return,\n",
        "              'Equal_Weight_Return': equal_weight_return,\n",
        "              'Train_Start_Date':    train_start_date,\n",
        "              'Train_End_Date':      train_end_date,\n",
        "              **feature_levels\n",
        "          })\n",
        "\n",
        "      # If no valid predictions:\n",
        "      if not results:\n",
        "          for attr in [\"duration\", \"total_cum_return\", \"filtered_cum_return\", \"total_sharpe\", \"filtered_sharpe\"]:\n",
        "              trial.set_user_attr(attr, 0)\n",
        "          return 0\n",
        "\n",
        "      # Build DataFrame of results\n",
        "      res_df = pd.DataFrame(results)\n",
        "\n",
        "      # Compute cumulative returns\n",
        "      total_cum    = (1 + res_df['Allocated_Return']).prod() - 1\n",
        "      filt_df      = res_df[res_df['Predicted_month'] >= pd.Timestamp(\"2000-01-01\")]\n",
        "      filtered_cum = (1 + filt_df['Allocated_Return']).prod() - 1 if not filt_df.empty else 0\n",
        "\n",
        "      # Sharpe ratio function\n",
        "      def sharpe(returns):\n",
        "          sd = np.std(returns)\n",
        "          return (np.mean(returns) / sd) * np.sqrt(12) if sd else 0\n",
        "\n",
        "      total_sharpe    = sharpe(res_df['Allocated_Return'])\n",
        "      filtered_sharpe = sharpe(filt_df['Allocated_Return']) if not filt_df.empty else 0\n",
        "\n",
        "      # Log attributes\n",
        "      duration = time.time() - start_time\n",
        "      trial.set_user_attr(\"duration\", duration)\n",
        "      trial.set_user_attr(\"total_cum_return\", total_cum)\n",
        "      trial.set_user_attr(\"filtered_cum_return\", filtered_cum)\n",
        "      trial.set_user_attr(\"total_sharpe\", total_sharpe)\n",
        "      trial.set_user_attr(\"filtered_sharpe\", filtered_sharpe)\n",
        "\n",
        "      return filtered_cum  # objective: maximize post-2000 cumulative return\n",
        "\n",
        "\n",
        "  # -------------------\n",
        "  # Callback for logging after each trial\n",
        "  # -------------------\n",
        "  def logging_callback(study, trial):\n",
        "      ua   = trial.user_attrs\n",
        "      mins, secs = divmod(int(ua.get(\"duration\", 0)), 60)\n",
        "      msg = (\n",
        "          f\"Trial {trial.number} in {mins:02d}:{secs:02d} | \"\n",
        "          f\"Best: {study.best_trial.value:.4f} | \"\n",
        "          f\"TotRet: {ua.get('total_cum_return',0):.4f} | \"\n",
        "          f\"Ret2000+: {ua.get('filtered_cum_return',0):.4f} | \"\n",
        "          f\"TotSharpe: {ua.get('total_sharpe',0):.4f} | \"\n",
        "          f\"Sharpe2000+: {ua.get('filtered_sharpe',0):.4f}\"\n",
        "      )\n",
        "      print(msg)\n",
        "\n",
        "      log_entry = {\n",
        "          'Trial': trial.number,\n",
        "          'Duration': f\"{mins:02d}:{secs:02d}\",\n",
        "          'Best_Run_So_Far': study.best_trial.value,\n",
        "          'Total_Cum_Return': ua.get('total_cum_return',0),\n",
        "          'Cum_Return_after_2000': ua.get('filtered_cum_return',0),\n",
        "          'Total_Sharpe': ua.get('total_sharpe',0),\n",
        "          'Sharpe_after_2000': ua.get('filtered_sharpe',0),\n",
        "          **trial.params\n",
        "      }\n",
        "      gb_optuna_log.append(log_entry)\n",
        "      pd.DataFrame(gb_optuna_log).to_csv(results_filename, sep=\";\", decimal=\",\", index=False)\n",
        "\n",
        "\n",
        "  # -------------------\n",
        "  # Run the Optuna study\n",
        "  # -------------------\n",
        "  study = optuna.create_study(\n",
        "      direction=\"maximize\",\n",
        "      sampler=optuna.samplers.TPESampler(seed=seed)\n",
        "  )\n",
        "  study.optimize(objective, n_trials=n_trials, callbacks=[logging_callback])\n",
        "  print(\"Optuna optimization completed.\")\n",
        "\n",
        "  # -------------------\n",
        "  # Visualize the results\n",
        "  # -------------------\n",
        "  opt_history_fig    = vis.plot_optimization_history(study)\n",
        "  opt_importance_fig = vis.plot_param_importances(study)\n",
        "  opt_history_fig.show()\n",
        "  opt_importance_fig.show()\n",
        "\n",
        "  # Display the best trial\n",
        "  best = study.best_trial\n",
        "  print(\"Best trial:\")\n",
        "  print(f\"  Value: {best.value:.4f}\")\n",
        "  for k, v in best.params.items():\n",
        "      print(f\"    {k}: {v}\")\n"
      ],
      "metadata": {
        "id": "K6JoZwTdQ8lL"
      },
      "id": "K6JoZwTdQ8lL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hybrid / tÃ¤Ã¤ sÃ¤ilyttÃ¤Ã¤ random forestin dataframen mut averagee painot ja laskee allocated returns nistÃ¤"
      ],
      "metadata": {
        "id": "0HZuBVFOW8qu"
      },
      "id": "0HZuBVFOW8qu"
    },
    {
      "cell_type": "code",
      "source": [
        "if Hybrid:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from functools import reduce\n",
        "\n",
        "    # names of the two resultâ€DataFrames in your namespace\n",
        "    MODEL_DF_NAMES = ['results_df_rf', 'results_df_rf2']\n",
        "\n",
        "    # 1) load raw factorâ€return sheet & rename its date column to match the models\n",
        "    df_returns = xls_file.parse(SHEET_NAME)\n",
        "    df_returns.rename(columns={'Date': 'Predicted_month'}, inplace=True)\n",
        "    # FACTORS should already be defined as your list of factorâ€return columns\n",
        "    df_factor = df_returns[['Predicted_month'] + FACTORS].copy()\n",
        "\n",
        "    # 2) extract each modelâ€™s month + prob vector\n",
        "    prob_dfs = []\n",
        "    for name in MODEL_DF_NAMES:\n",
        "        tmp = globals()[name][['Predicted_month', 'Predicted_Probabilities']].copy()\n",
        "        tmp.rename(\n",
        "            columns={'Predicted_Probabilities': f'Prob_{name}'},\n",
        "            inplace=True\n",
        "        )\n",
        "        prob_dfs.append(tmp)\n",
        "\n",
        "    # 3) innerâ€‘join on Predicted_month\n",
        "    df_probs = reduce(\n",
        "        lambda left, right: pd.merge(left, right, on='Predicted_month', how='inner'),\n",
        "        prob_dfs\n",
        "    )\n",
        "\n",
        "    # 4) bring in the Actual_Winner from your first RF run\n",
        "    df_probs = pd.merge(\n",
        "        df_probs,\n",
        "        results_df_rf[['Predicted_month', 'Actual_Winner']],\n",
        "        on='Predicted_month',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # 5) compute the averaged (â€œhybridâ€) probabilities\n",
        "    df_probs['Hybrid_Predicted_Probabilities'] = df_probs.apply(\n",
        "        lambda row: np.mean([row[f'Prob_{n}'] for n in MODEL_DF_NAMES], axis=0),\n",
        "        axis=1\n",
        "    )\n",
        "    # rename to match the other DataFramesâ€™ column\n",
        "    df_probs.rename(\n",
        "        columns={'Hybrid_Predicted_Probabilities': 'Predicted_Probabilities'},\n",
        "        inplace=True\n",
        "    )\n",
        "\n",
        "    # 6) merge in the factor returns\n",
        "    df_hybrid = pd.merge(\n",
        "        df_probs,\n",
        "        df_factor,\n",
        "        on='Predicted_month',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # 7) compute the hybrid allocated return\n",
        "    df_hybrid['Allocated_Return'] = df_hybrid.apply(\n",
        "        lambda row: np.dot(row['Predicted_Probabilities'], row[FACTORS].values),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # 8) keep only date, actual winner, predicted probabilities, and the allocated return\n",
        "    df_hybrid = df_hybrid[\n",
        "        ['Predicted_month', 'Actual_Winner', 'Predicted_Probabilities', 'Allocated_Return']\n",
        "    ]"
      ],
      "metadata": {
        "id": "JKYtkk2MWPC0"
      },
      "id": "JKYtkk2MWPC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model evaluation"
      ],
      "metadata": {
        "id": "A1BqWL_QXA8e"
      },
      "id": "A1BqWL_QXA8e"
    },
    {
      "cell_type": "code",
      "source": [
        "# CellÂ 3 â€” collect both RF and RF2 (and others) into your dict\n",
        "results_dfs = {}\n",
        "\n",
        "if RF:\n",
        "    results_dfs[\"Random Forest\"] = results_df_rf.copy()\n",
        "    print(\"Results from Random Forest added.\")\n",
        "\n",
        "if RF2:\n",
        "    results_dfs[\"Random Forest 2\"] = results_df_rf2.copy()\n",
        "    print(\"Results from Random ForestÂ 2 added.\")\n",
        "\n",
        "if GB:\n",
        "    results_dfs[\"Gradient Boosting\"] = results_df_gb.copy()\n",
        "    print(\"Results from Gradient Boosting added.\")\n",
        "\n",
        "if Hybrid:\n",
        "    results_dfs[\"Hybrid\"] = df_hybrid.copy()\n",
        "    print(\"Results from Hybrid Model added.\")\n",
        "\n",
        "if not results_dfs:\n",
        "    raise ValueError(\"No valid model was selected; set at least one of [RF, RF2, GB, Hybrid] to True.\")\n",
        "\n",
        "print(\"\\nAvailable model results:\")\n",
        "for name, df in results_dfs.items():\n",
        "    print(f\" â€¢ {name}: {df.shape[0]} rows Ã— {df.shape[1]} cols\")\n",
        "\n",
        "from IPython.display import display\n",
        "for name, df in results_dfs.items():\n",
        "    print(f\"\\n=== {name} (first 5 rows) ===\")\n",
        "    display(df.head())"
      ],
      "metadata": {
        "id": "FOzCGJrxXKUm"
      },
      "id": "FOzCGJrxXKUm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Increase column width so no text is truncated\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Define the date range\n",
        "start_date = pd.to_datetime('1968-08-01')\n",
        "end_date   = pd.to_datetime('2025-01-01')\n",
        "\n",
        "# Dictionary to store filtered results for each model using the new naming format.\n",
        "filtered_results_dfs = {}\n",
        "\n",
        "# Loop through each model's results dataframe in results_dfs and add numbering.\n",
        "for i, (model_name, df) in enumerate(results_dfs.items(), 1):\n",
        "    new_model_name = f\"ML{i}: {model_name}\"\n",
        "\n",
        "    # Convert 'Predicted_month' to datetime if not already\n",
        "    df['Predicted_month'] = pd.to_datetime(df['Predicted_month'])\n",
        "\n",
        "    # Filter the DataFrame within the specified date range and sort by date.\n",
        "    filtered_df = df[(df['Predicted_month'] >= start_date) & (df['Predicted_month'] <= end_date)].copy().sort_values('Predicted_month')\n",
        "\n",
        "    # Store the filtered dataframe in our new dictionary using the new model name.\n",
        "    filtered_results_dfs[new_model_name] = filtered_df\n",
        "\n",
        "    # Display the filtered results with a header showing the new model name.\n",
        "    print(f\"\\n=== Filtered Results for Model '{new_model_name}' ===\")\n",
        "    display(filtered_df)\n",
        "\n",
        "# Reset column width option to default after display.\n",
        "pd.reset_option('display.max_colwidth')\n"
      ],
      "metadata": {
        "id": "JmpzyRpGWP0n"
      },
      "id": "JmpzyRpGWP0n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PDP"
      ],
      "metadata": {
        "id": "GK6qRmzu5X1K"
      },
      "id": "GK6qRmzu5X1K"
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€ Cell: combined PDP heatmaps for RF and GB â”€â”€\n",
        "if RF and GB and compute_pdp:\n",
        "\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  # 1) Settings\n",
        "  z_grid    = np.array([-2, -1, 0, 1, 2])\n",
        "  eq_w      = 1.0 / len(FACTORS)    # e.g. 0.25 if 4 factors\n",
        "  eq_w_pct  = eq_w * 100            # e.g. 25.0%\n",
        "\n",
        "# â”€â”€ RF PDP â”€â”€\n",
        "    # prepare empty DataFrames: one per factor\n",
        "  pdp_dfs = {\n",
        "        fac: pd.DataFrame(index=FEATURES, columns=z_grid, dtype=float)\n",
        "        for fac in FACTORS\n",
        "    }\n",
        "\n",
        "    # compute raw PDP probabilities\n",
        "    for feat in FEATURES:\n",
        "        Î¼, Ïƒ = X_train[feat].mean(), X_train[feat].std()\n",
        "        for z in z_grid:\n",
        "            x_val = Î¼ + z * Ïƒ\n",
        "            X_tmp = X_train.copy()\n",
        "            X_tmp[feat] = x_val\n",
        "            avg_p = rf_model.predict_proba(X_tmp).mean(axis=0)\n",
        "            for cls, p in zip(rf_model.classes_, avg_p):\n",
        "                pdp_dfs[cls].at[feat, z] = p\n",
        "\n",
        "    # convert to %-point deviations\n",
        "    pdp_dev = {\n",
        "        fac: (df.subtract(eq_w)) * 100\n",
        "        for fac, df in pdp_dfs.items()\n",
        "    }\n",
        "    annot_dfs = {\n",
        "        fac: df_dev.applymap(lambda v: f\"{v:+.1f}%\")\n",
        "        for fac, df_dev in pdp_dev.items()\n",
        "    }\n",
        "    vlim = max(df_dev.abs().values.max() for df_dev in pdp_dev.values())\n",
        "\n",
        "    # plot 2Ã—2 heatmaps\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
        "    axes = axes.flatten()\n",
        "    for ax, fac in zip(axes, FACTORS):\n",
        "        sns.heatmap(\n",
        "            pdp_dev[fac], ax=ax,\n",
        "            cmap=\"vlag\", center=0.0,\n",
        "            vmin=-vlim, vmax=+vlim,\n",
        "            annot=annot_dfs[fac], fmt=\"\",\n",
        "            cbar=(ax is axes[-1]),\n",
        "            annot_kws={\"fontsize\":\"small\"}\n",
        "        )\n",
        "        ax.set_aspect(1 / 1.5)\n",
        "        ax.set_title(f\"{fac}\\nDeviation from {eq_w_pct:.0f}% equal weight\")\n",
        "        ax.set_xlabel(\"Feature z-value\")\n",
        "        ax.set_ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# â”€â”€ GB PDP â”€â”€\n",
        "if GB and compute_pdp:\n",
        "    # build mapping from numeric code â†’ factor name\n",
        "    y_cat   = y_train.astype('category')\n",
        "    mapping = dict(enumerate(y_cat.cat.categories))\n",
        "\n",
        "    # prepare empty DataFrames: one per factor\n",
        "    pdp_dfs = {\n",
        "        fac: pd.DataFrame(index=FEATURES, columns=z_grid, dtype=float)\n",
        "        for fac in mapping.values()\n",
        "    }\n",
        "\n",
        "    # compute raw PDP probabilities\n",
        "    for feat in FEATURES:\n",
        "        Î¼, Ïƒ = X_train[feat].mean(), X_train[feat].std()\n",
        "        for z in z_grid:\n",
        "            x_val = Î¼ + z * Ïƒ\n",
        "            X_tmp = X_train.copy()\n",
        "            X_tmp[feat] = x_val\n",
        "            avg_p = gb_model.predict_proba(X_tmp).mean(axis=0)\n",
        "            for ci, code in enumerate(gb_model.classes_):\n",
        "                fac = mapping[code]\n",
        "                pdp_dfs[fac].at[feat, z] = avg_p[ci]\n",
        "\n",
        "    # convert to %-point deviations\n",
        "    pdp_dev = {\n",
        "        fac: (df.subtract(eq_w)) * 100\n",
        "        for fac, df in pdp_dfs.items()\n",
        "    }\n",
        "    annot_dfs = {\n",
        "        fac: df_dev.applymap(lambda v: f\"{v:+.1f}%\")\n",
        "        for fac, df_dev in pdp_dev.items()\n",
        "    }\n",
        "    vlim = max(df_dev.abs().values.max() for df_dev in pdp_dev.values())\n",
        "\n",
        "    # plot 2Ã—2 heatmaps\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
        "    axes = axes.flatten()\n",
        "    for ax, fac in zip(axes, pdp_dfs.keys()):\n",
        "        sns.heatmap(\n",
        "            pdp_dev[fac], ax=ax,\n",
        "            cmap=\"vlag\", center=0.0,\n",
        "            vmin=-vlim, vmax=+vlim,\n",
        "            annot=annot_dfs[fac], fmt=\"\",\n",
        "            cbar=(ax is axes[-1]),\n",
        "            annot_kws={\"fontsize\":\"small\"}\n",
        "        )\n",
        "        ax.set_aspect(1 / 1.5)\n",
        "        ax.set_title(f\"{fac}\\nDeviation from {eq_w_pct:.0f}% equal weight\")\n",
        "        ax.set_xlabel(\"Feature z-value\")\n",
        "        ax.set_ylabel(\"Feature\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3l55ULwS5hA7"
      },
      "id": "3l55ULwS5hA7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###By feature plots"
      ],
      "metadata": {
        "id": "4UfR4mCrCDCh"
      },
      "id": "4UfR4mCrCDCh"
    },
    {
      "cell_type": "code",
      "source": [
        "if RF and compute_pdp:\n",
        "  fig, axes = plt.subplots(2, 4, figsize=(16, 8), sharex=True, sharey=True)\n",
        "  axes = axes.flatten()\n",
        "  for ax, feat in zip(axes, FEATURES):\n",
        "      for fac, df in pdp_dfs.items():\n",
        "          # Convert to %â€‘pt dev:\n",
        "          dev = (df.loc[feat] - eq_w) * 100\n",
        "          ax.plot(z_grid, dev, marker='o', label=fac)\n",
        "      ax.set_title(feat)\n",
        "      ax.axhline(0, color='gray', lw=0.8)\n",
        "      if feat == FEATURES[0]:\n",
        "          ax.legend(fontsize='small', ncol=2)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "BBoTmWBICBo3"
      },
      "id": "BBoTmWBICBo3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SHAP\n"
      ],
      "metadata": {
        "id": "Iaxe_3vM5Zc3"
      },
      "id": "Iaxe_3vM5Zc3"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Build the long DataFrame from shap_data\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "records = []\n",
        "for rec in shap_data:\n",
        "    month = rec['month']\n",
        "    mat   = rec['shap_values']  # shape = (n_factors, n_features)\n",
        "    for i, fac in enumerate(FACTORS):\n",
        "        for j, feat in enumerate(FEATURES):\n",
        "            records.append({\n",
        "                'month':      pd.to_datetime(month),\n",
        "                'factor':     fac,\n",
        "                'feature':    feat,\n",
        "                'shap_value': mat[i, j]\n",
        "            })\n",
        "shap_df = pd.DataFrame(records)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) Interactive controls\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "start_picker = widgets.DatePicker(\n",
        "    description=\"Start:\",\n",
        "    value=shap_df['month'].min().date()\n",
        ")\n",
        "end_picker = widgets.DatePicker(\n",
        "    description=\"End:\",\n",
        "    value=shap_df['month'].max().date()\n",
        ")\n",
        "agg_dropdown = widgets.Dropdown(\n",
        "    options=['average', 'mean', 'sum'],\n",
        "    value='average',\n",
        "    description='Aggregate:'\n",
        ")\n",
        "\n",
        "controls = widgets.HBox([start_picker, end_picker, agg_dropdown])\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Plot function\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def update_plot(start_date, end_date, agg):\n",
        "    df = shap_df[\n",
        "        (shap_df['month'] >= pd.to_datetime(start_date)) &\n",
        "        (shap_df['month'] <= pd.to_datetime(end_date))\n",
        "    ]\n",
        "    if df.empty:\n",
        "        print(\"No data in that range.\")\n",
        "        return\n",
        "\n",
        "    grouped = df.groupby(['factor','feature'], observed=True)['shap_value']\n",
        "    if agg in ('average', 'mean'):\n",
        "        df_agg = grouped.mean().reset_index()\n",
        "    else:  # 'sum'\n",
        "        df_agg = grouped.sum().reset_index()\n",
        "\n",
        "    pivot = (\n",
        "        df_agg\n",
        "          .pivot(index='factor', columns='feature', values='shap_value')\n",
        "          .reindex(index=FACTORS, columns=FEATURES)\n",
        "          .fillna(0)\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, len(FACTORS)*0.5))\n",
        "    left = np.zeros(len(pivot))\n",
        "    for feat in FEATURES:\n",
        "        vals = pivot[feat].values\n",
        "        ax.barh(pivot.index, vals, left=left, label=feat)\n",
        "        left += vals\n",
        "\n",
        "    ax.set_xlabel(f\"SHAP {agg}\")\n",
        "    ax.set_title(f\"SHAP {agg} from {start_date} to {end_date}\")\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Display everything\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "out = widgets.interactive_output(\n",
        "    update_plot,\n",
        "    {\n",
        "      'start_date': start_picker,\n",
        "      'end_date':   end_picker,\n",
        "      'agg':        agg_dropdown\n",
        "    }\n",
        ")\n",
        "\n",
        "display(controls, out)\n"
      ],
      "metadata": {
        "id": "TiYIWNkh5uZz"
      },
      "id": "TiYIWNkh5uZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Permutation"
      ],
      "metadata": {
        "id": "iXT0B_ar5dM4"
      },
      "id": "iXT0B_ar5dM4"
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Cell 2: Interactive Permutation Importance (choose dateâ€range & agg metric)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if RF and compute_permutation_importance:\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import ipywidgets as widgets\n",
        "  from IPython.display import display\n",
        "\n",
        "  # build DataFrame of permutation importances\n",
        "  perm_df = pd.DataFrame(\n",
        "      perm_importances_list,\n",
        "      index=months_list,\n",
        "      columns=RF1_FEATURES\n",
        "  )\n",
        "  perm_df.sort_index(inplace=True)\n",
        "\n",
        "  # widgets: start date, end date, aggregation\n",
        "  date_options   = list(perm_df.index)\n",
        "  start_widget   = widgets.Dropdown(options=date_options, description='Start:')\n",
        "  end_widget     = widgets.Dropdown(options=date_options,   description='End:')\n",
        "  agg_widget     = widgets.RadioButtons(options=['mean','median'], description='Agg.')\n",
        "\n",
        "  def plot_perm_range(start, end, agg):\n",
        "      # select slice (inclusive)\n",
        "      try:\n",
        "          block = perm_df.loc[start:end]\n",
        "      except KeyError:\n",
        "          print(\"Invalid range.\")\n",
        "          return\n",
        "      if block.empty:\n",
        "          print(\"No data for this range.\")\n",
        "          return\n",
        "\n",
        "      if agg == 'mean':\n",
        "          imp  = block.mean(axis=0)\n",
        "          title = f'Mean Permutation Importance\\n{start} â†’ {end}'\n",
        "      else:\n",
        "          imp  = block.median(axis=0)\n",
        "          title = f'Median Permutation Importance\\n{start} â†’ {end}'\n",
        "\n",
        "      plt.figure(figsize=(10,6))\n",
        "      imp.sort_values(ascending=True).plot.barh()\n",
        "      plt.title(title)\n",
        "      plt.xlabel('Importance')\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  ui = widgets.interactive(\n",
        "      plot_perm_range,\n",
        "      start=start_widget,\n",
        "      end=end_widget,\n",
        "      agg=agg_widget\n",
        "  )\n",
        "  display(ui)"
      ],
      "metadata": {
        "id": "IOVk3YXd51uv"
      },
      "id": "IOVk3YXd51uv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Confusion Matrix"
      ],
      "metadata": {
        "id": "-C0khzZW57a_"
      },
      "id": "-C0khzZW57a_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d0f495-1290-403b-86a2-7bd1c2c12814",
      "metadata": {
        "tags": [],
        "id": "88d0f495-1290-403b-86a2-7bd1c2c12814"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Comprehensive evaluation script\n",
        "===============================\n",
        "\n",
        "Outputs\n",
        "-------\n",
        "1.  Row-normalised **confusion-matrix heat-maps** + a printed numeric table\n",
        "    for each model\n",
        "2.  **Single combined per-factor table** with a merged header row\n",
        "    (Random Forest vs Gradient Boosting)\n",
        "3.  Headline **Overall-Performance Summary** table\n",
        "\"\"\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0. Imports and expected inputs\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "from IPython.display import display\n",
        "\n",
        "# The notebook/environment must already provide:\n",
        "#   FACTORS      : list[str]   â€“ the four factor names in display order\n",
        "#   results_dfs  : dict[str â†’ DataFrame] with columns\n",
        "#                   â€¢ â€œActual_Winnerâ€\n",
        "#                   â€¢ â€œPredicted_Winnerâ€\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "labels = FACTORS\n",
        "items  = list(results_dfs.items())              # [('Random Forest', df), ('Gradient Boosting', df)]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. Confusion-matrix heat-maps **and** printed tables\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, len(items), figsize=(6 * len(items), 5), squeeze=False)\n",
        "axes = axes[0]\n",
        "\n",
        "for idx, (model_name, df_res) in enumerate(items):\n",
        "    cm     = confusion_matrix(df_res.Actual_Winner, df_res.Predicted_Winner, labels=labels)\n",
        "    cm_pct = (cm / cm.sum(axis=1, keepdims=True)) * 100\n",
        "\n",
        "    # Heat-map\n",
        "    sns.heatmap(\n",
        "        cm_pct, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
        "        cbar=(idx == len(items) - 1),\n",
        "        xticklabels=labels, yticklabels=labels,\n",
        "        ax=axes[idx]\n",
        "    )\n",
        "    axes[idx].set_title(f\"{model_name} (row %)\\nn = {len(df_res)}\")\n",
        "    axes[idx].set_xlabel(\"Predicted winner\")\n",
        "    axes[idx].set_ylabel(\"True winner\")\n",
        "\n",
        "    # Printed numeric table\n",
        "    print(f\"\\nConfusion matrix for {model_name} (row %):\")\n",
        "    print(pd.DataFrame(cm_pct, index=labels, columns=labels)\n",
        "            .to_string(float_format=lambda x: f\"{x:.1f}\"))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. Combined per-factor metrics table (RF vs GB)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "per_factor_tables = {}\n",
        "\n",
        "for model_name, df_res in items:\n",
        "    y_true, y_pred = df_res.Actual_Winner, df_res.Predicted_Winner\n",
        "\n",
        "    rep = classification_report(\n",
        "        y_true, y_pred,\n",
        "        labels=labels, target_names=labels,\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "\n",
        "    df_cr = (pd.DataFrame(rep).T\n",
        "               .drop('accuracy', errors='ignore')\n",
        "               .rename(columns={'support': 'Samples'}))\n",
        "\n",
        "    for col in ['precision', 'recall', 'f1-score']:\n",
        "        df_cr[col] = (df_cr[col] * 100).round(1)\n",
        "    df_cr['Samples'] = df_cr['Samples'].astype(int)\n",
        "\n",
        "    df_cr = (df_cr.rename(columns={'precision':'Precision',\n",
        "                                   'recall':'Recall',\n",
        "                                   'f1-score':'F1-score'})\n",
        "                   [['Precision', 'Recall', 'F1-score', 'Samples']])\n",
        "\n",
        "    per_factor_tables[model_name] = df_cr\n",
        "\n",
        "# Concatenate side-by-side â†’ MultiIndex columns: level-0=model, level-1=metric\n",
        "combined = pd.concat(\n",
        "    {m: tbl.drop(columns='Samples') for m, tbl in per_factor_tables.items()},\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Single shared Samples column\n",
        "combined[('', 'Samples')] = next(iter(per_factor_tables.values()))['Samples']\n",
        "combined = combined.reindex(\n",
        "    columns=[c for c in combined.columns if c[1] != 'Samples'] + [('', 'Samples')]\n",
        ")\n",
        "combined.columns.set_names(['Model', 'Metric'], inplace=True)\n",
        "\n",
        "print(\"\\n## Per-Factor Metrics: Random Forest vs Gradient Boosting\\n\")\n",
        "display(\n",
        "    combined.style\n",
        "            .format(lambda x: f\"{x:.1f}%\" if isinstance(x, (float, np.floating))\n",
        "                                   else \"{:d}\".format(x))\n",
        "            .set_caption(\"Per-Factor Metrics (Combined)\")\n",
        "            .set_table_styles(\n",
        "                [\n",
        "                    {'selector': 'th', 'props': [('text-align', 'center')]},\n",
        "                    {'selector': 'th.col_heading.level0',\n",
        "                     'props': [('border-bottom', '1pt solid black')]}\n",
        "                ]\n",
        "            )\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. Overall-performance summary\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "summary_rows = []\n",
        "for model_name, df_res in items:\n",
        "    y_true, y_pred = df_res.Actual_Winner, df_res.Predicted_Winner\n",
        "    summary_rows.append({\n",
        "        'Model':              model_name,\n",
        "        'Accuracy (%)':       round(accuracy_score(y_true, y_pred) * 100, 1),\n",
        "        'Precision (wtd %)':  round(precision_score(y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'Recall  (wtd %)':    round(recall_score   (y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'F1 (wtd %)':         round(f1_score       (y_true, y_pred, average='weighted') * 100, 1),\n",
        "        'Samples':            len(y_true)\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows).set_index('Model')\n",
        "\n",
        "print(\"\\n### Overall Performance Summary ###\\n\")\n",
        "display(\n",
        "    summary_df.style\n",
        "              .format({\n",
        "                  'Accuracy (%)':      '{:.1f}%',\n",
        "                  'Precision (wtd %)': '{:.1f}%',\n",
        "                  'Recall  (wtd %)':   '{:.1f}%',\n",
        "                  'F1 (wtd %)':        '{:.1f}%',\n",
        "                  'Samples':           '{:d}'\n",
        "              })\n",
        "              .set_caption(\"Overall Performance Summary\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature importance"
      ],
      "metadata": {
        "id": "-U5ovbRVPoPM"
      },
      "id": "-U5ovbRVPoPM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5",
      "metadata": {
        "tags": [],
        "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume FEATURES is defined (e.g., FEATURES = ['CPI%', 'T10YFF', 'LEI%', 'Amihud', 'GARCH_1M'])\n",
        "# and results_dfs is a dictionary with keys like \"RF\", \"GB\", (and maybe \"Hybrid\")\n",
        "# where each value is a DataFrame that has a column \"Feature_Importances\" (an array).\n",
        "\n",
        "# 1. Compute overall average feature importances for each model.\n",
        "model_importances = {}\n",
        "for model_key, df in results_dfs.items():\n",
        "    # Stack the arrays from the \"Feature_Importances\" column and average over predictions.\n",
        "    model_importances[model_key] = np.vstack(df['Feature_Importances'].values).mean(axis=0)\n",
        "\n",
        "# 2. Create a DataFrame from the computed importances.\n",
        "# Rows: features, Columns: model keys.\n",
        "importance_df = pd.DataFrame(model_importances, index=FEATURES)\n",
        "\n",
        "# Optional: sort features by overall mean importance (averaged across models) so that\n",
        "# the most important features appear on top.\n",
        "importance_df['Mean'] = importance_df.mean(axis=1)\n",
        "importance_df = importance_df.sort_values(by='Mean', ascending=False)\n",
        "sorted_features = importance_df.index.tolist()\n",
        "importance_df = importance_df.drop(columns=['Mean'])\n",
        "\n",
        "# 3. Plot a grouped horizontal bar chart.\n",
        "models = importance_df.columns.tolist()\n",
        "n_models = len(models)\n",
        "n_features = len(sorted_features)\n",
        "y = np.arange(n_features)  # base positions for each feature group\n",
        "bar_height = 0.8 / n_models  # total group thickness is 0.8\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, max(4, n_features * 0.6)))\n",
        "for i, model in enumerate(models):\n",
        "    # Calculate an offset for each model in the group.\n",
        "    offset = (i - n_models/2) * bar_height + bar_height/2\n",
        "    ax.barh(y + offset, importance_df.loc[sorted_features, model], height=bar_height, label=model)\n",
        "\n",
        "ax.set_yticks(y)\n",
        "ax.set_yticklabels(sorted_features)\n",
        "ax.invert_yaxis()  # so the top feature is at the top\n",
        "ax.set_xlabel(\"Average Feature Importance\")\n",
        "ax.set_title(\"Comparison of Overall Average Feature Importances Across Models\")\n",
        "ax.legend(title=\"Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Allocation chart"
      ],
      "metadata": {
        "id": "bhRxmOoFPtEI"
      },
      "id": "bhRxmOoFPtEI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8",
      "metadata": {
        "tags": [],
        "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# â”€â”€ 0.  Figure parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "panel_height = 3.0\n",
        "fig_width    = 12\n",
        "num_models   = len(results_dfs)\n",
        "fig_height   = panel_height * num_models\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "    nrows=num_models, ncols=1,\n",
        "    figsize=(fig_width, fig_height),\n",
        "    sharex=True,\n",
        ")\n",
        "\n",
        "if num_models == 1:      # keep iterable\n",
        "    axes = [axes]\n",
        "\n",
        "# â”€â”€ 1.  Get the GLOBAL date span so every axis uses identical limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "all_dates = pd.concat(\n",
        "    [pd.to_datetime(df[\"Predicted_month\"], errors=\"coerce\") for df in results_dfs.values()]\n",
        ").dropna()\n",
        "date_min, date_max = all_dates.min(), all_dates.max()\n",
        "\n",
        "# â”€â”€ 2.  Plot each model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for ax, (model_key, df_model) in zip(axes, results_dfs.items()):\n",
        "    df_temp = df_model.copy()\n",
        "\n",
        "    # Parse dates & clean\n",
        "    df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors=\"coerce\")\n",
        "    df_temp = df_temp.dropna(subset=[\"Predicted_month\"]).sort_values(\"Predicted_month\")\n",
        "\n",
        "    # Probability matrix â†’ DataFrame\n",
        "    full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "    probability_df         = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "    probability_df[\"Date\"] = df_temp[\"Predicted_month\"].values\n",
        "\n",
        "    # Stackplot\n",
        "    ax.stackplot(\n",
        "        probability_df[\"Date\"],\n",
        "        [probability_df[col] for col in FACTORS],\n",
        "        labels=FACTORS,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "    # Aesthetics\n",
        "    ax.set_title(f\"{model_key} Outperforming Probabilities\", fontsize=12, pad=6)\n",
        "    ax.set_ylabel(\"Probability\", fontsize=10)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# â”€â”€ 3.  Remove x-axis padding & apply shared limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for ax in axes:\n",
        "    ax.set_xlim(date_min, date_max)  # exact span\n",
        "    ax.margins(x=0)                  # turn off the default 5% padding\n",
        "\n",
        "# Legend only on the first axis (or wherever you prefer)\n",
        "axes[0].legend(\n",
        "    loc=\"upper right\",\n",
        "    fontsize=\"x-small\",\n",
        "    title=\"Factors\",\n",
        "    frameon=True,\n",
        "    framealpha=1.0,\n",
        "    facecolor=\"white\",\n",
        "    edgecolor=\"black\",\n",
        ")\n",
        "\n",
        "# â”€â”€ 4.  Final touches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "axes[-1].set_xlabel(\"Date\", fontsize=10)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(left=0.04, right=0.995)   # trims the white border outside axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Factor weight analysis"
      ],
      "metadata": {
        "id": "PY247n9MPyWG"
      },
      "id": "PY247n9MPyWG"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Toggle:\n",
        "combine_all_models = False  # Set to True to combine all models into the same charts; False for individual charts per model\n",
        "\n",
        "# Set the date range for viewing.\n",
        "start_date = pd.to_datetime(\"1968-07-30\")\n",
        "end_date   = pd.to_datetime(\"2024-11-30\")\n",
        "\n",
        "# Define static equal weight value.\n",
        "equal_weight = 1 / len(FACTORS)  # e.g., for 5 factors equal_weight = 0.20\n",
        "\n",
        "if combine_all_models:\n",
        "    # Combined charts: One set of subplots (one per factor) for all models.\n",
        "    n_factors = len(FACTORS)\n",
        "    fig, axs = plt.subplots(n_factors, 1, figsize=(12, 4 * n_factors), sharex=False)\n",
        "    if n_factors == 1:\n",
        "        axs = [axs]  # ensure axs is iterable\n",
        "\n",
        "    for i, factor in enumerate(FACTORS):\n",
        "        ax = axs[i]\n",
        "        min_dates = []\n",
        "        max_dates = []\n",
        "\n",
        "        # Loop through each model's results\n",
        "        for model_key, df_model in results_dfs.items():\n",
        "            df_temp = df_model.copy()\n",
        "            df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors='coerce')\n",
        "            df_temp = df_temp.dropna(subset=[\"Predicted_month\"]).sort_values(\"Predicted_month\").reset_index(drop=True)\n",
        "\n",
        "            # Stack predicted probabilities into a DataFrame.\n",
        "            full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "            probability_df = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "            probability_df[\"Date\"] = df_temp[\"Predicted_month\"]\n",
        "\n",
        "            # Filter to desired date range.\n",
        "            mask = (probability_df[\"Date\"] >= start_date) & (probability_df[\"Date\"] <= end_date)\n",
        "            filtered_df = probability_df.loc[mask].reset_index(drop=True)\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                continue\n",
        "\n",
        "            ax.plot(filtered_df[\"Date\"], filtered_df[factor],\n",
        "                    label=f\"{factor}_{model_key}\", linewdth=0.6)\n",
        "\n",
        "            min_dates.append(filtered_df[\"Date\"].min())\n",
        "            max_dates.append(filtered_df[\"Date\"].max())\n",
        "\n",
        "        # Set x-axis limits to exactly the data span (if any data exist)\n",
        "        if min_dates and max_dates:\n",
        "            ax.set_xlim(min(min_dates), max(max_dates))\n",
        "\n",
        "        # Draw the static equal weight horizontal line.\n",
        "        ax.axhline(equal_weight, color='black', linestyle='--',\n",
        "                   label=f\"Equal Weight ({equal_weight:.2%})\")\n",
        "\n",
        "        ax.set_title(f\"{factor} Predicted Probabilities Across Models\", fontsize=14)\n",
        "        ax.set_ylabel(\"Probability\", fontsize=12)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        ax.legend(loc='best', fontsize='small')\n",
        "\n",
        "    plt.xlabel(\"Date\", fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    # Separate charts: Loop over each model and for each factor create individual charts.\n",
        "    for model_key, df_model in results_dfs.items():\n",
        "        for factor in FACTORS:\n",
        "            df_temp = df_model.copy()\n",
        "            df_temp[\"Predicted_month\"] = pd.to_datetime(df_temp[\"Predicted_month\"], errors='coerce')\n",
        "            df_temp = df_temp.dropna(subset=[\"Predicted_month\"]).sort_values(\"Predicted_month\").reset_index(drop=True)\n",
        "\n",
        "            full_probs = np.vstack(df_temp[\"Predicted_Probabilities\"].values)\n",
        "            probability_df = pd.DataFrame(full_probs, columns=FACTORS)\n",
        "            probability_df[\"Date\"] = df_temp[\"Predicted_month\"]\n",
        "\n",
        "            # Filter to desired date range.\n",
        "            mask = (probability_df[\"Date\"] >= start_date) & (probability_df[\"Date\"] <= end_date)\n",
        "            filtered_df = probability_df.loc[mask].reset_index(drop=True)\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                continue\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.plot(filtered_df[\"Date\"], filtered_df[factor],\n",
        "                     label=f\"{factor} Predicted Probability\", color='blue', linewidth=0.6)\n",
        "\n",
        "            plt.axhline(equal_weight, color='black', linestyle='--',\n",
        "                        label=f\"Equal Weight ({equal_weight:.2%})\")\n",
        "\n",
        "            plt.fill_between(filtered_df[\"Date\"],\n",
        "                             filtered_df[factor],\n",
        "                             equal_weight,\n",
        "                             where=(filtered_df[factor] > equal_weight),\n",
        "                             interpolate=True, color='green', alpha=0.3, label='Overweight')\n",
        "            plt.fill_between(filtered_df[\"Date\"],\n",
        "                             filtered_df[factor],\n",
        "                             equal_weight,\n",
        "                             where=(filtered_df[factor] < equal_weight),\n",
        "                             interpolate=True, color='red', alpha=0.3, label='Underweight')\n",
        "\n",
        "            plt.title(f\"{model_key} - Over/Under Weight for {factor}\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Probability\")\n",
        "            plt.ylim(0, 1)\n",
        "            # Set x-axis limits to exactly where data exists.\n",
        "            plt.xlim(filtered_df[\"Date\"].min(), filtered_df[\"Date\"].max())\n",
        "            plt.legend(loc='best')\n",
        "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "5My7U6ny7GAJ"
      },
      "id": "5My7U6ny7GAJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total outperforming probabilities"
      ],
      "metadata": {
        "id": "6wkhRaZrP6aF"
      },
      "id": "6wkhRaZrP6aF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. Compute average predicted probabilities per model\n",
        "# ----------------------------------------------------\n",
        "avg_probs_dict = {}\n",
        "avg_highest_factor_weight_dict = {}\n",
        "\n",
        "for model_key, df_model in results_dfs.items():\n",
        "    full_probs = np.vstack(df_model[\"Predicted_Probabilities\"].values)\n",
        "\n",
        "    # 1a. Compute the average probabilities across all rows\n",
        "    avg = full_probs.mean(axis=0)\n",
        "    avg_probs_dict[model_key] = pd.Series(avg, index=FACTORS)\n",
        "\n",
        "    # 1b. Compute the average of the highest weight factor\n",
        "    #     (for each time step, pick the max factor weight, then average those)\n",
        "    avg_highest_factor_weight_dict[model_key] = full_probs.max(axis=1).mean()\n",
        "\n",
        "# Create a DataFrame where rows = models, columns = factors\n",
        "avg_probs_df = pd.DataFrame(avg_probs_dict).T\n",
        "avg_probs_df.index.name = \"Model\"\n",
        "avg_probs_df = avg_probs_df.round(4)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. Generate consistent factor colors from stackplot\n",
        "# ----------------------------------------------------\n",
        "# Use a dummy stackplot to extract the assigned factor colors\n",
        "_, ax_dummy = plt.subplots()\n",
        "dummy_data = np.random.rand(10, len(FACTORS))\n",
        "dummy_dates = pd.date_range(\"2000-01-01\", periods=10)\n",
        "stack = ax_dummy.stackplot(dummy_dates, dummy_data.T, labels=FACTORS, alpha=0.8)\n",
        "plt.close()  # We donâ€™t want to display this\n",
        "\n",
        "# Build color map: factor name â†’ RGBA color\n",
        "factor_colors = {factor: poly.get_facecolor()[0] for factor, poly in zip(FACTORS, stack)}\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3. Display HTML Table of average probabilities\n",
        "# ----------------------------------------------------\n",
        "html_table = avg_probs_df.reset_index().to_html(index=False, classes=\"table table-striped table-bordered\", border=0)\n",
        "display(HTML(\"<h3>Average Outperforming Probabilities by Model</h3>\" + html_table))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. Print average of the highest factor weight by model\n",
        "# ----------------------------------------------------\n",
        "display(HTML(\"<h4>Average of the Highest Factor Weight by Model</h4>\"))\n",
        "for model_key, avg_highest in avg_highest_factor_weight_dict.items():\n",
        "    display(HTML(f\"<p><strong>{model_key}:</strong> {avg_highest:.4f}</p>\"))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 5. Stacked Bar Chart with Consistent Colors and Labels\n",
        "# ----------------------------------------------------\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "bottom = np.zeros(len(avg_probs_df))\n",
        "x = np.arange(len(avg_probs_df))\n",
        "\n",
        "for factor in FACTORS:\n",
        "    values = avg_probs_df[factor].values\n",
        "    bars = ax.bar(x, values, bottom=bottom,\n",
        "                  label=factor,\n",
        "                  color=factor_colors[factor],\n",
        "                  edgecolor=\"white\",\n",
        "                  linewidth=0.5)\n",
        "\n",
        "    # Centered labels\n",
        "    for bar, val in zip(bars, values):\n",
        "        if val > 0.03:\n",
        "            ax.text(\n",
        "                bar.get_x() + bar.get_width() / 2,\n",
        "                bar.get_y() + bar.get_height() / 2,\n",
        "                f\"{val * 100:.1f}%\",\n",
        "                ha=\"center\", va=\"center\", fontsize=9, color=\"white\"\n",
        "            )\n",
        "\n",
        "    bottom += values\n",
        "\n",
        "# Final touches\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(avg_probs_df.index)\n",
        "ax.set_ylabel(\"Strategy average factor weights\")\n",
        "ax.set_title(\"Strategy average factor weights\")\n",
        "ax.legend(title=\"Factor\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7GvhTSes34Ci"
      },
      "id": "7GvhTSes34Ci",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Return data"
      ],
      "metadata": {
        "id": "M0sRKlsm6Yja"
      },
      "id": "M0sRKlsm6Yja"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 0: Define column orders based on your requirements\n",
        "# ------------------------------------------------------------------------------\n",
        "# Common columns that are identical across all models.\n",
        "common_cols = ['Predicted_month', 'Mkt', 'RF', 'Mkt-RF', 'Us_standard'] + FACTORS + ['Equal_Weight_Return', 'Actual_Winner']\n",
        "\n",
        "# Model-specific columns that will be renamed.\n",
        "model_specific_cols = ['Allocated_Return', 'Predicted_Winner']\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 1. Build a base common DataFrame from one model's merged results.\n",
        "# ------------------------------------------------------------------------------\n",
        "# Take the first model as the base to extract common columns.\n",
        "base_key, base_df = list(results_dfs.items())[0]\n",
        "base_df = base_df.copy()\n",
        "base_df['Predicted_month'] = pd.to_datetime(base_df['Predicted_month'], errors='coerce')\n",
        "\n",
        "# Merge with df_sorted (the master DataFrame sorted by date) on date.\n",
        "base_df_local = base_df.merge(df_sorted, left_on='Predicted_month', right_on='Date', how='left')\n",
        "common_df = base_df_local[[c for c in common_cols if c in base_df_local.columns]].copy()\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 2. Process each model individually to extract the model-specific columns.\n",
        "# ------------------------------------------------------------------------------\n",
        "# We'll assign a new display name using numbering such that each model gets:\n",
        "# \"ML{number}: {Model Name}\"\n",
        "model_dfs = []         # Will hold one DataFrame per model.\n",
        "new_model_names = []   # To store new model names.\n",
        "for i, (model_key, df_model) in enumerate(results_dfs.items(), 1):\n",
        "    new_model_name = f\"ML{i}: {model_key}\"  # New display name.\n",
        "    new_model_names.append(new_model_name)\n",
        "\n",
        "    df_temp = df_model.copy()\n",
        "    df_temp['Predicted_month'] = pd.to_datetime(df_temp['Predicted_month'], errors='coerce')\n",
        "\n",
        "    # Merge with df_sorted on 'Predicted_month' = 'Date'\n",
        "    df_temp_local = df_temp.merge(df_sorted, left_on='Predicted_month', right_on='Date', how='left')\n",
        "\n",
        "    # Keep only the 'Predicted_month' plus the model-specific columns.\n",
        "    subset_cols = ['Predicted_month'] + [col for col in model_specific_cols if col in df_temp_local.columns]\n",
        "    df_subset = df_temp_local[subset_cols].copy()\n",
        "\n",
        "    # Rename model-specific columns with the new model name.\n",
        "    rename_dict = {}\n",
        "    for col in model_specific_cols:\n",
        "        if col in df_subset.columns:\n",
        "            rename_dict[col] = f\"{new_model_name} {col}\"\n",
        "    df_subset.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "    model_dfs.append(df_subset)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 3. Merge each model-specific DataFrame with the common DataFrame.\n",
        "# ------------------------------------------------------------------------------\n",
        "combined_df = common_df.copy()\n",
        "for df_sub in model_dfs:\n",
        "    combined_df = combined_df.merge(df_sub, on='Predicted_month', how='left')\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 4. Reorder the columns to match the desired order.\n",
        "# ------------------------------------------------------------------------------\n",
        "benchmark_cols = ['Mkt', 'RF', 'Mkt-RF', 'Us_standard']\n",
        "common_order = ['Predicted_month'] + benchmark_cols + FACTORS\n",
        "# Model-specific allocated return columns.\n",
        "allocated_cols = [f\"{name} Allocated_Return\" for name in new_model_names]\n",
        "# Model-specific predicted winner columns.\n",
        "predicted_cols = [f\"{name} Predicted_Winner\" for name in new_model_names]\n",
        "\n",
        "final_order = common_order + ['Equal_Weight_Return'] + allocated_cols + ['Actual_Winner'] + predicted_cols\n",
        "final_order = [col for col in final_order if col in combined_df.columns]\n",
        "\n",
        "combined_df = combined_df[final_order].sort_values('Predicted_month').reset_index(drop=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 5. Display the final combined results table.\n",
        "# ------------------------------------------------------------------------------\n",
        "display(combined_df)\n",
        "print(\"\\nFirst date in 'Predicted_month':\", pd.to_datetime(combined_df['Predicted_month']).min())\n",
        "print(\"Last date in 'Predicted_month':\", pd.to_datetime(combined_df['Predicted_month']).max())\n"
      ],
      "metadata": {
        "id": "rA982P5EGhj4"
      },
      "id": "rA982P5EGhj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "# Define your date range\n",
        "start_date = pd.to_datetime('2000-01-01')\n",
        "end_date   = pd.to_datetime('2024-12-30')\n",
        "\n",
        "# Create a filtered copy of combined_df (so the original data isn't lost)\n",
        "filtered_df = combined_df.loc[\n",
        "    (combined_df['Predicted_month'] >= start_date) &\n",
        "    (combined_df['Predicted_month'] <= end_date)\n",
        "].copy()\n",
        "\n",
        "# Ensure \"Year\" column exists in filtered_df\n",
        "if 'Year' not in filtered_df.columns:\n",
        "    filtered_df['Year'] = filtered_df['Predicted_month'].dt.year\n",
        "\n",
        "# Identify ML return columns and create a name map to remove \"Allocated_Return\"\n",
        "ml_return_cols = [c for c in filtered_df.columns if 'Allocated_Return' in c]\n",
        "ml_name_map = {ml: ml.replace(\"Allocated_Return\", \"\").strip() for ml in ml_return_cols}\n",
        "\n",
        "# Helper: Compute annual metrics (RF-adjusted)\n",
        "def compute_annual_metrics(returns: pd.Series, rf: pd.Series):\n",
        "    returns = returns.dropna()\n",
        "    if returns.empty:\n",
        "        return np.nan, np.nan, np.nan\n",
        "    rf = rf.reindex(returns.index)\n",
        "    ann_ret = (1 + returns).prod() - 1\n",
        "    ann_rf  = (1 + rf).prod() - 1\n",
        "    ann_ex_ret = ann_ret - ann_rf\n",
        "    ann_vol = (returns - rf).std() * np.sqrt(12)\n",
        "    ann_sharpe = ann_ex_ret / ann_vol if ann_vol else np.nan\n",
        "    return ann_ret, ann_vol, ann_sharpe\n",
        "\n",
        "# Build df_metrics (raw values) and df_excess (excess over Equal Weight)\n",
        "metrics_rows, excess_rows = [], []\n",
        "for year, grp in filtered_df.groupby('Year'):\n",
        "    ew_ret, ew_vol, ew_sharpe = compute_annual_metrics(grp['Equal_Weight_Return'], grp['RF'])\n",
        "    row_m = {'Year': year,\n",
        "             'Equal_Weight Return': ew_ret,\n",
        "             'Equal_Weight Vol':    ew_vol,\n",
        "             'Equal_Weight Sharpe': ew_sharpe}\n",
        "    row_e = {'Year': year}\n",
        "\n",
        "    for ml in ml_return_cols:\n",
        "        ml_short = ml_name_map[ml]\n",
        "        ml_ret, ml_vol, ml_sharpe = compute_annual_metrics(grp[ml], grp['RF'])\n",
        "        row_m[f\"{ml_short} Return\"]  = ml_ret\n",
        "        row_m[f\"{ml_short} Vol\"]     = ml_vol\n",
        "        row_m[f\"{ml_short} Sharpe\"]  = ml_sharpe\n",
        "\n",
        "        row_e[f\"{ml_short} Excess Return\"]  = ml_ret - ew_ret\n",
        "        row_e[f\"{ml_short} Excess Vol\"]     = ml_vol - ew_vol\n",
        "        row_e[f\"{ml_short} Excess Sharpe\"]  = ml_sharpe - ew_sharpe\n",
        "\n",
        "    metrics_rows.append(row_m)\n",
        "    excess_rows.append(row_e)\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics_rows).set_index('Year').sort_index()\n",
        "df_excess  = pd.DataFrame(excess_rows).set_index('Year').sort_index()\n",
        "\n",
        "# Function: Insert newline breaks for column names longer than max_width characters.\n",
        "def wrap_colname(colname, max_width=15):\n",
        "    lines = textwrap.wrap(colname, width=max_width)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Apply wrapping to all column names\n",
        "df_metrics.columns = [wrap_colname(col) for col in df_metrics.columns]\n",
        "df_excess.columns  = [wrap_colname(col) for col in df_excess.columns]\n",
        "\n",
        "# Function: Style dataframe to enable multiline headers and format numbers with a max of 3 decimals.\n",
        "def style_with_wrapping_and_format(df):\n",
        "    styled = df.style.set_table_styles([\n",
        "        {\n",
        "            'selector': 'th',\n",
        "            'props': [\n",
        "                ('white-space', 'pre-wrap'),  # allow multiline\n",
        "                ('word-wrap', 'break-word')   # break long words\n",
        "            ]\n",
        "        }\n",
        "    ]).format(lambda x: f\"{x:.3f}\" if isinstance(x, float) else x)\n",
        "    return styled\n",
        "\n",
        "# Display the raw metrics and excess metrics with formatted output.\n",
        "display(style_with_wrapping_and_format(df_metrics))\n",
        "display(style_with_wrapping_and_format(df_excess))\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Summary: Count how often each ML strategy \"beats\" Equal Weight.\n",
        "#  - Excess Return is \"better\" if > 0.\n",
        "#  - Excess Volatility is \"better\" if < 0.\n",
        "#  - Excess Sharpe is \"better\" if > 0.\n",
        "#\n",
        "# Average excess metrics are now calculated from all observations.\n",
        "# -----------------------------------------------------------------\n",
        "summary_rows = []\n",
        "total_years = len(df_excess)\n",
        "\n",
        "def w(ml_short, suffix):\n",
        "    return wrap_colname(f\"{ml_short} {suffix}\")\n",
        "\n",
        "for ml in ml_return_cols:\n",
        "    ml_short = ml_name_map[ml]\n",
        "    ret_series    = df_excess[w(ml_short, \"Excess Return\")]\n",
        "    vol_series    = df_excess[w(ml_short, \"Excess Vol\")]\n",
        "    sharpe_series = df_excess[w(ml_short, \"Excess Sharpe\")]\n",
        "\n",
        "    ret_pos_count    = (ret_series > 0).sum()\n",
        "    vol_neg_count    = (vol_series < 0).sum()\n",
        "    sharpe_pos_count = (sharpe_series > 0).sum()\n",
        "\n",
        "    # Average excess metrics now computed over all observations:\n",
        "    avg_ret    = ret_series.mean()\n",
        "    avg_vol    = vol_series.mean()\n",
        "    avg_sharpe = sharpe_series.mean()\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Strategy\": ml_short,\n",
        "        \"Excess Return (Positive) Count\": f\"{ret_pos_count}/{total_years}\",\n",
        "        \"Avg Excess Return\":   avg_ret,\n",
        "        \"Excess Vol (Negative) Count\":    f\"{vol_neg_count}/{total_years}\",\n",
        "        \"Avg Excess Vol\":      avg_vol,\n",
        "        \"Excess Sharpe (Positive) Count\": f\"{sharpe_pos_count}/{total_years}\",\n",
        "        \"Avg Excess Sharpe\":   avg_sharpe\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.columns = [wrap_colname(col) for col in summary_df.columns]\n",
        "\n",
        "display(style_with_wrapping_and_format(summary_df))\n"
      ],
      "metadata": {
        "id": "j8ieygX5yPei"
      },
      "id": "j8ieygX5yPei",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cumulative returns table"
      ],
      "metadata": {
        "id": "E3Xi_BH1iwiv"
      },
      "id": "E3Xi_BH1iwiv"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# PRELIMINARY: Use the merged multi-model table (combined_df)\n",
        "# ---------------------------------------------------------------------\n",
        "start_date = pd.to_datetime('1950-01-01')\n",
        "end_date   = pd.to_datetime('2024-12-30')\n",
        "df_filtered = combined_df[(combined_df['Predicted_month'] >= start_date) &\n",
        "                            (combined_df['Predicted_month'] <= end_date)].copy()\n",
        "\n",
        "# Rename benchmark column if present (using the first element of BENCHMARK)\n",
        "rename_dict = {}\n",
        "if BENCHMARK[0] in df_filtered.columns:\n",
        "    rename_dict[BENCHMARK[0]] = 'Benchmark Return'\n",
        "df_filtered.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Remove RF from factors (we exclude it)\n",
        "factors_to_use = [fac for fac in FACTORS if fac.upper() != 'RF']\n",
        "\n",
        "# Define possible benchmark columns (for cumulative returns).\n",
        "possible_bench = [\"Benchmark Return\", \"Mkt\", \"Mkt-RF\", \"Us_standard\"]\n",
        "benchmark_cols = [col for col in possible_bench if col in df_filtered.columns]\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Calculate Equal-Weighted Returns based on factors_to_use.\n",
        "if all(f in df_filtered.columns for f in factors_to_use):\n",
        "    df_filtered['Equal Factor Weight Strategy Return'] = df_filtered[factors_to_use].mean(axis=1)\n",
        "    equal_ret_col_list = ['Equal Factor Weight Strategy Return']\n",
        "else:\n",
        "    equal_ret_col_list = []\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Predicted Winner Weighted Strategy Return:\n",
        "# Use the base model's predicted winner column using new naming.\n",
        "base_model_key = list(results_dfs.keys())[0]\n",
        "base_model_new = f\"ML1: {base_model_key}\"  # First model is ML1.\n",
        "base_model_pred_col = f\"{base_model_new} Predicted_Winner\"\n",
        "if base_model_pred_col in df_filtered.columns:\n",
        "    df_filtered['Predicted_Winner'] = df_filtered[base_model_pred_col]\n",
        "\n",
        "def calc_winner_strategy(row):\n",
        "    pred = row['Predicted_Winner']\n",
        "    if pred in factors_to_use:\n",
        "        other_factors = [f for f in factors_to_use if f != pred]\n",
        "        if other_factors:\n",
        "            return 0.5 * row[pred] + 0.5 * row[other_factors].mean()\n",
        "        else:\n",
        "            return row[pred]\n",
        "    else:\n",
        "        return row[factors_to_use].mean()\n",
        "\n",
        "df_filtered['Predicted Winner Weighted Strategy Return'] = df_filtered.apply(calc_winner_strategy, axis=1)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Compute cumulative returns for each return series.\n",
        "# We'll work on a copy for cumulative computations.\n",
        "cum = df_filtered.copy()\n",
        "\n",
        "# 1. For each model's allocated return (using new names).\n",
        "allocated_cum_cols = []\n",
        "new_model_names = [f\"ML{i}: {model_key}\" for i, model_key in enumerate(results_dfs.keys(), 1)]\n",
        "for name in new_model_names:\n",
        "    col_alloc = f\"{name} Allocated_Return\"\n",
        "    if col_alloc in cum.columns:\n",
        "        new_cum_col = col_alloc.replace(\"Allocated_Return\", \"Cumulative Allocated Return\")\n",
        "        cum[new_cum_col] = (1 + cum[col_alloc]).cumprod() - 1\n",
        "        allocated_cum_cols.append(new_cum_col)\n",
        "\n",
        "# 2. For equal factor weight returns.\n",
        "if 'Equal Factor Weight Strategy Return' in cum.columns:\n",
        "    cum['Equal Factor Weight Cumulative Return'] = (1 + cum['Equal Factor Weight Strategy Return']).cumprod() - 1\n",
        "    equal_cum_cols = ['Equal Factor Weight Cumulative Return']\n",
        "else:\n",
        "    equal_cum_cols = []\n",
        "\n",
        "# 3. For each benchmark column.\n",
        "bench_cum_cols = []\n",
        "# If \"Benchmark Return\" is available, use the actual benchmark name from BENCHMARK[0].\n",
        "if \"Benchmark Return\" in cum.columns:\n",
        "    new_bench_col = f\"{BENCHMARK[0]} Cumulative Return\"\n",
        "    cum[new_bench_col] = (1 + cum[\"Benchmark Return\"]).cumprod() - 1\n",
        "    bench_cum_cols.append(new_bench_col)\n",
        "# Process any other benchmark columns\n",
        "for col in benchmark_cols:\n",
        "    if col != \"Benchmark Return\":\n",
        "        new_col = col + \" Cumulative Return\"\n",
        "        cum[new_col] = (1 + cum[col]).cumprod() - 1\n",
        "        bench_cum_cols.append(new_col)\n",
        "\n",
        "# 4. For Predicted Winner Weighted Strategy Return.\n",
        "if 'Predicted Winner Weighted Strategy Return' in cum.columns:\n",
        "    cum['Predicted Winner Weighted Cumulative Return'] = (1 + cum['Predicted Winner Weighted Strategy Return']).cumprod() - 1\n",
        "\n",
        "# 5. For each factor in factors_to_use: compute cumulative returns.\n",
        "factor_cum_cols = []\n",
        "for fac in factors_to_use:\n",
        "    if fac in cum.columns:\n",
        "        new_name = fac + \" Cumulative\"\n",
        "        cum[new_name] = (1 + cum[fac]).cumprod() - 1\n",
        "        factor_cum_cols.append(new_name)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Build the final cumulative returns table.\n",
        "# Final order:\n",
        "#   a. Common columns: Predicted_month, then benchmark cumulative returns, then factor cumulative returns.\n",
        "#   b. Then Equal Factor Weight Cumulative Return.\n",
        "#   c. Then each model's Cumulative Allocated Return.\n",
        "#   d. Then Predicted Winner Weighted Cumulative Return.\n",
        "# ---------------------------------------------------------------------\n",
        "final_common_order = ['Predicted_month'] + bench_cum_cols + factor_cum_cols\n",
        "final_order = final_common_order + equal_cum_cols + allocated_cum_cols\n",
        "if 'Predicted Winner Weighted Cumulative Return' in cum.columns:\n",
        "    final_order.append('Predicted Winner Weighted Cumulative Return')\n",
        "\n",
        "final_order = [col for col in final_order if col in cum.columns]\n",
        "cumulative_table = cum[final_order].sort_values('Predicted_month').reset_index(drop=True)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Display the Final Cumulative Returns Table.\n",
        "# ---------------------------------------------------------------------\n",
        "print(\"Cumulative Returns Table:\")\n",
        "display(cumulative_table)\n",
        "print(\"\\nFirst date in 'Predicted_month':\", pd.to_datetime(cumulative_table['Predicted_month']).min())\n",
        "print(\"Last date in 'Predicted_month':\", pd.to_datetime(cumulative_table['Predicted_month']).max())"
      ],
      "metadata": {
        "id": "wm06N1gjGjVr"
      },
      "id": "wm06N1gjGjVr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cumulative returns chart"
      ],
      "metadata": {
        "id": "W-uq2G9iPQwD"
      },
      "id": "W-uq2G9iPQwD"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# User-configurable toggles\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "cut_off_date        = pd.to_datetime(\"2000-01-01\")   # â‘  where to rebase\n",
        "show_50_50_strategy = False                          # keep your old toggles\n",
        "show_benchmark      = True\n",
        "use_log_scale       = True                           # â† log scale like the 3rd graph\n",
        "shade_out_of_sample = True                           # â‘¡ grey shading toggle\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Prep the data\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "df_plot  = cumulative_table.copy()\n",
        "start_dt = df_plot['Predicted_month'].min()\n",
        "end_dt   = df_plot['Predicted_month'].max()\n",
        "\n",
        "# Helper: rebase any cumulative-return series so it equals 1 at cut-off\n",
        "def rebase(series, cut_date):\n",
        "    \"\"\"Convert cumulative-return series to wealth curve rebased to 1 at cut_date.\"\"\"\n",
        "    wealth = 1 + series            # turn cum-return into wealth\n",
        "    base   = wealth.loc[series.index == cut_date]\n",
        "    if not base.empty and base.iloc[0] != 0:          # protect against divide-by-0\n",
        "        return wealth / base.iloc[0]\n",
        "    else:\n",
        "        return wealth / wealth.iloc[0]               # fallback: rebase to first point\n",
        "\n",
        "# Apply rebasing to every cumulative series we intend to plot\n",
        "rebased_cols = {}   # {col_name: rebased_series}\n",
        "for col in df_plot.columns:\n",
        "    if (\"Cumulative\" in col) and (col != \"Predicted_month\"):\n",
        "        rebased_cols[col] = rebase(\n",
        "            df_plot.set_index('Predicted_month')[col],\n",
        "            cut_off_date\n",
        "        )\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Plot\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.clf()\n",
        "\n",
        "# 1. ML models\n",
        "for col, series in rebased_cols.items():\n",
        "    if \"Cumulative Allocated Return\" in col:\n",
        "        plt.plot(series.index, series, label=col)\n",
        "\n",
        "# 2. Equal-weight factor\n",
        "if 'Equal Factor Weight Cumulative Return' in rebased_cols:\n",
        "    plt.plot(rebased_cols['Equal Factor Weight Cumulative Return'].index,\n",
        "             rebased_cols['Equal Factor Weight Cumulative Return'],\n",
        "             label='Equal Factor Weight')\n",
        "\n",
        "# 3. Benchmarks (optional)\n",
        "if show_benchmark:\n",
        "    for col in rebased_cols:\n",
        "        if (\"Benchmark\" in col or \"Mkt\" in col or \"Us_standard\" in col) and \"Mkt-RF\" not in col:\n",
        "            plt.plot(rebased_cols[col].index, rebased_cols[col], label=col)\n",
        "\n",
        "# 4. 50/50 predicted-winner strategy (optional)\n",
        "if show_50_50_strategy and 'Predicted Winner Weighted Cumulative Return' in rebased_cols:\n",
        "    plt.plot(rebased_cols['Predicted Winner Weighted Cumulative Return'].index,\n",
        "             rebased_cols['Predicted Winner Weighted Cumulative Return'],\n",
        "             label='50%/50% Predicted Winner')\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Cosmetics (log-scale, cut-off line, shading)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Growth of â‚¬1 invested\")\n",
        "plt.title(\"Cumulative Strategy Growth\")\n",
        "plt.xlim(start_dt, end_dt)\n",
        "plt.yscale('log' if use_log_scale else 'linear')\n",
        "plt.grid(True, which='both', linestyle=':')\n",
        "plt.legend()\n",
        "\n",
        "# Vertical cut-off marker\n",
        "plt.axvline(cut_off_date, color='gray', linestyle='--', linewidth=1)\n",
        "\n",
        "# Shaded out-of-sample region\n",
        "if shade_out_of_sample:\n",
        "    plt.axvspan(cut_off_date, end_dt, color='lightgrey', alpha=0.3, label='_nolegend_')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wqfmAhDk3KBx"
      },
      "id": "wqfmAhDk3KBx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PERFORMANCE METRICS"
      ],
      "metadata": {
        "id": "-YjFAG1ePN-9"
      },
      "id": "-YjFAG1ePN-9"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘                    U S E R   C O N F I G                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "METRIC_START_DATE = '2000-01-01'     # inclusive â€“ set None for \"earliest\"\n",
        "METRIC_END_DATE   = '2025-12-31'     # inclusive â€“ set None for \"latest\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  1)  S U B S E T   D A T A\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "df_metrics = combined_df.copy()\n",
        "df_metrics['Predicted_month'] = pd.to_datetime(df_metrics['Predicted_month'])\n",
        "\n",
        "if METRIC_START_DATE is not None:\n",
        "    df_metrics = df_metrics[df_metrics['Predicted_month'] >= METRIC_START_DATE]\n",
        "if METRIC_END_DATE   is not None:\n",
        "    df_metrics = df_metrics[df_metrics['Predicted_month'] <= METRIC_END_DATE]\n",
        "\n",
        "print(f\"\\n=== PERFORMANCE METRICS \"\n",
        "      f\"({df_metrics['Predicted_month'].min().date()} â†’ \"\n",
        "      f\"{df_metrics['Predicted_month'].max().date()}) ===\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  2)  H E L P E R   F N S\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def annualized_metrics(monthly_returns):\n",
        "    \"\"\"Annualised return, volatility & Sharpe from monthly returns.\"\"\"\n",
        "    monthly_returns = monthly_returns.fillna(0)\n",
        "    mean_m, std_m = monthly_returns.mean(), monthly_returns.std()\n",
        "    ann_ret = mean_m * 12\n",
        "    ann_vol = std_m * np.sqrt(12)\n",
        "    sharpe  = ann_ret / ann_vol if ann_vol != 0 else np.nan\n",
        "    return ann_ret, ann_vol, sharpe\n",
        "\n",
        "def max_drawdown(monthly_returns):\n",
        "    wealth = (1 + monthly_returns.fillna(0)).cumprod()\n",
        "    return (wealth / wealth.cummax() - 1).min()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  3)  P I C K   S T R A T E G Y   C O L U M N S\n",
        "#      (now including raw factor returns such as HY, IG, TIPS, â€¦)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "all_columns = df_metrics.columns.tolist()\n",
        "\n",
        "# 3a) pull in your factor names (excluding RF)\n",
        "factor_cols = [\n",
        "    fac for fac in FACTORS\n",
        "    if fac.upper() != 'RF' and fac in df_metrics.columns\n",
        "]\n",
        "\n",
        "# 3b) any column that has \"Return\" in it (but not \"Cumulative\")\n",
        "ret_cols = [\n",
        "    col for col in all_columns\n",
        "    if (\n",
        "        ((\"Return\" in col) or (col == BENCHMARK[0]) or (col == \"Benchmark Return\"))\n",
        "        and (\"Cumulative\" not in col)\n",
        "        and (col not in [\"Actual_Winner\", \"Predicted_month\"])\n",
        "    )\n",
        "]\n",
        "\n",
        "# combine them\n",
        "strategy_cols = factor_cols + ret_cols\n",
        "\n",
        "print(\"Strategy columns used:\")\n",
        "print(strategy_cols)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  4)  C A L C U L A T E   M E T R I C S\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "metrics = []\n",
        "for col in strategy_cols:\n",
        "    monthly = df_metrics[col]\n",
        "    ann_ret, ann_vol, sharpe = annualized_metrics(monthly)\n",
        "    mdd = max_drawdown(monthly)\n",
        "    metrics.append({\n",
        "        \"Strategy\": col,\n",
        "        \"Annualised Return\":    f\"{ann_ret*100:.2f}%\",\n",
        "        \"Annualised Volatility\":f\"{ann_vol*100:.2f}%\",\n",
        "        \"Sharpe Ratio\":         f\"{sharpe:.2f}\",\n",
        "        \"Max Drawdown\":         f\"{mdd*100:.2f}%\"\n",
        "    })\n",
        "\n",
        "metrics_df = (\n",
        "    pd.DataFrame(metrics)\n",
        "      .sort_values(\"Strategy\")\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  5)  D I S P L A Y   (with title above the table)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "title = (\n",
        "    f\"PERFORMANCE METRICS \"\n",
        "    f\"({df_metrics['Predicted_month'].min().date()} â†’ \"\n",
        "    f\"{df_metrics['Predicted_month'].max().date()})\"\n",
        ")\n",
        "\n",
        "html = metrics_df.to_html(index=False)\n",
        "display(HTML(f\"<h3 style='margin-bottom:8px'>{title}</h3>{html}\"))\n"
      ],
      "metadata": {
        "id": "1o0tq56K64bL"
      },
      "id": "1o0tq56K64bL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Drawdown chart"
      ],
      "metadata": {
        "id": "YXD3cJKFO_sE"
      },
      "id": "YXD3cJKFO_sE"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 1. TOGGLE OPTIONS\n",
        "# -------------------------------------------------------------------------\n",
        "show_benchmark_drawdown = True           # Toggle benchmark drawdown\n",
        "show_equal_weight_drawdown = True        # Toggle Equal Weight (single) drawdown\n",
        "show_winner_weighted_drawdown = False     # Toggle Winner Weighted drawdown\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 2. COPY cumulative_table (assumed computed previously)\n",
        "# -------------------------------------------------------------------------\n",
        "drawdown_df = cumulative_table.copy()\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 3. CALCULATE DRAWDOWNS USING WEALTH INDEX (Wealth = 1 + Cumulative Return)\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# a) For each ML model's cumulative allocated return column:\n",
        "ml_alloc_cols = [col for col in drawdown_df.columns if \"Cumulative Allocated Return\" in col]\n",
        "for col in ml_alloc_cols:\n",
        "    wealth = 1 + drawdown_df[col]\n",
        "    drawdown_name = col.replace(\"Cumulative Allocated Return\", \"Drawdown\")\n",
        "    drawdown_df[drawdown_name] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# b) For Benchmark:\n",
        "# Use the benchmark name from BENCHMARK[0]\n",
        "benchmark_name = BENCHMARK[0]  # for example, \"Mkt\"\n",
        "benchmark_cum_col = f\"{benchmark_name} Cumulative Return\"\n",
        "if benchmark_cum_col in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[benchmark_cum_col]\n",
        "    drawdown_df[f\"{benchmark_name} Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "elif \"Mkt Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Mkt Cumulative Return\"]\n",
        "    drawdown_df[\"Mkt Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "else:\n",
        "    print(\"WARNING: No benchmark cumulative return column found.\")\n",
        "\n",
        "# c) For Equal Weight (single version):\n",
        "if \"Equal Factor Weight Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Equal Factor Weight Cumulative Return\"]\n",
        "    drawdown_df[\"Equal Weight Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# d) For Predicted Winner Weighted:\n",
        "if \"Predicted Winner Weighted Cumulative Return\" in drawdown_df.columns:\n",
        "    wealth = 1 + drawdown_df[\"Predicted Winner Weighted Cumulative Return\"]\n",
        "    drawdown_df[\"Winner Weighted Drawdown\"] = wealth / wealth.cummax() - 1\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 4. FILTER BY DATE RANGE\n",
        "# -------------------------------------------------------------------------\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "drawdown_df[\"Predicted_month\"] = pd.to_datetime(drawdown_df[\"Predicted_month\"])\n",
        "plot_df = drawdown_df[(drawdown_df[\"Predicted_month\"] >= start_date) &\n",
        "                      (drawdown_df[\"Predicted_month\"] <= end_date)]\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5. PLOT THE DRAWDOWNS\n",
        "# -------------------------------------------------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.clf()  # Clear any existing figure\n",
        "\n",
        "# a) Plot each ML model's drawdown (those columns that start with \"ML\" and contain \"Drawdown\")\n",
        "for col in plot_df.columns:\n",
        "    if col.startswith(\"ML\") and \"Drawdown\" in col:\n",
        "        plt.plot(plot_df[\"Predicted_month\"], plot_df[col], label=col)\n",
        "\n",
        "# b) Plot Benchmark Drawdown if toggled on\n",
        "if show_benchmark_drawdown:\n",
        "    # Look for the benchmark drawdown column with the actual benchmark name (e.g., \"Mkt Drawdown\")\n",
        "    bench_drawdown_col = f\"{benchmark_name} Drawdown\"\n",
        "    if bench_drawdown_col in plot_df.columns:\n",
        "        plt.plot(plot_df[\"Predicted_month\"], plot_df[bench_drawdown_col], label=bench_drawdown_col)\n",
        "\n",
        "# c) Plot Equal Weight Drawdown if available\n",
        "if show_equal_weight_drawdown and \"Equal Weight Drawdown\" in plot_df.columns:\n",
        "    plt.plot(plot_df[\"Predicted_month\"], plot_df[\"Equal Weight Drawdown\"], label=\"Equal Weight Drawdown\")\n",
        "\n",
        "# d) Plot Winner Weighted Drawdown if toggled on\n",
        "if show_winner_weighted_drawdown and \"Winner Weighted Drawdown\" in plot_df.columns:\n",
        "    plt.plot(plot_df[\"Predicted_month\"], plot_df[\"Winner Weighted Drawdown\"], label=\"Winner Weighted Drawdown\")\n",
        "\n",
        "# Format the y-axis as percentages.\n",
        "plt.gca().yaxis.set_major_formatter(\n",
        "    mticker.FuncFormatter(lambda val, _: f\"{val*100:.0f}%\")\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 6. ENSURE THE X-AXIS SPANS EXACTLY THE DEFINED DATE RANGE\n",
        "# -------------------------------------------------------------------------\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Drawdown\")\n",
        "plt.title(\"Drawdowns of Strategies\")\n",
        "plt.xlim(start_date, end_date)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FK-XFzpv4SXo"
      },
      "id": "FK-XFzpv4SXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regression"
      ],
      "metadata": {
        "id": "S244JpMyoSVe"
      },
      "id": "S244JpMyoSVe"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from IPython.display import display\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "subtract_rf    = True\n",
        "reg_start_date = pd.to_datetime('2000-07-30')\n",
        "reg_end_date   = pd.to_datetime('2024-11-30')\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. LOAD FAMAâ€“FRENCH DATA\n",
        "# -----------------------------------------------------------------------------\n",
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_2ND_latest.xlsx\")\n",
        "df_factors = xls_file.parse(\"FF5\", dtype=str)\n",
        "df_factors[\"Date\"] = pd.to_datetime(df_factors[\"Date\"])\n",
        "\n",
        "factors      = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
        "all_ff5_cols = factors + ['RF']\n",
        "\n",
        "for col in all_ff5_cols:\n",
        "    df_factors[col] = (\n",
        "        df_factors[col]\n",
        "          .str.replace(\",\", \".\", regex=False)\n",
        "          .astype(float)\n",
        "          .div(100)      # convert from percent to decimal\n",
        "    )\n",
        "\n",
        "df_factors = df_factors.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. PREPARE MODEL NAMES AND STORAGE\n",
        "# -----------------------------------------------------------------------------\n",
        "# `results_dfs` and `combined_df` must already exist in your session.\n",
        "new_model_names         = [f\"ML{i}: {k}\" for i, k in enumerate(results_dfs.keys(), 1)]\n",
        "regression_summary_list = []\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. RUN REGRESSIONS FOR EACH MODEL\n",
        "# -----------------------------------------------------------------------------\n",
        "for new_model_name in new_model_names:\n",
        "    col = f\"{new_model_name} Allocated_Return\"\n",
        "    if col not in combined_df.columns:\n",
        "        print(f\"Skipping {new_model_name}: no column '{col}'\")\n",
        "        continue\n",
        "\n",
        "    # filter & rename\n",
        "    df_model = (\n",
        "        combined_df.loc[\n",
        "            (pd.to_datetime(combined_df['Predicted_month']) >= reg_start_date) &\n",
        "            (pd.to_datetime(combined_df['Predicted_month']) <= reg_end_date),\n",
        "            ['Predicted_month', col]\n",
        "        ]\n",
        "        .rename(columns={col: \"Allocated_Return\"})\n",
        "    )\n",
        "    df_model['Predicted_month'] = pd.to_datetime(df_model['Predicted_month'])\n",
        "\n",
        "    # merge factors\n",
        "    merged = (\n",
        "        pd.merge(\n",
        "            df_model,\n",
        "            df_factors[['Date'] + all_ff5_cols],\n",
        "            left_on=\"Predicted_month\", right_on=\"Date\", how=\"inner\")\n",
        "          .drop(columns=[\"Date\"])\n",
        "    )\n",
        "\n",
        "    # subtract RF?\n",
        "    merged['Y'] = merged['Allocated_Return'] - merged['RF'] if subtract_rf else merged['Allocated_Return']\n",
        "\n",
        "    # regress\n",
        "    X     = sm.add_constant(merged[factors])\n",
        "    y     = merged['Y']\n",
        "    model = sm.OLS(y, X, missing='drop').fit()\n",
        "\n",
        "    # extract\n",
        "    alpha_dec   = model.params.get('const', np.nan)\n",
        "    alpha_t     = model.tvalues.get('const', np.nan)\n",
        "    beta_mkt    = model.params.get('Mkt-RF', np.nan)\n",
        "    r2          = model.rsquared\n",
        "    r2_adj      = model.rsquared_adj\n",
        "    pval        = model.f_pvalue\n",
        "\n",
        "    # print in percent\n",
        "    print(f\"\\n=== {new_model_name} vs. FF5 ===\")\n",
        "    print(model.summary())\n",
        "    print(f\"Monthly Alpha:    {alpha_dec*100:.3f}%\")\n",
        "    print(f\"Alpha t-stat:     {alpha_t:.3f}\")\n",
        "    print(f\"Market Beta:      {beta_mkt:.3f}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # store decimals for table\n",
        "    regression_summary_list.append({\n",
        "        \"Model\":           new_model_name,\n",
        "        \"Alpha (dec)\":     alpha_dec,\n",
        "        \"Alpha t-stat\":    alpha_t,\n",
        "        \"Market Beta\":     beta_mkt,\n",
        "        \"R-squared\":       r2,\n",
        "        \"Adj. R-squared\":  r2_adj,\n",
        "        \"p-value\":         pval\n",
        "    })\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. EQUAL-WEIGHT STRATEGY\n",
        "# -----------------------------------------------------------------------------\n",
        "eq = (\n",
        "    combined_df.loc[\n",
        "        (pd.to_datetime(combined_df['Predicted_month']) >= reg_start_date) &\n",
        "        (pd.to_datetime(combined_df['Predicted_month']) <= reg_end_date),\n",
        "        ['Predicted_month', 'Equal_Weight_Return']\n",
        "    ]\n",
        "    .rename(columns={'Equal_Weight_Return':'EW_Return'})\n",
        ")\n",
        "eq['Predicted_month'] = pd.to_datetime(eq['Predicted_month'])\n",
        "\n",
        "eqm = (\n",
        "    pd.merge(\n",
        "        eq,\n",
        "        df_factors[['Date'] + all_ff5_cols],\n",
        "        left_on=\"Predicted_month\", right_on=\"Date\", how=\"inner\")\n",
        "      .drop(columns=[\"Date\"])\n",
        ")\n",
        "eqm['Y'] = eqm['EW_Return'] - eqm['RF'] if subtract_rf else eqm['EW_Return']\n",
        "\n",
        "X_eq     = sm.add_constant(eqm[factors])\n",
        "y_eq     = eqm['Y']\n",
        "model_eq = sm.OLS(y_eq, X_eq, missing='drop').fit()\n",
        "\n",
        "alpha_eq_dec = model_eq.params.get('const', np.nan)\n",
        "alpha_eq_t   = model_eq.tvalues.get('const', np.nan)\n",
        "beta_eq      = model_eq.params.get('Mkt-RF', np.nan)\n",
        "\n",
        "print(\"\\n=== Equal-Weight vs. FF5 ===\")\n",
        "print(model_eq.summary())\n",
        "print(f\"Monthly Alpha:    {alpha_eq_dec*100:.3f}%\")\n",
        "print(f\"Alpha t-stat:     {alpha_eq_t:.3f}\")\n",
        "print(f\"Market Beta:      {beta_eq:.3f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "regression_summary_list.append({\n",
        "    \"Model\":           \"Equal-Weight\",\n",
        "    \"Alpha (dec)\":     alpha_eq_dec,\n",
        "    \"Alpha t-stat\":    alpha_eq_t,\n",
        "    \"Market Beta\":     beta_eq,\n",
        "    \"R-squared\":       model_eq.rsquared,\n",
        "    \"Adj. R-squared\":  model_eq.rsquared_adj,\n",
        "    \"p-value\":         model_eq.f_pvalue\n",
        "})\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. SUMMARY TABLE (with % conversions)\n",
        "# -----------------------------------------------------------------------------\n",
        "df_sum = pd.DataFrame(regression_summary_list)\n",
        "\n",
        "# convert decimals to percent in new columns\n",
        "df_sum['Alpha (%)']           = df_sum['Alpha (dec)'] * 100\n",
        "df_sum['Ann. Alpha (%) comp'] = (1 + df_sum['Alpha (dec)'])**12 - 1\n",
        "df_sum['Ann. Alpha (%) comp'] = df_sum['Ann. Alpha (%) comp'] * 100\n",
        "df_sum['Ann. Alpha (%) lin']  = df_sum['Alpha (dec)'] * 12 * 100\n",
        "\n",
        "# round\n",
        "df_sum = (\n",
        "    df_sum.rename(columns={\n",
        "        'Alpha t-stat':   'Alpha t-stat',\n",
        "        'Market Beta':    'Market Beta',\n",
        "        'R-squared':      'RÂ²',\n",
        "        'Adj. R-squared': 'Adj. RÂ²',\n",
        "        'p-value':        'p-value'\n",
        "    })\n",
        "    .round({\n",
        "        'Alpha (%)':           3,\n",
        "        'Alpha t-stat':        3,\n",
        "        'Ann. Alpha (%) comp': 3,\n",
        "        'Ann. Alpha (%) lin':  3,\n",
        "        'Market Beta':         3,\n",
        "        'RÂ²':                  3,\n",
        "        'Adj. RÂ²':             3,\n",
        "        'p-value':             3\n",
        "    })\n",
        ")\n",
        "\n",
        "# ---------------- NEW, FRIENDLIER HEADLINE WITH DATE WINDOW -----------------\n",
        "date_window = f\"{reg_start_date.strftime('%b %Y')} â€“ {reg_end_date.strftime('%b %Y')}\"\n",
        "print(f\"\\n=== Summary of All Models ({date_window}, in percent) ===\")\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "display(df_sum[[\n",
        "    'Model',\n",
        "    'Alpha (%)',\n",
        "    'Alpha t-stat',\n",
        "    'Market Beta',\n",
        "    'RÂ²',\n",
        "    'Adj. RÂ²',\n",
        "    'p-value',\n",
        "    'Ann. Alpha (%) comp',\n",
        "    'Ann. Alpha (%) lin'\n",
        "]])"
      ],
      "metadata": {
        "id": "MOb-rnOzH_4W"
      },
      "id": "MOb-rnOzH_4W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "print(\"\\n=== PERFORMANCE METRICS ===\")\n",
        "\n",
        "def annual_sharpe(series):\n",
        "    \"\"\"\n",
        "    Calculate the annual Sharpe ratio from a monthly return Series.\n",
        "    - Annual return = (product(1 + monthly returns)) - 1\n",
        "    - Annual volatility = std(monthly returns) * sqrt(12)\n",
        "    - Sharpe = annual return / annual volatility (assuming risk-free rate = 0)\n",
        "    \"\"\"\n",
        "    annual_return = (1 + series).prod() - 1\n",
        "    annual_vol = series.std() * np.sqrt(12)\n",
        "    if annual_vol == 0:\n",
        "        return np.nan\n",
        "    return annual_return / annual_vol\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Define the date range and filter combined_df accordingly.\n",
        "# ---------------------------------------------------------------------\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "\n",
        "# Filter the merged DataFrame for the desired date range.\n",
        "df_filtered = combined_df[(combined_df['Predicted_month'] >= start_date) &\n",
        "                            (combined_df['Predicted_month'] <= end_date)].copy()\n",
        "\n",
        "# Create a \"Year\" column from Predicted_month.\n",
        "df_filtered[\"Year\"] = df_filtered[\"Predicted_month\"].dt.year\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Identify Strategy Columns for Regression Metrics:\n",
        "#    - ML strategy columns: Expected to have names like \"ML1: Random Forest Allocated_Return\", etc.\n",
        "#    - Benchmark: \"Benchmark Return\"\n",
        "#    - Equal Weight: \"Equal_Weight_Return\"\n",
        "# ---------------------------------------------------------------------\n",
        "ml_strategy_cols = [col for col in df_filtered.columns\n",
        "                    if col.startswith(\"ML\") and \"Allocated_Return\" in col and \"Cumulative\" not in col]\n",
        "\n",
        "bench_col = \"Benchmark Return\" if \"Benchmark Return\" in df_filtered.columns else None\n",
        "eq_col    = \"Equal_Weight_Return\" if \"Equal_Weight_Return\" in df_filtered.columns else None\n",
        "\n",
        "print(\"Strategy columns used for annual Sharpe calculation:\")\n",
        "print(\"ML Strategy Columns:\", ml_strategy_cols)\n",
        "if bench_col:\n",
        "    print(\"Benchmark Column:\", bench_col)\n",
        "if eq_col:\n",
        "    print(\"Equal Weight Column:\", eq_col)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Compute Annual Sharpe Ratios for Each Strategy\n",
        "# ---------------------------------------------------------------------\n",
        "annual_sharpe_dict = {}\n",
        "\n",
        "# Compute for each ML model column.\n",
        "for col in ml_strategy_cols:\n",
        "    annual_sharpe_dict[col] = df_filtered.groupby(\"Year\")[col].apply(annual_sharpe)\n",
        "\n",
        "# Compute for benchmark (if available).\n",
        "if bench_col is not None:\n",
        "    annual_sharpe_dict[bench_col] = df_filtered.groupby(\"Year\")[bench_col].apply(annual_sharpe)\n",
        "\n",
        "# Compute for equal weight (if available).\n",
        "if eq_col is not None:\n",
        "    annual_sharpe_dict[eq_col] = df_filtered.groupby(\"Year\")[eq_col].apply(annual_sharpe)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Combine the Results into One DataFrame and Round to 3 Decimals\n",
        "# ---------------------------------------------------------------------\n",
        "annual_sharpe_table = pd.DataFrame(annual_sharpe_dict)\n",
        "annual_sharpe_table = annual_sharpe_table.round(3)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Display the Annual Sharpe Ratios as a Neatly Formatted HTML Table\n",
        "# ---------------------------------------------------------------------\n",
        "display(HTML(\"<h3>Annual Sharpe Ratios by Year and Strategy</h3>\" + annual_sharpe_table.to_html(index=True)))\n"
      ],
      "metadata": {
        "id": "E0cAJzowyqZn"
      },
      "id": "E0cAJzowyqZn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ============================================================================\n",
        "# 1) Prepare Annual Return Data\n",
        "# ============================================================================\n",
        "\n",
        "# Define the date range for annual analysis.\n",
        "start_date = pd.to_datetime(\"2000-01-01\")\n",
        "end_date   = pd.to_datetime(\"2024-12-31\")\n",
        "\n",
        "# Filter the merged DataFrame (combined_df) for the desired date range.\n",
        "# (combined_df comes from your earlier multiâ€‘model merging steps.)\n",
        "df_annual = combined_df[(combined_df['Predicted_month'] >= start_date) &\n",
        "                          (combined_df['Predicted_month'] <= end_date)].copy()\n",
        "\n",
        "# Create a \"Year\" column.\n",
        "df_annual['Year'] = df_annual['Predicted_month'].dt.year\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Identify columns:\n",
        "#   â€¢ ML strategy columns: they contain \"Allocated_Return\" (e.g., \"ML1: Random Forest Allocated_Return\")\n",
        "#   â€¢ Benchmark: assume the column is \"Benchmark Return\" (or use what was defined earlier).\n",
        "#   â€¢ Equal Weight: assume \"Equal_Weight_Return\"\n",
        "#   â€¢ Factor columns: using the global FACTORS (e.g., ['SMB', 'HML', 'CMA', 'RMW'])\n",
        "# ---------------------------------------------------------------------\n",
        "ml_cols = [col for col in df_annual.columns if (\"Allocated_Return\" in col) and (\"Cumulative\" not in col)]\n",
        "benchmark_col = \"Benchmark Return\" if \"Benchmark Return\" in df_annual.columns else None\n",
        "equal_weight_col = \"Equal_Weight_Return\" if \"Equal_Weight_Return\" in df_annual.columns else None\n",
        "factor_cols = [fac for fac in FACTORS if fac in df_annual.columns]\n",
        "\n",
        "print(\"ML Strategy Columns:\", ml_cols)\n",
        "print(\"Benchmark Column:\", benchmark_col)\n",
        "print(\"Equal Weight Column:\", equal_weight_col)\n",
        "print(\"Factor Columns:\", factor_cols)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Function to compute annual return as the compounded return over the year.\n",
        "# ---------------------------------------------------------------------\n",
        "def annual_return(group, col):\n",
        "    \"\"\"Compound return over the group: product(1 + r) - 1.\"\"\"\n",
        "    return (1 + group[col]).prod() - 1\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Compute annual returns for each strategy.\n",
        "# We'll build a dictionary where keys are strategy names and values are Series indexed by Year.\n",
        "annual_returns = {}\n",
        "\n",
        "# For each ML model column.\n",
        "for col in ml_cols:\n",
        "    annual_returns[col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, col))\n",
        "\n",
        "# For benchmark.\n",
        "if benchmark_col is not None:\n",
        "    annual_returns[benchmark_col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, benchmark_col))\n",
        "\n",
        "# For equal weight strategy.\n",
        "if equal_weight_col is not None:\n",
        "    annual_returns[equal_weight_col] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, equal_weight_col))\n",
        "\n",
        "# For each factor.\n",
        "for fac in factor_cols:\n",
        "    annual_returns[fac] = df_annual.groupby(\"Year\").apply(lambda grp: annual_return(grp, fac))\n",
        "\n",
        "# Combine the computed annual returns into one DataFrame.\n",
        "annual_returns_df = pd.DataFrame(annual_returns)\n",
        "annual_returns_df = annual_returns_df.round(3)\n",
        "\n",
        "# Display the Annual Returns Table.\n",
        "display(HTML(\"<h3>Annual Returns Table</h3>\" + annual_returns_df.to_html()))\n",
        "\n",
        "# ============================================================================\n",
        "# 2) Compute Excess Returns and Plot by Factor\n",
        "# ============================================================================\n",
        "\n",
        "# For each factor, compute excess return for each ML model relative to that factor.\n",
        "# We define excess return as: (ML Annual Return) - (Factor Annual Return)\n",
        "excess_returns = {}\n",
        "for fac in factor_cols:\n",
        "    # Create a DataFrame of excess returns for all ML models for factor 'fac'\n",
        "    excess_df = pd.DataFrame()\n",
        "    for ml in ml_cols:\n",
        "        excess_df[ml] = annual_returns_df[ml] - annual_returns_df[fac]\n",
        "    excess_returns[fac] = excess_df\n",
        "\n",
        "# Now plot excess returns by factor.\n",
        "n_factors = len(factor_cols)\n",
        "if n_factors > 0:\n",
        "    # Create one subplot per factor.\n",
        "    fig, axes = plt.subplots(1, n_factors, figsize=(6 * n_factors, 5), sharex=True)\n",
        "    if n_factors == 1:\n",
        "        axes = [axes]\n",
        "    for i, fac in enumerate(factor_cols):\n",
        "        ax = axes[i]\n",
        "        # Plot a line for each ML model excess return for this factor.\n",
        "        for ml in ml_cols:\n",
        "            ax.plot(excess_returns[fac].index, excess_returns[fac][ml],\n",
        "                    marker='o', label=f'{ml} - {fac}')\n",
        "        ax.set_title(f'Excess Return: ML - {fac}')\n",
        "        ax.set_xlabel(\"Year\")\n",
        "        ax.set_ylabel(\"Excess Return\")\n",
        "        ax.grid(True, linestyle='--', alpha=0.7)\n",
        "        ax.legend(fontsize='small')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# 3) (Optional) Compute and Plot Annual Returns for Benchmark and Equal Weight\n",
        "# ============================================================================\n",
        "\n",
        "# For convenience, let's display the annual returns for benchmark and equal weight strategies.\n",
        "if benchmark_col is not None:\n",
        "    print(\"\\nAnnual Returns - Benchmark:\")\n",
        "    display(annual_returns_df[[benchmark_col]])\n",
        "if equal_weight_col is not None:\n",
        "    print(\"\\nAnnual Returns - Equal Weight Strategy:\")\n",
        "    display(annual_returns_df[[equal_weight_col]])\n"
      ],
      "metadata": {
        "id": "Lo1wj3nU3ceD"
      },
      "id": "Lo1wj3nU3ceD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Return comparison by period"
      ],
      "metadata": {
        "id": "tC8mxG1Ynm-j"
      },
      "id": "tC8mxG1Ynm-j"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1) Create a \"Year\" Column in the Merged DataFrame\n",
        "# -------------------------------------------------\n",
        "combined_df['Year'] = pd.to_datetime(combined_df['Predicted_month']).dt.year\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2) Define a Function to Calculate Annual Return\n",
        "# -------------------------------------------------\n",
        "def annual_return(series):\n",
        "    \"\"\"\n",
        "    Compute the annual compounded return from a monthly return series.\n",
        "    \"\"\"\n",
        "    return (1 + series).prod() - 1\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) Compute Annual Returns for Each Strategy:\n",
        "#    a) For each ML model's allocated return.\n",
        "#    b) For Benchmark Return.\n",
        "#    c) For Equal Weight Return.\n",
        "# -------------------------------------------------\n",
        "# a) For ML models: we assume these columns start with \"ML\" and contain \"Allocated_Return\"\n",
        "ml_cols = [col for col in combined_df.columns\n",
        "           if col.startswith(\"ML\") and \"Allocated_Return\" in col and \"Cumulative\" not in col]\n",
        "annual_returns_ml = {col: combined_df.groupby(\"Year\")[col].apply(annual_return) for col in ml_cols}\n",
        "\n",
        "# b) For Benchmark:\n",
        "annual_return_bench = None\n",
        "if \"Benchmark Return\" in combined_df.columns:\n",
        "    annual_return_bench = combined_df.groupby(\"Year\")[\"Benchmark Return\"].apply(annual_return)\n",
        "\n",
        "# c) For Equal Weight:\n",
        "annual_return_eq = None\n",
        "if \"Equal_Weight_Return\" in combined_df.columns:\n",
        "    annual_return_eq = combined_df.groupby(\"Year\")[\"Equal_Weight_Return\"].apply(annual_return)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4) Compute Annual Returns for Each Factor in FACTORS:\n",
        "# -------------------------------------------------\n",
        "annual_returns_factors = {}\n",
        "for factor in FACTORS:\n",
        "    if factor in combined_df.columns:\n",
        "        annual_returns_factors[factor] = combined_df.groupby(\"Year\")[factor].apply(annual_return)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5) Compute Excess Returns for each ML model relative to each factor.\n",
        "#    Excess = (ML Model Annual Return) - (Factor Annual Return)\n",
        "# -------------------------------------------------\n",
        "excess_returns = {}\n",
        "for ml_col, ml_series in annual_returns_ml.items():\n",
        "    df_excess = pd.DataFrame(index=ml_series.index)\n",
        "    for factor, factor_series in annual_returns_factors.items():\n",
        "        df_excess[f\"Excess ({ml_col} - {factor})\"] = ml_series - factor_series\n",
        "    excess_returns[ml_col] = df_excess\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 6) Build a Summary Table of Annual Returns for all Strategies\n",
        "# -------------------------------------------------\n",
        "years = sorted(combined_df['Year'].unique())\n",
        "annual_summary = pd.DataFrame(index=years)\n",
        "\n",
        "# Add ML model returns.\n",
        "for ml_col, series in annual_returns_ml.items():\n",
        "    annual_summary[ml_col] = series\n",
        "\n",
        "# Add benchmark return if available.\n",
        "if annual_return_bench is not None:\n",
        "    annual_summary[\"Benchmark Return\"] = annual_return_bench\n",
        "\n",
        "# Add equal weight return if available.\n",
        "if annual_return_eq is not None:\n",
        "    annual_summary[\"Equal_Weight_Return\"] = annual_return_eq\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 7) Display the Summary Table and (optionally) Excess Returns for the First ML Model\n",
        "# -------------------------------------------------\n",
        "print(\"Annual Returns Summary:\")\n",
        "display(annual_summary.round(3))\n",
        "\n",
        "# Optionally, display excess returns for the first ML model.\n",
        "first_ml_col = ml_cols[0] if ml_cols else None\n",
        "if first_ml_col is not None:\n",
        "    print(f\"\\nExcess Returns for {first_ml_col}:\")\n",
        "    display(excess_returns[first_ml_col].round(3))\n",
        "\n",
        "  # -------------------------------------------------\n",
        "# 8) Plot annual *excess* returns for each ML model\n",
        "#     relative to the Equal-Weight benchmark\n",
        "# -------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- choose the baseline you want to subtract ---\n",
        "baseline_series = annual_return_eq           # <-- equal-weight\n",
        "baseline_label  = \"Equal-Weight\"\n",
        "\n",
        "# guard-rail in case Equal-Weight isnâ€™t available\n",
        "if baseline_series is None:\n",
        "    raise ValueError(\"Equal-Weight returns not found; pick another baseline.\")\n",
        "\n",
        "# --- build a DataFrame whose columns are the excess returns weâ€™ll plot ---\n",
        "excess_plot_df = pd.concat(\n",
        "    {ml_name.replace(\"Allocated_Return\", \"\").strip(): ml_series - baseline_series\n",
        "     for ml_name, ml_series in annual_returns_ml.items()},\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# --- make the chart ------------------------------------------------------\n",
        "plt.figure(figsize=(11,6))\n",
        "\n",
        "for col in excess_plot_df.columns:\n",
        "    plt.plot(\n",
        "        excess_plot_df.index,            # years on the x-axis\n",
        "        excess_plot_df[col],             # excess returns\n",
        "        marker=\"o\",                      # a dot on each year\n",
        "        label=col                        # legend label = strategy name\n",
        "    )\n",
        "\n",
        "# horizontal line at 0 %\n",
        "plt.axhline(0, linestyle=\"--\", linewidth=1, alpha=0.7)\n",
        "\n",
        "# title reflects the true date range in your dataframe\n",
        "start_date = pd.to_datetime(combined_df[\"Predicted_month\"]).min().strftime(\"%Y-%m-%d\")\n",
        "end_date   = pd.to_datetime(combined_df[\"Predicted_month\"]).max().strftime(\"%Y-%m-%d\")\n",
        "plt.title(f\"Annual Excess Returns ({start_date} â€“ {end_date})\")\n",
        "\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(f\"Excess Return vs {baseline_label}\")\n",
        "plt.legend(title=\"Strategy\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_KfEgK83EKLT"
      },
      "id": "_KfEgK83EKLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corr Heat map & regiimi sharpet\n"
      ],
      "metadata": {
        "id": "WnQxAZGgWuKt"
      },
      "id": "WnQxAZGgWuKt"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = xls_file.parse(SHEET_NAME)\n",
        "df = df[[\"Date\"] + FACTORS]\n",
        "\n",
        "# Calculate correlations\n",
        "correlation_matrix = df[FACTORS].corr()\n",
        "\n",
        "# Show regular correlation table\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap of Factors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "trQUVO-yLcAS"
      },
      "id": "trQUVO-yLcAS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1) Clone or pull your repo ---\n",
        "repo_url  = \"https://github.com/Elkkujou/Gradu.git\"\n",
        "repo_name = \"Gradu\"\n",
        "\n",
        "if os.path.exists(repo_name):\n",
        "    subprocess.run([\"git\", \"-C\", repo_name, \"pull\"], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "\n",
        "# --- 2) Load the Excel sheet into data_ff5 ---\n",
        "xlsx_path = os.path.join(repo_name, \"THE_2ND_latest.xlsx\")\n",
        "xls_file  = pd.ExcelFile(xlsx_path)\n",
        "\n",
        "SHEET_NAME  = \"ajodata_FF5\"\n",
        "data_ff5    = xls_file.parse(SHEET_NAME)\n",
        "\n",
        "# --- 3) Parse the date column (assumed to be the first column) ---\n",
        "date_col = data_ff5.columns[0]\n",
        "data_ff5[date_col] = pd.to_datetime(data_ff5[date_col])\n",
        "\n",
        "# --- 4) Compute zâ€‘scores for your four features ---\n",
        "FEATURES = ['CPI%','T10Y3M', 'CFNAI', 'GARCH']\n",
        "z_cols   = [f + '_z' for f in FEATURES]\n",
        "\n",
        "# Crossâ€‘sample zâ€‘score: (x â€“ mean) / std\n",
        "data_ff5[z_cols] = data_ff5[FEATURES].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "# --- 5) Quick check ---\n",
        "print(data_ff5.loc[:, FEATURES + z_cols].head(10))"
      ],
      "metadata": {
        "id": "Nbkz9QHj6yph"
      },
      "id": "Nbkz9QHj6yph",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Make sure your Date column is datetime and set as index\n",
        "data_ff5['Date'] = pd.to_datetime(data_ff5.iloc[:, 0])\n",
        "data_ff5.set_index('Date', inplace=True)\n",
        "\n",
        "# 2) Define features and their zâ€‘score column names\n",
        "\n",
        "z_cols   = [f + '_z' for f in FEATURES]\n",
        "\n",
        "# 3) (Reâ€‘)compute zâ€‘scores if you havenâ€™t yet\n",
        "data_ff5[z_cols] = data_ff5[FEATURES].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "# 4) Plot each in its own figure\n",
        "for feat, zc in zip(FEATURES, z_cols):\n",
        "    median_val = data_ff5[zc].median()\n",
        "\n",
        "    plt.figure()                          # new figure for each chart\n",
        "    plt.plot(data_ff5.index, data_ff5[zc], label=f'{feat} Zâ€‘Score')\n",
        "    plt.axhline(0,        linewidth=1,   label='Zero')\n",
        "    plt.axhline(median_val, linestyle='--', linewidth=1, label=f'Median = {median_val:.2f}')\n",
        "\n",
        "    plt.title(f'{feat} Zâ€‘Score Over Time')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Zâ€‘Score')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BqHRQ1Fk7ujB"
      },
      "id": "BqHRQ1Fk7ujB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Define your features and factors\n",
        "\n",
        "ZCOLS    = [f + '_z' for f in FEATURES]\n",
        "FACTORS  = ['SMB', 'HML', 'CMA', 'RMW']\n",
        "\n",
        "# 2) Prepare an empty DataFrame to hold Sharpe ratios\n",
        "cols = []\n",
        "for feat in FEATURES:\n",
        "    cols += [f\"{feat} > 0 SR\", f\"{feat} < 0 SR\"]\n",
        "sharpe_df = pd.DataFrame(index=FACTORS, columns=cols, dtype=float)\n",
        "\n",
        "# 3) Compute annualized Sharpe = âˆš12 * mean(return) / std(return)\n",
        "for feat, zcol in zip(FEATURES, ZCOLS):\n",
        "    for fac in FACTORS:\n",
        "        mask_pos = data_ff5[zcol] > 0\n",
        "        mask_neg = ~mask_pos\n",
        "\n",
        "        r_pos = data_ff5.loc[mask_pos, fac]\n",
        "        r_neg = data_ff5.loc[mask_neg, fac]\n",
        "\n",
        "        # avoid division by zero\n",
        "        sr_pos = np.sqrt(12) * r_pos.mean() / r_pos.std() if r_pos.std() != 0 else np.nan\n",
        "        sr_neg = np.sqrt(12) * r_neg.mean() / r_neg.std() if r_neg.std() != 0 else np.nan\n",
        "\n",
        "        sharpe_df.loc[fac, f\"{feat} > 0 SR\"] = sr_pos\n",
        "        sharpe_df.loc[fac, f\"{feat} < 0 SR\"] = sr_neg\n",
        "\n",
        "# 4) Round and display\n",
        "sharpe_df = sharpe_df.round(3)\n",
        "print(sharpe_df)"
      ],
      "metadata": {
        "id": "2HuD8lXC8Z2X"
      },
      "id": "2HuD8lXC8Z2X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Load the data\n",
        "xlsx_path = 'THE_2ND_latest.xlsx'  # point this at your file\n",
        "data = pd.read_excel(xlsx_path, sheet_name='ajodata_FF5', parse_dates=[0])\n",
        "data.set_index(data.columns[0], inplace=True)\n",
        "\n",
        "z_cols   = [f + '_z' for f in FEATURES]\n",
        "data[z_cols] = data[FEATURES].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "# Helper to compute a Sharpeâ€byâ€regimes table\n",
        "def compute_sharpe(regimes):\n",
        "    df = pd.DataFrame(index=FACTORS, columns=regimes.keys(), dtype=float)\n",
        "    for fac in FACTORS:\n",
        "        for name, mask in regimes.items():\n",
        "            r = data.loc[mask, fac]\n",
        "            df.loc[fac, name] = np.sqrt(12) * r.mean() / r.std()\n",
        "    return df\n",
        "\n",
        "# Helper to plot a 4Ã—1 grid\n",
        "def plot_grid(sharpe_df, title):\n",
        "    regimes = sharpe_df.columns.tolist()\n",
        "    fig, axes = plt.subplots(4,1, figsize=(14,10), sharex=True)\n",
        "    for ax, fac in zip(axes, FACTORS):\n",
        "        vals = sharpe_df.loc[fac].astype(float)\n",
        "        bars = ax.bar(regimes, vals.values)\n",
        "        ax.axhline(0, color='gray', linewidth=0.8)\n",
        "        # annotate\n",
        "        for bar in bars:\n",
        "            h = bar.get_height()\n",
        "            ax.annotate(f\"{h:.2f}\",\n",
        "                        xy=(bar.get_x() + bar.get_width()/2, h),\n",
        "                        xytext=(0,4), textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom', fontsize=8)\n",
        "        # dashed separators after 1st and 5th bars\n",
        "        for sep in [1,5]:\n",
        "            ax.axvline(sep - 0.5, color='gray', linestyle='--', linewidth=1)\n",
        "        # common yâ€axis styling\n",
        "        ax.set_ylim(-0.5, 1.6)\n",
        "        ax.set_yticks(np.arange(-0.5, 1.6, 0.5))\n",
        "        ax.set_yticklabels([f\"{x:.1f}\" for x in np.arange(-0.5, 1.6, 0.5)])\n",
        "        ax.set_title(fac, pad=8)\n",
        "    axes[-1].set_xticklabels(regimes, rotation=45, ha='right')\n",
        "    plt.suptitle(title, y=0.98, fontsize=14)\n",
        "    plt.tight_layout(rect=[0,0,1,0.96])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "# Plot 1: Growth (CFNAI) & Inflation (CPI%) regimes\n",
        "regimes1 = {\n",
        "    'All':                            np.ones(len(data), dtype=bool),\n",
        "    'Growth Up':                      data['CFNAI_z'] > 0,\n",
        "    'Growth Down':                    data['CFNAI_z'] <= 0,\n",
        "    'Inflation Up':                   data['CPI%_z'] > 0,\n",
        "    'Inflation Down':                 data['CPI%_z'] <= 0,\n",
        "    'Growth Up & Inflation Up':       (data['CFNAI_z'] > 0)  & (data['CPI%_z'] > 0),\n",
        "    'Growth Up & Inflation Down':     (data['CFNAI_z'] > 0)  & (data['CPI%_z'] <= 0),\n",
        "    'Growth Down & Inflation Up':     (data['CFNAI_z'] <= 0) & (data['CPI%_z'] > 0),\n",
        "    'Growth Down & Inflation Down':   (data['CFNAI_z'] <= 0) & (data['CPI%_z'] <= 0),\n",
        "}\n",
        "sh1 = compute_sharpe(regimes1)\n",
        "plot_grid(sh1, \"Factor Sharpe Ratios by Growth (CFNAI) & Inflation (CPI%) Regimes\")\n",
        "\n",
        "\n",
        "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "# Plot 2: Term Spread (T10Y3M) & Volatility (GARCH) regimes\n",
        "regimes2 = {\n",
        "    'All':                                np.ones(len(data), dtype=bool),\n",
        "    'Term Spread Up':                     data['T10Y3M_z'] > 0,\n",
        "    'Term Spread Down':                   data['T10Y3M_z'] <= 0,\n",
        "    'Volatility Up':                      data['GARCH_z'] > 0,\n",
        "    'Volatility Down':                    data['GARCH_z'] <= 0,\n",
        "    'Term Spread Up & Volatility Up':     (data['T10Y3M_z'] > 0) & (data['GARCH_z'] > 0),\n",
        "    'Term Spread Up & Volatility Down':   (data['T10Y3M_z'] > 0) & (data['GARCH_z'] <= 0),\n",
        "    'Term Spread Down & Volatility Up':   (data['T10Y3M_z'] <= 0) & (data['GARCH_z'] > 0),\n",
        "    'Term Spread Down & Volatility Down': (data['T10Y3M_z'] <= 0) & (data['GARCH_z'] <= 0),\n",
        "}\n",
        "sh2 = compute_sharpe(regimes2)\n",
        "plot_grid(sh2, \"Factor Sharpe Ratios by Term Spread & Volatility Regimes\")"
      ],
      "metadata": {
        "id": "orGWVaL1TuJb"
      },
      "id": "orGWVaL1TuJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell X: Combined avg factorâ€weights per featureâ€level, across all models\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# 1) Compute avg_weight_results for each model (if you haven't already)\n",
        "avg_weight_results = {}\n",
        "for model_name, df in results_dfs.items():\n",
        "    df = df.copy()\n",
        "    # find your featureâ€level cols & compute their zâ€scores\n",
        "    feat_lvl_cols = [c for c in df.columns if c.startswith(\"Feature_Level_\")]\n",
        "    z_cols        = [c + \"_z\" for c in feat_lvl_cols]\n",
        "    df[z_cols]    = df[feat_lvl_cols].apply(lambda x: (x - x.mean())/x.std())\n",
        "\n",
        "    # explode the probabilityâ€lists into a DataFrame\n",
        "    probs = pd.DataFrame(\n",
        "        df[\"Predicted_Probabilities\"].tolist(),\n",
        "        index=df.index,\n",
        "        columns=FACTORS\n",
        "    )\n",
        "\n",
        "    # build perâ€feature tables\n",
        "    feature_tables = {}\n",
        "    for lvl_col, zcol in zip(feat_lvl_cols, z_cols):\n",
        "        avg_high = probs[df[zcol] > 0].mean()\n",
        "        avg_low  = probs[df[zcol] <= 0].mean()\n",
        "        feature_tables[lvl_col] = pd.DataFrame({\n",
        "            \"Above_0_z\":       avg_high,\n",
        "            \"Below_or_eq_0_z\": avg_low\n",
        "        })\n",
        "    avg_weight_results[model_name] = feature_tables\n",
        "\n",
        "# 2) Get the list of feature-level keys from any one model\n",
        "feat_lvl_cols = list(next(iter(avg_weight_results.values())).keys())\n",
        "\n",
        "# 3) For each featureâ€level, stitch together all models into one table\n",
        "for lvl_col in feat_lvl_cols:\n",
        "    combined = pd.DataFrame(index=FACTORS)\n",
        "    for model_name, tables in avg_weight_results.items():\n",
        "        tbl = tables[lvl_col].rename(columns={\n",
        "            \"Above_0_z\":       f\"{model_name} Above_0_z\",\n",
        "            \"Below_or_eq_0_z\": f\"{model_name} Below_or_eq_0_z\"\n",
        "        })\n",
        "        combined = combined.join(tbl, how=\"outer\")\n",
        "\n",
        "    print(f\"\\n=== {lvl_col} ===\")\n",
        "    display(combined)\n"
      ],
      "metadata": {
        "id": "M_VwB7Mw6WI7"
      },
      "id": "M_VwB7Mw6WI7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Regime-wise Correlation Heatmaps\n",
        "#\n",
        "# For the selected return columns, compute and plot the correlation matrix\n",
        "# for each market regime as a heatmap.\n",
        "\n",
        "# %%\n",
        "# Use the global FACTORS instead of redefining returns_columns\n",
        "unique_regimes = df[REGIMES_COLUMN].unique()\n",
        "for regime in unique_regimes:\n",
        "    regime_data = df[df[REGIMES_COLUMN] == regime][FACTORS]\n",
        "    corr = regime_data.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "    plt.title(f\"Return Correlation Heatmap - {regime}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4GbzDKk2FZYH"
      },
      "id": "4GbzDKk2FZYH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Sharpe Ratios by Market Regime\n",
        "#\n",
        "# Compute and visualize Sharpe ratios for selected factors across each regime,\n",
        "# as well as the unconditional (all-data) values, using a bar chart.\n",
        "# The numeric regime codes are converted back to their original names using the regime_mapping,\n",
        "# and then further shortened using regime_short_mapping.\n",
        "\n",
        "# %%\n",
        "# Define factors and regime columns (using global variables if already defined)\n",
        "factors_columns = FACTORS\n",
        "regimes_column = REGIMES_COLUMN   # Assumes REGIMES_COLUMN was defined earlier\n",
        "\n",
        "# Use the previously created regime_short_mapping to convert numeric codes back to short names.\n",
        "# (If a code is not in regime_short_mapping, it will default to \"Regime <code>\")\n",
        "regime_short_names = {reg: regime_short_mapping.get(reg, f\"Regime {reg}\")\n",
        "                      for reg in df[regimes_column].unique()}\n",
        "\n",
        "sharpe_ratios = {\n",
        "    regime_short_names[regime]: (\n",
        "        df[df[regimes_column] == regime][factors_columns].mean() /\n",
        "        df[df[regimes_column] == regime][factors_columns].std()\n",
        "    )\n",
        "    for regime in df[regimes_column].unique()\n",
        "}\n",
        "\n",
        "# Calculate the \"Unconditional\" Sharpe ratios (using all data)\n",
        "sharpe_ratios[\"Unconditional\"] = df[factors_columns].mean() / df[factors_columns].std()\n",
        "\n",
        "# Convert the dictionary to a DataFrame and set column names\n",
        "sharpe_ratios_df = pd.DataFrame(sharpe_ratios).T\n",
        "sharpe_ratios_df.columns = factors_columns\n",
        "\n",
        "# Plot the Sharpe ratios using the same styling as before.\n",
        "plt.figure(figsize=(14, 8))\n",
        "sharpe_ratios_df.plot(\n",
        "    kind=\"bar\",\n",
        "    grid=True,\n",
        "    colormap=\"viridis\",\n",
        "    title=\"Sharpe Ratios by Regime and Unconditional\",\n",
        "    figsize=(14, 8)\n",
        ")\n",
        "plt.ylabel(\"Sharpe Ratio\", fontsize=12)\n",
        "plt.xlabel(\"Market Regimes\", fontsize=12)\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.legend(title=\"Factors\", fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GCkBikW6A2o0"
      },
      "id": "GCkBikW6A2o0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature importance by period"
      ],
      "metadata": {
        "id": "SwsjcsWyoH2Z"
      },
      "id": "SwsjcsWyoH2Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======= USER-DEFINED DATE RANGE =======\n",
        "# Adjust these dates to view feature importances for a specific period\n",
        "start_date = pd.to_datetime('2020-01-01')\n",
        "end_date   = pd.to_datetime('2022-12-31')\n",
        "\n",
        "# ======= Filter the Data =======\n",
        "# Filter the results_df for the specified date range based on the 'Predicted_month' column\n",
        "filtered_results_df = results_df[\n",
        "    (results_df['Predicted_month'] >= start_date) &\n",
        "    (results_df['Predicted_month'] <= end_date)\n",
        "]\n",
        "\n",
        "# ======= Get Unique Regimes and Feature Count =======\n",
        "existing_regimes = filtered_results_df['Regime'].unique()\n",
        "n_regimes = len(existing_regimes)\n",
        "n_features = len(filtered_results_df['Feature_Importances'].iloc[0])  # Assumes each entry is a vector\n",
        "\n",
        "# ======= Robust Feature Naming =======\n",
        "try:\n",
        "    # Validate if the predefined FEATURES list matches the actual feature count\n",
        "    if len(FEATURES) != n_features:\n",
        "        print(f\"âš ï¸ Warning: FEATURES list length ({len(FEATURES)}) doesn't match model features ({n_features}).\")\n",
        "        print(\"Using auto-generated feature names instead.\")\n",
        "        raise ValueError\n",
        "    feature_names = FEATURES\n",
        "except (NameError, ValueError):\n",
        "    # Generate default feature names if there's a mismatch or if FEATURES is undefined\n",
        "    feature_names = [f'Feature {i+1}' for i in range(n_features)]\n",
        "    print(f\"Using auto-generated feature names for {n_features} features.\")\n",
        "\n",
        "# ======= Compute Overall Average Feature Importances =======\n",
        "overall_avg_fi = np.vstack(filtered_results_df['Feature_Importances'].values).mean(axis=0)\n",
        "\n",
        "# ======= Compute Regime-Specific Average Feature Importances =======\n",
        "regime_avg_fi = {}\n",
        "for regime_name in existing_regimes:\n",
        "    regime_df = filtered_results_df[filtered_results_df['Regime'] == regime_name]\n",
        "    regime_fi_array = np.vstack(regime_df['Feature_Importances'].values)\n",
        "    regime_avg_fi[regime_name] = regime_fi_array.mean(axis=0)\n",
        "\n",
        "# ======= Sort Features by Overall Importance (Descending) =======\n",
        "sorted_idx = overall_avg_fi.argsort()[::-1]\n",
        "sorted_idx = sorted_idx[sorted_idx < len(feature_names)]  # Ensure index bounds\n",
        "sorted_features = [feature_names[i] for i in sorted_idx]\n",
        "\n",
        "# ======= Plotting =======\n",
        "if n_regimes > 1:\n",
        "    total_plots = 1 + n_regimes  # One overall plot plus one for each regime\n",
        "    row_height = max(0.3 * n_features, 4)\n",
        "    fig, axs = plt.subplots(\n",
        "        total_plots,\n",
        "        1,\n",
        "        figsize=(19.5, total_plots * row_height),\n",
        "        gridspec_kw={'hspace': 0.4}\n",
        "    )\n",
        "    if total_plots == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    # --- Overall Feature Importances ---\n",
        "    axs[0].barh(\n",
        "        np.arange(n_features),\n",
        "        overall_avg_fi[sorted_idx],\n",
        "        color='steelblue',\n",
        "        edgecolor='black'\n",
        "    )\n",
        "    axs[0].set_yticks(np.arange(n_features))\n",
        "    axs[0].set_yticklabels(sorted_features)\n",
        "    axs[0].set_title(\"Overall Average Feature Importances\", pad=12)\n",
        "    axs[0].set_xlabel(\"Average Importance\")\n",
        "    axs[0].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # --- Regime-Specific Feature Importances ---\n",
        "    for idx, (regime_name, avg_fi) in enumerate(regime_avg_fi.items(), start=1):\n",
        "        sorted_regime_fi = avg_fi[sorted_idx]\n",
        "        axs[idx].barh(\n",
        "            np.arange(n_features),\n",
        "            sorted_regime_fi,\n",
        "            color='salmon',\n",
        "            edgecolor='black'\n",
        "        )\n",
        "        axs[idx].set_yticks(np.arange(n_features))\n",
        "        axs[idx].set_yticklabels(sorted_features)\n",
        "        axs[idx].set_title(f\"Feature Importances: {regime_name} Regime\", pad=12)\n",
        "        axs[idx].set_xlabel(\"Average Importance\")\n",
        "        axs[idx].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "else:\n",
        "    # If zero or one regime, show only the overall chart\n",
        "    row_height = max(0.3 * n_features, 4)\n",
        "    fig, ax = plt.subplots(\n",
        "        1, 1, figsize=(19.5, row_height),\n",
        "        gridspec_kw={'hspace': 0.4}\n",
        "    )\n",
        "    ax.barh(\n",
        "        np.arange(n_features),\n",
        "        overall_avg_fi[sorted_idx],\n",
        "        color='steelblue',\n",
        "        edgecolor='black'\n",
        "    )\n",
        "    ax.set_yticks(np.arange(n_features))\n",
        "    ax.set_yticklabels(sorted_features)\n",
        "    ax.set_title(\"Overall Average Feature Importances (No Multiple Regimes)\", pad=12)\n",
        "    ax.set_xlabel(\"Average Importance\")\n",
        "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout(pad=4.0)\n",
        "plt.subplots_adjust(left=0.3)  # Extra space for feature labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XgeSIiAu-M2b"
      },
      "id": "XgeSIiAu-M2b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}