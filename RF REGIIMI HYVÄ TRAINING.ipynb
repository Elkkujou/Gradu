{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# # GitHub Repository Setup\n",
        "#\n",
        "# This cell navigates to `/content`, removes any previous clone of the repository,\n",
        "# clones the latest version from GitHub, and lists the repository files.\n",
        "\n",
        "# %%\n",
        "%cd /content\n",
        "!rm -rf Gradu\n",
        "!git clone https://github.com/Elkkujou/Gradu.git\n",
        "%cd /content/Gradu\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "O58kIxTz4ycb",
        "outputId": "26031938-632e-4518-b189-98966d38cd3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O58kIxTz4ycb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 87 (delta 40), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (87/87), 5.24 MiB | 3.28 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n",
            "/content/Gradu\n",
            " chatti_RF.ipynb\t       FT_source.xlsx  'RF REGIIMI HYVÃ„ TRAINING.ipynb'   THE_ONE.xlsx\n",
            "'Financial turbulence.ipynb'   RF_Gradu.ipynb  'RF_regime (3).ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_training = False"
      ],
      "metadata": {
        "id": "-AF3FdwvaLPp"
      },
      "id": "-AF3FdwvaLPp",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4085d55c-e568-465c-9bcc-6013281c105d",
      "metadata": {
        "tags": [],
        "id": "4085d55c-e568-465c-9bcc-6013281c105d"
      },
      "outputs": [],
      "source": [
        "# # Import Required Libraries\n",
        "#\n",
        "# Import all necessary libraries for data manipulation, visualization,\n",
        "# machine learning, and regression analysis.\n",
        "\n",
        "# %%\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc",
      "metadata": {
        "tags": [],
        "id": "d31b30d7-aff9-4b1e-9eb2-3557c3993edc"
      },
      "outputs": [],
      "source": [
        "# # Load Excel Data & Define Global Constants\n",
        "#\n",
        "# Read the Excel file, parse the desired sheet, flatten any multi-index columns,\n",
        "# and define global constants that will be used throughout the notebook.\n",
        "\n",
        "# %%\n",
        "# Load and flatten the data\n",
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_ONE.xlsx\")\n",
        "df = xls_file.parse(\"returns non-log\")\n",
        "df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "# Global constants for columns (change names to uppercase for constants)\n",
        "VALID_FACTORS = [\n",
        "    'USA MOMENTUM Standard (Large+Mid Cap)',\n",
        "    'USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)',\n",
        "    'USA RISK WEIGHTED Standard (Large+Mid Cap)',\n",
        "    'USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)',\n",
        "    'USA ENHANCED VALUE Standard (Large+Mid Cap)'\n",
        "]\n",
        "FEATURES = ['VIXCLS', 'CPI', 'LEI', '10yr', 'Financial Turbulance', 'Regimes']\n",
        "REGIMES_COLUMN = 'Regimes'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6",
      "metadata": {
        "tags": [],
        "id": "15e9d46d-2b85-4c9b-84e6-32e612d2c4a6",
        "outputId": "3f20400c-a0c2-4fd5-a43a-d5e90a22cdcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices aligned: True\n",
            "Parameters and dataset verified.\n"
          ]
        }
      ],
      "source": [
        "# # Prepare Data for Model Training\n",
        "#\n",
        "# Filter the dataset to include only rows with valid factors,\n",
        "# encode categorical columns, drop missing values, and sort by date.\n",
        "\n",
        "# %%\n",
        "# Filter rows based on the global VALID_FACTORS\n",
        "df = df[df['Winning Factor'].isin(VALID_FACTORS)].reset_index(drop=True)\n",
        "\n",
        "# Encode the Regimes column using the global constant\n",
        "df[REGIMES_COLUMN] = df[REGIMES_COLUMN].astype('category').cat.codes\n",
        "\n",
        "# Define features and target using the global FEATURES constant\n",
        "X = df[FEATURES].dropna()\n",
        "y = df['Winning Factor'].astype('category').cat.codes.loc[X.index]\n",
        "\n",
        "print(\"Indices aligned:\", X.index.equals(y.index))\n",
        "\n",
        "# Ensure the data is sorted by date\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Verify required columns exist\n",
        "required_columns = FEATURES + ['USA Standard (Large+Mid Cap)'] + VALID_FACTORS\n",
        "for col in required_columns:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {col}\")\n",
        "print(\"Parameters and dataset verified.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "caba0264-13c9-4c25-b976-6fc51f3bf675",
      "metadata": {
        "tags": [],
        "id": "caba0264-13c9-4c25-b976-6fc51f3bf675"
      },
      "outputs": [],
      "source": [
        "# # Encode Winning Factor & Build Mappings\n",
        "#\n",
        "# Pre-encode the 'Winning Factor' column and create dictionaries to map full factor names\n",
        "# to shorter names and numeric IDs for later reference.\n",
        "\n",
        "# %%\n",
        "df['Winning Factor Encoded'] = df['Winning Factor'].astype('category').cat.codes\n",
        "winning_factor_categories = df['Winning Factor'].astype('category').cat.categories\n",
        "winning_factor_mapping = {i: cat for i, cat in enumerate(winning_factor_categories)}\n",
        "\n",
        "factor_rename_mapping = {\n",
        "    'USA MOMENTUM Standard (Large+Mid Cap)': 'Momentum',\n",
        "    'USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)': 'MinVol',\n",
        "    'USA RISK WEIGHTED Standard (Large+Mid Cap)': 'RiskWeighted',\n",
        "    'USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)': 'SectorNeutral',\n",
        "    'USA ENHANCED VALUE Standard (Large+Mid Cap)': 'EnhancedValue'\n",
        "}\n",
        "\n",
        "winning_factor_dict = {\n",
        "    full_factor: {\n",
        "        'full': full_factor,\n",
        "        'short': factor_rename_mapping.get(full_factor, full_factor),\n",
        "        'id': i\n",
        "    } for i, full_factor in enumerate(winning_factor_categories)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define Rolling Window Parameters\n",
        "#\n",
        "# Set the training percentage, window size, and step size for the rolling window model training.\n",
        "\n",
        "# %%\n",
        "train_pct = 1.00  # Use 100% of data for rolling window training\n",
        "train_end_idx = int(len(df) * train_pct)\n",
        "\n",
        "window_size = 120   # Number of observations per training window\n",
        "step_size = 1      # Step size for rolling window\n"
      ],
      "metadata": {
        "id": "NIurZ-lJPu5f"
      },
      "id": "NIurZ-lJPu5f",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Hyperparameters Table\n",
        "\n",
        "| Hyperparameter       | Purpose                                   | Common Choices                  |\n",
        "|----------------------|-------------------------------------------|---------------------------------|\n",
        "| `n_estimators`      | Number of trees                           | 100 (default), 200, 500         |\n",
        "| `max_depth`         | Max tree depth                            | `None` (default), 10, 20        |\n",
        "| `min_samples_split` | Min samples needed to split a node       | 2 (default), 10, 20             |\n",
        "| `min_samples_leaf`  | Min samples in a leaf                    | 1 (default), 5, 10              |\n",
        "| `max_features`      | Features per split                       | `'sqrt'` (default), `'log2'`, `None` |\n",
        "| `bootstrap`         | Use bootstrap sampling                    | `True` (default), `False`       |\n",
        "| `random_state`      | Set a random seed                         | `None`, 42, 0                   |\n",
        "| `criterion`         | Splitting method                          | `'gini'` (default), `'entropy'` |\n",
        "| `oob_score`        | Out-of-bag validation                     | `False` (default), `True`       |\n",
        "| `n_jobs`           | Parallel training                         | `None`, `-1` (all CPUs)         |\n"
      ],
      "metadata": {
        "id": "g3wGcKzuVZJ7"
      },
      "id": "g3wGcKzuVZJ7"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Rolling Window Training & Prediction\n",
        "#\n",
        "# Train a Random Forest model in a rolling window fashion. For each window, split the data,\n",
        "# train the model, predict probabilities, and record detailed results including feature importances.\n",
        "\n",
        "# %%\n",
        "allocated_returns = []\n",
        "all_true_labels = []\n",
        "all_pred_labels = []\n",
        "detailed_results = []\n",
        "\n",
        "feature_importances_list = []\n",
        "probability_matrix = []  # To record predicted probability vectors\n",
        "probability_dates = []   # Corresponding dates for each prediction\n",
        "\n",
        "# Loop through the data using a rolling window\n",
        "for start_idx in range(0, train_end_idx - window_size, step_size):\n",
        "    train_idx = range(start_idx, start_idx + window_size)\n",
        "    test_idx = [start_idx + window_size]\n",
        "\n",
        "    train_data = df.iloc[train_idx]\n",
        "    test_data = df.iloc[test_idx]\n",
        "\n",
        "    X_train = train_data[FEATURES].dropna()\n",
        "    y_train = train_data['Winning Factor Encoded'].loc[X_train.index]\n",
        "    X_test = test_data[FEATURES].dropna()\n",
        "\n",
        "    X_train, y_train = X_train.align(y_train, axis=0)\n",
        "\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    feature_importances_list.append(rf_model.feature_importances_)\n",
        "\n",
        "    if not X_test.empty:\n",
        "        probabilities = rf_model.predict_proba(X_test)\n",
        "        probability_matrix.append(probabilities[0])\n",
        "        probability_dates.append(test_data['Date'].values[0])\n",
        "\n",
        "        # Use the global VALID_FACTORS for portfolio return calculation\n",
        "        portfolio_return = (probabilities * test_data[VALID_FACTORS].values).sum(axis=1)\n",
        "        allocated_returns.extend(portfolio_return)\n",
        "\n",
        "        y_pred = probabilities.argmax(axis=1)[0]\n",
        "        y_test = test_data['Winning Factor Encoded'].iloc[0]\n",
        "        all_true_labels.append(y_test)\n",
        "        all_pred_labels.append(y_pred)\n",
        "\n",
        "        full_pred = winning_factor_mapping[y_pred]\n",
        "        full_test = winning_factor_mapping[y_test]\n",
        "        result_dict = {\n",
        "            'Date': test_data['Date'].values[0],\n",
        "            'Correct': (y_pred == y_test),\n",
        "            'Predicted_Winner': winning_factor_dict[full_pred]['short'],\n",
        "            'Actual_Winner': winning_factor_dict[full_test]['short'],\n",
        "            'Allocated_Return': portfolio_return[0],\n",
        "            'Max_Probability': probabilities[0, y_pred]\n",
        "        }\n",
        "        for i, full_factor in enumerate(winning_factor_categories):\n",
        "            short_name = winning_factor_dict[full_factor]['short']\n",
        "            result_dict[f'Prob_{short_name}'] = probabilities[0, i]\n",
        "        detailed_results.append(result_dict)\n"
      ],
      "metadata": {
        "id": "YjHj_tiKSCYZ"
      },
      "id": "YjHj_tiKSCYZ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Ensure final test dataset has the necessary features\n",
        "X_final_test = final_test_data[['VIXCLS', 'CPI', 'LEI', '10yr', 'Financial Turbulance', 'Regimes']].dropna()\n",
        "y_final_test = final_test_data['Winning Factor'].astype('category').cat.codes.loc[X_final_test.index]\n",
        "\n",
        "# Align indices\n",
        "X_final_test, y_final_test = X_final_test.align(y_final_test, axis=0)\n",
        "\n",
        "# Predict the winning factor for the final test set\n",
        "if not X_final_test.empty:\n",
        "    y_pred_proba = rf_model.predict_proba(X_final_test)  # Predict probabilities\n",
        "    y_pred = y_pred_proba.argmax(axis=1)  # Select the factor with the highest probability\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(y_final_test, y_pred)\n",
        "\n",
        "    print(f\"Model Accuracy on Final Test Set ({1 - train_pct:.0%} of data): {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Final test dataset is empty or misaligned.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mcecTBImSNGE",
        "outputId": "3a69f36e-12da-4921-8732-a2f163decd6b"
      },
      "id": "mcecTBImSNGE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'final_test_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-743b2101cdaa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ensure final test dataset has the necessary features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_final_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VIXCLS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CPI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LEI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10yr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Financial Turbulance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Regimes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_final_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Winning Factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_final_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397edbd8-1854-48d3-b5b1-f6a9e24fe2ab",
      "metadata": {
        "tags": [],
        "id": "397edbd8-1854-48d3-b5b1-f6a9e24fe2ab"
      },
      "outputs": [],
      "source": [
        "# # Display Detailed Prediction Results\n",
        "#\n",
        "# Create and print a table summarizing the prediction results from the rolling window,\n",
        "# including dates, correctness, predictions, and allocated returns.\n",
        "\n",
        "# %%\n",
        "detailed_results_df = pd.DataFrame(detailed_results)\n",
        "prob_cols = [col for col in detailed_results_df.columns if col.startswith('Prob_')]\n",
        "ordered_cols = ['Date', 'Correct', 'Predicted_Winner', 'Actual_Winner'] + prob_cols + ['Allocated_Return', 'Max_Probability']\n",
        "detailed_results_df = detailed_results_df[ordered_cols]\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(tabulate(detailed_results_df, headers='keys', tablefmt='psql', showindex=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d0f495-1290-403b-86a2-7bd1c2c12814",
      "metadata": {
        "tags": [],
        "id": "88d0f495-1290-403b-86a2-7bd1c2c12814"
      },
      "outputs": [],
      "source": [
        "# # Evaluate Accuracy & Confusion Matrix\n",
        "#\n",
        "# Compute the overall prediction accuracy and display a confusion matrix heatmap.\n",
        "\n",
        "# %%\n",
        "accuracy = accuracy_score(all_true_labels, all_pred_labels)\n",
        "print(f\"Rolling Window Out-of-Sample Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Use REGIMES_COLUMN for consistency if needed; here, we build labels based on winning factors.\n",
        "labels = [winning_factor_dict[winning_factor_mapping[i]]['short'] for i in sorted(winning_factor_mapping.keys())]\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix (Rolling Window Predictions)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5",
      "metadata": {
        "tags": [],
        "id": "6f3b40dd-d04a-475d-b328-7baabf2114f5"
      },
      "outputs": [],
      "source": [
        "# # Plot Average Feature Importances\n",
        "#\n",
        "# Calculate and visualize the average feature importances across all rolling windows using a horizontal bar chart.\n",
        "\n",
        "# %%\n",
        "feature_importances_array = np.array(feature_importances_list)\n",
        "average_feature_importance = feature_importances_array.mean(axis=0)\n",
        "\n",
        "feature_names = FEATURES  # Use the global FEATURES constant\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, average_feature_importance, color='skyblue', edgecolor='black')\n",
        "plt.xlabel(\"Average Feature Importance\", fontsize=12)\n",
        "plt.ylabel(\"Features\", fontsize=12)\n",
        "plt.title(\"Average Feature Importance Across Rolling Windows\", fontsize=14)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8",
      "metadata": {
        "tags": [],
        "id": "9714d2c9-98b2-4fd5-8ea1-db0c582091a8"
      },
      "outputs": [],
      "source": [
        "# # Plot Stacked Area Chart of Probabilities\n",
        "#\n",
        "# Visualize the evolution of predicted probabilities for each factor over time using a stacked area chart.\n",
        "\n",
        "# %%\n",
        "# Build a DataFrame from the probability matrix using the global VALID_FACTORS\n",
        "probability_df = pd.DataFrame(probability_matrix, columns=VALID_FACTORS)\n",
        "probability_df['Date'] = probability_dates\n",
        "probability_df = probability_df.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.stackplot(\n",
        "    probability_df['Date'],\n",
        "    [probability_df[col] for col in VALID_FACTORS],\n",
        "    labels=VALID_FACTORS,\n",
        "    alpha=0.8\n",
        ")\n",
        "plt.title(\"Outperforming Probabilities of Each Factor (ML Prediction)\", fontsize=14)\n",
        "plt.xlabel(\"Date\", fontsize=12)\n",
        "plt.ylabel(\"Probability\", fontsize=12)\n",
        "plt.legend(loc='upper left', fontsize='small')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6704d84c-c905-4314-853f-2328ed0b1a98",
      "metadata": {
        "tags": [],
        "id": "6704d84c-c905-4314-853f-2328ed0b1a98"
      },
      "outputs": [],
      "source": [
        "# # Plot Cumulative Returns (Strategy vs Benchmark)\n",
        "#\n",
        "# Compute and plot cumulative returns for the ML strategy (using probability-weighted returns)\n",
        "# and for the benchmark over time.\n",
        "\n",
        "# %%\n",
        "strategy_returns = np.array(allocated_returns)\n",
        "benchmark_returns = df.iloc[window_size:]['USA Standard (Large+Mid Cap)'].values[:len(strategy_returns)]\n",
        "\n",
        "cumulative_strategy = (1 + strategy_returns).cumprod()\n",
        "cumulative_benchmark = (1 + benchmark_returns).cumprod()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.loc[window_size:, 'Date'][:len(cumulative_strategy)], cumulative_strategy,\n",
        "         label=\"ML Strategy (Probability Weighted)\", color=\"blue\")\n",
        "plt.plot(df.loc[window_size:, 'Date'][:len(cumulative_benchmark)], cumulative_benchmark,\n",
        "         label=\"Benchmark (USA Standard)\", color=\"orange\")\n",
        "plt.title(\"Cumulative Returns: ML Strategy vs Benchmark\", fontsize=14)\n",
        "plt.xlabel(\"Date\", fontsize=12)\n",
        "plt.ylabel(\"Cumulative Return\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618dad99-4355-4b60-9930-c3ed58694ad7",
      "metadata": {
        "tags": [],
        "id": "618dad99-4355-4b60-9930-c3ed58694ad7"
      },
      "outputs": [],
      "source": [
        "# # Compute and Display Performance Metrics\n",
        "#\n",
        "# Calculate annualized return, volatility, Sharpe ratio, tracking error, and information ratio for both the ML strategy and the benchmark,\n",
        "# then display these metrics in a table.\n",
        "\n",
        "# %%\n",
        "def annualized_return(returns):\n",
        "    \"\"\"Compute the compounded annualized return (assuming monthly returns).\"\"\"\n",
        "    return np.prod(1 + returns)**(12 / len(returns)) - 1\n",
        "\n",
        "def annualized_volatility(returns):\n",
        "    \"\"\"Annualize the standard deviation of monthly returns.\"\"\"\n",
        "    return np.std(returns) * np.sqrt(12)\n",
        "\n",
        "def sharpe_ratio(returns):\n",
        "    \"\"\"Compute the Sharpe Ratio (assuming zero risk-free rate).\"\"\"\n",
        "    return annualized_return(returns) / annualized_volatility(returns)\n",
        "\n",
        "def tracking_error(strategy_returns, benchmark_returns):\n",
        "    \"\"\"Annualize the standard deviation of the return differences.\"\"\"\n",
        "    return np.std(strategy_returns - benchmark_returns) * np.sqrt(12)\n",
        "\n",
        "def information_ratio(strategy_returns, benchmark_returns):\n",
        "    \"\"\"Compute the Information Ratio.\"\"\"\n",
        "    excess_return = annualized_return(strategy_returns) - annualized_return(benchmark_returns)\n",
        "    return excess_return / tracking_error(strategy_returns, benchmark_returns)\n",
        "\n",
        "ml_annualized_return = annualized_return(strategy_returns)\n",
        "ml_annualized_volatility = annualized_volatility(strategy_returns)\n",
        "ml_sharpe_ratio = sharpe_ratio(strategy_returns)\n",
        "ml_tracking_error = tracking_error(strategy_returns, benchmark_returns)\n",
        "ml_information_ratio = information_ratio(strategy_returns, benchmark_returns)\n",
        "\n",
        "benchmark_annualized_return = annualized_return(benchmark_returns)\n",
        "benchmark_annualized_volatility = annualized_volatility(benchmark_returns)\n",
        "benchmark_sharpe_ratio = sharpe_ratio(benchmark_returns)\n",
        "\n",
        "metrics_table = pd.DataFrame({\n",
        "    \"Metric\": [\n",
        "        \"Annualized Return\",\n",
        "        \"Annualized Volatility\",\n",
        "        \"Sharpe Ratio\",\n",
        "        \"Tracking Error\",\n",
        "        \"Information Ratio\"\n",
        "    ],\n",
        "    \"ML Strategy\": [\n",
        "        f\"{ml_annualized_return*100:.2f}%\",\n",
        "        f\"{ml_annualized_volatility*100:.2f}%\",\n",
        "        f\"{ml_sharpe_ratio:.6f}\",\n",
        "        f\"{ml_tracking_error*100:.2f}%\",\n",
        "        f\"{ml_information_ratio:.2f}\"\n",
        "    ],\n",
        "    \"Benchmark\": [\n",
        "        f\"{benchmark_annualized_return*100:.2f}%\",\n",
        "        f\"{benchmark_annualized_volatility*100:.2f}%\",\n",
        "        f\"{benchmark_sharpe_ratio:.6f}\",\n",
        "        \"nan%\",\n",
        "        \"nan\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(metrics_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303fa9f5-81da-4d9c-8032-b734a15fd9ce",
      "metadata": {
        "id": "303fa9f5-81da-4d9c-8032-b734a15fd9ce"
      },
      "outputs": [],
      "source": [
        "# # OLS Regression Analysis: Strategy vs Benchmark Returns\n",
        "#\n",
        "# Run an OLS regression to examine the relationship between the ML strategy returns and the benchmark returns,\n",
        "# and display the regression summary.\n",
        "\n",
        "# %%\n",
        "regression_data = pd.DataFrame({\n",
        "    'Strategy': strategy_returns,\n",
        "    'Benchmark': benchmark_returns\n",
        "}).dropna()\n",
        "\n",
        "X_reg = regression_data['Benchmark']\n",
        "y_reg = regression_data['Strategy']\n",
        "X_reg = sm.add_constant(X_reg)\n",
        "\n",
        "model = sm.OLS(y_reg, X_reg).fit()\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Regime-wise Correlation Heatmaps\n",
        "#\n",
        "# For the selected return columns, compute and plot the correlation matrix\n",
        "# for each market regime as a heatmap.\n",
        "\n",
        "# %%\n",
        "# Use the global VALID_FACTORS instead of redefining returns_columns\n",
        "unique_regimes = df[REGIMES_COLUMN].unique()\n",
        "for regime in unique_regimes:\n",
        "    regime_data = df[df[REGIMES_COLUMN] == regime][VALID_FACTORS]\n",
        "    corr = regime_data.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "    plt.title(f\"Return Correlation Heatmap - {regime}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4GbzDKk2FZYH"
      },
      "id": "4GbzDKk2FZYH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot Sharpe Ratios by Market Regime\n",
        "#\n",
        "# Compute and visualize Sharpe ratios for selected factors across each regime,\n",
        "# as well as the unconditional (all-data) values, using a bar chart.\n",
        "\n",
        "# %%\n",
        "# For this analysis, we assume the relevant factors for Sharpe ratios are in columns 1:7.\n",
        "# (Adjust the slicing as needed.)\n",
        "factors_columns = df.columns[1:7]\n",
        "regimes_column = REGIMES_COLUMN\n",
        "\n",
        "sharpe_ratios = {}\n",
        "for regime in df[regimes_column].unique():\n",
        "    regime_data = df[df[regimes_column] == regime][factors_columns]\n",
        "    mean_returns = regime_data.mean()\n",
        "    std_devs = regime_data.std()\n",
        "    sharpe_ratios[regime] = mean_returns / std_devs\n",
        "\n",
        "# Compute \"Unconditional\" Sharpe ratios (using all data)\n",
        "unconditional_mean = df[factors_columns].mean()\n",
        "unconditional_std = df[factors_columns].std()\n",
        "sharpe_ratios[\"Unconditional\"] = unconditional_mean / unconditional_std\n",
        "\n",
        "sharpe_ratios_df = pd.DataFrame(sharpe_ratios).T\n",
        "sharpe_ratios_df.columns = factors_columns\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sharpe_ratios_df.plot(kind=\"bar\", grid=True, colormap=\"viridis\", title=\"Sharpe Ratios by Regime and Unconditional\")\n",
        "plt.ylabel(\"Sharpe Ratio\", fontsize=12)\n",
        "plt.xlabel(\"Market Regimes\", fontsize=12)\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.legend(title=\"Factors\", fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GCkBikW6A2o0"
      },
      "id": "GCkBikW6A2o0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}