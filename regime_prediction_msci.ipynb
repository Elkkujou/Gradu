{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Mn3d88mwsKETxO0gMdfa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPPizlV3oIUh",
        "outputId": "6a4ed357-63e6-4676-8f61-483fa6b096b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 271 (delta 70), reused 0 (delta 0), pack-reused 136 (from 1)\u001b[K\n",
            "Receiving objects: 100% (271/271), 29.79 MiB | 19.84 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n",
            "/content/Gradu\n",
            " chatti_RF.ipynb\t       regime_prediction_famafrench.ipynb  'RF REGIIMI HYVÃ„ TRAINING.ipynb'\n",
            "'Financial turbulence.ipynb'   regime_prediction_msci.ipynb\t   'RF_regime (3).ipynb'\n",
            " FT_source.xlsx\t\t       regime_pred.txt\t\t\t    THE_ONE.xlsx\n",
            " Regiimi_prediction.ipynb      RF_Gradu.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf Gradu\n",
        "!git clone https://github.com/Elkkujou/Gradu.git\n",
        "%cd /content/Gradu\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_drawdowns = True\n",
        "drawdowns_from = 'USA MOMENTUM Standard (Large+Mid Cap)'\n",
        "cluster_n = 3\n",
        "\n",
        "normmalize = True\n",
        "ML_reg = True\n",
        "ML_long = False\n",
        "DL = False"
      ],
      "metadata": {
        "id": "nQWZcw65odSb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "FhY_-l5aofPM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_ONE.xlsx\")\n",
        "excel_df = xls_file.parse(\"returns non-log\")\n",
        "\n",
        "excel_df.columns = excel_df.columns.get_level_values(0)\n",
        "excel_df['Date'] = pd.to_datetime(excel_df['Date'])\n",
        "excel_df.sort_values('Date', inplace=True)\n",
        "\n",
        "print(\"Headers in the 'returns non-log' sheet:\")\n",
        "print(excel_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS4jmrFtoiJa",
        "outputId": "1248c352-3a86-4588-b016-e7b308ea02c0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers in the 'returns non-log' sheet:\n",
            "Index(['Date', 'USA Standard (Large+Mid Cap)',\n",
            "       'USA MOMENTUM Standard (Large+Mid Cap)',\n",
            "       'USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)',\n",
            "       'USA RISK WEIGHTED Standard (Large+Mid Cap)',\n",
            "       'USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)',\n",
            "       'USA ENHANCED VALUE Standard (Large+Mid Cap)', 'Winning Factor',\n",
            "       'VIXCLS', 'GDPC1', 'CPI', 'LEI', '10yr', 'Financial Turbulance',\n",
            "       '(Regime)', 'Financial condition', 'Drawdown', 'HY Spread', 'IG Spread',\n",
            "       '10y-2y', 'Vix-regimes2', 'Vix-regimes3', 'FT_regimes2', 'FT_regimes3',\n",
            "       'DD_regimes2', 'DD_regimes3', 'cluster_0 (minimal drawdown',\n",
            "       'cluster_1 (moderate drawdown)', 'cluster_2 (severe drawdown)', 'SMB',\n",
            "       'HML', 'RMW', 'CMA', 'MOM', '(Regimes)', 'Regimes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if calc_drawdowns:\n",
        "    # Calculate the cumulative portfolio values using excel_df and the specified drawdowns_from column\n",
        "    portfolio = (1 + excel_df[drawdowns_from]).cumprod()\n",
        "\n",
        "    # Define a function to compute the maximum drawdown over a rolling window\n",
        "    def max_dd(s):\n",
        "        return (s / s.cummax() - 1).min()\n",
        "\n",
        "    # Calculate the 3-month rolling drawdown using the portfolio series\n",
        "    dd_series = portfolio.rolling(window=3, min_periods=3).apply(max_dd, raw=False)\n",
        "\n",
        "    # Create a temporary DataFrame to store dates and the calculated drawdowns\n",
        "    dd_temp = pd.DataFrame({\n",
        "        'Date': excel_df['Date'],\n",
        "        '3M_Max_Drawdown': dd_series\n",
        "    })\n",
        "\n",
        "    # Drop rows with missing drawdown data to ensure complete observations\n",
        "    dd_temp = dd_temp.dropna()\n",
        "\n",
        "    print(\"Drawdown calculation (temporary DataFrame):\")\n",
        "    print(dd_temp.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRsD7p1TQc6o",
        "outputId": "f31fa3b4-8e83-401b-830f-42690f51ea99"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drawdown calculation (temporary DataFrame):\n",
            "        Date  3M_Max_Drawdown\n",
            "2 1990-05-31        -0.014564\n",
            "3 1990-06-29         0.000000\n",
            "4 1990-07-31         0.000000\n",
            "5 1990-08-31        -0.086261\n",
            "6 1990-09-28        -0.128945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit KMeans clustering on the temporary DataFrame's '3M_Max_Drawdown' column\n",
        "kmeans = KMeans(n_clusters=cluster_n, random_state=42)\n",
        "dd_temp['DD_cluster'] = kmeans.fit_predict(dd_temp[['3M_Max_Drawdown']])\n",
        "\n",
        "# Merge the cluster labels from dd_temp into excel_df by matching on the 'Date' column.\n",
        "# This adds a new column 'DD_cluster' to excel_df.\n",
        "excel_df = excel_df.merge(dd_temp[['Date', 'DD_cluster']], on='Date', how='left')\n",
        "\n",
        "print(\"excel_df with DD_cluster added:\")\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(excel_df.head().to_html(index=False)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "ND-2VF-SS187",
        "outputId": "3ab12b11-d7af-4e6b-91f3-291ee31d3847"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excel_df with DD_cluster added:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>USA Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MOMENTUM Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)</th>\n",
              "      <th>USA RISK WEIGHTED Standard (Large+Mid Cap)</th>\n",
              "      <th>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</th>\n",
              "      <th>USA ENHANCED VALUE Standard (Large+Mid Cap)</th>\n",
              "      <th>Winning Factor</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>(Regime)</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>Drawdown</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "      <th>Vix-regimes2</th>\n",
              "      <th>Vix-regimes3</th>\n",
              "      <th>FT_regimes2</th>\n",
              "      <th>FT_regimes3</th>\n",
              "      <th>DD_regimes2</th>\n",
              "      <th>DD_regimes3</th>\n",
              "      <th>cluster_0 (minimal drawdown</th>\n",
              "      <th>cluster_1 (moderate drawdown)</th>\n",
              "      <th>cluster_2 (severe drawdown)</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>MOM</th>\n",
              "      <th>(Regimes)</th>\n",
              "      <th>Regimes</th>\n",
              "      <th>DD_cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1990-03-30</td>\n",
              "      <td>0.020702</td>\n",
              "      <td>0.028022</td>\n",
              "      <td>0.012313</td>\n",
              "      <td>0.013039</td>\n",
              "      <td>0.036524</td>\n",
              "      <td>0.013845</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>21.40</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>63.5</td>\n",
              "      <td>8.59</td>\n",
              "      <td>9.383220</td>\n",
              "      <td>Recovery</td>\n",
              "      <td>0.04713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.08</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0162</td>\n",
              "      <td>-0.0292</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>-0.0102</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-04-30</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>-0.014564</td>\n",
              "      <td>-0.031345</td>\n",
              "      <td>-0.042294</td>\n",
              "      <td>-0.007806</td>\n",
              "      <td>-0.032085</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>63.6</td>\n",
              "      <td>8.79</td>\n",
              "      <td>4.756642</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.13602</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.10</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0033</td>\n",
              "      <td>-0.0259</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-05-31</td>\n",
              "      <td>0.089444</td>\n",
              "      <td>0.112070</td>\n",
              "      <td>0.079487</td>\n",
              "      <td>0.080355</td>\n",
              "      <td>0.101743</td>\n",
              "      <td>0.081134</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>16.82</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.76</td>\n",
              "      <td>14.686352</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.15632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0235</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>-0.0168</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-06-29</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>0.022340</td>\n",
              "      <td>-0.010553</td>\n",
              "      <td>-0.010138</td>\n",
              "      <td>0.011909</td>\n",
              "      <td>-0.016679</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>18.39</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.48</td>\n",
              "      <td>8.020190</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.08472</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.45</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>-0.0193</td>\n",
              "      <td>-0.0103</td>\n",
              "      <td>-0.0039</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-07-31</td>\n",
              "      <td>-0.004276</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>-0.001134</td>\n",
              "      <td>-0.011361</td>\n",
              "      <td>-0.000470</td>\n",
              "      <td>-0.008691</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>28.18</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.004619</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.47</td>\n",
              "      <td>25.637526</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.24339</td>\n",
              "      <td>-0.010680</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Low</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0316</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>-0.0018</td>\n",
              "      <td>0.0321</td>\n",
              "      <td>0.0610</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FEATURES = ['VIXCLS', 'CPI', 'LEI', '10yr', 'Financial condition', '10y-2y', 'Financial Turbulance']\n",
        "\n",
        "FEATURES = [\n",
        "    'VIXCLS',\n",
        "    'GDPC1',\n",
        "    'CPI',\n",
        "    'LEI',\n",
        "    '10yr',\n",
        "    'Financial Turbulance',\n",
        "    'Financial condition',\n",
        "    'HY Spread',\n",
        "    'IG Spread',\n",
        "    '10y-2y'\n",
        "]\n",
        "\n",
        "\n",
        "TRUE_REGIME = 'DD_cluster'\n",
        "DATE = 'Date'\n",
        "\n",
        "selected_columns =  [DATE] + [TRUE_REGIME] +FEATURES\n"
      ],
      "metadata": {
        "id": "r9Cg8WsZqU34"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing = [col for col in selected_columns if col not in excel_df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
        "\n",
        "# Subset and drop rows with empty values\n",
        "input_df = excel_df[selected_columns]\n",
        "orig_rows = len(input_df)\n",
        "input_df = input_df.dropna()\n",
        "print(f\"Original rows: {orig_rows}, Dropped rows: {orig_rows - len(input_df)}\")\n",
        "print(f\"First obs: {input_df[DATE].min()}, Last obs: {input_df[DATE].max()}\")\n",
        "\n",
        "# Display as neat HTML table (adjust 'rows_to_show' as needed)\n",
        "rows_to_show = 10\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(input_df.head(rows_to_show).to_html(index=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "7yQYY08pMCVR",
        "outputId": "5bcb618e-450a-4bba-c856-da753b114cdd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 416, Dropped rows: 81\n",
            "First obs: 1996-12-31 00:00:00, Last obs: 2024-10-31 00:00:00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>DD_cluster</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1996-12-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.47</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>77.7</td>\n",
              "      <td>6.30</td>\n",
              "      <td>7.860576</td>\n",
              "      <td>0.00043</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-01-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.14</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001886</td>\n",
              "      <td>77.8</td>\n",
              "      <td>6.58</td>\n",
              "      <td>14.956959</td>\n",
              "      <td>-0.03500</td>\n",
              "      <td>2.73</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-02-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.17</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>78.3</td>\n",
              "      <td>6.42</td>\n",
              "      <td>13.043063</td>\n",
              "      <td>0.05391</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-03-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.66</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.3</td>\n",
              "      <td>6.69</td>\n",
              "      <td>10.821978</td>\n",
              "      <td>0.05726</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-04-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.92</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.7</td>\n",
              "      <td>6.89</td>\n",
              "      <td>10.938933</td>\n",
              "      <td>0.00925</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-05-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.19</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.9</td>\n",
              "      <td>6.71</td>\n",
              "      <td>4.038058</td>\n",
              "      <td>-0.01056</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.53</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>80.4</td>\n",
              "      <td>6.49</td>\n",
              "      <td>7.517614</td>\n",
              "      <td>-0.02150</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-07-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.08</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>81.1</td>\n",
              "      <td>6.22</td>\n",
              "      <td>14.684361</td>\n",
              "      <td>0.01571</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-08-29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.81</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.002494</td>\n",
              "      <td>82.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>10.252527</td>\n",
              "      <td>0.03394</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.87</td>\n",
              "      <td>0.008539</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>82.3</td>\n",
              "      <td>6.21</td>\n",
              "      <td>6.511195</td>\n",
              "      <td>0.10651</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jY0ai22WK_kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Calculate the number of observations for each regime in the data\n",
        "regime_counts = input_df[TRUE_REGIME].value_counts().sort_index().reset_index()\n",
        "regime_counts.columns = [TRUE_REGIME, 'Count']\n",
        "\n",
        "print(\"Number of observations per regime:\")\n",
        "print(tabulate(regime_counts, headers='keys', tablefmt='psql', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeP-z42p8ae2",
        "outputId": "d8cc1a38-cdc0-4316-cf31-0302b4d9c826"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations per regime:\n",
            "+--------------+---------+\n",
            "|   DD_cluster |   Count |\n",
            "|--------------+---------|\n",
            "|            0 |     204 |\n",
            "|            1 |     102 |\n",
            "|            2 |      29 |\n",
            "+--------------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if normmalize == True:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Instantiate the scaler and apply it in-place to the FEATURES columns\n",
        "    scaler = StandardScaler()\n",
        "    input_df[FEATURES] = scaler.fit_transform(input_df[FEATURES])\n",
        "\n",
        "    print(\"Normalization applied. First 10 observations:\")\n",
        "    display(HTML(input_df.head(10).to_html(index=False)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "dlkbkE3YYiEG",
        "outputId": "4a381540-1301-498c-e612-2b3b17f3c004"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization applied. First 10 observations:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>DD_cluster</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1996-12-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.110862</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>0.158638</td>\n",
              "      <td>-1.496475</td>\n",
              "      <td>1.871825</td>\n",
              "      <td>-0.411545</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>-0.909269</td>\n",
              "      <td>-1.082181</td>\n",
              "      <td>-0.415568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-01-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.025812</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>-0.058714</td>\n",
              "      <td>-1.487664</td>\n",
              "      <td>2.062500</td>\n",
              "      <td>0.235650</td>\n",
              "      <td>-0.253834</td>\n",
              "      <td>-1.032720</td>\n",
              "      <td>-1.106567</td>\n",
              "      <td>-0.539840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-02-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.022004</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>-0.059929</td>\n",
              "      <td>-1.443610</td>\n",
              "      <td>1.953543</td>\n",
              "      <td>0.061101</td>\n",
              "      <td>0.383025</td>\n",
              "      <td>-0.988915</td>\n",
              "      <td>-1.130954</td>\n",
              "      <td>-0.539840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-03-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.086743</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.489887</td>\n",
              "      <td>-1.355504</td>\n",
              "      <td>2.137408</td>\n",
              "      <td>-0.141463</td>\n",
              "      <td>0.407021</td>\n",
              "      <td>-0.949092</td>\n",
              "      <td>-1.106567</td>\n",
              "      <td>-0.581264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-04-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.053739</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.490021</td>\n",
              "      <td>-1.320261</td>\n",
              "      <td>2.273604</td>\n",
              "      <td>-0.130797</td>\n",
              "      <td>0.063127</td>\n",
              "      <td>-1.052631</td>\n",
              "      <td>-1.082181</td>\n",
              "      <td>-0.560552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-05-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019465</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.704261</td>\n",
              "      <td>-1.302640</td>\n",
              "      <td>2.151027</td>\n",
              "      <td>-0.760162</td>\n",
              "      <td>-0.078771</td>\n",
              "      <td>-1.056614</td>\n",
              "      <td>-1.118761</td>\n",
              "      <td>-0.581264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023694</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>-0.061944</td>\n",
              "      <td>-1.258586</td>\n",
              "      <td>2.001211</td>\n",
              "      <td>-0.442824</td>\n",
              "      <td>-0.157134</td>\n",
              "      <td>-1.040684</td>\n",
              "      <td>-1.143147</td>\n",
              "      <td>-0.736604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-07-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347390</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>-0.276851</td>\n",
              "      <td>-1.196911</td>\n",
              "      <td>1.817346</td>\n",
              "      <td>0.210789</td>\n",
              "      <td>0.109400</td>\n",
              "      <td>-1.088472</td>\n",
              "      <td>-1.130954</td>\n",
              "      <td>-0.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-08-29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.440056</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>0.149492</td>\n",
              "      <td>-1.117615</td>\n",
              "      <td>1.871825</td>\n",
              "      <td>-0.193398</td>\n",
              "      <td>0.239981</td>\n",
              "      <td>-1.088472</td>\n",
              "      <td>-1.167534</td>\n",
              "      <td>-0.695180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.447673</td>\n",
              "      <td>0.201170</td>\n",
              "      <td>0.147369</td>\n",
              "      <td>-1.091183</td>\n",
              "      <td>1.810537</td>\n",
              "      <td>-0.534610</td>\n",
              "      <td>0.759796</td>\n",
              "      <td>-0.929180</td>\n",
              "      <td>-1.009021</td>\n",
              "      <td>-0.809096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ML_reg == True:\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from IPython.display import display, HTML\n",
        "    import itertools\n",
        "\n",
        "    # Define predictors and target using the given column lists\n",
        "    predictors = FEATURES\n",
        "    target = TRUE_REGIME\n",
        "\n",
        "    # Drop rows with missing values in predictors or target\n",
        "    data = input_df.dropna(subset=predictors + [target]).reset_index(drop=True)\n",
        "    X = data[predictors]\n",
        "    y = data[target]\n",
        "    # Also grab the DATE column for printing prediction timestamps\n",
        "    dates = data[DATE]\n",
        "\n",
        "    # Define the models (including GNB)\n",
        "    models = {\n",
        "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "        'SVC_linear': SVC(kernel='linear', probability=True, random_state=42),\n",
        "        'SVC_rbf': SVC(kernel='rbf', probability=True, random_state=42),\n",
        "        'GNB': GaussianNB()\n",
        "    }\n",
        "\n",
        "    window_size = 60  # e.g., 60 observations for training\n",
        "    unique_regimes = np.unique(y)\n",
        "\n",
        "    # Dictionary to store ensemble results for each combination subset\n",
        "    ensemble_results = {}\n",
        "    model_names = list(models.keys())\n",
        "\n",
        "    # Loop over all possible subset sizes (pairs, triplets, quartets, quintets, full set)\n",
        "    for r in range(2, len(model_names) + 1):\n",
        "        for combo in itertools.combinations(model_names, r):\n",
        "            combo_name = \"+\".join(combo)\n",
        "            combo_acc = []          # accuracy for each rolling iteration\n",
        "            combo_vote_details = [] # list of vote-count dicts for each iteration\n",
        "            combo_y_true = []       # true label for each iteration\n",
        "            combo_y_pred = []       # ensemble prediction for each iteration\n",
        "            print(f\"Evaluating combination: {combo_name}\")\n",
        "            for i in range(len(X)):\n",
        "                if i < window_size:\n",
        "                    continue\n",
        "                # Define training and test sets for the rolling window\n",
        "                X_train_window = X.iloc[i-window_size:i]\n",
        "                y_train_window = y.iloc[i-window_size:i]\n",
        "                X_test_window = X.iloc[[i]]\n",
        "                y_test_window = y.iloc[[i]]\n",
        "                preds = []\n",
        "                # For each model in the combination, fit and predict\n",
        "                for name in combo:\n",
        "                    model = models[name]\n",
        "                    model.fit(X_train_window, y_train_window)\n",
        "                    pred = model.predict(X_test_window)[0]\n",
        "                    preds.append(pred)\n",
        "                # Count votes for each regime in this iteration\n",
        "                vote_count = {reg: preds.count(reg) for reg in unique_regimes}\n",
        "                combo_vote_details.append(vote_count)\n",
        "                # Majority vote for ensemble prediction\n",
        "                ensemble_prediction = max(set(preds), key=preds.count)\n",
        "                combo_acc.append(1.0 if ensemble_prediction == y_test_window.values[0] else 0.0)\n",
        "                combo_y_true.append(y_test_window.values[0])\n",
        "                combo_y_pred.append(ensemble_prediction)\n",
        "            # Average ensemble accuracy over all iterations\n",
        "            avg_acc = np.mean(combo_acc)\n",
        "            # For each regime, compute average vote count over all iterations\n",
        "            avg_votes = {reg: np.mean([vote[reg] for vote in combo_vote_details]) for reg in unique_regimes}\n",
        "            # Convert average vote counts to percentages (relative to ensemble size r)\n",
        "            avg_vote_percent = {reg: (avg_votes[reg] / r) * 100 for reg in unique_regimes}\n",
        "            ensemble_results[combo_name] = {\n",
        "                'average_accuracy': avg_acc,\n",
        "                'iterations': len(combo_acc),\n",
        "                'average_votes': avg_votes,\n",
        "                'average_vote_percent': avg_vote_percent,\n",
        "                'y_true': combo_y_true,\n",
        "                'y_pred': combo_y_pred\n",
        "            }\n",
        "            print(f\"Combination {combo_name} average accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "    # Prepare a summary DataFrame with key information for each combination\n",
        "    summary_data = []\n",
        "    for combo_name, result in ensemble_results.items():\n",
        "        row = {\n",
        "            'Combination': combo_name,\n",
        "            'Models': len(combo_name.split('+')),\n",
        "            'Iterations': result['iterations'],\n",
        "            'Average Accuracy (%)': f\"{result['average_accuracy']*100:.2f}\"\n",
        "        }\n",
        "        # Add average vote percentage for each regime\n",
        "        for reg in unique_regimes:\n",
        "            row[f'Avg Vote % ({reg})'] = f\"{result['average_vote_percent'][reg]:.2f}\"\n",
        "        summary_data.append(row)\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "    print(\"\\nEnsemble Results Summary:\")\n",
        "    display(HTML(df_summary.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "sivK9Crtiv-a",
        "outputId": "acb62016-3705-4eda-8986-ba0906f9ea2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating combination: RandomForest+GradientBoosting\n",
            "Combination RandomForest+GradientBoosting average accuracy: 0.6545\n",
            "Evaluating combination: RandomForest+LogisticRegression\n",
            "Combination RandomForest+LogisticRegression average accuracy: 0.7018\n",
            "Evaluating combination: RandomForest+SVC_linear\n",
            "Combination RandomForest+SVC_linear average accuracy: 0.7127\n",
            "Evaluating combination: RandomForest+SVC_rbf\n",
            "Combination RandomForest+SVC_rbf average accuracy: 0.6764\n",
            "Evaluating combination: RandomForest+GNB\n",
            "Combination RandomForest+GNB average accuracy: 0.6800\n",
            "Evaluating combination: GradientBoosting+LogisticRegression\n",
            "Combination GradientBoosting+LogisticRegression average accuracy: 0.6836\n",
            "Evaluating combination: GradientBoosting+SVC_linear\n",
            "Combination GradientBoosting+SVC_linear average accuracy: 0.6836\n",
            "Evaluating combination: GradientBoosting+SVC_rbf\n",
            "Combination GradientBoosting+SVC_rbf average accuracy: 0.6655\n",
            "Evaluating combination: GradientBoosting+GNB\n",
            "Combination GradientBoosting+GNB average accuracy: 0.6655\n",
            "Evaluating combination: LogisticRegression+SVC_linear\n",
            "Combination LogisticRegression+SVC_linear average accuracy: 0.6945\n",
            "Evaluating combination: LogisticRegression+SVC_rbf\n",
            "Combination LogisticRegression+SVC_rbf average accuracy: 0.6691\n",
            "Evaluating combination: LogisticRegression+GNB\n",
            "Combination LogisticRegression+GNB average accuracy: 0.6836\n",
            "Evaluating combination: SVC_linear+SVC_rbf\n",
            "Combination SVC_linear+SVC_rbf average accuracy: 0.6727\n",
            "Evaluating combination: SVC_linear+GNB\n",
            "Combination SVC_linear+GNB average accuracy: 0.6873\n",
            "Evaluating combination: SVC_rbf+GNB\n",
            "Combination SVC_rbf+GNB average accuracy: 0.6727\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression average accuracy: 0.6655\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_linear\n",
            "Combination RandomForest+GradientBoosting+SVC_linear average accuracy: 0.6655\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_rbf\n",
            "Combination RandomForest+GradientBoosting+SVC_rbf average accuracy: 0.6655\n",
            "Evaluating combination: RandomForest+GradientBoosting+GNB\n",
            "Combination RandomForest+GradientBoosting+GNB average accuracy: 0.6655\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_linear\n",
            "Combination RandomForest+LogisticRegression+SVC_linear average accuracy: 0.6800\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_rbf\n",
            "Combination RandomForest+LogisticRegression+SVC_rbf average accuracy: 0.7018\n",
            "Evaluating combination: RandomForest+LogisticRegression+GNB\n",
            "Combination RandomForest+LogisticRegression+GNB average accuracy: 0.7091\n",
            "Evaluating combination: RandomForest+SVC_linear+SVC_rbf\n",
            "Combination RandomForest+SVC_linear+SVC_rbf average accuracy: 0.7055\n",
            "Evaluating combination: RandomForest+SVC_linear+GNB\n",
            "Combination RandomForest+SVC_linear+GNB average accuracy: 0.7091\n",
            "Evaluating combination: RandomForest+SVC_rbf+GNB\n",
            "Combination RandomForest+SVC_rbf+GNB average accuracy: 0.6873\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_linear\n",
            "Combination GradientBoosting+LogisticRegression+SVC_linear average accuracy: 0.6800\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_rbf\n",
            "Combination GradientBoosting+LogisticRegression+SVC_rbf average accuracy: 0.6727\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+GNB\n",
            "Combination GradientBoosting+LogisticRegression+GNB average accuracy: 0.6727\n",
            "Evaluating combination: GradientBoosting+SVC_linear+SVC_rbf\n",
            "Combination GradientBoosting+SVC_linear+SVC_rbf average accuracy: 0.6909\n",
            "Evaluating combination: GradientBoosting+SVC_linear+GNB\n",
            "Combination GradientBoosting+SVC_linear+GNB average accuracy: 0.6727\n",
            "Evaluating combination: GradientBoosting+SVC_rbf+GNB\n",
            "Combination GradientBoosting+SVC_rbf+GNB average accuracy: 0.6727\n",
            "Evaluating combination: LogisticRegression+SVC_linear+SVC_rbf\n",
            "Combination LogisticRegression+SVC_linear+SVC_rbf average accuracy: 0.6764\n",
            "Evaluating combination: LogisticRegression+SVC_linear+GNB\n",
            "Combination LogisticRegression+SVC_linear+GNB average accuracy: 0.6800\n",
            "Evaluating combination: LogisticRegression+SVC_rbf+GNB\n",
            "Combination LogisticRegression+SVC_rbf+GNB average accuracy: 0.6873\n",
            "Evaluating combination: SVC_linear+SVC_rbf+GNB\n",
            "Combination SVC_linear+SVC_rbf+GNB average accuracy: 0.6836\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_linear\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_linear average accuracy: 0.6982\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_rbf\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_rbf average accuracy: 0.6836\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+GNB\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+GNB average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_linear+SVC_rbf\n",
            "Combination RandomForest+GradientBoosting+SVC_linear+SVC_rbf average accuracy: 0.6982\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_linear+GNB\n",
            "Combination RandomForest+GradientBoosting+SVC_linear+GNB average accuracy: 0.6982\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_rbf+GNB\n",
            "Combination RandomForest+GradientBoosting+SVC_rbf+GNB average accuracy: 0.6727\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_linear+SVC_rbf\n",
            "Combination RandomForest+LogisticRegression+SVC_linear+SVC_rbf average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_linear+GNB\n",
            "Combination RandomForest+LogisticRegression+SVC_linear+GNB average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_rbf+GNB\n",
            "Combination RandomForest+LogisticRegression+SVC_rbf+GNB average accuracy: 0.6836\n",
            "Evaluating combination: RandomForest+SVC_linear+SVC_rbf+GNB\n",
            "Combination RandomForest+SVC_linear+SVC_rbf+GNB average accuracy: 0.6873\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf\n",
            "Combination GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf average accuracy: 0.6800\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_linear+GNB\n",
            "Combination GradientBoosting+LogisticRegression+SVC_linear+GNB average accuracy: 0.6836\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_rbf+GNB\n",
            "Combination GradientBoosting+LogisticRegression+SVC_rbf+GNB average accuracy: 0.6836\n",
            "Evaluating combination: GradientBoosting+SVC_linear+SVC_rbf+GNB\n",
            "Combination GradientBoosting+SVC_linear+SVC_rbf+GNB average accuracy: 0.6909\n",
            "Evaluating combination: LogisticRegression+SVC_linear+SVC_rbf+GNB\n",
            "Combination LogisticRegression+SVC_linear+SVC_rbf+GNB average accuracy: 0.6764\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_linear+GNB\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_linear+GNB average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_rbf+GNB\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_rbf+GNB average accuracy: 0.6909\n",
            "Evaluating combination: RandomForest+GradientBoosting+SVC_linear+SVC_rbf+GNB\n",
            "Combination RandomForest+GradientBoosting+SVC_linear+SVC_rbf+GNB average accuracy: 0.6945\n",
            "Evaluating combination: RandomForest+LogisticRegression+SVC_linear+SVC_rbf+GNB\n",
            "Combination RandomForest+LogisticRegression+SVC_linear+SVC_rbf+GNB average accuracy: 0.7018\n",
            "Evaluating combination: GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB\n",
            "Combination GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB average accuracy: 0.6800\n",
            "Evaluating combination: RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB\n",
            "Combination RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB average accuracy: 0.6909\n",
            "\n",
            "Ensemble Results Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Combination</th>\n",
              "      <th>Models</th>\n",
              "      <th>Iterations</th>\n",
              "      <th>Average Accuracy (%)</th>\n",
              "      <th>Avg Vote % (0.0)</th>\n",
              "      <th>Avg Vote % (1.0)</th>\n",
              "      <th>Avg Vote % (2.0)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>65.45</td>\n",
              "      <td>64.55</td>\n",
              "      <td>28.00</td>\n",
              "      <td>7.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>70.18</td>\n",
              "      <td>68.73</td>\n",
              "      <td>23.64</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_linear</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>71.27</td>\n",
              "      <td>69.82</td>\n",
              "      <td>23.09</td>\n",
              "      <td>7.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_rbf</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>67.64</td>\n",
              "      <td>75.45</td>\n",
              "      <td>20.00</td>\n",
              "      <td>4.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GNB</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>70.36</td>\n",
              "      <td>22.91</td>\n",
              "      <td>6.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>67.09</td>\n",
              "      <td>24.36</td>\n",
              "      <td>8.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_linear</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>68.18</td>\n",
              "      <td>23.82</td>\n",
              "      <td>8.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_rbf</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>73.82</td>\n",
              "      <td>20.73</td>\n",
              "      <td>5.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+GNB</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>68.73</td>\n",
              "      <td>23.64</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_linear</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>72.36</td>\n",
              "      <td>19.45</td>\n",
              "      <td>8.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_rbf</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>66.91</td>\n",
              "      <td>78.00</td>\n",
              "      <td>16.36</td>\n",
              "      <td>5.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+GNB</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>72.91</td>\n",
              "      <td>19.27</td>\n",
              "      <td>7.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SVC_linear+SVC_rbf</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>79.09</td>\n",
              "      <td>15.82</td>\n",
              "      <td>5.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SVC_linear+GNB</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>68.73</td>\n",
              "      <td>74.00</td>\n",
              "      <td>18.73</td>\n",
              "      <td>7.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SVC_rbf+GNB</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>79.64</td>\n",
              "      <td>15.64</td>\n",
              "      <td>4.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>66.79</td>\n",
              "      <td>25.33</td>\n",
              "      <td>7.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_linear</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>67.52</td>\n",
              "      <td>24.97</td>\n",
              "      <td>7.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>71.27</td>\n",
              "      <td>22.91</td>\n",
              "      <td>5.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>66.55</td>\n",
              "      <td>67.88</td>\n",
              "      <td>24.85</td>\n",
              "      <td>7.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_linear</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>70.30</td>\n",
              "      <td>22.06</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>70.18</td>\n",
              "      <td>74.06</td>\n",
              "      <td>20.00</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>70.91</td>\n",
              "      <td>70.67</td>\n",
              "      <td>21.94</td>\n",
              "      <td>7.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_linear+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>70.55</td>\n",
              "      <td>74.79</td>\n",
              "      <td>19.64</td>\n",
              "      <td>5.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_linear+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>70.91</td>\n",
              "      <td>71.39</td>\n",
              "      <td>21.58</td>\n",
              "      <td>7.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_rbf+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.73</td>\n",
              "      <td>75.15</td>\n",
              "      <td>19.52</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_linear</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>69.21</td>\n",
              "      <td>22.55</td>\n",
              "      <td>8.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>72.97</td>\n",
              "      <td>20.48</td>\n",
              "      <td>6.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>69.58</td>\n",
              "      <td>22.42</td>\n",
              "      <td>8.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_linear+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>69.09</td>\n",
              "      <td>73.70</td>\n",
              "      <td>20.12</td>\n",
              "      <td>6.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_linear+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>70.30</td>\n",
              "      <td>22.06</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_rbf+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>74.06</td>\n",
              "      <td>20.00</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_linear+SVC_rbf</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>67.64</td>\n",
              "      <td>76.48</td>\n",
              "      <td>17.21</td>\n",
              "      <td>6.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_linear+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>73.09</td>\n",
              "      <td>19.15</td>\n",
              "      <td>7.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_rbf+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.73</td>\n",
              "      <td>76.85</td>\n",
              "      <td>17.09</td>\n",
              "      <td>6.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>3</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>77.58</td>\n",
              "      <td>16.73</td>\n",
              "      <td>5.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_linear</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.82</td>\n",
              "      <td>68.45</td>\n",
              "      <td>23.73</td>\n",
              "      <td>7.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_rbf</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>71.27</td>\n",
              "      <td>22.18</td>\n",
              "      <td>6.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>68.73</td>\n",
              "      <td>23.64</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_linear+SVC_rbf</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.82</td>\n",
              "      <td>71.82</td>\n",
              "      <td>21.91</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_linear+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.82</td>\n",
              "      <td>69.27</td>\n",
              "      <td>23.36</td>\n",
              "      <td>7.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>67.27</td>\n",
              "      <td>72.09</td>\n",
              "      <td>21.82</td>\n",
              "      <td>6.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_linear+SVC_rbf</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>73.91</td>\n",
              "      <td>19.73</td>\n",
              "      <td>6.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_linear+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>71.36</td>\n",
              "      <td>21.18</td>\n",
              "      <td>7.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>74.18</td>\n",
              "      <td>19.64</td>\n",
              "      <td>6.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.73</td>\n",
              "      <td>74.73</td>\n",
              "      <td>19.36</td>\n",
              "      <td>5.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>73.09</td>\n",
              "      <td>20.09</td>\n",
              "      <td>6.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_linear+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>70.55</td>\n",
              "      <td>21.55</td>\n",
              "      <td>7.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>68.36</td>\n",
              "      <td>73.36</td>\n",
              "      <td>20.00</td>\n",
              "      <td>6.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>69.09</td>\n",
              "      <td>73.91</td>\n",
              "      <td>19.73</td>\n",
              "      <td>6.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LogisticRegression+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>4</td>\n",
              "      <td>275</td>\n",
              "      <td>67.64</td>\n",
              "      <td>76.00</td>\n",
              "      <td>17.55</td>\n",
              "      <td>6.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>71.71</td>\n",
              "      <td>21.53</td>\n",
              "      <td>6.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_linear+GNB</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>69.67</td>\n",
              "      <td>22.69</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_rbf+GNB</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>69.09</td>\n",
              "      <td>71.93</td>\n",
              "      <td>21.45</td>\n",
              "      <td>6.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>69.45</td>\n",
              "      <td>72.36</td>\n",
              "      <td>21.24</td>\n",
              "      <td>6.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+LogisticRegression+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>70.18</td>\n",
              "      <td>74.04</td>\n",
              "      <td>19.49</td>\n",
              "      <td>6.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>5</td>\n",
              "      <td>275</td>\n",
              "      <td>68.00</td>\n",
              "      <td>73.38</td>\n",
              "      <td>19.78</td>\n",
              "      <td>6.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>RandomForest+GradientBoosting+LogisticRegression+SVC_linear+SVC_rbf+GNB</td>\n",
              "      <td>6</td>\n",
              "      <td>275</td>\n",
              "      <td>69.09</td>\n",
              "      <td>72.18</td>\n",
              "      <td>21.03</td>\n",
              "      <td>6.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ML_long == True:\n",
        "\n",
        "  #TÃ¤Ã¤ Model testaa training windowit 12 -> 120 kk ja nÃ¤yttÃ¤Ã¤ kaikille accuracyt + regiimi kohtaset accuracyt\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from IPython.display import display, HTML\n",
        "\n",
        "  # Define predictors and target using the given column lists\n",
        "  predictors = FEATURES\n",
        "  target = TRUE_REGIME\n",
        "\n",
        "  # Drop rows with missing values in predictors or target\n",
        "  data = input_df.dropna(subset=predictors + [target]).reset_index(drop=True)\n",
        "  X = data[predictors]\n",
        "  y = data[target]\n",
        "  # Also grab the DATE column for printing prediction timestamps\n",
        "  dates = data[DATE]\n",
        "\n",
        "  # Define the models\n",
        "  models = {\n",
        "      'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "      'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "      'LogisticRegression': LogisticRegression(max_iter=2000, random_state=42),  # Increased max_iter\n",
        "      'SVC_linear': SVC(kernel='linear', probability=True, random_state=42),\n",
        "      'SVC_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
        "  }\n",
        "\n",
        "  # Get the unique regimes from the target\n",
        "  unique_regimes = np.unique(y)\n",
        "\n",
        "  # Lists to store overall results (one row per training window size)\n",
        "  overall_results = []\n",
        "\n",
        "  # Dictionary to store regime-specific results.\n",
        "  # Keys are the regime values; values will be a list of dictionaries (one per training window size)\n",
        "  regime_results = {reg: [] for reg in unique_regimes}\n",
        "\n",
        "  # Loop over training windows from 1 year (12 months) to 10 years (120 months)\n",
        "  for window_size in range(12, 121, 12):\n",
        "      print(\"=\"*50)\n",
        "      print(f\"Running rolling window evaluation with training window of {window_size} months\")\n",
        "\n",
        "      # Initialize dictionaries for this run\n",
        "      rolling_accuracies = {name: [] for name in models}\n",
        "      pred_true = {name: {'y_true': [], 'y_pred': []} for name in models}\n",
        "\n",
        "      # Loop over the dataset in a rolling window manner\n",
        "      for i in range(len(X)):\n",
        "          if i < window_size:\n",
        "              continue\n",
        "\n",
        "          # Training period: previous 'window_size' observations\n",
        "          train_end = dates.iloc[i-1]  # Last date in training window\n",
        "          test_date = dates.iloc[i]     # Date for prediction\n",
        "\n",
        "          X_train_window = X.iloc[i-window_size:i]\n",
        "          y_train_window = y.iloc[i-window_size:i]\n",
        "          X_test_window = X.iloc[[i]]\n",
        "          y_test_window = y.iloc[[i]]\n",
        "\n",
        "          # Loop through each model, fit, predict, and store accuracies\n",
        "          for name, model in models.items():\n",
        "              # Check if the training window contains at least 2 unique classes\n",
        "              if len(np.unique(y_train_window)) < 2:\n",
        "                  print(f\"Skipping model {name} for timestamp {test_date} due to only one class in training window.\")\n",
        "                  rolling_accuracies[name].append(np.nan)\n",
        "                  pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "                  pred_true[name]['y_pred'].append(None)\n",
        "                  continue\n",
        "\n",
        "              model.fit(X_train_window, y_train_window)\n",
        "              y_pred = model.predict(X_test_window)\n",
        "              acc = accuracy_score(y_test_window, y_pred)\n",
        "              rolling_accuracies[name].append(acc)\n",
        "              pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "              pred_true[name]['y_pred'].append(y_pred[0])\n",
        "\n",
        "      # Compute overall average rolling window accuracy for each model\n",
        "      # Use np.nanmean to ignore NaN values\n",
        "      avg_accuracies = {name: np.nanmean(rolling_accuracies[name]) if rolling_accuracies[name] else 0\n",
        "                        for name in models}\n",
        "\n",
        "      # Build a result row for overall accuracy\n",
        "      overall_row = {\n",
        "          \"Training Window (months)\": window_size,\n",
        "          \"RandomForest\": f\"{avg_accuracies['RandomForest']*100:.2f}%\" if not np.isnan(avg_accuracies['RandomForest']) else \"N/A\",\n",
        "          \"GradientBoosting\": f\"{avg_accuracies['GradientBoosting']*100:.2f}%\" if not np.isnan(avg_accuracies['GradientBoosting']) else \"N/A\",\n",
        "          \"LogisticRegression\": f\"{avg_accuracies['LogisticRegression']*100:.2f}%\" if not np.isnan(avg_accuracies['LogisticRegression']) else \"N/A\",\n",
        "          \"SVC_linear\": f\"{avg_accuracies['SVC_linear']*100:.2f}%\" if not np.isnan(avg_accuracies['SVC_linear']) else \"N/A\",\n",
        "          \"SVC_rbf\": f\"{avg_accuracies['SVC_rbf']*100:.2f}%\" if not np.isnan(avg_accuracies['SVC_rbf']) else \"N/A\"\n",
        "      }\n",
        "      overall_results.append(overall_row)\n",
        "\n",
        "      # For each regime, compute regime-specific accuracy per model from the predictions made in this run\n",
        "      for reg in unique_regimes:\n",
        "          regime_acc = {}\n",
        "          for name in models:\n",
        "              # Filter predictions for the current regime (using true labels)\n",
        "              y_true_reg = [yt for yt in pred_true[name]['y_true'] if yt == reg]\n",
        "              y_pred_reg = [yp for yt, yp in zip(pred_true[name]['y_true'], pred_true[name]['y_pred']) if yt == reg]\n",
        "              if len(y_true_reg) > 0:\n",
        "                  acc_reg = np.mean(np.array(y_true_reg) == np.array(y_pred_reg))\n",
        "              else:\n",
        "                  acc_reg = np.nan\n",
        "              regime_acc[name] = acc_reg\n",
        "\n",
        "          # Build a row for this regime and training window\n",
        "          regime_row = {\"Training Window (months)\": window_size}\n",
        "          for name in models:\n",
        "              regime_row[name] = f\"{regime_acc[name]*100:.2f}%\" if not np.isnan(regime_acc[name]) else \"N/A\"\n",
        "          regime_results[reg].append(regime_row)\n",
        "\n",
        "      print(f\"Completed training window = {window_size} months\")\n",
        "      print(\"=\"*50)\n",
        "\n",
        "  # Display overall results table\n",
        "  df_overall = pd.DataFrame(overall_results)\n",
        "  print(\"Overall Rolling Window Average Accuracy:\")\n",
        "  display(HTML(df_overall.to_html(index=False)))\n",
        "\n",
        "  # Now display separate tables for each regime\n",
        "  for reg in unique_regimes:\n",
        "      df_regime = pd.DataFrame(regime_results[reg])\n",
        "      print(f\"\\nRolling Window Accuracy for Regime {reg}:\")\n",
        "      display(HTML(df_regime.to_html(index=False)))\n",
        "\n",
        "  # Optionally, you can also compute and display confusion matrices per model if desired.\n"
      ],
      "metadata": {
        "id": "vp7FA1IRumLl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DL == True:\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")  # Suppress warnings\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential, Model\n",
        "    from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "    import xgboost as xgb\n",
        "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # Define the experiment function with remapping of training labels if needed\n",
        "    def run_experiment(training_window, seq_len,\n",
        "                       lstm_units_first=128, lstm_units_second=32, dropout_rate=0.3,\n",
        "                       xgb_n_estimators=100, xgb_max_depth=4, xgb_learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Runs the rolling-window hybrid (LSTM + XGBoost) experiment using a given training_window (in months)\n",
        "        and a sequence length (seq_len). If the training labels do not form a contiguous set starting at 0,\n",
        "        they are remapped. Returns overall accuracy, total number of predictions, and regime-specific accuracies.\n",
        "        \"\"\"\n",
        "        all_preds = []   # To store predictions\n",
        "        all_true = []    # To store true regime labels\n",
        "\n",
        "        # Ensure data is sorted by date\n",
        "        data = input_df.sort_values(DATE).reset_index(drop=True)\n",
        "\n",
        "        # Rolling window: iterate from index=training_window to end of data\n",
        "        for i in range(training_window, len(data)):\n",
        "            # Use the previous 'training_window' months as training data\n",
        "            train_window = data.iloc[i - training_window:i].reset_index(drop=True)\n",
        "            if len(train_window) < training_window:\n",
        "                continue\n",
        "\n",
        "            # Generate overlapping sequences of length 'seq_len' within the training window\n",
        "            X_train_sequences = []\n",
        "            y_train = []\n",
        "            for j in range(len(train_window) - seq_len + 1):\n",
        "                seq = train_window[FEATURES].iloc[j : j + seq_len].values\n",
        "                target = train_window[TRUE_REGIME].iloc[j + seq_len - 1]  # regime at end of sequence\n",
        "                X_train_sequences.append(seq)\n",
        "                y_train.append(target)\n",
        "            X_train_sequences = np.array(X_train_sequences)  # shape: (num_samples, seq_len, num_features)\n",
        "            y_train = np.array(y_train)\n",
        "\n",
        "            # Remap training labels to contiguous integers starting at 0 if needed.\n",
        "            unique_classes = np.unique(y_train)\n",
        "            mapping = {old: new for new, old in enumerate(unique_classes)}\n",
        "            inverse_mapping = {v: k for k, v in mapping.items()}\n",
        "            y_train_mapped = np.array([mapping[val] for val in y_train])\n",
        "\n",
        "            # Build the LSTM feature extractor using an explicit Input layer\n",
        "            input_layer = Input(shape=(seq_len, len(FEATURES)))\n",
        "            lstm_out = LSTM(lstm_units_first, return_sequences=True)(input_layer)\n",
        "            lstm_out = LSTM(lstm_units_second, return_sequences=False)(lstm_out)\n",
        "            dropout_out = Dropout(dropout_rate)(lstm_out)\n",
        "            feature_extractor = Model(inputs=input_layer, outputs=dropout_out)\n",
        "\n",
        "            # Extract features from training sequences\n",
        "            X_train_features = feature_extractor.predict(X_train_sequences, verbose=0)\n",
        "\n",
        "            # Train an XGBoost classifier on these features using the remapped labels.\n",
        "            clf = xgb.XGBClassifier(\n",
        "                n_estimators=xgb_n_estimators,\n",
        "                max_depth=xgb_max_depth,\n",
        "                learning_rate=xgb_learning_rate,\n",
        "                use_label_encoder=False,\n",
        "                eval_metric='mlogloss'\n",
        "            )\n",
        "            clf.fit(X_train_features, y_train_mapped)\n",
        "\n",
        "            # For prediction, use the last 'seq_len'-month sequence from the training window\n",
        "            X_pred_seq = train_window[FEATURES].iloc[-seq_len:].values.reshape(1, seq_len, len(FEATURES))\n",
        "            X_pred_feature = feature_extractor.predict(X_pred_seq, verbose=0)\n",
        "            pred_mapped = clf.predict(X_pred_feature)[0]\n",
        "            # Map back to original label\n",
        "            pred_regime = inverse_mapping[pred_mapped]\n",
        "\n",
        "            # The true regime for the next month (at time index i)\n",
        "            true_regime = data[TRUE_REGIME].iloc[i]\n",
        "\n",
        "            all_preds.append(pred_regime)\n",
        "            all_true.append(true_regime)\n",
        "\n",
        "        # Compute overall accuracy and total number of predictions\n",
        "        overall_acc = accuracy_score(all_true, all_preds)\n",
        "        total_obs = len(all_preds)\n",
        "\n",
        "        # Compute regime-specific accuracies\n",
        "        regimes = np.unique(all_true)\n",
        "        regime_accuracies = {}\n",
        "        for r in regimes:\n",
        "            indices = [idx for idx, val in enumerate(all_true) if val == r]\n",
        "            if len(indices) > 0:\n",
        "                correct = sum(1 for idx in indices if all_preds[idx] == all_true[idx])\n",
        "                regime_acc = correct / len(indices)\n",
        "                regime_accuracies[r] = regime_acc\n",
        "            else:\n",
        "                regime_accuracies[r] = np.nan\n",
        "\n",
        "        return {\n",
        "            \"training_window\": training_window,\n",
        "            \"seq_len\": seq_len,\n",
        "            \"total_obs\": total_obs,\n",
        "            \"overall_accuracy\": overall_acc,\n",
        "            \"regime_accuracies\": regime_accuracies\n",
        "        }\n",
        "\n",
        "    # Prepare to store experiment results in a list of dictionaries\n",
        "    results = []\n",
        "\n",
        "    # Define training windows from 1 to 10 years (in months) â€“ assume 1 year = 12 months\n",
        "    for tw in range(12, 121, 12):  # 12, 24, ..., 120 months\n",
        "        # Define sequence length percentages: 25%, 50%, 75%, and 100% of training window\n",
        "        for frac in [0.25, 0.5, 0.75, 1.0]:\n",
        "            seq = int(round(tw * frac))\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Running experiment with training_window = {tw} months and seq_len = {seq} months\")\n",
        "            res = run_experiment(training_window=tw, seq_len=seq)\n",
        "            # Build a result row that includes run parameters and accuracies\n",
        "            row = {\n",
        "                \"Training Window (months)\": tw,\n",
        "                \"Seq Length (months)\": seq,\n",
        "                \"Total Observations\": res[\"total_obs\"],\n",
        "                \"Overall Accuracy\": f\"{res['overall_accuracy']*100:.2f}%\",\n",
        "                \"Accuracy Regime 0\": f\"{res['regime_accuracies'].get(0, np.nan)*100:.2f}%\" if 0 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 1\": f\"{res['regime_accuracies'].get(1, np.nan)*100:.2f}%\" if 1 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 2\": f\"{res['regime_accuracies'].get(2, np.nan)*100:.2f}%\" if 2 in res[\"regime_accuracies\"] else \"N/A\"\n",
        "            }\n",
        "            results.append(row)\n",
        "            print(\"=\"*50)\n",
        "\n",
        "    # Convert results to a DataFrame and display as an HTML table\n",
        "    df_results = pd.DataFrame(results)\n",
        "    display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "DoyxwlWcFY1z"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame and display as an HTML table\n",
        "df_results = pd.DataFrame(results)\n",
        "display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "aFjKoZBkmOQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "d7feefb4-a835-4d24-f779-d36d67420881"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-712872e5cbed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert results to a DataFrame and display as an HTML table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    }
  ]
}