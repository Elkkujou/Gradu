{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdvj1Ccbsj7Ocf3IZDvBio"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPPizlV3oIUh",
        "outputId": "0a76f278-46fd-4022-a738-03911045bac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 259 (delta 62), reused 0 (delta 0), pack-reused 136 (from 1)\u001b[K\n",
            "Receiving objects: 100% (259/259), 29.78 MiB | 14.84 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "/content/Gradu\n",
            " chatti_RF.ipynb\t       regime_prediction_famafrench.ipynb  'RF REGIIMI HYVÄ TRAINING.ipynb'\n",
            "'Financial turbulence.ipynb'   regime_prediction_msci.ipynb\t   'RF_regime (3).ipynb'\n",
            " FT_source.xlsx\t\t       regime_pred.txt\t\t\t    THE_ONE.xlsx\n",
            " Regiimi_prediction.ipynb      RF_Gradu.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf Gradu\n",
        "!git clone https://github.com/Elkkujou/Gradu.git\n",
        "%cd /content/Gradu\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_drawdowns = True\n",
        "drawdowns_from = 'USA MOMENTUM Standard (Large+Mid Cap)'\n",
        "cluster_n = 3\n",
        "\n",
        "ML = False\n",
        "DL = True"
      ],
      "metadata": {
        "id": "nQWZcw65odSb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "FhY_-l5aofPM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_ONE.xlsx\")\n",
        "excel_df = xls_file.parse(\"returns non-log\")\n",
        "\n",
        "excel_df.columns = excel_df.columns.get_level_values(0)\n",
        "excel_df['Date'] = pd.to_datetime(excel_df['Date'])\n",
        "excel_df.sort_values('Date', inplace=True)\n",
        "\n",
        "print(\"Headers in the 'returns non-log' sheet:\")\n",
        "print(excel_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS4jmrFtoiJa",
        "outputId": "e26b09fc-6e23-4198-f848-165939bc98ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers in the 'returns non-log' sheet:\n",
            "Index(['Date', 'USA Standard (Large+Mid Cap)',\n",
            "       'USA MOMENTUM Standard (Large+Mid Cap)',\n",
            "       'USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)',\n",
            "       'USA RISK WEIGHTED Standard (Large+Mid Cap)',\n",
            "       'USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)',\n",
            "       'USA ENHANCED VALUE Standard (Large+Mid Cap)', 'Winning Factor',\n",
            "       'VIXCLS', 'GDPC1', 'CPI', 'LEI', '10yr', 'Financial Turbulance',\n",
            "       '(Regime)', 'Financial condition', 'Drawdown', 'HY Spread', 'IG Spread',\n",
            "       '10y-2y', 'Vix-regimes2', 'Vix-regimes3', 'FT_regimes2', 'FT_regimes3',\n",
            "       'DD_regimes2', 'DD_regimes3', 'cluster_0 (minimal drawdown',\n",
            "       'cluster_1 (moderate drawdown)', 'cluster_2 (severe drawdown)', 'SMB',\n",
            "       'HML', 'RMW', 'CMA', 'MOM', '(Regimes)', 'Regimes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if calc_drawdowns:\n",
        "    # Calculate the cumulative portfolio values using excel_df and the specified drawdowns_from column\n",
        "    portfolio = (1 + excel_df[drawdowns_from]).cumprod()\n",
        "\n",
        "    # Define a function to compute the maximum drawdown over a rolling window\n",
        "    def max_dd(s):\n",
        "        return (s / s.cummax() - 1).min()\n",
        "\n",
        "    # Calculate the 3-month rolling drawdown using the portfolio series\n",
        "    dd_series = portfolio.rolling(window=3, min_periods=3).apply(max_dd, raw=False)\n",
        "\n",
        "    # Create a temporary DataFrame to store dates and the calculated drawdowns\n",
        "    dd_temp = pd.DataFrame({\n",
        "        'Date': excel_df['Date'],\n",
        "        '3M_Max_Drawdown': dd_series\n",
        "    })\n",
        "\n",
        "    # Drop rows with missing drawdown data to ensure complete observations\n",
        "    dd_temp = dd_temp.dropna()\n",
        "\n",
        "    print(\"Drawdown calculation (temporary DataFrame):\")\n",
        "    print(dd_temp.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRsD7p1TQc6o",
        "outputId": "e0e92490-177f-4359-e026-e4e9683da0dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drawdown calculation (temporary DataFrame):\n",
            "        Date  3M_Max_Drawdown\n",
            "2 1990-05-31        -0.014564\n",
            "3 1990-06-29         0.000000\n",
            "4 1990-07-31         0.000000\n",
            "5 1990-08-31        -0.086261\n",
            "6 1990-09-28        -0.128945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit KMeans clustering on the temporary DataFrame's '3M_Max_Drawdown' column\n",
        "kmeans = KMeans(n_clusters=cluster_n, random_state=42)\n",
        "dd_temp['DD_cluster'] = kmeans.fit_predict(dd_temp[['3M_Max_Drawdown']])\n",
        "\n",
        "# Merge the cluster labels from dd_temp into excel_df by matching on the 'Date' column.\n",
        "# This adds a new column 'DD_cluster' to excel_df.\n",
        "excel_df = excel_df.merge(dd_temp[['Date', 'DD_cluster']], on='Date', how='left')\n",
        "\n",
        "print(\"excel_df with DD_cluster added:\")\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(excel_df.head().to_html(index=False)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ND-2VF-SS187",
        "outputId": "12968c19-fb0f-4db0-dac7-d16470fc6cbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excel_df with DD_cluster added:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>USA Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MOMENTUM Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)</th>\n",
              "      <th>USA RISK WEIGHTED Standard (Large+Mid Cap)</th>\n",
              "      <th>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</th>\n",
              "      <th>USA ENHANCED VALUE Standard (Large+Mid Cap)</th>\n",
              "      <th>Winning Factor</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>(Regime)</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>Drawdown</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "      <th>Vix-regimes2</th>\n",
              "      <th>Vix-regimes3</th>\n",
              "      <th>FT_regimes2</th>\n",
              "      <th>FT_regimes3</th>\n",
              "      <th>DD_regimes2</th>\n",
              "      <th>DD_regimes3</th>\n",
              "      <th>cluster_0 (minimal drawdown</th>\n",
              "      <th>cluster_1 (moderate drawdown)</th>\n",
              "      <th>cluster_2 (severe drawdown)</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>MOM</th>\n",
              "      <th>(Regimes)</th>\n",
              "      <th>Regimes</th>\n",
              "      <th>DD_cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1990-03-30</td>\n",
              "      <td>0.020702</td>\n",
              "      <td>0.028022</td>\n",
              "      <td>0.012313</td>\n",
              "      <td>0.013039</td>\n",
              "      <td>0.036524</td>\n",
              "      <td>0.013845</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>21.40</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>63.5</td>\n",
              "      <td>8.59</td>\n",
              "      <td>9.383220</td>\n",
              "      <td>Recovery</td>\n",
              "      <td>0.04713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.08</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0162</td>\n",
              "      <td>-0.0292</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>-0.0102</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-04-30</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>-0.014564</td>\n",
              "      <td>-0.031345</td>\n",
              "      <td>-0.042294</td>\n",
              "      <td>-0.007806</td>\n",
              "      <td>-0.032085</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>63.6</td>\n",
              "      <td>8.79</td>\n",
              "      <td>4.756642</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.13602</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.10</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0033</td>\n",
              "      <td>-0.0259</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-05-31</td>\n",
              "      <td>0.089444</td>\n",
              "      <td>0.112070</td>\n",
              "      <td>0.079487</td>\n",
              "      <td>0.080355</td>\n",
              "      <td>0.101743</td>\n",
              "      <td>0.081134</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>16.82</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.76</td>\n",
              "      <td>14.686352</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.15632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0235</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>-0.0168</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-06-29</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>0.022340</td>\n",
              "      <td>-0.010553</td>\n",
              "      <td>-0.010138</td>\n",
              "      <td>0.011909</td>\n",
              "      <td>-0.016679</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>18.39</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.48</td>\n",
              "      <td>8.020190</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.08472</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.45</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>-0.0193</td>\n",
              "      <td>-0.0103</td>\n",
              "      <td>-0.0039</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-07-31</td>\n",
              "      <td>-0.004276</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>-0.001134</td>\n",
              "      <td>-0.011361</td>\n",
              "      <td>-0.000470</td>\n",
              "      <td>-0.008691</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>28.18</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.004619</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.47</td>\n",
              "      <td>25.637526</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.24339</td>\n",
              "      <td>-0.010680</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Low</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0316</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>-0.0018</td>\n",
              "      <td>0.0321</td>\n",
              "      <td>0.0610</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FEATURES = ['VIXCLS', 'CPI', 'LEI', '10yr', 'Financial condition', '10y-2y', 'Financial Turbulance']\n",
        "\n",
        "FEATURES = [\n",
        "    'VIXCLS',\n",
        "    'GDPC1',\n",
        "    'CPI',\n",
        "    'LEI',\n",
        "    '10yr',\n",
        "    'Financial Turbulance',\n",
        "    'Financial condition',\n",
        "    'HY Spread',\n",
        "    'IG Spread',\n",
        "    '10y-2y'\n",
        "]\n",
        "\n",
        "\n",
        "TRUE_REGIME = 'DD_cluster'\n",
        "DATE = 'Date'\n",
        "\n",
        "selected_columns =  [DATE] + [TRUE_REGIME] +FEATURES\n"
      ],
      "metadata": {
        "id": "r9Cg8WsZqU34"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing = [col for col in selected_columns if col not in excel_df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
        "\n",
        "# Subset and drop rows with empty values\n",
        "input_df = excel_df[selected_columns]\n",
        "orig_rows = len(input_df)\n",
        "input_df = input_df.dropna()\n",
        "print(f\"Original rows: {orig_rows}, Dropped rows: {orig_rows - len(input_df)}\")\n",
        "print(f\"First obs: {input_df[DATE].min()}, Last obs: {input_df[DATE].max()}\")\n",
        "\n",
        "# Display as neat HTML table (adjust 'rows_to_show' as needed)\n",
        "rows_to_show = 10\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(input_df.head(rows_to_show).to_html(index=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "7yQYY08pMCVR",
        "outputId": "72deb05b-7c3b-40d0-a278-69ca4dd7c0f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 416, Dropped rows: 81\n",
            "First obs: 1996-12-31 00:00:00, Last obs: 2024-10-31 00:00:00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>DD_cluster</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1996-12-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.47</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>77.7</td>\n",
              "      <td>6.30</td>\n",
              "      <td>7.860576</td>\n",
              "      <td>0.00043</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-01-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.14</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001886</td>\n",
              "      <td>77.8</td>\n",
              "      <td>6.58</td>\n",
              "      <td>14.956959</td>\n",
              "      <td>-0.03500</td>\n",
              "      <td>2.73</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-02-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.17</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>78.3</td>\n",
              "      <td>6.42</td>\n",
              "      <td>13.043063</td>\n",
              "      <td>0.05391</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-03-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.66</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.3</td>\n",
              "      <td>6.69</td>\n",
              "      <td>10.821978</td>\n",
              "      <td>0.05726</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-04-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.92</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.7</td>\n",
              "      <td>6.89</td>\n",
              "      <td>10.938933</td>\n",
              "      <td>0.00925</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-05-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.19</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.9</td>\n",
              "      <td>6.71</td>\n",
              "      <td>4.038058</td>\n",
              "      <td>-0.01056</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.53</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>80.4</td>\n",
              "      <td>6.49</td>\n",
              "      <td>7.517614</td>\n",
              "      <td>-0.02150</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-07-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.08</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>81.1</td>\n",
              "      <td>6.22</td>\n",
              "      <td>14.684361</td>\n",
              "      <td>0.01571</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-08-29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.81</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.002494</td>\n",
              "      <td>82.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>10.252527</td>\n",
              "      <td>0.03394</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.87</td>\n",
              "      <td>0.008539</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>82.3</td>\n",
              "      <td>6.21</td>\n",
              "      <td>6.511195</td>\n",
              "      <td>0.10651</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jY0ai22WK_kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Calculate the number of observations for each regime in the data\n",
        "regime_counts = input_df[TRUE_REGIME].value_counts().sort_index().reset_index()\n",
        "regime_counts.columns = [TRUE_REGIME, 'Count']\n",
        "\n",
        "print(\"Number of observations per regime:\")\n",
        "print(tabulate(regime_counts, headers='keys', tablefmt='psql', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeP-z42p8ae2",
        "outputId": "5cb868f9-4aea-4443-9241-46f8cae4e1d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations per regime:\n",
            "+--------------+---------+\n",
            "|   DD_cluster |   Count |\n",
            "|--------------+---------|\n",
            "|            0 |     204 |\n",
            "|            1 |     102 |\n",
            "|            2 |      29 |\n",
            "+--------------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ML == True:\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from IPython.display import display, HTML\n",
        "\n",
        "  # Define predictors and target using the given column lists\n",
        "  predictors = FEATURES\n",
        "  target = TRUE_REGIME\n",
        "\n",
        "  # Drop rows with missing values in predictors or target\n",
        "  data = input_df.dropna(subset=predictors + [target]).reset_index(drop=True)\n",
        "  X = data[predictors]\n",
        "  y = data[target]\n",
        "  # Also grab the DATE column for printing prediction timestamps\n",
        "  dates = data[DATE]\n",
        "\n",
        "  # Define the models\n",
        "  models = {\n",
        "      'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "      'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "      'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "      'SVC_linear': SVC(kernel='linear', probability=True, random_state=42),\n",
        "      'SVC_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
        "  }\n",
        "\n",
        "  # Get the unique regimes from the target\n",
        "  unique_regimes = np.unique(y)\n",
        "\n",
        "  # Lists to store overall results (one row per training window size)\n",
        "  overall_results = []\n",
        "\n",
        "  # Dictionary to store regime-specific results\n",
        "  # Keys are the regime values; values will be a list of dictionaries (one per training window size)\n",
        "  regime_results = {reg: [] for reg in unique_regimes}\n",
        "\n",
        "  # Loop over training windows from 1 year (12 months) to 10 years (120 months)\n",
        "  for window_size in range(12, 121, 12):\n",
        "      print(\"=\"*50)\n",
        "      print(f\"Running rolling window evaluation with training window of {window_size} months\")\n",
        "\n",
        "      # Initialize dictionaries for this run\n",
        "      rolling_accuracies = {name: [] for name in models}\n",
        "      pred_true = {name: {'y_true': [], 'y_pred': []} for name in models}\n",
        "\n",
        "      # Loop over the dataset in a rolling window manner\n",
        "      for i in range(len(X)):\n",
        "          if i < window_size:\n",
        "              continue\n",
        "\n",
        "          # Training period: previous 'window_size' observations\n",
        "          train_end = dates.iloc[i-1]  # Last date in training window\n",
        "          test_date = dates.iloc[i]     # Date for prediction\n",
        "\n",
        "          X_train_window = X.iloc[i-window_size:i]\n",
        "          y_train_window = y.iloc[i-window_size:i]\n",
        "          X_test_window = X.iloc[[i]]\n",
        "          y_test_window = y.iloc[[i]]\n",
        "\n",
        "          # Loop through each model, fit, predict, and store accuracies\n",
        "          for name, model in models.items():\n",
        "              model.fit(X_train_window, y_train_window)\n",
        "              y_pred = model.predict(X_test_window)\n",
        "              acc = accuracy_score(y_test_window, y_pred)\n",
        "              rolling_accuracies[name].append(acc)\n",
        "              pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "              pred_true[name]['y_pred'].append(y_pred[0])\n",
        "\n",
        "      # Compute overall average rolling window accuracy for each model\n",
        "      avg_accuracies = {name: np.mean(rolling_accuracies[name]) if rolling_accuracies[name] else 0\n",
        "                        for name in models}\n",
        "\n",
        "      # Build a result row for overall accuracy\n",
        "      overall_row = {\n",
        "          \"Training Window (months)\": window_size,\n",
        "          \"RandomForest\": f\"{avg_accuracies['RandomForest']*100:.2f}%\",\n",
        "          \"GradientBoosting\": f\"{avg_accuracies['GradientBoosting']*100:.2f}%\",\n",
        "          \"LogisticRegression\": f\"{avg_accuracies['LogisticRegression']*100:.2f}%\",\n",
        "          \"SVC_linear\": f\"{avg_accuracies['SVC_linear']*100:.2f}%\",\n",
        "          \"SVC_rbf\": f\"{avg_accuracies['SVC_rbf']*100:.2f}%\"\n",
        "      }\n",
        "      overall_results.append(overall_row)\n",
        "\n",
        "      # For each regime, compute regime-specific accuracy per model from the predictions made in this run\n",
        "      for reg in unique_regimes:\n",
        "          regime_acc = {}\n",
        "          for name in models:\n",
        "              # Filter predictions for the current regime (using true labels)\n",
        "              y_true_reg = [yt for yt in pred_true[name]['y_true'] if yt == reg]\n",
        "              # Also get the corresponding predictions\n",
        "              y_pred_reg = [yp for yt, yp in zip(pred_true[name]['y_true'], pred_true[name]['y_pred']) if yt == reg]\n",
        "              # Compute accuracy only if there is at least one prediction\n",
        "              if len(y_true_reg) > 0:\n",
        "                  acc_reg = np.mean(np.array(y_true_reg) == np.array(y_pred_reg))\n",
        "              else:\n",
        "                  acc_reg = np.nan\n",
        "              regime_acc[name] = acc_reg\n",
        "\n",
        "          # Build a row for this regime and training window\n",
        "          regime_row = {\"Training Window (months)\": window_size}\n",
        "          for name in models:\n",
        "              regime_row[name] = f\"{regime_acc[name]*100:.2f}%\" if not np.isnan(regime_acc[name]) else \"N/A\"\n",
        "          regime_results[reg].append(regime_row)\n",
        "\n",
        "      print(f\"Completed training window = {window_size} months\")\n",
        "      print(\"=\"*50)\n",
        "\n",
        "  # Display overall results table\n",
        "  df_overall = pd.DataFrame(overall_results)\n",
        "  print(\"Overall Rolling Window Average Accuracy:\")\n",
        "  display(HTML(df_overall.to_html(index=False)))\n",
        "\n",
        "  # Now display separate tables for each regime\n",
        "  for reg in unique_regimes:\n",
        "      df_regime = pd.DataFrame(regime_results[reg])\n",
        "      print(f\"\\nRolling Window Accuracy for Regime {reg}:\")\n",
        "      display(HTML(df_regime.to_html(index=False)))\n",
        "\n",
        "  # Optionally, you can also compute and display confusion matrices per model if desired.\n"
      ],
      "metadata": {
        "id": "vp7FA1IRumLl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DL == True:\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")  # Suppress warnings\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential, Model\n",
        "    from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "    import xgboost as xgb\n",
        "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # Define the experiment function with remapping of training labels if needed\n",
        "    def run_experiment(training_window, seq_len,\n",
        "                       lstm_units_first=128, lstm_units_second=32, dropout_rate=0.3,\n",
        "                       xgb_n_estimators=100, xgb_max_depth=4, xgb_learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Runs the rolling-window hybrid (LSTM + XGBoost) experiment using a given training_window (in months)\n",
        "        and a sequence length (seq_len). If the training labels do not form a contiguous set starting at 0,\n",
        "        they are remapped. Returns overall accuracy, total number of predictions, and regime-specific accuracies.\n",
        "        \"\"\"\n",
        "        all_preds = []   # To store predictions\n",
        "        all_true = []    # To store true regime labels\n",
        "\n",
        "        # Ensure data is sorted by date\n",
        "        data = input_df.sort_values(DATE).reset_index(drop=True)\n",
        "\n",
        "        # Rolling window: iterate from index=training_window to end of data\n",
        "        for i in range(training_window, len(data)):\n",
        "            # Use the previous 'training_window' months as training data\n",
        "            train_window = data.iloc[i - training_window:i].reset_index(drop=True)\n",
        "            if len(train_window) < training_window:\n",
        "                continue\n",
        "\n",
        "            # Generate overlapping sequences of length 'seq_len' within the training window\n",
        "            X_train_sequences = []\n",
        "            y_train = []\n",
        "            for j in range(len(train_window) - seq_len + 1):\n",
        "                seq = train_window[FEATURES].iloc[j : j + seq_len].values\n",
        "                target = train_window[TRUE_REGIME].iloc[j + seq_len - 1]  # regime at end of sequence\n",
        "                X_train_sequences.append(seq)\n",
        "                y_train.append(target)\n",
        "            X_train_sequences = np.array(X_train_sequences)  # shape: (num_samples, seq_len, num_features)\n",
        "            y_train = np.array(y_train)\n",
        "\n",
        "            # Remap training labels to contiguous integers starting at 0 if needed.\n",
        "            unique_classes = np.unique(y_train)\n",
        "            mapping = {old: new for new, old in enumerate(unique_classes)}\n",
        "            inverse_mapping = {v: k for k, v in mapping.items()}\n",
        "            y_train_mapped = np.array([mapping[val] for val in y_train])\n",
        "\n",
        "            # Build the LSTM feature extractor using an explicit Input layer\n",
        "            input_layer = Input(shape=(seq_len, len(FEATURES)))\n",
        "            lstm_out = LSTM(lstm_units_first, return_sequences=True)(input_layer)\n",
        "            lstm_out = LSTM(lstm_units_second, return_sequences=False)(lstm_out)\n",
        "            dropout_out = Dropout(dropout_rate)(lstm_out)\n",
        "            feature_extractor = Model(inputs=input_layer, outputs=dropout_out)\n",
        "\n",
        "            # Extract features from training sequences\n",
        "            X_train_features = feature_extractor.predict(X_train_sequences, verbose=0)\n",
        "\n",
        "            # Train an XGBoost classifier on these features using the remapped labels.\n",
        "            clf = xgb.XGBClassifier(\n",
        "                n_estimators=xgb_n_estimators,\n",
        "                max_depth=xgb_max_depth,\n",
        "                learning_rate=xgb_learning_rate,\n",
        "                use_label_encoder=False,\n",
        "                eval_metric='mlogloss'\n",
        "            )\n",
        "            clf.fit(X_train_features, y_train_mapped)\n",
        "\n",
        "            # For prediction, use the last 'seq_len'-month sequence from the training window\n",
        "            X_pred_seq = train_window[FEATURES].iloc[-seq_len:].values.reshape(1, seq_len, len(FEATURES))\n",
        "            X_pred_feature = feature_extractor.predict(X_pred_seq, verbose=0)\n",
        "            pred_mapped = clf.predict(X_pred_feature)[0]\n",
        "            # Map back to original label\n",
        "            pred_regime = inverse_mapping[pred_mapped]\n",
        "\n",
        "            # The true regime for the next month (at time index i)\n",
        "            true_regime = data[TRUE_REGIME].iloc[i]\n",
        "\n",
        "            all_preds.append(pred_regime)\n",
        "            all_true.append(true_regime)\n",
        "\n",
        "        # Compute overall accuracy and total number of predictions\n",
        "        overall_acc = accuracy_score(all_true, all_preds)\n",
        "        total_obs = len(all_preds)\n",
        "\n",
        "        # Compute regime-specific accuracies\n",
        "        regimes = np.unique(all_true)\n",
        "        regime_accuracies = {}\n",
        "        for r in regimes:\n",
        "            indices = [idx for idx, val in enumerate(all_true) if val == r]\n",
        "            if len(indices) > 0:\n",
        "                correct = sum(1 for idx in indices if all_preds[idx] == all_true[idx])\n",
        "                regime_acc = correct / len(indices)\n",
        "                regime_accuracies[r] = regime_acc\n",
        "            else:\n",
        "                regime_accuracies[r] = np.nan\n",
        "\n",
        "        return {\n",
        "            \"training_window\": training_window,\n",
        "            \"seq_len\": seq_len,\n",
        "            \"total_obs\": total_obs,\n",
        "            \"overall_accuracy\": overall_acc,\n",
        "            \"regime_accuracies\": regime_accuracies\n",
        "        }\n",
        "\n",
        "    # Prepare to store experiment results in a list of dictionaries\n",
        "    results = []\n",
        "\n",
        "    # Define training windows from 1 to 10 years (in months) – assume 1 year = 12 months\n",
        "    for tw in range(12, 121, 12):  # 12, 24, ..., 120 months\n",
        "        # Define sequence length percentages: 25%, 50%, 75%, and 100% of training window\n",
        "        for frac in [0.25, 0.5, 0.75, 1.0]:\n",
        "            seq = int(round(tw * frac))\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Running experiment with training_window = {tw} months and seq_len = {seq} months\")\n",
        "            res = run_experiment(training_window=tw, seq_len=seq)\n",
        "            # Build a result row that includes run parameters and accuracies\n",
        "            row = {\n",
        "                \"Training Window (months)\": tw,\n",
        "                \"Seq Length (months)\": seq,\n",
        "                \"Total Observations\": res[\"total_obs\"],\n",
        "                \"Overall Accuracy\": f\"{res['overall_accuracy']*100:.2f}%\",\n",
        "                \"Accuracy Regime 0\": f\"{res['regime_accuracies'].get(0, np.nan)*100:.2f}%\" if 0 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 1\": f\"{res['regime_accuracies'].get(1, np.nan)*100:.2f}%\" if 1 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 2\": f\"{res['regime_accuracies'].get(2, np.nan)*100:.2f}%\" if 2 in res[\"regime_accuracies\"] else \"N/A\"\n",
        "            }\n",
        "            results.append(row)\n",
        "            print(\"=\"*50)\n",
        "\n",
        "    # Convert results to a DataFrame and display as an HTML table\n",
        "    df_results = pd.DataFrame(results)\n",
        "    display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "DoyxwlWcFY1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f0c1e6-f3db-4faf-f2d0-9ad21fa0cf7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Running experiment with training_window = 12 months and seq_len = 3 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 12 months and seq_len = 6 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 12 months and seq_len = 9 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 12 months and seq_len = 12 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 24 months and seq_len = 6 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 24 months and seq_len = 12 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 24 months and seq_len = 18 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 24 months and seq_len = 24 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 36 months and seq_len = 9 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 36 months and seq_len = 18 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 36 months and seq_len = 27 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 36 months and seq_len = 36 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 48 months and seq_len = 12 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 48 months and seq_len = 24 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 48 months and seq_len = 36 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 48 months and seq_len = 48 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 60 months and seq_len = 15 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 60 months and seq_len = 30 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running experiment with training_window = 60 months and seq_len = 45 months\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame and display as an HTML table\n",
        "df_results = pd.DataFrame(results)\n",
        "display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "aFjKoZBkmOQb"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}