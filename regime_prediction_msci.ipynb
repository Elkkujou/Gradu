{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbtbyjVmhPFX9blQsJtExo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPPizlV3oIUh",
        "outputId": "b268501e-e188-4abe-d70a-defbb6f538ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Gradu'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 265 (delta 66), reused 0 (delta 0), pack-reused 136 (from 1)\u001b[K\n",
            "Receiving objects: 100% (265/265), 29.78 MiB | 16.67 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n",
            "/content/Gradu\n",
            " chatti_RF.ipynb\t       regime_prediction_famafrench.ipynb  'RF REGIIMI HYVÃ„ TRAINING.ipynb'\n",
            "'Financial turbulence.ipynb'   regime_prediction_msci.ipynb\t   'RF_regime (3).ipynb'\n",
            " FT_source.xlsx\t\t       regime_pred.txt\t\t\t    THE_ONE.xlsx\n",
            " Regiimi_prediction.ipynb      RF_Gradu.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf Gradu\n",
        "!git clone https://github.com/Elkkujou/Gradu.git\n",
        "%cd /content/Gradu\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_drawdowns = True\n",
        "drawdowns_from = 'USA MOMENTUM Standard (Large+Mid Cap)'\n",
        "cluster_n = 3\n",
        "\n",
        "normmalize = True\n",
        "ML_reg = True\n",
        "ML_long = False\n",
        "DL = False"
      ],
      "metadata": {
        "id": "nQWZcw65odSb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "FhY_-l5aofPM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xls_file = pd.ExcelFile(\"/content/Gradu/THE_ONE.xlsx\")\n",
        "excel_df = xls_file.parse(\"returns non-log\")\n",
        "\n",
        "excel_df.columns = excel_df.columns.get_level_values(0)\n",
        "excel_df['Date'] = pd.to_datetime(excel_df['Date'])\n",
        "excel_df.sort_values('Date', inplace=True)\n",
        "\n",
        "print(\"Headers in the 'returns non-log' sheet:\")\n",
        "print(excel_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS4jmrFtoiJa",
        "outputId": "73733448-daba-4b6f-9277-adfd3e0a4bb3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers in the 'returns non-log' sheet:\n",
            "Index(['Date', 'USA Standard (Large+Mid Cap)',\n",
            "       'USA MOMENTUM Standard (Large+Mid Cap)',\n",
            "       'USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)',\n",
            "       'USA RISK WEIGHTED Standard (Large+Mid Cap)',\n",
            "       'USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)',\n",
            "       'USA ENHANCED VALUE Standard (Large+Mid Cap)', 'Winning Factor',\n",
            "       'VIXCLS', 'GDPC1', 'CPI', 'LEI', '10yr', 'Financial Turbulance',\n",
            "       '(Regime)', 'Financial condition', 'Drawdown', 'HY Spread', 'IG Spread',\n",
            "       '10y-2y', 'Vix-regimes2', 'Vix-regimes3', 'FT_regimes2', 'FT_regimes3',\n",
            "       'DD_regimes2', 'DD_regimes3', 'cluster_0 (minimal drawdown',\n",
            "       'cluster_1 (moderate drawdown)', 'cluster_2 (severe drawdown)', 'SMB',\n",
            "       'HML', 'RMW', 'CMA', 'MOM', '(Regimes)', 'Regimes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if calc_drawdowns:\n",
        "    # Calculate the cumulative portfolio values using excel_df and the specified drawdowns_from column\n",
        "    portfolio = (1 + excel_df[drawdowns_from]).cumprod()\n",
        "\n",
        "    # Define a function to compute the maximum drawdown over a rolling window\n",
        "    def max_dd(s):\n",
        "        return (s / s.cummax() - 1).min()\n",
        "\n",
        "    # Calculate the 3-month rolling drawdown using the portfolio series\n",
        "    dd_series = portfolio.rolling(window=3, min_periods=3).apply(max_dd, raw=False)\n",
        "\n",
        "    # Create a temporary DataFrame to store dates and the calculated drawdowns\n",
        "    dd_temp = pd.DataFrame({\n",
        "        'Date': excel_df['Date'],\n",
        "        '3M_Max_Drawdown': dd_series\n",
        "    })\n",
        "\n",
        "    # Drop rows with missing drawdown data to ensure complete observations\n",
        "    dd_temp = dd_temp.dropna()\n",
        "\n",
        "    print(\"Drawdown calculation (temporary DataFrame):\")\n",
        "    print(dd_temp.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRsD7p1TQc6o",
        "outputId": "58f1c6b9-68f8-4a73-e3e0-0da45c457585"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drawdown calculation (temporary DataFrame):\n",
            "        Date  3M_Max_Drawdown\n",
            "2 1990-05-31        -0.014564\n",
            "3 1990-06-29         0.000000\n",
            "4 1990-07-31         0.000000\n",
            "5 1990-08-31        -0.086261\n",
            "6 1990-09-28        -0.128945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit KMeans clustering on the temporary DataFrame's '3M_Max_Drawdown' column\n",
        "kmeans = KMeans(n_clusters=cluster_n, random_state=42)\n",
        "dd_temp['DD_cluster'] = kmeans.fit_predict(dd_temp[['3M_Max_Drawdown']])\n",
        "\n",
        "# Merge the cluster labels from dd_temp into excel_df by matching on the 'Date' column.\n",
        "# This adds a new column 'DD_cluster' to excel_df.\n",
        "excel_df = excel_df.merge(dd_temp[['Date', 'DD_cluster']], on='Date', how='left')\n",
        "\n",
        "print(\"excel_df with DD_cluster added:\")\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(excel_df.head().to_html(index=False)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ND-2VF-SS187",
        "outputId": "ce0292d8-6e85-47aa-c110-485baba18d0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excel_df with DD_cluster added:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>USA Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MOMENTUM Standard (Large+Mid Cap)</th>\n",
              "      <th>USA MINIMUM VOLATILITY (USD) Standard (Large+Mid Cap)</th>\n",
              "      <th>USA RISK WEIGHTED Standard (Large+Mid Cap)</th>\n",
              "      <th>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</th>\n",
              "      <th>USA ENHANCED VALUE Standard (Large+Mid Cap)</th>\n",
              "      <th>Winning Factor</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>(Regime)</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>Drawdown</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "      <th>Vix-regimes2</th>\n",
              "      <th>Vix-regimes3</th>\n",
              "      <th>FT_regimes2</th>\n",
              "      <th>FT_regimes3</th>\n",
              "      <th>DD_regimes2</th>\n",
              "      <th>DD_regimes3</th>\n",
              "      <th>cluster_0 (minimal drawdown</th>\n",
              "      <th>cluster_1 (moderate drawdown)</th>\n",
              "      <th>cluster_2 (severe drawdown)</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>RMW</th>\n",
              "      <th>CMA</th>\n",
              "      <th>MOM</th>\n",
              "      <th>(Regimes)</th>\n",
              "      <th>Regimes</th>\n",
              "      <th>DD_cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1990-03-30</td>\n",
              "      <td>0.020702</td>\n",
              "      <td>0.028022</td>\n",
              "      <td>0.012313</td>\n",
              "      <td>0.013039</td>\n",
              "      <td>0.036524</td>\n",
              "      <td>0.013845</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>21.40</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>63.5</td>\n",
              "      <td>8.59</td>\n",
              "      <td>9.383220</td>\n",
              "      <td>Recovery</td>\n",
              "      <td>0.04713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.08</td>\n",
              "      <td>High</td>\n",
              "      <td>Low</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0162</td>\n",
              "      <td>-0.0292</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>-0.0102</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-04-30</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>-0.014564</td>\n",
              "      <td>-0.031345</td>\n",
              "      <td>-0.042294</td>\n",
              "      <td>-0.007806</td>\n",
              "      <td>-0.032085</td>\n",
              "      <td>USA SECTOR NEUTRAL QUALITY Standard (Large+Mid Cap)</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>63.6</td>\n",
              "      <td>8.79</td>\n",
              "      <td>4.756642</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.13602</td>\n",
              "      <td>-0.023292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.10</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0033</td>\n",
              "      <td>-0.0259</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-05-31</td>\n",
              "      <td>0.089444</td>\n",
              "      <td>0.112070</td>\n",
              "      <td>0.079487</td>\n",
              "      <td>0.080355</td>\n",
              "      <td>0.101743</td>\n",
              "      <td>0.081134</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>16.82</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.76</td>\n",
              "      <td>14.686352</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>-0.15632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0235</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>-0.0168</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-06-29</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>0.022340</td>\n",
              "      <td>-0.010553</td>\n",
              "      <td>-0.010138</td>\n",
              "      <td>0.011909</td>\n",
              "      <td>-0.016679</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>18.39</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.48</td>\n",
              "      <td>8.020190</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.08472</td>\n",
              "      <td>-0.006432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.45</td>\n",
              "      <td>High</td>\n",
              "      <td>High</td>\n",
              "      <td>Normal Turbulence</td>\n",
              "      <td>Low Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>-0.0193</td>\n",
              "      <td>-0.0103</td>\n",
              "      <td>-0.0039</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990-07-31</td>\n",
              "      <td>-0.004276</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>-0.001134</td>\n",
              "      <td>-0.011361</td>\n",
              "      <td>-0.000470</td>\n",
              "      <td>-0.008691</td>\n",
              "      <td>USA MOMENTUM Standard (Large+Mid Cap)</td>\n",
              "      <td>28.18</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.004619</td>\n",
              "      <td>63.3</td>\n",
              "      <td>8.47</td>\n",
              "      <td>25.637526</td>\n",
              "      <td>Slowdown</td>\n",
              "      <td>0.24339</td>\n",
              "      <td>-0.010680</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Low</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>High Turbulence</td>\n",
              "      <td>Normal Drawdown</td>\n",
              "      <td>Moderate Drawdown</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0316</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>-0.0018</td>\n",
              "      <td>0.0321</td>\n",
              "      <td>0.0610</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FEATURES = ['VIXCLS', 'CPI', 'LEI', '10yr', 'Financial condition', '10y-2y', 'Financial Turbulance']\n",
        "\n",
        "FEATURES = [\n",
        "    'VIXCLS',\n",
        "    'GDPC1',\n",
        "    'CPI',\n",
        "    'LEI',\n",
        "    '10yr',\n",
        "    'Financial Turbulance',\n",
        "    'Financial condition',\n",
        "    'HY Spread',\n",
        "    'IG Spread',\n",
        "    '10y-2y'\n",
        "]\n",
        "\n",
        "\n",
        "TRUE_REGIME = 'DD_cluster'\n",
        "DATE = 'Date'\n",
        "\n",
        "selected_columns =  [DATE] + [TRUE_REGIME] +FEATURES\n"
      ],
      "metadata": {
        "id": "r9Cg8WsZqU34"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing = [col for col in selected_columns if col not in excel_df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
        "\n",
        "# Subset and drop rows with empty values\n",
        "input_df = excel_df[selected_columns]\n",
        "orig_rows = len(input_df)\n",
        "input_df = input_df.dropna()\n",
        "print(f\"Original rows: {orig_rows}, Dropped rows: {orig_rows - len(input_df)}\")\n",
        "print(f\"First obs: {input_df[DATE].min()}, Last obs: {input_df[DATE].max()}\")\n",
        "\n",
        "# Display as neat HTML table (adjust 'rows_to_show' as needed)\n",
        "rows_to_show = 10\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(input_df.head(rows_to_show).to_html(index=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "7yQYY08pMCVR",
        "outputId": "96d2f122-b74c-41ec-da88-ac5474bde376"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 416, Dropped rows: 81\n",
            "First obs: 1996-12-31 00:00:00, Last obs: 2024-10-31 00:00:00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>DD_cluster</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1996-12-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.47</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>77.7</td>\n",
              "      <td>6.30</td>\n",
              "      <td>7.860576</td>\n",
              "      <td>0.00043</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-01-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.14</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001886</td>\n",
              "      <td>77.8</td>\n",
              "      <td>6.58</td>\n",
              "      <td>14.956959</td>\n",
              "      <td>-0.03500</td>\n",
              "      <td>2.73</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-02-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.17</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>78.3</td>\n",
              "      <td>6.42</td>\n",
              "      <td>13.043063</td>\n",
              "      <td>0.05391</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-03-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.66</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.3</td>\n",
              "      <td>6.69</td>\n",
              "      <td>10.821978</td>\n",
              "      <td>0.05726</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-04-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.92</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>79.7</td>\n",
              "      <td>6.89</td>\n",
              "      <td>10.938933</td>\n",
              "      <td>0.00925</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-05-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.19</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.9</td>\n",
              "      <td>6.71</td>\n",
              "      <td>4.038058</td>\n",
              "      <td>-0.01056</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.53</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>80.4</td>\n",
              "      <td>6.49</td>\n",
              "      <td>7.517614</td>\n",
              "      <td>-0.02150</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-07-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.08</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>81.1</td>\n",
              "      <td>6.22</td>\n",
              "      <td>14.684361</td>\n",
              "      <td>0.01571</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-08-29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.81</td>\n",
              "      <td>0.012486</td>\n",
              "      <td>0.002494</td>\n",
              "      <td>82.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>10.252527</td>\n",
              "      <td>0.03394</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.87</td>\n",
              "      <td>0.008539</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>82.3</td>\n",
              "      <td>6.21</td>\n",
              "      <td>6.511195</td>\n",
              "      <td>0.10651</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jY0ai22WK_kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Calculate the number of observations for each regime in the data\n",
        "regime_counts = input_df[TRUE_REGIME].value_counts().sort_index().reset_index()\n",
        "regime_counts.columns = [TRUE_REGIME, 'Count']\n",
        "\n",
        "print(\"Number of observations per regime:\")\n",
        "print(tabulate(regime_counts, headers='keys', tablefmt='psql', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeP-z42p8ae2",
        "outputId": "ef151be2-2f27-400e-d6d2-e977e455dd46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations per regime:\n",
            "+--------------+---------+\n",
            "|   DD_cluster |   Count |\n",
            "|--------------+---------|\n",
            "|            0 |     204 |\n",
            "|            1 |     102 |\n",
            "|            2 |      29 |\n",
            "+--------------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if normmalize == True:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Instantiate the scaler and apply it in-place to the FEATURES columns\n",
        "    scaler = StandardScaler()\n",
        "    input_df[FEATURES] = scaler.fit_transform(input_df[FEATURES])\n",
        "\n",
        "    print(\"Normalization applied. First 10 observations:\")\n",
        "    display(HTML(input_df.head(10).to_html(index=False)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dlkbkE3YYiEG",
        "outputId": "d059becc-93d2-4dd7-b227-1bb77efb749c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization applied. First 10 observations:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Date</th>\n",
              "      <th>DD_cluster</th>\n",
              "      <th>VIXCLS</th>\n",
              "      <th>GDPC1</th>\n",
              "      <th>CPI</th>\n",
              "      <th>LEI</th>\n",
              "      <th>10yr</th>\n",
              "      <th>Financial Turbulance</th>\n",
              "      <th>Financial condition</th>\n",
              "      <th>HY Spread</th>\n",
              "      <th>IG Spread</th>\n",
              "      <th>10y-2y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1996-12-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.110862</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>0.158638</td>\n",
              "      <td>-1.496475</td>\n",
              "      <td>1.871825</td>\n",
              "      <td>-0.411545</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>-0.909269</td>\n",
              "      <td>-1.082181</td>\n",
              "      <td>-0.415568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-01-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.025812</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>-0.058714</td>\n",
              "      <td>-1.487664</td>\n",
              "      <td>2.062500</td>\n",
              "      <td>0.235650</td>\n",
              "      <td>-0.253834</td>\n",
              "      <td>-1.032720</td>\n",
              "      <td>-1.106567</td>\n",
              "      <td>-0.539840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-02-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.022004</td>\n",
              "      <td>0.029919</td>\n",
              "      <td>-0.059929</td>\n",
              "      <td>-1.443610</td>\n",
              "      <td>1.953543</td>\n",
              "      <td>0.061101</td>\n",
              "      <td>0.383025</td>\n",
              "      <td>-0.988915</td>\n",
              "      <td>-1.130954</td>\n",
              "      <td>-0.539840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-03-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.086743</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.489887</td>\n",
              "      <td>-1.355504</td>\n",
              "      <td>2.137408</td>\n",
              "      <td>-0.141463</td>\n",
              "      <td>0.407021</td>\n",
              "      <td>-0.949092</td>\n",
              "      <td>-1.106567</td>\n",
              "      <td>-0.581264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-04-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.053739</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.490021</td>\n",
              "      <td>-1.320261</td>\n",
              "      <td>2.273604</td>\n",
              "      <td>-0.130797</td>\n",
              "      <td>0.063127</td>\n",
              "      <td>-1.052631</td>\n",
              "      <td>-1.082181</td>\n",
              "      <td>-0.560552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-05-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019465</td>\n",
              "      <td>0.867842</td>\n",
              "      <td>-0.704261</td>\n",
              "      <td>-1.302640</td>\n",
              "      <td>2.151027</td>\n",
              "      <td>-0.760162</td>\n",
              "      <td>-0.078771</td>\n",
              "      <td>-1.056614</td>\n",
              "      <td>-1.118761</td>\n",
              "      <td>-0.581264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-06-30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023694</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>-0.061944</td>\n",
              "      <td>-1.258586</td>\n",
              "      <td>2.001211</td>\n",
              "      <td>-0.442824</td>\n",
              "      <td>-0.157134</td>\n",
              "      <td>-1.040684</td>\n",
              "      <td>-1.143147</td>\n",
              "      <td>-0.736604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-07-31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347390</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>-0.276851</td>\n",
              "      <td>-1.196911</td>\n",
              "      <td>1.817346</td>\n",
              "      <td>0.210789</td>\n",
              "      <td>0.109400</td>\n",
              "      <td>-1.088472</td>\n",
              "      <td>-1.130954</td>\n",
              "      <td>-0.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-08-29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.440056</td>\n",
              "      <td>0.525492</td>\n",
              "      <td>0.149492</td>\n",
              "      <td>-1.117615</td>\n",
              "      <td>1.871825</td>\n",
              "      <td>-0.193398</td>\n",
              "      <td>0.239981</td>\n",
              "      <td>-1.088472</td>\n",
              "      <td>-1.167534</td>\n",
              "      <td>-0.695180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.447673</td>\n",
              "      <td>0.201170</td>\n",
              "      <td>0.147369</td>\n",
              "      <td>-1.091183</td>\n",
              "      <td>1.810537</td>\n",
              "      <td>-0.534610</td>\n",
              "      <td>0.759796</td>\n",
              "      <td>-0.929180</td>\n",
              "      <td>-1.009021</td>\n",
              "      <td>-0.809096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ML_reg == True:\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.naive_bayes import GaussianNB\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from IPython.display import display, HTML\n",
        "\n",
        "  # Define predictors and target using the given column lists\n",
        "  predictors = FEATURES\n",
        "  target = TRUE_REGIME\n",
        "\n",
        "  # Drop rows with missing values in predictors or target\n",
        "  data = input_df.dropna(subset=predictors + [target]).reset_index(drop=True)\n",
        "  X = data[predictors]\n",
        "  y = data[target]\n",
        "  # Also grab the DATE column for printing prediction timestamps\n",
        "  dates = data[DATE]\n",
        "\n",
        "  # Define the models, including Gaussian Naive Bayes (GNB)\n",
        "  models = {\n",
        "      'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "      'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "      'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "      'SVC_linear': SVC(kernel='linear', probability=True, random_state=42),\n",
        "      'SVC_rbf': SVC(kernel='rbf', probability=True, random_state=42),\n",
        "      'GNB': GaussianNB()\n",
        "  }\n",
        "\n",
        "  window_size = 60  # e.g., 60 observations for training\n",
        "  rolling_accuracies = {name: [] for name in models}\n",
        "\n",
        "  # Dictionaries to store true and predicted labels for each model for confusion matrix calculation\n",
        "  pred_true = {name: {'y_true': [], 'y_pred': []} for name in models}\n",
        "\n",
        "  print(\"Starting rolling window evaluation:\")\n",
        "\n",
        "  # Loop over the dataset in a rolling window manner\n",
        "  for i in range(len(X)):\n",
        "      if i < window_size:\n",
        "          print(f\"Skipping prediction for timestamp {dates.iloc[i]} \"\n",
        "                f\"(insufficient data: {i} observations available, need {window_size}).\")\n",
        "          continue\n",
        "\n",
        "      # Training period is the previous window_size observations\n",
        "      # Training period ends at the date corresponding to index i-1\n",
        "      train_end = dates.iloc[i-1]\n",
        "      # The prediction is for the date at index i\n",
        "      test_date = dates.iloc[i]\n",
        "\n",
        "      X_train_window = X.iloc[i-window_size:i]\n",
        "      y_train_window = y.iloc[i-window_size:i]\n",
        "      X_test_window = X.iloc[[i]]\n",
        "      y_test_window = y.iloc[[i]]\n",
        "\n",
        "      # Loop through each model, fit, predict and print the training end date and prediction date\n",
        "      for name, model in models.items():\n",
        "          model.fit(X_train_window, y_train_window)\n",
        "          y_pred = model.predict(X_test_window)\n",
        "          acc = accuracy_score(y_test_window, y_pred)\n",
        "          print(f\"Training period ended at {train_end} - Prediction for period {test_date}: \"\n",
        "                f\"Model '{name}' Accuracy = {acc:.2f}\")\n",
        "          rolling_accuracies[name].append(acc)\n",
        "          # Save true and predicted values for confusion matrix calculation\n",
        "          pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "          pred_true[name]['y_pred'].append(y_pred[0])\n",
        "\n",
        "  # Print average rolling window accuracy for each model\n",
        "  print(\"\\nRolling Window Average Accuracy:\")\n",
        "  for name, acc_list in rolling_accuracies.items():\n",
        "      avg_acc = np.mean(acc_list) if acc_list else 0\n",
        "      print(f\"{name}: {avg_acc:.2f}\")\n",
        "\n",
        "  # Compute and display confusion matrix for each model\n",
        "  for name in models:\n",
        "      cm = confusion_matrix(pred_true[name]['y_true'], pred_true[name]['y_pred'])\n",
        "      print(f\"\\nConfusion Matrix for {name}:\")\n",
        "      print(cm)\n",
        "\n",
        "      # Plot confusion matrix heatmap\n",
        "      plt.figure(figsize=(6, 4))\n",
        "      sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "      plt.title(f'Confusion Matrix for {name}')\n",
        "      plt.ylabel('Actual')\n",
        "      plt.xlabel('Predicted')\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "sivK9Crtiv-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ML_long == True:\n",
        "\n",
        "  #TÃ¤Ã¤ Model testaa training windowit 12 -> 120 kk ja nÃ¤yttÃ¤Ã¤ kaikille accuracyt + regiimi kohtaset accuracyt\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from IPython.display import display, HTML\n",
        "\n",
        "  # Define predictors and target using the given column lists\n",
        "  predictors = FEATURES\n",
        "  target = TRUE_REGIME\n",
        "\n",
        "  # Drop rows with missing values in predictors or target\n",
        "  data = input_df.dropna(subset=predictors + [target]).reset_index(drop=True)\n",
        "  X = data[predictors]\n",
        "  y = data[target]\n",
        "  # Also grab the DATE column for printing prediction timestamps\n",
        "  dates = data[DATE]\n",
        "\n",
        "  # Define the models\n",
        "  models = {\n",
        "      'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "      'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "      'LogisticRegression': LogisticRegression(max_iter=2000, random_state=42),  # Increased max_iter\n",
        "      'SVC_linear': SVC(kernel='linear', probability=True, random_state=42),\n",
        "      'SVC_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
        "  }\n",
        "\n",
        "  # Get the unique regimes from the target\n",
        "  unique_regimes = np.unique(y)\n",
        "\n",
        "  # Lists to store overall results (one row per training window size)\n",
        "  overall_results = []\n",
        "\n",
        "  # Dictionary to store regime-specific results.\n",
        "  # Keys are the regime values; values will be a list of dictionaries (one per training window size)\n",
        "  regime_results = {reg: [] for reg in unique_regimes}\n",
        "\n",
        "  # Loop over training windows from 1 year (12 months) to 10 years (120 months)\n",
        "  for window_size in range(12, 121, 12):\n",
        "      print(\"=\"*50)\n",
        "      print(f\"Running rolling window evaluation with training window of {window_size} months\")\n",
        "\n",
        "      # Initialize dictionaries for this run\n",
        "      rolling_accuracies = {name: [] for name in models}\n",
        "      pred_true = {name: {'y_true': [], 'y_pred': []} for name in models}\n",
        "\n",
        "      # Loop over the dataset in a rolling window manner\n",
        "      for i in range(len(X)):\n",
        "          if i < window_size:\n",
        "              continue\n",
        "\n",
        "          # Training period: previous 'window_size' observations\n",
        "          train_end = dates.iloc[i-1]  # Last date in training window\n",
        "          test_date = dates.iloc[i]     # Date for prediction\n",
        "\n",
        "          X_train_window = X.iloc[i-window_size:i]\n",
        "          y_train_window = y.iloc[i-window_size:i]\n",
        "          X_test_window = X.iloc[[i]]\n",
        "          y_test_window = y.iloc[[i]]\n",
        "\n",
        "          # Loop through each model, fit, predict, and store accuracies\n",
        "          for name, model in models.items():\n",
        "              # Check if the training window contains at least 2 unique classes\n",
        "              if len(np.unique(y_train_window)) < 2:\n",
        "                  print(f\"Skipping model {name} for timestamp {test_date} due to only one class in training window.\")\n",
        "                  rolling_accuracies[name].append(np.nan)\n",
        "                  pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "                  pred_true[name]['y_pred'].append(None)\n",
        "                  continue\n",
        "\n",
        "              model.fit(X_train_window, y_train_window)\n",
        "              y_pred = model.predict(X_test_window)\n",
        "              acc = accuracy_score(y_test_window, y_pred)\n",
        "              rolling_accuracies[name].append(acc)\n",
        "              pred_true[name]['y_true'].append(y_test_window.values[0])\n",
        "              pred_true[name]['y_pred'].append(y_pred[0])\n",
        "\n",
        "      # Compute overall average rolling window accuracy for each model\n",
        "      # Use np.nanmean to ignore NaN values\n",
        "      avg_accuracies = {name: np.nanmean(rolling_accuracies[name]) if rolling_accuracies[name] else 0\n",
        "                        for name in models}\n",
        "\n",
        "      # Build a result row for overall accuracy\n",
        "      overall_row = {\n",
        "          \"Training Window (months)\": window_size,\n",
        "          \"RandomForest\": f\"{avg_accuracies['RandomForest']*100:.2f}%\" if not np.isnan(avg_accuracies['RandomForest']) else \"N/A\",\n",
        "          \"GradientBoosting\": f\"{avg_accuracies['GradientBoosting']*100:.2f}%\" if not np.isnan(avg_accuracies['GradientBoosting']) else \"N/A\",\n",
        "          \"LogisticRegression\": f\"{avg_accuracies['LogisticRegression']*100:.2f}%\" if not np.isnan(avg_accuracies['LogisticRegression']) else \"N/A\",\n",
        "          \"SVC_linear\": f\"{avg_accuracies['SVC_linear']*100:.2f}%\" if not np.isnan(avg_accuracies['SVC_linear']) else \"N/A\",\n",
        "          \"SVC_rbf\": f\"{avg_accuracies['SVC_rbf']*100:.2f}%\" if not np.isnan(avg_accuracies['SVC_rbf']) else \"N/A\"\n",
        "      }\n",
        "      overall_results.append(overall_row)\n",
        "\n",
        "      # For each regime, compute regime-specific accuracy per model from the predictions made in this run\n",
        "      for reg in unique_regimes:\n",
        "          regime_acc = {}\n",
        "          for name in models:\n",
        "              # Filter predictions for the current regime (using true labels)\n",
        "              y_true_reg = [yt for yt in pred_true[name]['y_true'] if yt == reg]\n",
        "              y_pred_reg = [yp for yt, yp in zip(pred_true[name]['y_true'], pred_true[name]['y_pred']) if yt == reg]\n",
        "              if len(y_true_reg) > 0:\n",
        "                  acc_reg = np.mean(np.array(y_true_reg) == np.array(y_pred_reg))\n",
        "              else:\n",
        "                  acc_reg = np.nan\n",
        "              regime_acc[name] = acc_reg\n",
        "\n",
        "          # Build a row for this regime and training window\n",
        "          regime_row = {\"Training Window (months)\": window_size}\n",
        "          for name in models:\n",
        "              regime_row[name] = f\"{regime_acc[name]*100:.2f}%\" if not np.isnan(regime_acc[name]) else \"N/A\"\n",
        "          regime_results[reg].append(regime_row)\n",
        "\n",
        "      print(f\"Completed training window = {window_size} months\")\n",
        "      print(\"=\"*50)\n",
        "\n",
        "  # Display overall results table\n",
        "  df_overall = pd.DataFrame(overall_results)\n",
        "  print(\"Overall Rolling Window Average Accuracy:\")\n",
        "  display(HTML(df_overall.to_html(index=False)))\n",
        "\n",
        "  # Now display separate tables for each regime\n",
        "  for reg in unique_regimes:\n",
        "      df_regime = pd.DataFrame(regime_results[reg])\n",
        "      print(f\"\\nRolling Window Accuracy for Regime {reg}:\")\n",
        "      display(HTML(df_regime.to_html(index=False)))\n",
        "\n",
        "  # Optionally, you can also compute and display confusion matrices per model if desired.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vp7FA1IRumLl",
        "outputId": "aaa3c85d-6594-4e27-da26-52fd5b9330ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Running rolling window evaluation with training window of 12 months\n",
            "Skipping model RandomForest for timestamp 2004-03-31 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2004-03-31 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2004-03-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2004-03-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2004-03-31 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2004-04-30 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2004-04-30 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2004-04-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2004-04-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2004-04-30 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2013-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2013-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2013-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2013-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2013-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2013-08-30 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2013-08-30 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2013-08-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2013-08-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2013-08-30 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2015-05-29 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2015-05-29 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2015-05-29 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2015-05-29 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2015-05-29 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2015-06-30 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2015-06-30 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2015-06-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2015-06-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2015-06-30 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2015-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2015-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2015-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2015-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2015-07-31 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2015-08-31 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2015-08-31 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2015-08-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2015-08-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2015-08-31 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2017-12-29 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2017-12-29 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2017-12-29 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2017-12-29 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2017-12-29 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2018-01-31 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2018-01-31 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2018-01-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2018-01-31 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2018-01-31 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2018-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2018-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2018-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2018-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2018-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2018-03-30 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2018-03-30 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2018-03-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2018-03-30 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2018-03-30 00:00:00 due to only one class in training window.\n",
            "Skipping model RandomForest for timestamp 2020-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model GradientBoosting for timestamp 2020-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model LogisticRegression for timestamp 2020-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_linear for timestamp 2020-02-28 00:00:00 due to only one class in training window.\n",
            "Skipping model SVC_rbf for timestamp 2020-02-28 00:00:00 due to only one class in training window.\n",
            "Completed training window = 12 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 24 months\n",
            "Completed training window = 24 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 36 months\n",
            "Completed training window = 36 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 48 months\n",
            "Completed training window = 48 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 60 months\n",
            "Completed training window = 60 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 72 months\n",
            "Completed training window = 72 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 84 months\n",
            "Completed training window = 84 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 96 months\n",
            "Completed training window = 96 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 108 months\n",
            "Completed training window = 108 months\n",
            "==================================================\n",
            "==================================================\n",
            "Running rolling window evaluation with training window of 120 months\n",
            "Completed training window = 120 months\n",
            "==================================================\n",
            "Overall Rolling Window Average Accuracy:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Training Window (months)</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>SVC_linear</th>\n",
              "      <th>SVC_rbf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>66.77%</td>\n",
              "      <td>60.65%</td>\n",
              "      <td>64.52%</td>\n",
              "      <td>63.55%</td>\n",
              "      <td>60.65%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>63.67%</td>\n",
              "      <td>59.16%</td>\n",
              "      <td>63.67%</td>\n",
              "      <td>65.92%</td>\n",
              "      <td>63.02%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>64.88%</td>\n",
              "      <td>58.86%</td>\n",
              "      <td>65.89%</td>\n",
              "      <td>64.21%</td>\n",
              "      <td>61.87%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>64.46%</td>\n",
              "      <td>62.02%</td>\n",
              "      <td>66.90%</td>\n",
              "      <td>64.81%</td>\n",
              "      <td>62.72%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>66.91%</td>\n",
              "      <td>62.18%</td>\n",
              "      <td>69.09%</td>\n",
              "      <td>68.73%</td>\n",
              "      <td>66.55%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>68.44%</td>\n",
              "      <td>60.84%</td>\n",
              "      <td>67.68%</td>\n",
              "      <td>68.82%</td>\n",
              "      <td>65.40%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>64.94%</td>\n",
              "      <td>63.75%</td>\n",
              "      <td>68.13%</td>\n",
              "      <td>67.73%</td>\n",
              "      <td>64.94%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>67.36%</td>\n",
              "      <td>61.51%</td>\n",
              "      <td>67.78%</td>\n",
              "      <td>68.20%</td>\n",
              "      <td>63.60%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>67.40%</td>\n",
              "      <td>67.84%</td>\n",
              "      <td>69.60%</td>\n",
              "      <td>69.60%</td>\n",
              "      <td>63.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>67.44%</td>\n",
              "      <td>65.58%</td>\n",
              "      <td>70.23%</td>\n",
              "      <td>68.84%</td>\n",
              "      <td>65.58%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rolling Window Accuracy for Regime 0.0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Training Window (months)</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>SVC_linear</th>\n",
              "      <th>SVC_rbf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>75.00%</td>\n",
              "      <td>67.00%</td>\n",
              "      <td>77.50%</td>\n",
              "      <td>75.00%</td>\n",
              "      <td>73.50%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>78.95%</td>\n",
              "      <td>70.00%</td>\n",
              "      <td>82.11%</td>\n",
              "      <td>83.16%</td>\n",
              "      <td>84.74%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>79.67%</td>\n",
              "      <td>69.78%</td>\n",
              "      <td>84.62%</td>\n",
              "      <td>81.87%</td>\n",
              "      <td>86.26%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>79.21%</td>\n",
              "      <td>73.60%</td>\n",
              "      <td>85.96%</td>\n",
              "      <td>83.71%</td>\n",
              "      <td>87.64%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>79.55%</td>\n",
              "      <td>75.00%</td>\n",
              "      <td>86.36%</td>\n",
              "      <td>86.93%</td>\n",
              "      <td>91.48%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>83.43%</td>\n",
              "      <td>73.37%</td>\n",
              "      <td>86.98%</td>\n",
              "      <td>88.17%</td>\n",
              "      <td>92.31%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>80.62%</td>\n",
              "      <td>78.12%</td>\n",
              "      <td>88.12%</td>\n",
              "      <td>88.75%</td>\n",
              "      <td>91.88%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>82.89%</td>\n",
              "      <td>73.03%</td>\n",
              "      <td>86.84%</td>\n",
              "      <td>88.82%</td>\n",
              "      <td>90.79%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>81.94%</td>\n",
              "      <td>81.25%</td>\n",
              "      <td>88.89%</td>\n",
              "      <td>88.19%</td>\n",
              "      <td>90.28%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>81.88%</td>\n",
              "      <td>78.26%</td>\n",
              "      <td>89.86%</td>\n",
              "      <td>90.58%</td>\n",
              "      <td>92.03%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rolling Window Accuracy for Regime 1.0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Training Window (months)</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>SVC_linear</th>\n",
              "      <th>SVC_rbf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>46.81%</td>\n",
              "      <td>44.68%</td>\n",
              "      <td>35.11%</td>\n",
              "      <td>38.30%</td>\n",
              "      <td>37.23%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>37.23%</td>\n",
              "      <td>41.49%</td>\n",
              "      <td>32.98%</td>\n",
              "      <td>37.23%</td>\n",
              "      <td>30.85%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>42.22%</td>\n",
              "      <td>44.44%</td>\n",
              "      <td>37.78%</td>\n",
              "      <td>34.44%</td>\n",
              "      <td>24.44%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>38.82%</td>\n",
              "      <td>45.88%</td>\n",
              "      <td>31.76%</td>\n",
              "      <td>30.59%</td>\n",
              "      <td>23.53%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>43.59%</td>\n",
              "      <td>39.74%</td>\n",
              "      <td>34.62%</td>\n",
              "      <td>32.05%</td>\n",
              "      <td>23.08%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>40.54%</td>\n",
              "      <td>37.84%</td>\n",
              "      <td>29.73%</td>\n",
              "      <td>29.73%</td>\n",
              "      <td>17.57%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>36.62%</td>\n",
              "      <td>38.03%</td>\n",
              "      <td>29.58%</td>\n",
              "      <td>28.17%</td>\n",
              "      <td>19.72%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>38.81%</td>\n",
              "      <td>43.28%</td>\n",
              "      <td>31.34%</td>\n",
              "      <td>29.85%</td>\n",
              "      <td>19.40%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>41.27%</td>\n",
              "      <td>46.03%</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>36.51%</td>\n",
              "      <td>19.05%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>42.11%</td>\n",
              "      <td>47.37%</td>\n",
              "      <td>28.07%</td>\n",
              "      <td>26.32%</td>\n",
              "      <td>22.81%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rolling Window Accuracy for Regime 2.0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Training Window (months)</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>SVC_linear</th>\n",
              "      <th>SVC_rbf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>44.83%</td>\n",
              "      <td>41.38%</td>\n",
              "      <td>41.38%</td>\n",
              "      <td>37.93%</td>\n",
              "      <td>20.69%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>48.15%</td>\n",
              "      <td>44.44%</td>\n",
              "      <td>40.74%</td>\n",
              "      <td>44.44%</td>\n",
              "      <td>22.22%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>40.74%</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>44.44%</td>\n",
              "      <td>22.22%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>45.83%</td>\n",
              "      <td>33.33%</td>\n",
              "      <td>50.00%</td>\n",
              "      <td>45.83%</td>\n",
              "      <td>16.67%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>47.62%</td>\n",
              "      <td>38.10%</td>\n",
              "      <td>52.38%</td>\n",
              "      <td>52.38%</td>\n",
              "      <td>19.05%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>50.00%</td>\n",
              "      <td>15.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>10.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>35.00%</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>5.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>45.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>5.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>30.00%</td>\n",
              "      <td>55.00%</td>\n",
              "      <td>40.00%</td>\n",
              "      <td>5.00%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if DL == True:\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")  # Suppress warnings\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential, Model\n",
        "    from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "    import xgboost as xgb\n",
        "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # Define the experiment function with remapping of training labels if needed\n",
        "    def run_experiment(training_window, seq_len,\n",
        "                       lstm_units_first=128, lstm_units_second=32, dropout_rate=0.3,\n",
        "                       xgb_n_estimators=100, xgb_max_depth=4, xgb_learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Runs the rolling-window hybrid (LSTM + XGBoost) experiment using a given training_window (in months)\n",
        "        and a sequence length (seq_len). If the training labels do not form a contiguous set starting at 0,\n",
        "        they are remapped. Returns overall accuracy, total number of predictions, and regime-specific accuracies.\n",
        "        \"\"\"\n",
        "        all_preds = []   # To store predictions\n",
        "        all_true = []    # To store true regime labels\n",
        "\n",
        "        # Ensure data is sorted by date\n",
        "        data = input_df.sort_values(DATE).reset_index(drop=True)\n",
        "\n",
        "        # Rolling window: iterate from index=training_window to end of data\n",
        "        for i in range(training_window, len(data)):\n",
        "            # Use the previous 'training_window' months as training data\n",
        "            train_window = data.iloc[i - training_window:i].reset_index(drop=True)\n",
        "            if len(train_window) < training_window:\n",
        "                continue\n",
        "\n",
        "            # Generate overlapping sequences of length 'seq_len' within the training window\n",
        "            X_train_sequences = []\n",
        "            y_train = []\n",
        "            for j in range(len(train_window) - seq_len + 1):\n",
        "                seq = train_window[FEATURES].iloc[j : j + seq_len].values\n",
        "                target = train_window[TRUE_REGIME].iloc[j + seq_len - 1]  # regime at end of sequence\n",
        "                X_train_sequences.append(seq)\n",
        "                y_train.append(target)\n",
        "            X_train_sequences = np.array(X_train_sequences)  # shape: (num_samples, seq_len, num_features)\n",
        "            y_train = np.array(y_train)\n",
        "\n",
        "            # Remap training labels to contiguous integers starting at 0 if needed.\n",
        "            unique_classes = np.unique(y_train)\n",
        "            mapping = {old: new for new, old in enumerate(unique_classes)}\n",
        "            inverse_mapping = {v: k for k, v in mapping.items()}\n",
        "            y_train_mapped = np.array([mapping[val] for val in y_train])\n",
        "\n",
        "            # Build the LSTM feature extractor using an explicit Input layer\n",
        "            input_layer = Input(shape=(seq_len, len(FEATURES)))\n",
        "            lstm_out = LSTM(lstm_units_first, return_sequences=True)(input_layer)\n",
        "            lstm_out = LSTM(lstm_units_second, return_sequences=False)(lstm_out)\n",
        "            dropout_out = Dropout(dropout_rate)(lstm_out)\n",
        "            feature_extractor = Model(inputs=input_layer, outputs=dropout_out)\n",
        "\n",
        "            # Extract features from training sequences\n",
        "            X_train_features = feature_extractor.predict(X_train_sequences, verbose=0)\n",
        "\n",
        "            # Train an XGBoost classifier on these features using the remapped labels.\n",
        "            clf = xgb.XGBClassifier(\n",
        "                n_estimators=xgb_n_estimators,\n",
        "                max_depth=xgb_max_depth,\n",
        "                learning_rate=xgb_learning_rate,\n",
        "                use_label_encoder=False,\n",
        "                eval_metric='mlogloss'\n",
        "            )\n",
        "            clf.fit(X_train_features, y_train_mapped)\n",
        "\n",
        "            # For prediction, use the last 'seq_len'-month sequence from the training window\n",
        "            X_pred_seq = train_window[FEATURES].iloc[-seq_len:].values.reshape(1, seq_len, len(FEATURES))\n",
        "            X_pred_feature = feature_extractor.predict(X_pred_seq, verbose=0)\n",
        "            pred_mapped = clf.predict(X_pred_feature)[0]\n",
        "            # Map back to original label\n",
        "            pred_regime = inverse_mapping[pred_mapped]\n",
        "\n",
        "            # The true regime for the next month (at time index i)\n",
        "            true_regime = data[TRUE_REGIME].iloc[i]\n",
        "\n",
        "            all_preds.append(pred_regime)\n",
        "            all_true.append(true_regime)\n",
        "\n",
        "        # Compute overall accuracy and total number of predictions\n",
        "        overall_acc = accuracy_score(all_true, all_preds)\n",
        "        total_obs = len(all_preds)\n",
        "\n",
        "        # Compute regime-specific accuracies\n",
        "        regimes = np.unique(all_true)\n",
        "        regime_accuracies = {}\n",
        "        for r in regimes:\n",
        "            indices = [idx for idx, val in enumerate(all_true) if val == r]\n",
        "            if len(indices) > 0:\n",
        "                correct = sum(1 for idx in indices if all_preds[idx] == all_true[idx])\n",
        "                regime_acc = correct / len(indices)\n",
        "                regime_accuracies[r] = regime_acc\n",
        "            else:\n",
        "                regime_accuracies[r] = np.nan\n",
        "\n",
        "        return {\n",
        "            \"training_window\": training_window,\n",
        "            \"seq_len\": seq_len,\n",
        "            \"total_obs\": total_obs,\n",
        "            \"overall_accuracy\": overall_acc,\n",
        "            \"regime_accuracies\": regime_accuracies\n",
        "        }\n",
        "\n",
        "    # Prepare to store experiment results in a list of dictionaries\n",
        "    results = []\n",
        "\n",
        "    # Define training windows from 1 to 10 years (in months) â€“ assume 1 year = 12 months\n",
        "    for tw in range(12, 121, 12):  # 12, 24, ..., 120 months\n",
        "        # Define sequence length percentages: 25%, 50%, 75%, and 100% of training window\n",
        "        for frac in [0.25, 0.5, 0.75, 1.0]:\n",
        "            seq = int(round(tw * frac))\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Running experiment with training_window = {tw} months and seq_len = {seq} months\")\n",
        "            res = run_experiment(training_window=tw, seq_len=seq)\n",
        "            # Build a result row that includes run parameters and accuracies\n",
        "            row = {\n",
        "                \"Training Window (months)\": tw,\n",
        "                \"Seq Length (months)\": seq,\n",
        "                \"Total Observations\": res[\"total_obs\"],\n",
        "                \"Overall Accuracy\": f\"{res['overall_accuracy']*100:.2f}%\",\n",
        "                \"Accuracy Regime 0\": f\"{res['regime_accuracies'].get(0, np.nan)*100:.2f}%\" if 0 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 1\": f\"{res['regime_accuracies'].get(1, np.nan)*100:.2f}%\" if 1 in res[\"regime_accuracies\"] else \"N/A\",\n",
        "                \"Accuracy Regime 2\": f\"{res['regime_accuracies'].get(2, np.nan)*100:.2f}%\" if 2 in res[\"regime_accuracies\"] else \"N/A\"\n",
        "            }\n",
        "            results.append(row)\n",
        "            print(\"=\"*50)\n",
        "\n",
        "    # Convert results to a DataFrame and display as an HTML table\n",
        "    df_results = pd.DataFrame(results)\n",
        "    display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "DoyxwlWcFY1z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to a DataFrame and display as an HTML table\n",
        "df_results = pd.DataFrame(results)\n",
        "display(HTML(df_results.to_html(index=False)))\n"
      ],
      "metadata": {
        "id": "aFjKoZBkmOQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "091af9c3-10e1-4ef8-977a-595efb15abbe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-712872e5cbed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert results to a DataFrame and display as an HTML table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    }
  ]
}